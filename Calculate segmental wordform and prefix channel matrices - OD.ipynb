{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.066145Z",
     "start_time": "2019-09-12T01:27:50.060984Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Requirements</a></span></li><li><span><a href=\"#Usage\" data-toc-modified-id=\"Usage-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Usage</a></span></li></ul></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#numpy-/-pytorch-representations\" data-toc-modified-id=\"numpy-/-pytorch-representations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span><code>numpy</code> / <code>pytorch</code> representations</a></span></li><li><span><a href=\"#Calculation-and-Export\" data-toc-modified-id=\"Calculation-and-Export-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Calculation and Export</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions-for-a-single-prefix-or-wordform\" data-toc-modified-id=\"Functions-for-a-single-prefix-or-wordform-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Functions for a single prefix or wordform</a></span></li><li><span><a href=\"#Functions-for-calculating-CMs-for-all-prefixes-of-a-given-length-(in-batches)\" data-toc-modified-id=\"Functions-for-calculating-CMs-for-all-prefixes-of-a-given-length-(in-batches)-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Functions for calculating CMs for all prefixes of a given length (in batches)</a></span></li><li><span><a href=\"#Functions-for-calculating-CMs-for-all-wordforms-of-a-given-length-(in-batches)\" data-toc-modified-id=\"Functions-for-calculating-CMs-for-all-wordforms-of-a-given-length-(in-batches)-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Functions for calculating CMs for all wordforms of a given length (in batches)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given\n",
    " - a filepath to a triphone channel model $c$\n",
    " - a filepath $w$ to a `.json` file specifying a conditional distribution $p(W|V)$ on segmental wordforms given orthographic ones\n",
    " - an output filepath prefix $o$\n",
    " - an optional filepath $p$ to a `.json` file specifying a 'preview' channel distribution to be included in calculated channel matrices.\n",
    "\n",
    "this notebook calculates a channel matrix for each source prefix and writes these channel matrices to file (with prefix given by $o$), with each file corresponding to a block of source prefixes of the same length. Within a block, the ordering of source prefixes/wordforms is given by alphabetically sorting the relevant set of prefixes (or just full wordforms, if $f$).\n",
    "\n",
    "#FIXME update to reflect other exports (including the channel matrix stacks acccctually used in subsequent notebooks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `numpy`\n",
    " - `pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.112627Z",
     "start_time": "2019-09-12T01:27:50.075231Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import getcwd, chdir, listdir, path, mkdir, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.674995Z",
     "start_time": "2019-09-12T01:27:50.115137Z"
    }
   },
   "outputs": [],
   "source": [
    "from boilerplate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.682987Z",
     "start_time": "2019-09-12T01:27:50.678009Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "c = ''\n",
    "# c = 'CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/LTR_Buckeye_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json'\n",
    "# c = \"CM_AmE_destressed_aligned_w_LTR_newdic_destressed_pseudocount0.01/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json\"\n",
    "# c = \"CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json\"\n",
    "# c = \"CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json\"\n",
    "\n",
    "b = ''\n",
    "# b = \"CM_AmE_destressed_aligned_w_LTR_newdic_destressed_pseudocount0.01/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_pC1X012.npy\"\n",
    "# b = 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pC1X012.npy'\n",
    "# b = 'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_pC1X012.npy'\n",
    "\n",
    "w = ''\n",
    "# w = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# w = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# w = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# w = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "\n",
    "o = ''\n",
    "# o = 'CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/LTR_Buckeye_aligned_CM_filtered_LM_filtered_OD'\n",
    "# o = 'CM_AmE_destressed_aligned_w_LTR_newdic_destressed_pseudocount0.01/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_OD'\n",
    "# o = 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_OD'\n",
    "# o = 'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_OD'\n",
    "\n",
    "p = ''\n",
    "## p = 'CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/p3Y1X01.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.698794Z",
     "start_time": "2019-09-12T01:27:50.685032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pC1X012.npy_metadata.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pC1X012Y012s.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_md = b + \"_metadata.json\"\n",
    "b_o = b.split(\".npy\")[0] + \"Y012s.txt\"\n",
    "\n",
    "b_md\n",
    "b_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.708187Z",
     "start_time": "2019-09-12T01:27:50.701698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matrix fp': 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pC1X012.npy',\n",
       " 'matrix shape': [57798, 10540],\n",
       " 'Produced in step': 'Step 4d',\n",
       " 'Produced in notebook': 'Calculate observation distribution given channel models',\n",
       " 'X012s': {'from fp': 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json',\n",
       "  'changes': 'sorted',\n",
       "  'size': 10540},\n",
       " 'Y012s': {'from fp': {'preview': 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_p3Y1X01.json',\n",
       "   'postview': 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_p6Y0X01.json',\n",
       "   'center': 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json'},\n",
       "  'changes': 'sorted',\n",
       "  'exported fp': 'CM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_pC1X012Y012s.txt',\n",
       "  'size': 57798}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importDict(b_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.713420Z",
     "start_time": "2019-09-12T01:27:50.710713Z"
    }
   },
   "outputs": [],
   "source": [
    "ensure_dir_exists(path.dirname(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.718214Z",
     "start_time": "2019-09-12T01:27:50.715082Z"
    }
   },
   "outputs": [],
   "source": [
    "# if p == '':\n",
    "#     r = False\n",
    "# else:\n",
    "#     r = True\n",
    "#     print('Including preview distribution in channel matrix calculations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.726757Z",
     "start_time": "2019-09-12T01:27:50.720607Z"
    }
   },
   "outputs": [],
   "source": [
    "from probdist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:50.731434Z",
     "start_time": "2019-09-12T01:27:50.728939Z"
    }
   },
   "outputs": [],
   "source": [
    "from string_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:51.773167Z",
     "start_time": "2019-09-12T01:27:50.733036Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:51.778860Z",
     "start_time": "2019-09-12T01:27:51.775365Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:51.783712Z",
     "start_time": "2019-09-12T01:27:51.780831Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:51.790784Z",
     "start_time": "2019-09-12T01:27:51.785648Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "J = -1\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def par(gen_expr):\n",
    "    return Parallel(n_jobs=J, backend=BACKEND, verbose=V, prefer=PREFER)(gen_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:52.119156Z",
     "start_time": "2019-09-12T01:27:51.792724Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:52.123362Z",
     "start_time": "2019-09-12T01:27:52.121011Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.128074Z",
     "start_time": "2019-09-12T01:27:52.125083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "TITAN RTX\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "TITAN RTX\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(torch.cuda.get_device_name(1))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(1)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_cached(1)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.134896Z",
     "start_time": "2019-09-12T01:27:53.130045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "my_device = cpu\n",
    "# my_device = gpu\n",
    "torch.cuda.set_device(1)\n",
    "my_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.140614Z",
     "start_time": "2019-09-12T01:27:53.136406Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda_ft = torch.cuda.FloatTensor\n",
    "cuda_dt = torch.cuda.DoubleTensor\n",
    "\n",
    "ft = torch.FloatTensor\n",
    "dt = torch.DoubleTensor\n",
    "\n",
    "my_ft = ft\n",
    "my_dt = dt\n",
    "# my_ft = cuda_ft\n",
    "# my_dt = cuda_dt\n",
    "\n",
    "my_tt = torch.float64\n",
    "\n",
    "torch.set_default_tensor_type(my_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.145725Z",
     "start_time": "2019-09-12T01:27:53.142300Z"
    }
   },
   "outputs": [],
   "source": [
    "testing = False\n",
    "benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.270320Z",
     "start_time": "2019-09-12T01:27:53.147446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G        992M         63G        1.8M        123G        185G\r\n",
      "Swap:           18G         15M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.738437Z",
     "start_time": "2019-09-12T01:27:53.273603Z"
    }
   },
   "outputs": [],
   "source": [
    "p3Y1X012 = condDistsAsProbDists(importProbDist(c))\n",
    "\n",
    "assert uniformOutcomes(p3Y1X012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.748831Z",
     "start_time": "2019-09-12T01:27:53.739915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleRightEdgeTriphs = {x012 for x012 in set(conditions(p3Y1X012)) if rightEdge + '.' + rightEdge in x012}\n",
    "doubleRightEdgeTriphs\n",
    "# assert len(doubleRightEdgeTriphs) == 0\n",
    "\n",
    "if len(doubleRightEdgeTriphs) > 0:\n",
    "    print('Restoring p3Y1X012...')\n",
    "    p3Y1X012 = condProbDistAsDicts(p3Y1X012)\n",
    "    \n",
    "    for x012 in doubleRightEdgeTriphs:\n",
    "        del p3Y1X012[x012]\n",
    "    \n",
    "    for x012 in p3Y1X012:\n",
    "        del p3Y1X012[x012][rightEdge]\n",
    "    \n",
    "    assert areNormalized(p3Y1X012)\n",
    "    assert uniformOutcomes(p3Y1X012)\n",
    "    \n",
    "    p3Y1X012 = condDistsAsProbDists(p3Y1X012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.756092Z",
     "start_time": "2019-09-12T01:27:53.754011Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     p3Y1X01 = condDistsAsProbDists(importProbDist(p))\n",
    "#     assert uniformOutcomes(pY1X01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:53.884563Z",
     "start_time": "2019-09-12T01:27:53.758595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G        1.0G         63G        1.8M        123G        184G\r\n",
      "Swap:           18G         15M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:27:54.022283Z",
     "start_time": "2019-09-12T01:27:53.887920Z"
    }
   },
   "outputs": [],
   "source": [
    "pW_V = condDistsAsProbDists(importProbDist(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:06.624363Z",
     "start_time": "2019-09-12T01:27:54.023607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Wordforms| = 30833\n",
      "Restoring lexicon...\n",
      "|Prefixes| = 98570\n",
      "|triphones| in lexicon = 10540\n"
     ]
    }
   ],
   "source": [
    "#extract segmental wordforms from w\n",
    "Ws = union(list(map(lambda d: set(conditions(d)), \n",
    "                    pW_V.values())))\n",
    "Ws_t = tuple(sorted(list(Ws)))\n",
    "print(f'|Wordforms| = {len(Ws)}')\n",
    "\n",
    "if rightEdge + '.' + rightEdge in lexiconTo2factors(Ws):\n",
    "    print('Restoring lexicon...')\n",
    "    \n",
    "    def restoreWordform(w):\n",
    "        w_t = ds2t(w)\n",
    "        assert w_t[-1] == rightEdge and w_t[-2] == rightEdge\n",
    "        w_t = w_t[:-1]\n",
    "        return t2ds(w_t)\n",
    "    \n",
    "    Ws = set(map(restoreWordform, Ws))\n",
    "    Ws_t = tuple(sorted(list(Ws)))\n",
    "\n",
    "#extract prefixes from w\n",
    "Ps = union(map(getPrefixes, Ws))\n",
    "prefixes = Ps\n",
    "print(f'|Prefixes| = {len(Ps)}')\n",
    "Ps_t = tuple(sorted(list(Ps)))\n",
    "prefixes_t = Ps_t\n",
    "\n",
    "#extract inventory from w\n",
    "Xs = lexiconToInventory(Ws)\n",
    "    \n",
    "#extract triphones from w\n",
    "lexiconTriphones = lexiconTo3factors(Ws)\n",
    "print(f'|triphones| in lexicon = {len(lexiconTriphones)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:06.752299Z",
     "start_time": "2019-09-12T01:29:06.625881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G        1.0G         63G        1.8M        123G        184G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "del pW_V\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:06.775686Z",
     "start_time": "2019-09-12T01:29:06.755555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|triphones| in channel model = 10540\n",
      "|Y1s| = 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract triphones from c\n",
    "channelTriphones = set(p3Y1X012.keys())\n",
    "\n",
    "print(f'|triphones| in channel model = {len(channelTriphones)}')\n",
    "\n",
    "X012s = channelTriphones\n",
    "X012s_t = tuple(sorted(list(X012s)))\n",
    "\n",
    "#extract response phones\n",
    "Y1s = outcomes(p3Y1X012)\n",
    "Y1s_t = tuple(sorted(list(Y1s)))\n",
    "print(f'|Y1s| = {len(Y1s)}')\n",
    "\n",
    "leftEdge in Y1s\n",
    "rightEdge in Y1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:06.783980Z",
     "start_time": "2019-09-12T01:29:06.777435Z"
    }
   },
   "outputs": [],
   "source": [
    "assert all({triph in channelTriphones for triph in lexiconTriphones})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:11.726455Z",
     "start_time": "2019-09-12T01:29:06.786768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57798, 10540)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.87352736"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "57798"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pC1X012_np = np.load(b)\n",
    "pC1X012_np.shape\n",
    "pC1X012_np.nbytes / 1e9\n",
    "\n",
    "pC1X012_torch = torch.tensor(pC1X012_np)\n",
    "\n",
    "Y012s_t = importSeqs(b_o, tuple)\n",
    "Y012s = set(Y012s_t)\n",
    "len(Y012s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:11.917469Z",
     "start_time": "2019-09-12T01:29:11.727887Z"
    }
   },
   "outputs": [],
   "source": [
    "assert pC1X012_np.shape[0] == len(Y012s)\n",
    "assert pC1X012_np.shape[1] == len(X012s)\n",
    "assert lexiconToInventory(Y012s) - edgeSymbols == Y1s\n",
    "assert tuple(sorted(list(Y012s))) == Y012s_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:11.926266Z",
     "start_time": "2019-09-12T01:29:11.919295Z"
    }
   },
   "outputs": [],
   "source": [
    "def pC1X012_calc(y012=None, x012=None, asType = 'ndarray'):\n",
    "    if y012 is None:\n",
    "        if asType == 'ndarray':\n",
    "            return pC1X012_np[:, X012s_t.index(x012)]\n",
    "        elif asType == 'torch':\n",
    "            return torch.from_numpy(pC1X012_np[:, X012s_t.index(x012)])\n",
    "        elif asType == 'dict':\n",
    "            return {y012:pC1X012_np[Y012s_t.index(y012), X012s_t.index(x012)]\n",
    "                    for y012 in y012s_t}\n",
    "        else:\n",
    "            raise Exception(\"Acceptable asType arguments = {'dict', 'ndarray', 'torch'}\")\n",
    "    if x012 is None:\n",
    "        if asType == 'ndarray':\n",
    "            return pC1X012_np[Y012s_t.index(y012),:]\n",
    "        elif asType == 'torch':\n",
    "            return torch.from_numpy(pC1X012_np[Y012s_t.index(y012),:])\n",
    "        else:\n",
    "            raise Exception(\"Acceptable asType arguments = {'ndarray', 'torch'}\")\n",
    "    return pC1X012_np[Y012s_t.index(y012), X012s_t.index(x012)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:11.930836Z",
     "start_time": "2019-09-12T01:29:11.928084Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     channelDiphones = set(p3Y1X01.keys())\n",
    "#     print(f'|X012s| in channel model = {len(channelDiphones)}')\n",
    "    \n",
    "#     lexiconDiphones = lexiconTo2factors(Ws)\n",
    "#     unmodelableLexiconDiphones = {diph for diph in lexiconDiphones if diph not in channelDiphones}\n",
    "#     print(f'unmodelable lexicon diphones = \\n{unmodelableLexiconDiphones}')\n",
    "#     assert all({diph in channelDiphones for diph in lexiconDiphones if ds2t(diph)[0] != leftEdge and ds2t(diph)[1] != rightEdge})\n",
    "#     print(f'|X012s| in lexicon = {len(lexiconDiphones)}')\n",
    "    \n",
    "#     X01s = lexiconDiphones\n",
    "#     assert outcomes(p3Y1X01) == Y1s\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no gating trials that bear on $p(Y_{i+1}|X_i; X_{i+1} = ⋉)$, but a reasonable assumption is that there are plenty of good acoustic cues that any given segment $X_i$ is the end of the word (i.e. that $X_{i+1} = ⋉$) given the context of an isolated word recognition task, and that there are plenty of good acoustic cues that any given segment is NOT the end of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:11.935688Z",
     "start_time": "2019-09-12T01:29:11.932410Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     p3Y1X01 = condProbDistAsDicts(p3Y1X01)\n",
    "    \n",
    "#     # add ⋉ to the outcomes of every existing conditioning outcome\n",
    "#     for x01 in p3Y1X01:\n",
    "#         p3Y1X01[x01].update({rightEdge:0.0})\n",
    "\n",
    "#     # create new conditioning events\n",
    "#     wordEndDiphones = {x + '.' + rightEdge for x in Xs}\n",
    "#     list(wordEndDiphones)[:5]\n",
    "\n",
    "#     # create their distribution over outcomes\n",
    "#     deltaDist = {y1:0.0 for y1 in Y1s}\n",
    "#     deltaDist.update({rightEdge:1.0})\n",
    "\n",
    "#     # add the new wordend conditioning events to the preview distribution\n",
    "#     p3Y1X01.update({wordEnd:deltaDist for wordEnd in wordEndDiphones})\n",
    "#     p3Y1X01['aʊ.s']['s']\n",
    "#     p3Y1X01['ɑ.⋉']\n",
    "\n",
    "#     # check that everything worked\n",
    "#     for x01 in p3Y1X01:\n",
    "#         assert rightEdge in p3Y1X01[x01]\n",
    "#     #     if rightEdge not in p3Y1X01[x01]:\n",
    "#     #         p3Y1X01[x01][rightEdge] = 0.0\n",
    "\n",
    "#     assert areNormalized(p3Y1X01)\n",
    "#     assert uniformOutcomes(p3Y1X01)\n",
    "\n",
    "#     channelDiphones = set(p3Y1X01.keys())\n",
    "\n",
    "#     unmodelableLexiconDiphones = {diph for diph in lexiconDiphones if diph not in channelDiphones}\n",
    "#     print(f'unmodelable lexicon diphones = \\n{unmodelableLexiconDiphones}')\n",
    "#     assert all({diph in channelDiphones for diph in lexiconDiphones if ds2t(diph)[0] != leftEdge and ds2t(diph)[1] != rightEdge})\n",
    "    \n",
    "#     #we'll worry about left-edge initial diphones later\n",
    "    \n",
    "#     # let's trim the preview model's conditioning events\n",
    "#     p3Y1X01 = {x01:p3Y1X01[x01] for x01 in p3Y1X01 if x01 in lexiconDiphones}\n",
    "    \n",
    "#     p3Y1X01 = condDistsAsProbDists(p3Y1X01)\n",
    "    \n",
    "#     X01s_RE = set(p3Y1X01.keys())\n",
    "#     len(X01s_RE)\n",
    "    \n",
    "# #     print(X01s_RE - X01s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `numpy` / `pytorch` representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.263905Z",
     "start_time": "2019-09-12T01:29:11.937299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.272498Z",
     "start_time": "2019-09-12T01:29:12.267184Z"
    }
   },
   "outputs": [],
   "source": [
    "Xmap = seqsToIndexMap(Xs)\n",
    "XOHmap = seqsToOneHotMap(Xs)\n",
    "# XOHmap_torch = {k:torch.tensor(XOHmap[k])\n",
    "#                 for k in XOHmap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.331175Z",
     "start_time": "2019-09-12T01:29:12.274738Z"
    }
   },
   "outputs": [],
   "source": [
    "X012map = seqsToIndexMap(X012s)\n",
    "# X012OHs = seqMapToOneHots(X012map)\n",
    "X012OHmap = seqsToOneHotMap(X012s)\n",
    "# X012OHmap_torch = {k:torch.tensor(X012OHmap[k])\n",
    "#                    for k in X012OHmap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.336099Z",
     "start_time": "2019-09-12T01:29:12.333116Z"
    }
   },
   "outputs": [],
   "source": [
    "Y1map = seqsToIndexMap(Y1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.418365Z",
     "start_time": "2019-09-12T01:29:12.338078Z"
    }
   },
   "outputs": [],
   "source": [
    "Y012map = seqsToIndexMap(Y012s)\n",
    "# Y012OHmap = seqsToOneHotMap(Y012s)\n",
    "# Y012OHmap_torch = {k:torch.tensor(Y012OHmap[k])\n",
    "#                    for k in Y012OHmap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.422899Z",
     "start_time": "2019-09-12T01:29:12.420372Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     X01REmap = seqsToIndexMap(X01s_RE)\n",
    "#     X01REOHs = seqMapToOneHots(X01REmap)\n",
    "#     X01REOHmap = seqsToOneHotMap(X01s_RE)\n",
    "    \n",
    "#     Y1s_RE = outcomes(p3Y1X01)\n",
    "#     len(Y1s_RE)\n",
    "#     Y1s_RE_list = sorted(list(Y1s_RE))\n",
    "\n",
    "#     print(Y1s_RE - Y1s)\n",
    "\n",
    "#     Y1REmap = seqsToIndexMap(Y1s_RE)\n",
    "\n",
    "#     Y1REOHs = seqMapToOneHots(Y1REmap)\n",
    "#     Y1REOHmap = seqsToOneHotMap(Y1s_RE)\n",
    "#     OHY1REmap = oneHotToSeqMap(Y1s_RE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `r` is `True`, then to ensure uniformity of event spaces between the triphone channel distribution and the preview distribution, we'll add a $⋉$ outcome (with probability 0.0) to each conditional distribution in the triphone channel distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.429447Z",
     "start_time": "2019-09-12T01:29:12.424732Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     for x012 in p3Y1X012:\n",
    "#         p3Y1X012[x012].update({rightEdge:0.0})\n",
    "#         assert rightEdge in p3Y1X012[x012]\n",
    "#         assert p3Y1X012[x012][rightEdge] == 0.0\n",
    "\n",
    "#     outcomes(p3Y1X012) == Y1s\n",
    "#     outcomes(p3Y1X012) == Y1s_RE\n",
    "#     areNormalized(p3Y1X012)\n",
    "#     uniformOutcomes(p3Y1X012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.516609Z",
     "start_time": "2019-09-12T01:29:12.431404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  9,  6, 12])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('t.i.f', 'i.f.l')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([5459, 2190])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2, 10540)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10540,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dsToUniphoneIndices(ds, uniphoneToIndexMap, asTorch=False):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    if asTorch:\n",
    "        return torch.tensor([uniphoneToIndexMap[uniphone] for uniphone in uniphoneSeq])\n",
    "    return np.array([uniphoneToIndexMap[uniphone] for uniphone in uniphoneSeq])\n",
    "\n",
    "def dsToUniphoneOHs(ds, uniphoneToOHmap, asTorch=False):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    if asTorch:\n",
    "#         return torch.tensor([uniphoneToOHmap[uniphone] for uniphone in uniphoneSeq])\n",
    "        return torch.tensor(np.array([uniphoneToOHmap[uniphone] for uniphone in uniphoneSeq]))\n",
    "    return np.array([uniphoneToOHmap[uniphone] for uniphone in uniphoneSeq])\n",
    "\n",
    "def dsToTriphoneSeq(ds):\n",
    "    return dsToKfactorSequence(3, ds)\n",
    "\n",
    "def dsToTriphoneIndices(ds, triphoneToIndexMap, asTorch=False):\n",
    "    triphoneSeq = dsToTriphoneSeq(ds)\n",
    "    if asTorch:\n",
    "        return torch.tensor(np.array([triphoneToIndexMap[triphone] for triphone in triphoneSeq]))\n",
    "    return np.array([triphoneToIndexMap[triphone] for triphone in triphoneSeq])\n",
    "\n",
    "def dsToTriphoneOHs(ds, triphoneToOHmap, asTorch=False):\n",
    "    triphoneSeq = dsToTriphoneSeq(ds)\n",
    "    if asTorch:\n",
    "        return torch.tensor(np.array([triphoneToOHmap[triphone] for triphone in triphoneSeq]))\n",
    "    return np.array([triphoneToOHmap[triphone] for triphone in triphoneSeq])\n",
    "\n",
    "del XOHmap\n",
    "# dsToUniphoneIndices('t.i.f.l', Xmap)\n",
    "# dsToUniphoneOHs('t.i.f.l', XOHmap)\n",
    "# dsToUniphoneOHs('t.i.f.l', XOHmap, True)\n",
    "# del XOHmap\n",
    "# dsToTriphoneSeq('t.i.f.l')\n",
    "# dsToTriphoneIndices('t.i.f.l', X012map)\n",
    "# dsToTriphoneOHs('t.i.f.l', X012OHmap)\n",
    "# dsToTriphoneOHs('t.i.f.l', X012OHmap).shape\n",
    "# dsToTriphoneOHs('t.i.f.l', X012OHmap)[0].shape\n",
    "# dsToTriphoneOHs('t.i.f.l', X012OHmap)[0][5528]\n",
    "# dsToTriphoneOHs('t.i.f.l', X012OHmap)[1][5352]\n",
    "# dsToTriphoneOHs('t.i.f.l', X012OHmap, True)[1][5352]\n",
    "\n",
    "# dsToUniphoneIndices('t.i.b.i', Xmap)\n",
    "# dsToUniphoneOHs('t.i.b.i', XOHmap)\n",
    "# dsToTriphoneSeq('t.i.b.i')\n",
    "# dsToTriphoneIndices('t.i.b.i', X012map)\n",
    "# dsToTriphoneOHs('t.i.b.i', X012OHmap)\n",
    "# dsToTriphoneOHs('t.i.b.i', X012OHmap).shape\n",
    "# dsToTriphoneOHs('t.i.b.i', X012OHmap)[0].shape\n",
    "# dsToTriphoneOHs('t.i.b.i', X012OHmap)[0][5528]\n",
    "# dsToTriphoneOHs('t.i.b.i', X012OHmap)[1][5352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:12.904559Z",
     "start_time": "2019-09-12T01:29:12.518994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.295078Z",
     "start_time": "2019-09-12T01:29:12.908409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 10540)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3Y1X012_np = condDistFamilyToNP(p3Y1X012)\n",
    "# if r:\n",
    "#     testNPcondDist(p3Y1X012_np, X012map, Y1REmap, p3Y1X012)\n",
    "# else:\n",
    "#     testNPcondDist(p3Y1X012_np, X012map, Y1map, p3Y1X012)\n",
    "testNPcondDist(p3Y1X012_np, X012map, Y1map, p3Y1X012)\n",
    "p3Y1X012_np.shape\n",
    "\n",
    "p3Y1X012_torch = torch.tensor(p3Y1X012_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.301406Z",
     "start_time": "2019-09-12T01:29:13.296496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57798, 10540)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([57798, 10540])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pC1X012_np.shape\n",
    "pC1X012_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.306668Z",
     "start_time": "2019-09-12T01:29:13.303174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.87352736"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pC1X012_np.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.322070Z",
     "start_time": "2019-09-12T01:29:13.308077Z"
    }
   },
   "outputs": [],
   "source": [
    "del p3Y1X012\n",
    "# del p3Y1X012_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.673996Z",
     "start_time": "2019-09-12T01:29:13.323374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.681702Z",
     "start_time": "2019-09-12T01:29:13.677595Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     p3Y1X01_np = condDistFamilyToNP(p3Y1X01)\n",
    "#     testNPcondDist(p3Y1X01_np, X01REmap, Y1REmap, p3Y1X01)\n",
    "#     p3Y1X01_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.687588Z",
     "start_time": "2019-09-12T01:29:13.684185Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.697329Z",
     "start_time": "2019-09-12T01:29:13.689663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.s.l.ɪ.ð.ɚ.⋉'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_wordform = choice(list(Ws))\n",
    "random_source_wordform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.713046Z",
     "start_time": "2019-09-12T01:29:13.699258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.d.ɛ.s.t.ɪ.n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_prefix = choice(list(Ps))\n",
    "random_source_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.718517Z",
     "start_time": "2019-09-12T01:29:13.715129Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomPrefix(l, alphabet=Xs):\n",
    "    return randomString(alphabet, l, hasLeftEdge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.725922Z",
     "start_time": "2019-09-12T01:29:13.720517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.s.v.ɑ.dʒ.u.b'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_channel_prefix2 = randomPrefix(len(ds2t(random_source_wordform))-1, alphabet=Y1s)\n",
    "random_channel_prefix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:13.772213Z",
     "start_time": "2019-09-12T01:29:13.727780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.n.ɪ.t.ɪ'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.æ.ɔɪ.ɑ.z'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_source_prefix = getRandomKey(pX0i)\n",
    "random_source_prefix = choice(list(Ps))\n",
    "while ds2t(random_source_prefix)[-1] == rightEdge:\n",
    "#     random_source_prefix = getRandomKey(pX0i)\n",
    "    random_source_prefix = choice(list(Ps))\n",
    "while len(ds2t(random_source_prefix)) > len(ds2t(random_source_wordform)):\n",
    "#     random_source_prefix = getRandomKey(pX0i)\n",
    "    random_source_prefix = choice(list(Ps))\n",
    "random_source_prefix\n",
    "random_channel_prefix = randomPrefix(len(ds2t(random_source_prefix))-1, alphabet=Y1s)\n",
    "random_channel_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.120752Z",
     "start_time": "2019-09-12T01:29:13.773632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.127794Z",
     "start_time": "2019-09-12T01:29:14.124031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t_OH = [dsToTriphoneOHs(x0k, X012OHmap)\n",
    "#            for x0k in Ps_t]\n",
    "\n",
    "# BAD. strangely slow?\n",
    "# Ps_t_np = np.array(list(par(delayed(dsToTriphoneOHs)(x0k, X012OHmap) \n",
    "#                             for x0k in Ps_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.132799Z",
     "start_time": "2019-09-12T01:29:14.130294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t_OH_torch = [torch.tensor(x0k_OH)\n",
    "#                  for x0k_OH in Ps_t_OH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.136976Z",
     "start_time": "2019-09-12T01:29:14.134703Z"
    }
   },
   "outputs": [],
   "source": [
    "#not currently using these...\n",
    "# del Ps_t_OH\n",
    "# del Ps_t_OH_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.550101Z",
     "start_time": "2019-09-12T01:29:14.138797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for a single prefix or wordform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.564151Z",
     "start_time": "2019-09-12T01:29:14.553557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.n.ɪ', 'n.ɪ.t', 'ɪ.t.ɪ')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.n.ɪ.t.ɪ'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sourcePrefixToTriphones(x0k):\n",
    "    xp_t = ds2t(x0k) #\"x prefix\"\n",
    "    \n",
    "#     xi = xp_t[-2] #just-completed segment\n",
    "#     xk = xp_t[-1] #upcoming segment that we only get coarticulatory information about\n",
    "    \n",
    "#     xik_ds = t2ds((xi, xk))\n",
    "#     preview_dist = p3Y1X01[xik_ds]\n",
    "    \n",
    "    x012s = dsToKfactorSequence(3, t2ds(xp_t))\n",
    "    return x012s\n",
    "\n",
    "random_triphoneSeq = sourcePrefixToTriphones(random_source_prefix)\n",
    "random_triphoneSeq\n",
    "threeFactorSequenceToDS(random_triphoneSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.571090Z",
     "start_time": "2019-09-12T01:29:14.565884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10220, 4278, 8521)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sourcePrefixToTriphoneIndices(x0k):\n",
    "    triphoneSequence = sourcePrefixToTriphones(x0k)\n",
    "    return tuple(map(lambda x012: X012map[x012], triphoneSequence))\n",
    "\n",
    "sourcePrefixToTriphoneIndices(random_source_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.578710Z",
     "start_time": "2019-09-12T01:29:14.572961Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah = np.zeros((len(Y1s), 1))\n",
    "blah[-1] = 1.0\n",
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.582937Z",
     "start_time": "2019-09-12T01:29:14.580375Z"
    }
   },
   "outputs": [],
   "source": [
    "# from numba import jit, njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.587637Z",
     "start_time": "2019-09-12T01:29:14.584611Z"
    }
   },
   "outputs": [],
   "source": [
    "# # @njit(parallel=True)\n",
    "# @njit\n",
    "def sourcePrefixStackToChannelMatrix(x0k_OHs):\n",
    "    return pC1X012_np @ x0k_OHs.T\n",
    "#     return np.matmul(pC1X012_np, x0k_OHs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.601511Z",
     "start_time": "2019-09-12T01:29:14.589473Z"
    }
   },
   "outputs": [],
   "source": [
    "def sourcePrefixToChannelMatrix_l(x0k, debug=False):\n",
    "    #if statement below raised from previous location; effect not tested since this function isn't actually called anywhere in this notebook\n",
    "    # NB that non-sensical output is still possible / untested in downstream output where prefixes of length <= 2 are involved.\n",
    "    if x0k == leftEdge or (len(ds2t(x0k)) == 2 and ds2t(x0k)[0] == leftEdge):\n",
    "        raise Exception('This is not well-defined.')\n",
    "#         C = np.zeros((len(Y1s_RE), 1))\n",
    "#         C = np.zeros((len(Y012s), 1))\n",
    "#         C[-1] = 1.0\n",
    "#         return C.reshape(len(Y1s_RE),1)\n",
    "#         return C.reshape(len(Y1s),1)\n",
    "    triphoneOHs = dsToTriphoneOHs(x0k, X012OHmap)\n",
    "    if debug:\n",
    "        print('x0k = {0}'.format(x0k))\n",
    "        print('|x0k| = {0}'.format(len(ds2t(x0k))))\n",
    "        print('triphoneIdxs = {0}'.format(sourcePrefixToTriphoneIndices(x0k)))\n",
    "        print('triphoneOHs.shape = {0}'.format(triphoneOHs.shape))\n",
    "        print('p3Y1X012_np.shape = {0}'.format(p3Y1X012_np.shape))\n",
    "        print('pC1X012_np.shape = {0}'.format(pC1X012_np.shape))\n",
    "#         print('result = p3Y1X012_np * triphoneOHs.T')\n",
    "        print('result = pC1X012_np * triphoneOHs.T')\n",
    "#     result = np.matmul(p3Y1X012_np, triphoneOHs.T)\n",
    "    result = np.matmul(pC1X012_np, triphoneOHs.T)\n",
    "    return result\n",
    "\n",
    "def sourcePrefixToChannelMatrix(x0k):\n",
    "    #if statement below raised from previous location; effect not tested since this function isn't actually called anywhere in this notebook\n",
    "    if x0k == leftEdge or (len(ds2t(x0k)) == 2 and ds2t(x0k)[0] == leftEdge):\n",
    "        raise Exception('This is not well-defined.')\n",
    "#         C = np.zeros((len(Y1s_RE), 1))\n",
    "#         C = np.zeros((len(Y012s), 1))\n",
    "#         C[-1] = 1.0\n",
    "#         return C.reshape(len(Y1s_RE),1)\n",
    "#         return C.reshape(len(Y1s),1)\n",
    "    triphoneIndices = sourcePrefixToTriphoneIndices(x0k)\n",
    "#     C = np.array([[p3Y1X012_np[Y1REmap[y1], x012_idx] for x012_idx in triphoneIndices] for y1 in sorted(Y1s_RE)])\n",
    "#     C = np.array([[p3Y1X012_np[Y1map[y1], x012_idx] \n",
    "#                    for x012_idx in triphoneIndices] \n",
    "#                   for y1 in Y1s_t])\n",
    "    C = np.array([[pC1X012_np[Y012map[y012], x012_idx] \n",
    "               for x012_idx in triphoneIndices] \n",
    "              for y012 in Y012s_t])\n",
    "#     if x0k == leftEdge or (len(ds2t(x0k)) == 2 and ds2t(x0k)[0] == leftEdge):\n",
    "#         raise Exception('This is not well-defined.')\n",
    "# #         C = np.zeros((len(Y1s_RE), 1))\n",
    "# #         C = np.zeros((len(Y012s), 1))\n",
    "# #         C[-1] = 1.0\n",
    "# #         return C.reshape(len(Y1s_RE),1)\n",
    "# #         return C.reshape(len(Y1s),1)\n",
    "    assert len(triphoneIndices) == len(dsToKfactorSequence(3, x0k)), f\"{len(triphoneIndices)} != {len(dsToKfactorSequence(3, x0k))}\\n\\t x0k = {x0k}\\n\\t {dsToKfactorSequence(3, x0k)}\\n\\t {triphoneIndices}\"\n",
    "    assert len(dsToKfactorSequence(3, x0k)) == C.shape[1], f\"{C.shape[1]} != {len(dsToKfactorSequence(3, x0k))}\\n\\t x0f = {wordform}\"\n",
    "    return C\n",
    "\n",
    "\n",
    "# if r:\n",
    "#     def sourcePrefixToChannelMatrix(x0k):\n",
    "#         triphoneIndices = sourcePrefixToTriphoneIndices(x0k)\n",
    "#         C = np.array([[p3Y1X012_np[Y1REmap[y1], x012_idx] for x012_idx in triphoneIndices] for y1 in sorted(Y1s_RE)])\n",
    "#     #     C = np.array([[p3Y1X012_np[Y1map[y1], x012_idx] \n",
    "#     #                    for x012_idx in triphoneIndices] \n",
    "#     #                   for y1 in Y1s_t])\n",
    "#         if x0k == leftEdge or (len(ds2t(x0k)) == 2 and ds2t(x0k)[0] == leftEdge):\n",
    "#             C = np.zeros((len(Y1s_RE), 1))\n",
    "#     #         C = np.zeros((len(Y1s), 1))\n",
    "#             C[-1] = 1.0\n",
    "#             return C.reshape(len(Y1s_RE),1)\n",
    "#     #         return C.reshape(len(Y1s),1)\n",
    "#         return C\n",
    "# else:\n",
    "#     def sourcePrefixToChannelMatrix(x0k):\n",
    "#         triphoneIndices = sourcePrefixToTriphoneIndices(x0k)\n",
    "# #         C = np.array([[p3Y1X012_np[Y1REmap[y1], x012_idx] for x012_idx in triphoneIndices] for y1 in sorted(Y1s_RE)])\n",
    "#         C = np.array([[p3Y1X012_np[Y1map[y1], x012_idx] \n",
    "#                        for x012_idx in triphoneIndices] \n",
    "#                       for y1 in Y1s_t])\n",
    "#         if x0k == leftEdge or (len(ds2t(x0k)) == 2 and ds2t(x0k)[0] == leftEdge):\n",
    "# #             C = np.zeros((len(Y1s_RE), 1))\n",
    "#             C = np.zeros((len(Y1s), 1))\n",
    "#             C[-1] = 1.0\n",
    "# #             return C.reshape(len(Y1s_RE),1)\n",
    "#             return C.reshape(len(Y1s),1)\n",
    "#         assert len(triphoneIndices) == len(dsToKfactorSequence(3, x0k)), f\"{len(triphoneIndices)} != {len(dsToKfactorSequence(3, x0k))}\\n\\t x0k = {x0k}\\n\\t {dsToKfactorSequence(3, x0k)}\\n\\t {triphoneIndices}\"\n",
    "#         assert len(dsToKfactorSequence(3, x0k)) == C.shape[1], f\"{C.shape[1]} != {len(dsToKfactorSequence(3, x0k))}\\n\\t x0f = {wordform}\"\n",
    "#         return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:14.615536Z",
     "start_time": "2019-09-12T01:29:14.603268Z"
    }
   },
   "outputs": [],
   "source": [
    "def sourcePrefixStackToChannelMatrix_t_c(x0k_OHs_tr):\n",
    "#     return pC1X012_torch @ x0k_OHs.t()\n",
    "#     return torch.matmul(pC1X012_torch, x0k_OHs.t())\n",
    "    return torch.matmul(pC1X012_torch_c, x0k_OHs_tr)\n",
    "\n",
    "def sourcePrefixStackToChannelMatrix_t(x0k_OHs_tr):\n",
    "#     return pC1X012_torch @ x0k_OHs.t()\n",
    "#     return torch.matmul(pC1X012_torch, x0k_OHs.t())\n",
    "    return torch.matmul(pC1X012_torch, x0k_OHs_tr)\n",
    "\n",
    "def sourcePrefixStackToChannelMatrix_t_tr(x0k_OHs):\n",
    "#     return pC1X012_torch @ x0k_OHs.t()\n",
    "    return torch.matmul(pC1X012_torch, x0k_OHs.t())\n",
    "#     return torch.matmul(pC1X012_torch, x0k_OHs)\n",
    "\n",
    "def sourcePrefixToChannelMatrix_l_t(x0k, debug=False):\n",
    "    triphoneOHs = dsToTriphoneOHs(x0k, X012OHmap, True)\n",
    "    if debug:\n",
    "        print('x0k = {0}'.format(x0k))\n",
    "        print('|x0k| = {0}'.format(len(ds2t(x0k))))\n",
    "        print('triphoneIdxs = {0}'.format(sourcePrefixToTriphoneIndices(x0k)))\n",
    "        print('triphoneOHs.shape = {0}'.format(triphoneOHs.shape))\n",
    "        print('p3Y1X012_np.shape = {0}'.format(p3Y1X012_np.shape))\n",
    "        print('pC1X012_np.shape = {0}'.format(pC1X012_np.shape))\n",
    "#         print('result = p3Y1X012_np * triphoneOHs.T')\n",
    "        print('result = pC1X012_torch * triphoneOHs.t()')\n",
    "#     result = np.matmul(p3Y1X012_np, triphoneOHs.T)\n",
    "    result = torch.matmul(pC1X012_torch, triphoneOHs.t())\n",
    "    return result\n",
    "\n",
    "def sourcePrefixToChannelMatrix_t(x0k):\n",
    "    #if statement below raised from previous location; effect not tested since this function isn't actually called anywhere in this notebook\n",
    "    if x0k == leftEdge or (len(ds2t(x0k)) == 2 and ds2t(x0k)[0] == leftEdge):\n",
    "        raise Exception('This is not well-defined.')\n",
    "#         C = np.zeros((len(Y1s_RE), 1))\n",
    "#         C = np.zeros((len(Y012s), 1))\n",
    "#         C[-1] = 1.0\n",
    "#         return C.reshape(len(Y1s_RE),1)\n",
    "#         return C.reshape(len(Y1s),1)\n",
    "    triphoneIndices = sourcePrefixToTriphoneIndices(x0k)\n",
    "#     C = np.array([[p3Y1X012_np[Y1REmap[y1], x012_idx] for x012_idx in triphoneIndices] for y1 in sorted(Y1s_RE)])\n",
    "#     C = np.array([[p3Y1X012_np[Y1map[y1], x012_idx] \n",
    "#                    for x012_idx in triphoneIndices] \n",
    "#                   for y1 in Y1s_t])\n",
    "    C = torch.tensor([[pC1X012_torch[Y012map[y012], x012_idx] \n",
    "                       for x012_idx in triphoneIndices] \n",
    "                      for y012 in Y012s_t])\n",
    "    assert len(triphoneIndices) == len(dsToKfactorSequence(3, x0k)), f\"{len(triphoneIndices)} != {len(dsToKfactorSequence(3, x0k))}\\n\\t x0k = {x0k}\\n\\t {dsToKfactorSequence(3, x0k)}\\n\\t {triphoneIndices}\"\n",
    "    assert len(dsToKfactorSequence(3, x0k)) == C.shape[1], f\"{C.shape[1]} != {len(dsToKfactorSequence(3, x0k))}\\n\\t x0f = {wordform}\"\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:15.060094Z",
     "start_time": "2019-09-12T01:29:14.622294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⋊.n.ɪ.t.ɪ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.60742382e-07, 3.48583936e-07],\n",
       "       [0.00000000e+00, 3.60742382e-07, 3.48583936e-07],\n",
       "       [0.00000000e+00, 2.25938650e-06, 3.48583936e-07],\n",
       "       ...,\n",
       "       [4.78438925e-05, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.78438925e-05, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(random_source_prefix)\n",
    "sourcePrefixToChannelMatrix_l(random_source_prefix, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:15.221113Z",
     "start_time": "2019-09-12T01:29:15.062457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⋊.n.ɪ.t.ɪ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 3.6074e-07, 3.4858e-07],\n",
       "        [0.0000e+00, 3.6074e-07, 3.4858e-07],\n",
       "        [0.0000e+00, 2.2594e-06, 3.4858e-07],\n",
       "        ...,\n",
       "        [4.7844e-05, 0.0000e+00, 0.0000e+00],\n",
       "        [4.7844e-05, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(random_source_prefix)\n",
    "sourcePrefixToChannelMatrix_l_t(random_source_prefix, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:15.228485Z",
     "start_time": "2019-09-12T01:29:15.222574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(p3Y1X012_np, dsToTriphoneOHs(random_source_prefix, X012OHmap).T) == p3Y1X012_np @ dsToTriphoneOHs(random_source_prefix, X012OHmap).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:16.090943Z",
     "start_time": "2019-09-12T01:29:15.229943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcePrefixToChannelMatrix_l(random_source_prefix) == sourcePrefixStackToChannelMatrix(dsToTriphoneOHs(random_source_prefix, X012OHmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:17.126206Z",
     "start_time": "2019-09-12T01:29:16.092338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.n.ɪ.t.ɪ'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(57798, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " ...\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "random_source_prefix\n",
    "sourcePrefixToChannelMatrix_l(random_source_prefix).shape\n",
    "print(sourcePrefixToChannelMatrix_l(random_source_prefix) == sourcePrefixToChannelMatrix(random_source_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.048260Z",
     "start_time": "2019-09-12T01:29:17.127462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.n.ɪ.t.ɪ'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(57798, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " ...\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "random_source_prefix\n",
    "sourcePrefixToChannelMatrix_l(random_source_prefix).shape\n",
    "print(sourcePrefixToChannelMatrix_l(random_source_prefix) == sourcePrefixToChannelMatrix(random_source_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.051703Z",
     "start_time": "2019-09-12T01:29:18.049691Z"
    }
   },
   "outputs": [],
   "source": [
    "# from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.202953Z",
     "start_time": "2019-09-12T01:29:18.053041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊',\n",
       " '⋊.aɪ',\n",
       " '⋊.aɪ.b',\n",
       " '⋊.aɪ.b.j',\n",
       " '⋊.aɪ.b.j.u',\n",
       " '⋊.aɪ.b.j.u.p',\n",
       " '⋊.aɪ.b.j.u.p.ɹ',\n",
       " '⋊.aɪ.b.j.u.p.ɹ.oʊ',\n",
       " '⋊.aɪ.b.j.u.p.ɹ.oʊ.f',\n",
       " '⋊.aɪ.b.j.u.p.ɹ.oʊ.f.ʌ')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "98570"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'⋊',\n",
       " '⋊.aɪ',\n",
       " '⋊.aʊ',\n",
       " '⋊.b',\n",
       " '⋊.d',\n",
       " '⋊.dʒ',\n",
       " '⋊.eɪ',\n",
       " '⋊.f',\n",
       " '⋊.g',\n",
       " '⋊.h',\n",
       " '⋊.i',\n",
       " '⋊.j',\n",
       " '⋊.k',\n",
       " '⋊.l',\n",
       " '⋊.m',\n",
       " '⋊.n',\n",
       " '⋊.oʊ',\n",
       " '⋊.p',\n",
       " '⋊.s',\n",
       " '⋊.t',\n",
       " '⋊.tʃ',\n",
       " '⋊.u',\n",
       " '⋊.v',\n",
       " '⋊.w',\n",
       " '⋊.z',\n",
       " '⋊.æ',\n",
       " '⋊.ð',\n",
       " '⋊.ɑ',\n",
       " '⋊.ɔɪ',\n",
       " '⋊.ɚ',\n",
       " '⋊.ɛ',\n",
       " '⋊.ɪ',\n",
       " '⋊.ɹ',\n",
       " '⋊.ʃ',\n",
       " '⋊.ʌ',\n",
       " '⋊.ʒ',\n",
       " '⋊.θ'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_t[:10]\n",
    "len(Ps_t)\n",
    "len({p for p in Ps if len(ds2t(p)) < 3})\n",
    "{p for p in Ps if len(ds2t(p)) < 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.207455Z",
     "start_time": "2019-09-12T01:29:18.204027Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_source_prefixes = choices(tuple({p for p in Ps if len(ds2t(p)) > 2}), k=5000)\n",
    "    random_source_prefixes_OHs = [dsToTriphoneOHs(p, X012OHmap)\n",
    "                                  for p in random_source_prefixes]\n",
    "    random_source_prefixes_OHs_t = [torch.tensor(each) for each in random_source_prefixes_OHs]\n",
    "    random_source_prefixes_OHs_tr_t = [torch.tensor(each).t() for each in random_source_prefixes_OHs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.213121Z",
     "start_time": "2019-09-12T01:29:18.208519Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    sum([torch_nbytes(each)\n",
    "         for each in random_source_prefixes_OHs_tr_t]) / 1e9\n",
    "    # random_source_prefixes_OHs_tr_t\n",
    "    random_source_prefixes_OHs_tr_t_c = [each.cuda() for each in random_source_prefixes_OHs_tr_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.217413Z",
     "start_time": "2019-09-12T01:29:18.214135Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    torch_nbytes(pC1X012_torch) / 1e9\n",
    "    pC1X012_torch_c = pC1X012_torch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.222567Z",
     "start_time": "2019-09-12T01:29:18.218368Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #544ms / cmu+tarski before driver update\n",
    "    #288ms / cmu+tarski\n",
    "    %timeit -n 10 sourcePrefixToChannelMatrix_l(choice(random_source_prefixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.227118Z",
     "start_time": "2019-09-12T01:29:18.223604Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    sourcePrefixToChannelMatrix_l(choice(random_source_prefixes)).nbytes / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.231144Z",
     "start_time": "2019-09-12T01:29:18.228160Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #649ms / cmu+tarski before driver update\n",
    "    #286ms / cmu+tarski\n",
    "    %timeit -n 10 sourcePrefixStackToChannelMatrix(choice(random_source_prefixes_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.236463Z",
     "start_time": "2019-09-12T01:29:18.232157Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #1.11s cmu+tarski before driver update\n",
    "    #116ms cmu+tarski\n",
    "    %timeit -n 10 sourcePrefixStackToChannelMatrix_t_tr(choice(random_source_prefixes_OHs_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.241692Z",
     "start_time": "2019-09-12T01:29:18.238207Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #1.05s cmu+tarski before driver update\n",
    "    #116ms cmu+tarski\n",
    "    %timeit -n 10 sourcePrefixStackToChannelMatrix_t(choice(random_source_prefixes_OHs_tr_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.247282Z",
     "start_time": "2019-09-12T01:29:18.243330Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #run this cell more than once\n",
    "\n",
    "    #57.4𝛍s cmu+tarski before driver update\n",
    "    #37.4𝛍s cmu+tarski\n",
    "    %timeit -n 10 sourcePrefixStackToChannelMatrix_t_c(choice(random_source_prefixes_OHs_tr_t_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.271194Z",
     "start_time": "2019-09-12T01:29:18.248666Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #run this cell more than once\n",
    "    \n",
    "    #203ms cmu+tarski before driver update\n",
    "    #168ms cmu+tarski\n",
    "    %timeit -n 10 sourcePrefixStackToChannelMatrix_t_c(choice(random_source_prefixes_OHs_t).t().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.276411Z",
     "start_time": "2019-09-12T01:29:18.273069Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    pC1X012_torch_c.shape\n",
    "    len(Y012s_t), len(X012s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.281667Z",
     "start_time": "2019-09-12T01:29:18.278318Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rsp_OH_trc = random_source_prefixes_OHs_tr_t_c[0]\n",
    "    rsp_OH_trc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.285742Z",
     "start_time": "2019-09-12T01:29:18.282960Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rsp_OH_CM = sourcePrefixStackToChannelMatrix_t_c(rsp_OH_trc)\n",
    "    rsp_OH_CM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.620938Z",
     "start_time": "2019-09-12T01:29:18.287021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.628625Z",
     "start_time": "2019-09-12T01:29:18.623832Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    del random_source_prefixes_OHs_tr_t_c\n",
    "    del random_source_prefixes\n",
    "    del random_source_prefixes_OHs\n",
    "    del random_source_prefixes_OHs_t\n",
    "    del random_source_prefixes_OHs_tr_t\n",
    "    del pC1X012_torch_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.634641Z",
     "start_time": "2019-09-12T01:29:18.630260Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.952141Z",
     "start_time": "2019-09-12T01:29:18.635901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson learned:** \n",
    " - Load as much onto the cuda device ahead of time as you can afford. Use `torch_nbytes` to determine size ahead of time.\n",
    " - Make functions parameterizable so that they don't depend on some object that isn't on the device.\n",
    " - Break functions down into things cuda can do and stuff on either side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.959565Z",
     "start_time": "2019-09-12T01:29:18.955364Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     def sourcePrefixToPreviewVector(x0k):\n",
    "#         xp_t = ds2t(x0k) #\"x prefix\"\n",
    "\n",
    "#         if len(xp_t) < 2:\n",
    "#             raise Exception('|x0k| must be > 1.')\n",
    "#         if len(xp_t) == 2 and xp_t[0] == leftEdge:\n",
    "#     #         raise Exception(\"There's no gating data that bears on this calculation, nor is it that interesting.\")\n",
    "#             uniformProb = 1.0 / len(Y1s_RE)\n",
    "#             preview_dist = uniformProb * np.ones((len(Y1s_RE), 1))#garbage\n",
    "#             return preview_dist.reshape(len(Y1s_RE),1)\n",
    "\n",
    "#         xi = xp_t[-2] #just-completed segment\n",
    "#         xk = xp_t[-1] #upcoming segment that we only get coarticulatory information about\n",
    "\n",
    "#         xik_ds = t2ds((xi, xk))\n",
    "#         preview_dist = p3Y1X01[xik_ds]\n",
    "#     #     assert Y1s_RE == set(preview_dist.keys()) #comment out once you are reasonably confident this is true by construction\n",
    "\n",
    "#         return np.array([preview_dist[y1] for y1 in sorted(Y1s_RE)])\n",
    "\n",
    "#     sourcePrefixToPreviewVector(random_source_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.964270Z",
     "start_time": "2019-09-12T01:29:18.961645Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     # returns p(Y0K|x0k)\n",
    "#     def makeExtendedChannelMatrixByPrefix(prefix):\n",
    "#         # NB:\n",
    "#         # if len(prefix) == n (including leftEdge), \n",
    "#         # then the extended channel matrix will have dimensions 39 x (n-1)\n",
    "\n",
    "#         p = prefix\n",
    "#         if prefix != leftEdge:# and not (len(ds2t(p)) == 2 and ds2t(p)[0] == leftEdge):\n",
    "#     #     if prefix != leftEdge and not (len(ds2t(p)) == 2 and ds2t(p)[0] == leftEdge):\n",
    "#             return np.hstack( (sourcePrefixToChannelMatrix(p) , sourcePrefixToPreviewVector(p).reshape(39,1)))\n",
    "#         else: #the extended channel matrix is garbage that should never be asked for\n",
    "#             l = len(ds2t(p))\n",
    "#             return np.zeros((39, l-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.968503Z",
     "start_time": "2019-09-12T01:29:18.965970Z"
    }
   },
   "outputs": [],
   "source": [
    "# if f:\n",
    "#     print('Source sequences = wordforms and prefixes')\n",
    "#     source_seqs = prefixes_t #prefixes include full wordforms\n",
    "# else:\n",
    "#     print('Source sequences = just full wordforms')\n",
    "#     source_seqs = Ws_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.973509Z",
     "start_time": "2019-09-12T01:29:18.970090Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "#     xCMsByPrefixIndex = [makeExtendedChannelMatrixByPrefix(s)\n",
    "#                          for s in source_seqs]\n",
    "#     xCMsByPrefixIndex_torch = [None] + [torch.from_numpy(each) for each in xCMsByPrefixIndex[1:]]\n",
    "\n",
    "#     xCMsByPrefixIndex[3].shape\n",
    "# if r:\n",
    "#     xCMsByPrefixIndex = [makeExtendedChannelMatrixByPrefix(p)\n",
    "#                          for p in prefixes_t]\n",
    "#     xCMsByPrefixIndex_torch = [None] + [torch.from_numpy(each) for each in xCMsByPrefixIndex[1:]]\n",
    "\n",
    "#     xCMsByPrefixIndex[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.977530Z",
     "start_time": "2019-09-12T01:29:18.975171Z"
    }
   },
   "outputs": [],
   "source": [
    "#original idea: process prefixes in blocks of 5000, \n",
    "# with order corresponding to ordering in Ps_t\n",
    "#\n",
    "# won't work because some prefixes are too short for pC1X012 to be well-defined\n",
    "\n",
    "# #split the prefixes_t into blocks of 5000\n",
    "# len(Ps_t)\n",
    "# chunk_size = 5000\n",
    "# Ps_t_chunked = [Ps_t[i * chunk_size:(i + 1) * chunk_size] for i in range((len(Ps_t) + chunk_size - 1) // chunk_size )]\n",
    "# [len(chunk) for chunk in Ps_t_chunked]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for calculating CMs for all prefixes of a given length (in batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:18.982164Z",
     "start_time": "2019-09-12T01:29:18.979213Z"
    }
   },
   "outputs": [],
   "source": [
    "# def trimBoundariesFromSequence(seq):\n",
    "#     temp = list(dottedStringToTuple(seq))\n",
    "#     if len(temp) < 1:\n",
    "#         return seq\n",
    "#     if temp[0] == leftEdge:\n",
    "#         temp = temp[1:]\n",
    "#     if len(temp) < 1:\n",
    "#         return tupleToDottedString(tuple(temp))\n",
    "#     if temp[-1] == rightEdge:\n",
    "#         temp = temp[:-1]\n",
    "#     return tupleToDottedString(tuple(temp))\n",
    "\n",
    "# def stringLengths(L, includingEdges = False):\n",
    "#     if includingEdges:\n",
    "#         return {len(ds2t(s)) for s in L}\n",
    "#     L_no_edges = {trimBoundariesFromSequence(s) for s in L}\n",
    "#     return stringLengths(L_no_edges, includingEdges = True)\n",
    "\n",
    "# def LbyLength(L, includingEdges = False):\n",
    "#     lengths = stringLengths(L, includingEdges=includingEdges)\n",
    "# #     if includingEdges:\n",
    "# #         my_L = L\n",
    "# #     else:\n",
    "# #         my_L = {trimBoundariesFromSequence(s) for s in L}\n",
    "#     l_to_s = {l:set() for l in lengths}\n",
    "#     for s in L:\n",
    "#         if includingEdges:\n",
    "#             my_s = s\n",
    "#         else:\n",
    "#             my_s = trimBoundariesFromSequence(s)\n",
    "#         my_l = len(ds2t(my_s))\n",
    "#         l_to_s[my_l].add(s)\n",
    "#     return l_to_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:19.091580Z",
     "start_time": "2019-09-12T01:29:18.983829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengthsInclEdges = stringLengths(Ws, True)\n",
    "wordlengthsInclEdges\n",
    "prefixlengthsInclEdges = stringLengths(Ps, True)\n",
    "prefixlengthsInclEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:19.337351Z",
     "start_time": "2019-09-12T01:29:19.092959Z"
    }
   },
   "outputs": [],
   "source": [
    "prefixesByLength = walk_values(lambda Ss: tuple(sorted(Ss)), LbyLength(Ps, True))\n",
    "wordformsByLength = walk_values(lambda Ss: tuple(sorted(Ss)), LbyLength(Ws, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:29:50.957920Z",
     "start_time": "2019-09-12T01:29:19.339200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0859s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  20 | elapsed:    0.2s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.9s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:    0.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    2.4s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  20 | elapsed:    6.3s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:   13.0s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   16.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0471s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  18 | elapsed:    0.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:    0.3s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  18 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  18 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  18 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    0.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "# whole cell now takes 30s / cmu+tarski\n",
    "\n",
    "def mapStringsToIDs(Ss, S_t):\n",
    "    return [S_t.index(s) for s in Ss]\n",
    "\n",
    "def mapSsToID_helper(l, Ss, S_t):\n",
    "    return (l, mapStringsToIDs(Ss, S_t))\n",
    "\n",
    "length_to_prefix_IDs = dict(par(delayed(mapSsToID_helper)(l, prefixesByLength[l], Ps_t)\n",
    "                                for l in prefixesByLength))\n",
    "\n",
    "length_to_wordform_IDs = dict(par(delayed(mapSsToID_helper)(l, wordformsByLength[l], Ws_t)\n",
    "                                  for l in wordformsByLength))\n",
    "\n",
    "#both calculations below together take 2m / cmu+tarski\n",
    "# length_to_prefix_IDs = walk_values(partial(lmap, lambda p: Ps_t.index(p)), \n",
    "#                                           prefixesByLength)\n",
    "\n",
    "length_to_wordform_IDs = walk_values(partial(lmap, lambda w: Ws_t.index(w)), \n",
    "                                          wordformsByLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:39.260915Z",
     "start_time": "2019-09-12T01:29:50.959767Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0390s.) Setting batch_size=10.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 370 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 860 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1240 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1660 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1890 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2120 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2370 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2620 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2890 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3160 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3450 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3740 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4050 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4360 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4690 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 5020 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 5370 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5720 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 6090 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6460 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6850 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 7240 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 7650 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 8060 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8490 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 8920 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 9370 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9820 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 10290 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 10760 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 11250 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 11740 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 12250 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 12760 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 13290 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 13820 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 14370 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 14920 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 15490 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 16060 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 16650 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 17240 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 17850 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 18460 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19090 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19720 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 20370 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 21020 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 21690 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 22360 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 23050 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 23740 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 24450 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 25160 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 25890 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 26620 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 27370 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 28120 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 28890 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 29660 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 30450 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 30833 out of 30833 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0041s.) Setting batch_size=96.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0264s.) Setting batch_size=1452.\n",
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 30833 out of 30833 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# whole cell now takes 1m / cmu+tarski\n",
    "\n",
    "def wordform_id_to_prefix_id_helper(w):\n",
    "    return (Ws_t.index(w), [Ps_t.index(p) for p in Ps if p == w][0])\n",
    "\n",
    "wordform_id_to_prefix_id = dict(par(delayed(wordform_id_to_prefix_id_helper)(w)\n",
    "                                    for w in Ws_t))\n",
    "\n",
    "def prefix_id_to_wordform_id_helper(w_idx):\n",
    "    return (wordform_id_to_prefix_id[w_idx], w_idx)\n",
    "\n",
    "prefix_id_to_wordform_id = dict(par(delayed(prefix_id_to_wordform_id_helper)(w_idx)\n",
    "                                    for w_idx in wordform_id_to_prefix_id))\n",
    "\n",
    "#code below takes 4m / cmu+tarski\n",
    "# wordform_id_to_prefix_id = {Ws_t.index(w):[Ps_t.index(p) for p in Ps if p == w][0]\n",
    "#                             for w in Ws_t}\n",
    "\n",
    "# prefix_id_to_wordform_id = flip(wordform_id_to_prefix_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.353354Z",
     "start_time": "2019-09-12T01:30:39.263732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i.p.u'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'i.p'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'i.p.u.?'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_to_wordform_to_prefix = {l:{w:t2ds(ds2t(w)[:l])\n",
    "                                   for w in Ws}\n",
    "                                for l in wordlengthsInclEdges}\n",
    "\n",
    "coerceDStoLength('i.p.u', 3)\n",
    "coerceDStoLength('i.p.u', 2)\n",
    "coerceDStoLength('i.p.u', 4)\n",
    "    \n",
    "length_to_wordform_to_padded_prefix = {l:{w:coerceDStoLength(w, l)\n",
    "                                          for w in Ws}\n",
    "                                       for l in prefixlengthsInclEdges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.358374Z",
     "start_time": "2019-09-12T01:30:41.354544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ʌ.g.ɹ.ɛ.s.ɚ.z.⋉'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.ʌ.g.ɹ.ɛ.s.ɚ.z.⋉.?.?.?'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw = choice(Ws_t); rw\n",
    "length_to_wordform_to_padded_prefix[12][rw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.363515Z",
     "start_time": "2019-09-12T01:30:41.359531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7, 10540)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(rw))\n",
    "dsToTriphoneOHs(rw, X012OHmap).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.370755Z",
     "start_time": "2019-09-12T01:30:41.365065Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.d.i.k.ɹ.ɪ.m.ʌ.n.ʌ.l.ʌ.z.eɪ.ʃ.ʌ',\n",
       " '⋊.d.i.k.ʌ.n.t.æ.m.ʌ.n.eɪ.ʃ.ʌ.n.⋉',\n",
       " '⋊.d.ɪ.s.g.ɹ.ʌ.n.t.ʌ.l.m.ʌ.n.t.⋉',\n",
       " '⋊.d.ɪ.s.k.ɹ.ɪ.m.ʌ.n.ʌ.t.ɑ.ɹ.i.⋉',\n",
       " '⋊.d.ɪ.s.k.ʌ.m.b.ɑ.b.j.u.l.eɪ.t.ʌ',\n",
       " '⋊.d.ɪ.s.p.ɹ.ʌ.p.ɑ.ɹ.ʃ.ʌ.n.ɪ.t.⋉',\n",
       " '⋊.d.ɪ.s.p.ɹ.ʌ.p.ɑ.ɹ.ʃ.ʌ.n.ʌ.t.l',\n",
       " '⋊.d.ɪ.s.t.ɹ.ɪ.b.j.u.t.ɚ.ʃ.ɪ.p.⋉',\n",
       " '⋊.d.ɪ.s.ɑ.ɹ.g.ʌ.n.ʌ.z.eɪ.ʃ.ʌ.n.⋉',\n",
       " '⋊.f.ʌ.n.d.ʌ.m.ɛ.n.t.ʌ.l.ɪ.s.t.s',\n",
       " '⋊.f.ʌ.n.d.ʌ.m.ɛ.n.t.ʌ.l.ɪ.s.t.⋉',\n",
       " '⋊.f.ʌ.n.d.ʌ.m.ɛ.n.t.ʌ.l.ɪ.z.ʌ.m',\n",
       " '⋊.h.oʊ.m.oʊ.s.ɛ.k.ʃ.u.æ.l.ʌ.t.i.⋉',\n",
       " '⋊.h.ɑ.s.p.ɪ.t.ʌ.l.ʌ.z.eɪ.ʃ.ʌ.n.⋉',\n",
       " '⋊.h.ɛ.t.ɚ.oʊ.s.ɛ.k.ʃ.u.æ.l.ɪ.t.i',\n",
       " '⋊.j.u.n.ɪ.l.æ.t.ɚ.ʌ.l.ɪ.z.ʌ.m.⋉',\n",
       " '⋊.k.aʊ.n.t.ɚ.p.ɹ.ʌ.d.ʌ.k.t.ɪ.v.⋉',\n",
       " '⋊.k.ɑ.n.f.ɹ.ʌ.n.t.eɪ.ʃ.ʌ.n.ʌ.l.⋉',\n",
       " '⋊.k.ɑ.n.f.ʌ.d.ɛ.n.ʃ.i.æ.l.ʌ.t.i',\n",
       " '⋊.k.ɑ.n.s.t.ɪ.t.u.ʃ.ʌ.n.æ.l.ɪ.t',\n",
       " '⋊.k.ɑ.n.s.t.ʌ.t.u.ʃ.ʌ.n.ʌ.l.i.⋉',\n",
       " '⋊.k.ɑ.n.v.ɚ.s.eɪ.ʃ.ʌ.n.ʌ.l.ʌ.s.t',\n",
       " '⋊.k.ɑ.ɹ.d.i.oʊ.v.æ.s.k.j.ʌ.l.ɚ.⋉',\n",
       " '⋊.k.ɹ.ɪ.m.ʌ.n.ʌ.l.ɪ.s.t.ɪ.k.s.⋉',\n",
       " '⋊.k.ʌ.n.g.ɹ.æ.tʃ.ʌ.l.eɪ.ʃ.ʌ.n.z.⋉',\n",
       " '⋊.k.ʌ.n.t.ɛ.m.p.ɚ.eɪ.n.i.ʌ.s.l.i',\n",
       " '⋊.m.aɪ.k.ɹ.oʊ.b.i.ɑ.l.ʌ.dʒ.ɪ.s.t.⋉',\n",
       " '⋊.m.aɪ.k.ɹ.oʊ.ɑ.ɹ.g.ʌ.n.ɪ.z.ʌ.m.z',\n",
       " '⋊.m.j.u.n.ɪ.s.ʌ.p.æ.l.ɪ.t.i.z.⋉',\n",
       " '⋊.m.æ.k.ɹ.oʊ.ɛ.k.ʌ.n.ɑ.m.ɪ.k.s.⋉',\n",
       " '⋊.m.ɪ.s.k.æ.l.k.j.ʌ.l.eɪ.t.ɪ.d.⋉',\n",
       " '⋊.m.ɪ.s.k.ʌ.m.j.u.n.ʌ.k.eɪ.ʃ.ʌ.n',\n",
       " '⋊.m.ɪ.s.ɹ.ɛ.p.ɹ.ɪ.z.ɛ.n.t.eɪ.ʃ.ʌ',\n",
       " '⋊.m.ɪ.s.ɹ.ɛ.p.ɹ.ɪ.z.ɛ.n.t.ɪ.d.⋉',\n",
       " '⋊.m.ɪ.s.ɹ.ɛ.p.ɹ.ʌ.z.ɛ.n.t.ɪ.ŋ.⋉',\n",
       " '⋊.m.ɪ.s.ʌ.n.d.ɚ.s.t.æ.n.d.ɪ.ŋ.z',\n",
       " '⋊.m.ɪ.s.ʌ.n.d.ɚ.s.t.æ.n.d.ɪ.ŋ.⋉',\n",
       " '⋊.m.ɪ.s.ʌ.p.ɹ.oʊ.p.ɹ.i.eɪ.t.ɪ.d.⋉',\n",
       " '⋊.n.ɑ.n.g.ʌ.v.ɚ.n.m.ɛ.n.t.ʌ.l.⋉',\n",
       " '⋊.p.ɹ.ɑ.p.ʌ.g.ʌ.n.d.ɪ.s.t.ɪ.k.⋉',\n",
       " '⋊.p.ɹ.ɑ.t.ʌ.s.t.ʌ.n.t.ɪ.z.ʌ.m.⋉',\n",
       " '⋊.p.ɹ.ɪ.d.ɪ.k.t.ʌ.b.ɪ.l.ɪ.t.i.⋉',\n",
       " '⋊.p.ɹ.ʌ.f.ɛ.ʃ.ʌ.n.ʌ.l.ɪ.z.ʌ.m.⋉',\n",
       " '⋊.p.ɹ.ʌ.k.ɹ.æ.s.t.ʌ.n.eɪ.t.ɪ.ŋ.⋉',\n",
       " '⋊.p.ɹ.ʌ.k.ɹ.æ.s.t.ʌ.n.eɪ.t.ʌ.d.⋉',\n",
       " '⋊.p.ɹ.ʌ.k.ɹ.æ.s.t.ʌ.n.eɪ.ʃ.ʌ.n.⋉',\n",
       " '⋊.s.u.p.ɚ.ʌ.n.t.ɛ.n.d.ʌ.n.t.s.⋉',\n",
       " '⋊.s.ɛ.n.s.eɪ.ʃ.ʌ.n.ʌ.l.aɪ.z.ɪ.ŋ.⋉',\n",
       " '⋊.s.ɛ.n.s.eɪ.ʃ.ʌ.n.ʌ.l.ɪ.s.t.ɪ.k',\n",
       " '⋊.s.ɛ.n.s.eɪ.ʃ.ʌ.n.ʌ.l.ɪ.z.ʌ.m.⋉',\n",
       " '⋊.s.ɛ.n.t.ʌ.m.ɛ.n.t.æ.l.ɪ.t.i.⋉',\n",
       " '⋊.t.ɛ.l.ʌ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ',\n",
       " '⋊.t.ɛ.l.ʌ.k.ʌ.m.j.u.n.ʌ.k.eɪ.ʃ.ʌ',\n",
       " '⋊.t.ɹ.æ.n.z.k.ɑ.n.t.ɪ.n.ɛ.n.t.ʌ',\n",
       " '⋊.æ.d.m.ɪ.n.ɪ.s.t.ɹ.eɪ.ʃ.ʌ.n.z.⋉',\n",
       " '⋊.æ.n.t.aɪ.d.ɪ.p.ɹ.ɛ.s.ʌ.n.t.s.⋉',\n",
       " '⋊.æ.n.θ.ɹ.ʌ.p.ɑ.l.ʌ.dʒ.ɪ.s.t.s.⋉',\n",
       " '⋊.ɑ.t.ʌ.b.aɪ.ʌ.g.ɹ.æ.f.ɪ.k.ʌ.l.⋉',\n",
       " '⋊.ɛ.k.s.k.ɹ.u.s.i.eɪ.t.ɪ.ŋ.l.i.⋉',\n",
       " '⋊.ɛ.k.s.t.ɹ.æ.v.ʌ.g.ʌ.n.t.l.i.⋉',\n",
       " '⋊.ɛ.k.s.t.ɹ.ʌ.k.ɚ.ɪ.k.j.ʌ.l.ɚ.⋉',\n",
       " '⋊.ɛ.k.s.t.ɹ.ʌ.t.ɚ.ɛ.s.t.ɹ.i.ʌ.l',\n",
       " '⋊.ɛ.n.d.oʊ.k.ɹ.ʌ.n.ɑ.l.ʌ.dʒ.ʌ.s.t',\n",
       " '⋊.ɛ.n.v.aɪ.ɹ.ʌ.n.m.ɛ.n.t.ʌ.l.ɪ.s',\n",
       " '⋊.ɛ.p.ɪ.d.i.m.i.ʌ.l.ɑ.dʒ.ɪ.k.ʌ.l',\n",
       " '⋊.ɪ.l.ɛ.k.t.ɹ.oʊ.m.æ.g.n.ɛ.t.ɪ.k',\n",
       " '⋊.ɪ.m.p.ɹ.ɑ.v.ɪ.z.eɪ.ʃ.ʌ.n.ʌ.l.⋉',\n",
       " '⋊.ɪ.n.d.ɪ.s.k.ɹ.ɪ.m.ʌ.n.ʌ.t.l.i',\n",
       " '⋊.ɪ.n.d.ɪ.s.t.ɪ.ŋ.g.w.ɪ.ʃ.ʌ.b.ʌ',\n",
       " '⋊.ɪ.n.d.ɪ.v.ɪ.dʒ.u.ʌ.l.ɪ.s.t.ɪ.k',\n",
       " '⋊.ɪ.n.d.ʌ.s.t.ɹ.i.ʌ.l.ɪ.z.eɪ.ʃ.ʌ',\n",
       " '⋊.ɪ.n.d.ʌ.s.t.ɹ.ʌ.k.t.ɪ.b.ʌ.l.⋉',\n",
       " '⋊.ɪ.n.k.ʌ.n.v.i.n.j.ʌ.n.s.ɪ.z.⋉',\n",
       " '⋊.ɪ.n.s.t.ɪ.t.u.ʃ.ʌ.n.ʌ.l.aɪ.z.d',\n",
       " '⋊.ɪ.n.s.t.ɪ.t.u.ʃ.ʌ.n.ʌ.l.aɪ.z.⋉',\n",
       " '⋊.ɪ.n.s.t.ɪ.t.u.ʃ.ʌ.n.ʌ.l.ɪ.z.eɪ',\n",
       " '⋊.ɪ.n.s.t.ɹ.ʌ.m.ɛ.n.t.eɪ.ʃ.ʌ.n.⋉',\n",
       " '⋊.ɪ.n.s.t.ʌ.n.t.æ.n.i.ʌ.s.l.i.⋉',\n",
       " '⋊.ɪ.n.s.ɪ.g.n.j.ɪ.f.ɪ.k.ʌ.n.t.⋉',\n",
       " '⋊.ɪ.n.t.ɚ.k.ɑ.n.t.ʌ.n.ɛ.n.t.ʌ.l',\n",
       " '⋊.ɪ.n.v.aɪ.ɹ.ʌ.n.m.ɛ.n.t.ʌ.l.i.⋉',\n",
       " '⋊.ɪ.n.v.aɪ.ɹ.ʌ.n.m.ɛ.n.t.ʌ.l.ɪ.s',\n",
       " '⋊.ɪ.ŋ.k.ɑ.n.s.ɪ.s.t.ɛ.n.s.i.z.⋉',\n",
       " '⋊.ɪ.ŋ.k.ɑ.n.s.ʌ.k.w.ɛ.n.tʃ.ʌ.l.⋉',\n",
       " '⋊.ɪ.ɹ.ʌ.s.p.ɑ.n.s.ʌ.b.ɪ.l.ʌ.t.i',\n",
       " '⋊.ɹ.i.d.ɪ.s.t.ɹ.ɪ.b.j.u.t.ɪ.d.⋉',\n",
       " '⋊.ɹ.i.d.ɪ.s.t.ɹ.ɪ.b.j.u.t.ɪ.ŋ.⋉',\n",
       " '⋊.ɹ.i.s.p.ɑ.n.s.ʌ.b.ɪ.l.ʌ.t.i.z',\n",
       " '⋊.ɹ.i.s.p.ɑ.n.s.ʌ.b.ɪ.l.ʌ.t.i.⋉',\n",
       " '⋊.ɹ.ɛ.p.ɹ.ʌ.z.ɛ.n.t.ʌ.t.ɪ.v.z.⋉',\n",
       " '⋊.ɹ.ɛ.p.ɹ.ʌ.z.ʌ.n.t.eɪ.ʃ.ʌ.n.z.⋉',\n",
       " '⋊.ʌ.k.j.u.m.j.ʌ.l.eɪ.t.ɪ.v.l.i.⋉',\n",
       " '⋊.ʌ.n.d.ɚ.ɹ.ɛ.p.ɹ.ɪ.z.ɛ.n.t.ɪ.d',\n",
       " '⋊.ʌ.n.k.ɑ.n.s.t.ʌ.t.u.ʃ.ʌ.n.ʌ.l',\n",
       " '⋊.ʌ.n.k.ʌ.n.t.æ.m.ʌ.n.eɪ.t.ʌ.d.⋉',\n",
       " '⋊.ʌ.n.ɹ.ɛ.k.ʌ.g.n.aɪ.z.ʌ.b.ʌ.l.⋉')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixesByLength[16]\n",
    "len(prefixesByLength[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.374246Z",
     "start_time": "2019-09-12T01:30:41.372321Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_sixteen_OH_stack = torch.stack([torch.tensor(dsToTriphoneOHs(p, X012OHmap), dtype=torch.short)\n",
    "#                                   for p in prefixesByLength[16]])\n",
    "# p_sixteen_OH_stack.shape\n",
    "# p_sixteen_OH_stack.dtype\n",
    "\n",
    "# p_sixteen_OH_stack_tr = p_sixteen_OH_stack.transpose(1, 2)\n",
    "# p_sixteen_OH_stack_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.378230Z",
     "start_time": "2019-09-12T01:30:41.375805Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_sixteen_OH_stack_tr_c = p_sixteen_OH_stack_tr.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.382023Z",
     "start_time": "2019-09-12T01:30:41.379750Z"
    }
   },
   "outputs": [],
   "source": [
    "# pC1X012_torch_c = pC1X012_torch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.385891Z",
     "start_time": "2019-09-12T01:30:41.383522Z"
    }
   },
   "outputs": [],
   "source": [
    "# CM_zero = torch.matmul(pC1X012_torch_c, p_sixteen_OH_stack_tr_c[0].type(torch.double))\n",
    "# CM_zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.389986Z",
     "start_time": "2019-09-12T01:30:41.387468Z"
    }
   },
   "outputs": [],
   "source": [
    "# pC1X012_torch_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.394084Z",
     "start_time": "2019-09-12T01:30:41.391530Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_sixteen_OH_stack_CMs_c = torch.matmul(pC1X012_torch_c, p_sixteen_OH_stack_tr_c.type(torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.397740Z",
     "start_time": "2019-09-12T01:30:41.395662Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_sixteen_OH_stack_CMs_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.401512Z",
     "start_time": "2019-09-12T01:30:41.399295Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.equal(p_sixteen_OH_stack_CMs_c, \n",
    "#             torch.einsum('ik,pkj->pij',\n",
    "#                          pC1X012_torch_c,\n",
    "#                          p_sixteen_OH_stack_tr_c.type(torch.double)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.405087Z",
     "start_time": "2019-09-12T01:30:41.403056Z"
    }
   },
   "outputs": [],
   "source": [
    "# del p_sixteen_OH_stack\n",
    "# del p_sixteen_OH_stack_tr\n",
    "# del p_sixteen_OH_stack_tr_c\n",
    "# del p_sixteen_OH_stack_CMs_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:41.749423Z",
     "start_time": "2019-09-12T01:30:41.406671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         10G         54G        1.8M        123G        175G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:54.329787Z",
     "start_time": "2019-09-12T01:30:41.752220Z"
    }
   },
   "outputs": [],
   "source": [
    "#map each length to a stack of n_l OHs, each of shape (l-2, s), where s = # triphones\n",
    "\n",
    "length_to_prefix_OH_matrices = {l:torch.stack([torch.tensor(dsToTriphoneOHs(p, X012OHmap), dtype=torch.short)\n",
    "                                               for p in prefixesByLength[l]])\n",
    "                                for l in prefixlengthsInclEdges}\n",
    "\n",
    "# length_to_wordform_OH_matrices = {l:torch.stack([torch.tensor(dsToTriphoneOHs(w, X012OHmap), dtype=torch.short)\n",
    "#                                                for w in wordformsByLength[l]])\n",
    "#                                   for l in wordlengthsInclEdges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:54.883379Z",
     "start_time": "2019-09-12T01:30:54.331329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         21G         42G        1.8M        123G        164G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:54.893719Z",
     "start_time": "2019-09-12T01:30:54.886779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_to_prefix_OH_matrices[1].size()[1] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:58.259528Z",
     "start_time": "2019-09-12T01:30:54.895613Z"
    }
   },
   "outputs": [],
   "source": [
    "pC1X012_torch_c = pC1X012_torch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:58.263506Z",
     "start_time": "2019-09-12T01:30:58.261082Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T01:30:58.270233Z",
     "start_time": "2019-09-12T01:30:58.264919Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunkList(chunk_size, l):\n",
    "    return [l[i * chunk_size:(i + 1) * chunk_size] for i in range((len(l) + chunk_size - 1) // chunk_size )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:04:03.374979Z",
     "start_time": "2019-09-12T01:30:58.271577Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"1\": shape None, type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"2\": shape None, type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([554, 1, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([554, 57798, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"3\": shape (554, 57798, 1), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:01<00:11,  1.55it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([4402, 2, 10540])\n",
      "\t2 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1/2 [00:14<00:14, 14.49s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:21<00:00, 12.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([4402, 57798, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"4\": shape (4402, 57798, 2), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:26<02:06,  7.93s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([12988, 3, 10540])\n",
      "\t5 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:21<01:27, 21.90s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:43<01:05, 21.94s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [01:06<00:44, 22.00s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [01:28<00:22, 22.05s/it]\u001b[A\n",
      "100%|██████████| 5/5 [01:35<00:00, 17.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([12988, 57798, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"5\": shape (12988, 57798, 3), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:19<09:50, 39.34s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([18100, 4, 10540])\n",
      "\t7 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:29<02:57, 29.60s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:59<02:28, 29.62s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [01:28<01:58, 29.64s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [01:58<01:28, 29.66s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [02:28<00:59, 29.67s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [02:58<00:29, 29.68s/it]\u001b[A\n",
      "100%|██████████| 7/7 [02:59<00:00, 21.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([18100, 57798, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"6\": shape (18100, 57798, 4), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [05:53<21:23, 91.67s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([18069, 5, 10540])\n",
      "\t7 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:37<03:42, 37.12s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [01:14<03:05, 37.12s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [01:51<02:28, 37.11s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [02:28<01:51, 37.10s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [03:05<01:14, 37.09s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [03:42<00:37, 37.10s/it]\u001b[A\n",
      "100%|██████████| 7/7 [03:43<00:00, 26.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([18069, 57798, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"7\": shape (18069, 57798, 5), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [10:27<31:44, 146.50s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([15080, 6, 10540])\n",
      "\t6 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [00:44<03:42, 44.43s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [01:28<02:57, 44.43s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [02:13<02:13, 44.43s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [02:57<01:28, 44.43s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [03:42<00:44, 44.43s/it]\u001b[A\n",
      "100%|██████████| 6/6 [03:43<00:00, 31.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([15080, 57798, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"8\": shape (15080, 57798, 6), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [15:02<36:59, 184.92s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([11274, 7, 10540])\n",
      "\t4 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t6 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:34<02:52, 34.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 2/6 [01:09<02:18, 34.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [01:43<01:43, 34.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 4/6 [02:18<01:09, 34.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [02:53<00:34, 34.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [03:15<00:00, 30.90s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([11274, 57798, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"9\": shape (11274, 57798, 7), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [19:45<39:19, 214.48s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([7767, 8, 10540])\n",
      "\t3 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t4 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t8 chunks of size 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:55<06:25, 55.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 2/8 [01:14<04:26, 44.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [01:34<03:05, 37.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 4/8 [01:54<02:07, 31.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▎   | 5/8 [02:14<01:24, 28.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 6/8 [02:33<00:51, 25.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 7/8 [02:53<00:23, 23.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 8/8 [03:08<00:00, 21.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([7767, 57798, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"10\": shape (7767, 57798, 8), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [24:17<38:38, 231.82s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([4828, 9, 10540])\n",
      "\t2 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t3 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t5 chunks of size 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [01:02<04:08, 62.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [01:24<02:30, 50.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [01:46<01:23, 41.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [02:09<00:35, 35.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [02:27<00:00, 30.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([4828, 57798, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"11\": shape (4828, 57798, 9), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [28:05<34:34, 230.49s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([2814, 10, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t2 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t3 chunks of size 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [01:09<02:18, 69.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [01:34<00:55, 55.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [01:54<00:00, 45.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([2814, 57798, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"12\": shape (2814, 57798, 10), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [31:15<29:08, 218.53s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([1490, 11, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:40<00:00, 40.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([1490, 57798, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"13\": shape (1490, 57798, 11), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [32:03<19:30, 167.15s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([735, 12, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([735, 57798, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"14\": shape (735, 57798, 12), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [32:32<12:35, 125.93s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([283, 13, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([283, 57798, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"15\": shape (283, 57798, 13), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [32:43<07:37, 91.41s/it] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([96, 14, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([96, 57798, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"16\": shape (96, 57798, 14), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [32:47<04:20, 65.17s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([35, 15, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([35, 57798, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"17\": shape (35, 57798, 15), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [32:49<02:18, 46.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([14, 16, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([14, 57798, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"18\": shape (14, 57798, 16), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [32:50<01:05, 32.51s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([3, 17, 10540])\n",
      "\t1 chunks of size 3000\n",
      "\tCM stack shape = torch.Size([3, 57798, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"19\": shape (3, 57798, 17), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [32:50<00:22, 22.82s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([1, 18, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([1, 57798, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"20\": shape (1, 57798, 18), type \"<f8\">"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [32:50<00:00, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "#before driver update:\n",
    "#chunk size 100 -> 5.75m on tarski w/ peak mem usage ~130GB and peak GPU mem usage of ~5GB?\n",
    "#chunk size 300 -> 5.5m on tarski w/ peak mem usage ~130GB and peak GPU mem usage of ~8-9GB\n",
    "#chunk size 1000 -> 5.5m on tarski w/ peak mem usage ~130GB and peak GPU mem usage of ~13GB\n",
    "#chunk size 3000 -> 5.5m on tarski w/ peak mem usage ~130GB and peak GPU mem usage of ~?GB\n",
    "\n",
    "#after driver update:\n",
    "#chunk size 100 -> ?m on tarski w/ peak mem usage = high enough to trigger memguard (>=186GB)\n",
    "# \n",
    "# FIXME need to write the CMs *for each l* to disk / memory-map them.\n",
    "#    *Options include*:\n",
    "#      making a directory and making\n",
    "#         1. tiledb arrays for each l\n",
    "#         2. numpy memory mapped arrays for each l\n",
    "#      3. making a hdf5 <archive?> for the whole thing\n",
    "# \n",
    "#     - Option #1 (tiledb) will have the best concurrent read support (useful for parallelizing segmental posterior calcs)\n",
    "#     - *BUT* if you organize segmental posterior calcs by length, then you can just load the entire tensor into memory for just that length\n",
    "#       -> this is most comparable to what you're already doing and most desirable in terms of performance anyway\n",
    "#     -> Pursue option 3\n",
    "\n",
    "\n",
    "#chunk size 100 -> ≈60m on tarski, peak GPU usage around 6GB\n",
    "#chunk size 2000 -> \n",
    "#chunk size 3000 -> ≈33m on tarski, peak GPU usage around 21GB, but GPU runs out of memory on l=9\n",
    "\n",
    "my_ext = '.hdf5'\n",
    "OD_by_length_prefix_fp = o + '_by_length_by_prefix_index' + my_ext\n",
    "with h5py.File(OD_by_length_prefix_fp, 'w') as f:\n",
    "#     length_to_prefix_CMs = []\n",
    "    # length_to_prefix_CMs = dict()\n",
    "    \n",
    "    chunk_size = 3000\n",
    "#     chunk_size = 2000\n",
    "#     chunk_size = 1000\n",
    "#     chunk_size = 100\n",
    "#     chunk_size = 300\n",
    "\n",
    "    for l in tqdm(length_to_prefix_OH_matrices):\n",
    "        if length_to_prefix_OH_matrices[l].size()[1] == 0:\n",
    "            \n",
    "            #see http://docs.h5py.org/en/stable/high/dataset.html#creating-and-reading-empty-or-null-datasets-and-attributes\n",
    "            f.create_dataset(str(l), dtype='float64') #h5py empty \n",
    "#             length_to_prefix_CMs.append(None)\n",
    "    #         length_to_prefix_CMs[l] = None\n",
    "        else:\n",
    "            memTrigger()\n",
    "\n",
    "            print('-' * 40)\n",
    "            print(f\"\\tOH stack size = {length_to_prefix_OH_matrices[l].size()}\")\n",
    "\n",
    "            chunks = chunkList(chunk_size, length_to_prefix_OH_matrices[l])\n",
    "            print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "            \n",
    "            try:\n",
    "                chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "                                               chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "                                  for chunk in tqdm(chunks, total=len(chunks))]\n",
    "            except:\n",
    "                print(f'Chunk size {chunk_size} too large')\n",
    "                torch.cuda.empty_cache()\n",
    "                if chunk_size > 1000:\n",
    "                    chunk_size = chunk_size - 1000\n",
    "                    print(f'Reducing chunk size by 1000 to {chunk_size}')\n",
    "                    chunks = chunkList(chunk_size, length_to_prefix_OH_matrices[l])\n",
    "                    print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "                    try:\n",
    "                        chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "                                               chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "                                  for chunk in tqdm(chunks, total=len(chunks))]\n",
    "                    except:\n",
    "                        print(f'Chunk size {chunk_size} *still * too large')\n",
    "                        torch.cuda.empty_cache()\n",
    "                        if chunk_size > 1000:\n",
    "                            chunk_size = chunk_size - 1000\n",
    "                            print(f'Reducing chunk size by another 1000 to {chunk_size}')\n",
    "                        else:\n",
    "                            chunk_size = int(chunk_size / 2)\n",
    "                            print(f'Reducing chunk size by half to {chunk_size}')\n",
    "                        chunks = chunkList(chunk_size, length_to_prefix_OH_matrices[l])\n",
    "                        print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "                        chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "                                               chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "                                  for chunk in tqdm(chunks, total=len(chunks))]\n",
    "                else:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    raise Exception('Out of memory.')\n",
    "            del chunks\n",
    "            \n",
    "            result = torch.cat(chunked_result)\n",
    "            del chunked_result\n",
    "            print(f\"\\tCM stack shape = {result.shape}\")\n",
    "            result_np = result.numpy()\n",
    "            del result\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "#             length_to_prefix_CMs.append(result)\n",
    "    #         length_to_prefix_CMs[l] = result\n",
    "            f.create_dataset(str(l), result_np.shape, dtype='float64', data=result_np)\n",
    "            del result_np\n",
    "\n",
    "#             del chunks\n",
    "#             del chunked_result\n",
    "#             del result\n",
    "#             del result_np\n",
    "            print('')\n",
    "    \n",
    "    \n",
    "# length_to_prefix_CMs = []\n",
    "# # length_to_prefix_CMs = dict()\n",
    "# for l in tqdm(length_to_prefix_OH_matrices):\n",
    "#     if length_to_prefix_OH_matrices[l].size()[1] == 0:\n",
    "#         length_to_prefix_CMs.append(None)\n",
    "# #         length_to_prefix_CMs[l] = None\n",
    "#     else:\n",
    "#         memTrigger()\n",
    "\n",
    "#         print('-' * 40)\n",
    "#         print(f\"\\tOH stack size = {length_to_prefix_OH_matrices[l].size()}\")\n",
    "# #         chunk_size = 3000\n",
    "# #         chunk_size = 1000\n",
    "#         chunk_size = 100\n",
    "# #         chunk_size = 300\n",
    "#         chunks = chunkList(chunk_size, length_to_prefix_OH_matrices[l])\n",
    "#         print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "#         chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "#                                        chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "#                           for chunk in tqdm(chunks, total=len(chunks))]\n",
    "#         result = torch.cat(chunked_result)\n",
    "#         print(f\"\\tCM stack shape = {result.shape}\")\n",
    "#         print(f\"\\tCM stack dtype = {result.dtype}\")\n",
    "#         length_to_prefix_CMs.append(result)\n",
    "# #         length_to_prefix_CMs[l] = result\n",
    "#         torch.cuda.empty_cache()\n",
    "#         del chunks\n",
    "#         del chunked_result\n",
    "#         del result\n",
    "#         print('')\n",
    "# #         result = []\n",
    "# #         for chunk in chunks:\n",
    "# #             result.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:04:04.016192Z",
     "start_time": "2019-09-12T02:04:03.379211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         23G        2.6G         11M        161G        162G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:11:59.101254Z",
     "start_time": "2019-09-12T02:11:59.090641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '3', '4', '5', '6', '7', '8', '9']>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OD_by_length_prefix_f = h5py.File(OD_by_length_prefix_fp, 'r')\n",
    "OD_by_length_prefix_f.keys()\n",
    "group10 = OD_by_length_prefix_f['10']\n",
    "group10.shape\n",
    "group10.dtype\n",
    "OD_by_length_prefix_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:26:10.951844Z",
     "start_time": "2019-09-12T02:26:10.941827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tCM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_OD_by_length_by_prefix.hdf5\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_OD_by_length_by_prefix.hdf5_metadata.json\n"
     ]
    }
   ],
   "source": [
    "CMs_by_length_by_prefix_md = {\n",
    "#     'r':r,\n",
    "    'length':len(length_to_prefix_OH_matrices),\n",
    "    'W':{'from fp':w,\n",
    "         'changes':'(x)CMs constructed from sorted prefixes of W; final ⋉ stripped',\n",
    "         'size':len(Ws_t)},\n",
    "    'P':{'from fp':w,\n",
    "         'changes':'(x)CMs constructed from sorted prefixes of W after final ⋉ stripped',\n",
    "         'size':len(Ps_t)},\n",
    "    'C':{'from fp':c,\n",
    "         'changes':'None'}\n",
    "}\n",
    "\n",
    "my_fp = o + '_by_length_by_prefix_index.hdf5'\n",
    "exportMatrixMetadata(my_fp + '_metadata.json',\n",
    "                     my_fp,\n",
    "                     None,\n",
    "                     CMs_by_length_by_prefix_md,\n",
    "                     'Step 4e',\n",
    "                     'Calculate segmental wordform and prefix channel matrices',\n",
    "                     {'organization':'Each l maps to a pytorch tensor of dim (n_{l-2}, |Y012s|, l-2), where the ordering of the first dimension corresponds to alphabetical order of prefixes of length l.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T23:30:08.214597Z",
     "start_time": "2019-09-09T23:30:08.211087Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# length_to_prefix_CMs = {l:torch.matmul(pC1X012_torch_c, \n",
    "#                                        length_to_prefix_OH_matrices[l].transpose(1,2).cuda().type(torch.double)).cpu()\n",
    "#                           if length_to_prefix_OH_matrices[l].size()[1] != 0 else None\n",
    "#                         for l in tqdm(length_to_prefix_OH_matrices)}\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for calculating CMs for all wordforms of a given length (in batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:15:22.214761Z",
     "start_time": "2019-09-12T02:15:21.142762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         50G        105G         11M         31G        135G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:15:28.341559Z",
     "start_time": "2019-09-12T02:15:23.034422Z"
    }
   },
   "outputs": [],
   "source": [
    "length_to_wordform_OH_matrices = {l:torch.stack([torch.tensor(dsToTriphoneOHs(w, X012OHmap), dtype=torch.short)\n",
    "                                               for w in wordformsByLength[l]])\n",
    "                                  for l in wordlengthsInclEdges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:15:29.858519Z",
     "start_time": "2019-09-12T02:15:29.237726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         27G        127G         11M         31G        158G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:26:05.231396Z",
     "start_time": "2019-09-12T02:15:41.588436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([10, 1, 10540])\n",
      "\t1 chunks of size 3000\n",
      "\tCM stack shape = torch.Size([10, 57798, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"3\": shape (10, 57798, 1), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 1/18 [00:00<00:01,  9.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([253, 2, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([253, 57798, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"4\": shape (253, 57798, 2), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 2/18 [00:01<00:08,  1.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([1843, 3, 10540])\n",
      "\t1 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([1843, 57798, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"5\": shape (1843, 57798, 3), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 3/18 [00:17<01:16,  5.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([4166, 4, 10540])\n",
      "\t2 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:28<00:28, 28.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [00:40<00:00, 23.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([4166, 57798, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"6\": shape (4166, 57798, 4), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 4/18 [01:04<04:08, 17.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([5599, 5, 10540])\n",
      "\t2 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:36<00:36, 36.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [01:08<00:00, 35.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([5599, 57798, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"7\": shape (5599, 57798, 5), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 5/18 [02:25<07:55, 36.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([5558, 6, 10540])\n",
      "\t2 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:44<00:44, 44.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [01:22<00:00, 42.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([5558, 57798, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"8\": shape (5558, 57798, 6), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 6/18 [04:00<10:52, 54.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([4550, 7, 10540])\n",
      "\t2 chunks of size 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size 3000 too large\n",
      "Reducing chunk size by 1000 to 2000\n",
      "\t3 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [00:34<01:09, 34.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [01:09<00:34, 34.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [01:18<00:00, 27.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([4550, 57798, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"9\": shape (4550, 57798, 7), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 7/18 [06:20<14:37, 79.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([3509, 8, 10540])\n",
      "\t2 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:39<00:39, 39.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [01:09<00:00, 36.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([3509, 57798, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"10\": shape (3509, 57798, 8), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 8/18 [07:41<13:21, 80.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([2318, 9, 10540])\n",
      "\t2 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:44<00:44, 44.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [00:51<00:00, 33.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([2318, 57798, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"11\": shape (2318, 57798, 9), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 9/18 [08:41<11:07, 74.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([1464, 10, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:36<00:00, 36.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([1464, 57798, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"12\": shape (1464, 57798, 10), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 10/18 [09:23<08:37, 64.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([813, 11, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:22<00:00, 22.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([813, 57798, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"13\": shape (813, 57798, 11), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 11/18 [09:50<06:12, 53.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([463, 12, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([463, 57798, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"14\": shape (463, 57798, 12), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 12/18 [10:06<04:12, 42.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([191, 13, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([191, 57798, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"15\": shape (191, 57798, 13), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 13/18 [10:13<02:38, 31.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([61, 14, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([61, 57798, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"16\": shape (61, 57798, 14), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 14/18 [10:16<01:31, 22.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([21, 15, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([21, 57798, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"17\": shape (21, 57798, 15), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 15/18 [10:17<00:48, 16.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([11, 16, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([11, 57798, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"18\": shape (11, 57798, 16), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 16/18 [10:17<00:23, 11.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([2, 17, 10540])\n",
      "\t1 chunks of size 2000\n",
      "\tCM stack shape = torch.Size([2, 57798, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"19\": shape (2, 57798, 17), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 17/18 [10:17<00:08,  8.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "\tOH stack size = torch.Size([1, 18, 10540])\n",
      "\t1 chunks of size 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCM stack shape = torch.Size([1, 57798, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"20\": shape (1, 57798, 18), type \"<f8\">"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 18/18 [10:18<00:00,  5.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "#after driver update:\n",
    "\n",
    "#chunk size 100 -> ≈?m on tarski, peak GPU usage around ?GB\n",
    "#chunk size 2000 -> \n",
    "#chunk size 3000 -> ≈10m on tarski, peak GPU usage around ?GB\n",
    "\n",
    "my_ext = '.hdf5'\n",
    "OD_by_length_wordform_fp = o + '_by_length_by_wordform_index' + my_ext\n",
    "with h5py.File(OD_by_length_wordform_fp, 'w') as f:\n",
    "#     length_to_prefix_CMs = []\n",
    "    # length_to_prefix_CMs = dict()\n",
    "    \n",
    "    chunk_size = 3000\n",
    "#     chunk_size = 2000\n",
    "#     chunk_size = 1000\n",
    "#     chunk_size = 100\n",
    "#     chunk_size = 300\n",
    "    \n",
    "    for l in tqdm(length_to_wordform_OH_matrices):\n",
    "        if length_to_wordform_OH_matrices[l].size()[1] == 0:\n",
    "            \n",
    "            #see http://docs.h5py.org/en/stable/high/dataset.html#creating-and-reading-empty-or-null-datasets-and-attributes\n",
    "            f.create_dataset(str(l), dtype='float64') #h5py empty \n",
    "#             length_to_prefix_CMs.append(None)\n",
    "    #         length_to_prefix_CMs[l] = None\n",
    "        else:\n",
    "            memTrigger()\n",
    "\n",
    "            print('-' * 40)\n",
    "            print(f\"\\tOH stack size = {length_to_wordform_OH_matrices[l].size()}\")\n",
    "\n",
    "            chunks = chunkList(chunk_size, length_to_wordform_OH_matrices[l])\n",
    "            print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "            \n",
    "            try:\n",
    "                chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "                                               chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "                                  for chunk in tqdm(chunks, total=len(chunks))]\n",
    "            except:\n",
    "                print(f'Chunk size {chunk_size} too large')\n",
    "                torch.cuda.empty_cache()\n",
    "                if chunk_size > 1000:\n",
    "                    chunk_size = chunk_size - 1000\n",
    "                    print(f'Reducing chunk size by 1000 to {chunk_size}')\n",
    "                    chunks = chunkList(chunk_size, length_to_wordform_OH_matrices[l])\n",
    "                    print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "                    try:\n",
    "                        chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "                                               chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "                                  for chunk in tqdm(chunks, total=len(chunks))]\n",
    "                    except:\n",
    "                        print(f'Chunk size {chunk_size} *still * too large')\n",
    "                        torch.cuda.empty_cache()\n",
    "                        if chunk_size > 1000:\n",
    "                            chunk_size = chunk_size - 1000\n",
    "                            print(f'Reducing chunk size by another 1000 to {chunk_size}')\n",
    "                        else:\n",
    "                            chunk_size = int(chunk_size / 2)\n",
    "                            print(f'Reducing chunk size by half to {chunk_size}')\n",
    "                        chunks = chunkList(chunk_size, length_to_wordform_OH_matrices[l])\n",
    "                        print(f\"\\t{len(chunks)} chunks of size {chunk_size}\")\n",
    "                        chunked_result = [torch.matmul(pC1X012_torch_c, \n",
    "                                               chunk.transpose(1,2).type(torch.double).cuda()).cpu()\n",
    "                                  for chunk in tqdm(chunks, total=len(chunks))]\n",
    "                else:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    raise Exception('Out of memory.')\n",
    "            del chunks\n",
    "            \n",
    "            result = torch.cat(chunked_result)\n",
    "            del chunked_result\n",
    "            print(f\"\\tCM stack shape = {result.shape}\")\n",
    "            result_np = result.numpy()\n",
    "            del result\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "#             length_to_prefix_CMs.append(result)\n",
    "    #         length_to_prefix_CMs[l] = result\n",
    "            f.create_dataset(str(l), result_np.shape, dtype='float64', data=result_np)\n",
    "            del result_np\n",
    "\n",
    "#             del chunks\n",
    "#             del chunked_result\n",
    "#             del result\n",
    "#             del result_np\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:26:05.942979Z",
     "start_time": "2019-09-12T02:26:05.234834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           187G         27G         42G         11M        117G        158G\r\n",
      "Swap:           18G         14M         18G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:26:10.938702Z",
     "start_time": "2019-09-12T02:26:05.946952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '3', '4', '5', '6', '7', '8', '9']>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OD_by_length_wordform_f = h5py.File(OD_by_length_wordform_fp, 'r')\n",
    "OD_by_length_wordform_f.keys()\n",
    "# OD_by_length_wordform_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T02:26:10.970527Z",
     "start_time": "2019-09-12T02:26:10.953638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tCM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_OD_by_length_by_wordform.hdf5\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_CMU_destressed_pseudocount0.01/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_OD_by_length_by_wordform.hdf5_metadata.json\n"
     ]
    }
   ],
   "source": [
    "CMs_by_length_by_wordform_md = {\n",
    "#     'r':r,\n",
    "    'length':len(length_to_wordform_OH_matrices),\n",
    "    'W':{'from fp':w,\n",
    "         'changes':'(x)CMs constructed from sorted prefixes of W; final ⋉ stripped',\n",
    "         'size':len(Ws_t)},\n",
    "    'P':{'from fp':w,\n",
    "         'changes':'(x)CMs constructed from sorted prefixes of W after final ⋉ stripped',\n",
    "         'size':len(Ps_t)},\n",
    "    'C':{'from fp':c,\n",
    "         'changes':'None'}\n",
    "}\n",
    "\n",
    "my_fp = o + '_by_length_by_wordform_index.hdf5'\n",
    "exportMatrixMetadata(my_fp + '_metadata.json',\n",
    "                     my_fp,\n",
    "                     None,\n",
    "                     CMs_by_length_by_wordform_md,\n",
    "                     'Step 4e',\n",
    "                     'Calculate segmental wordform and prefix channel matrices',\n",
    "                     {'organization':'Each l maps to a pytorch tensor of dim (n_{l-2}, |Y012s|, l-2), where the ordering of the first dimension corresponds to alphabetical order of wordforms of length l.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Run driver notebook from 3e down through 4e\n",
    "# Run this notebook (either manually or setting up a new subsetp in 4e) \n",
    "# Run driver on 5a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
