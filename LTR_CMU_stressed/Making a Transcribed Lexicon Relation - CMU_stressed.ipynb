{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:07.758335Z",
     "start_time": "2019-05-14T18:15:07.755423Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import data</a></span></li><li><span><a href=\"#Project-down-to-orthography-and-transcription-columns\" data-toc-modified-id=\"Project-down-to-orthography-and-transcription-columns-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Project down to orthography and transcription columns</a></span></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any given notebook like this is designed to produce a `.tsv` file with two columns from an arbitrary source\n",
    " - orthographic wordforms\n",
    " - transcribed wordforms\n",
    " \n",
    "i.e. to define a relation between orthographic wordforms and transcribed wordforms.\n",
    "\n",
    "The transcribed lexicon relation file can then be used somewhat more uniformly by downstream processing notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:18.168209Z",
     "start_time": "2019-05-14T18:15:18.165676Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import chdir, getcwd, listdir, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:18.423112Z",
     "start_time": "2019-05-14T18:15:18.420455Z"
    }
   },
   "outputs": [],
   "source": [
    "lexiconDataInFilename = 'cmudict-0.7b_IPA_stressed.tsv'\n",
    "\n",
    "lexiconDataOutFilename = 'LTR_CMU_stressed.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:18.857173Z",
     "start_time": "2019-05-14T18:15:18.844088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cube/home/AD/emeinhar/wr/LTR_CMU_stressed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:19.477344Z",
     "start_time": "2019-05-14T18:15:19.475258Z"
    }
   },
   "outputs": [],
   "source": [
    "orthography_out_fieldname = 'Orthographic_Wordform'\n",
    "transcription_out_fieldname = 'Transcription'\n",
    "fieldnames_out = (orthography_out_fieldname, transcription_out_fieldname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:19.639009Z",
     "start_time": "2019-05-14T18:15:19.635110Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:20.421035Z",
     "start_time": "2019-05-14T18:15:19.942011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133854"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['Orthography', 'Transcription'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Orthography', '!EXCLAMATION-POINT'),\n",
       "             ('Transcription', 'ɛ2.k.s.k.l.ʌ0.m.eɪ1.ʃ.ʌ0.n.p.ɔɪ2.n.t')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_in = []\n",
    "with open(lexiconDataInFilename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    my_reader = csv.DictReader(csvfile, delimiter='\\t', quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "    for row in my_reader:\n",
    "        #print(row)\n",
    "        lexicon_in.append(row)\n",
    "\n",
    "len(lexicon_in)\n",
    "lexicon_in[0].keys()\n",
    "lexicon_in[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project down to orthography and transcription columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:21.421281Z",
     "start_time": "2019-05-14T18:15:21.419377Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:21.730959Z",
     "start_time": "2019-05-14T18:15:21.727261Z"
    }
   },
   "outputs": [],
   "source": [
    "def project(raw_row):\n",
    "    new_row = OrderedDict()\n",
    "    new_row[orthography_out_fieldname] = raw_row['Orthography']\n",
    "    new_row[transcription_out_fieldname] = raw_row['Transcription']\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:22.389962Z",
     "start_time": "2019-05-14T18:15:22.168735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133854"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Orthographic_Wordform', '!EXCLAMATION-POINT'),\n",
       "             ('Transcription', 'ɛ2.k.s.k.l.ʌ0.m.eɪ1.ʃ.ʌ0.n.p.ɔɪ2.n.t')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_out = list(map(project,\n",
    "                       lexicon_in))\n",
    "len(lexicon_out)\n",
    "lexicon_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:24.106946Z",
     "start_time": "2019-05-14T18:15:23.822091Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(lexiconDataOutFilename, 'w', newline='\\n') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames_out, delimiter='\\t', quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(lexicon_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:24.558658Z",
     "start_time": "2019-05-14T18:15:24.551747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cube/home/AD/emeinhar/wr/LTR_CMU_stressed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Making a Transcribed Lexicon Relation - CMU_stressed.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'cmudict-0.7b_IPA_stressed.tsv',\n",
       " 'LTR_CMU_stressed.tsv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()\n",
    "listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T18:15:29.875180Z",
     "start_time": "2019-05-14T18:15:29.757201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tOrthographic_Wordform\tTranscription\r",
      "\r\n",
      "     2\t!EXCLAMATION-POINT\tɛ2.k.s.k.l.ʌ0.m.eɪ1.ʃ.ʌ0.n.p.ɔɪ2.n.t\r",
      "\r\n",
      "     3\t\"CLOSE-QUOTE\tk.l.oʊ1.z.k.w.oʊ1.t\r",
      "\r\n",
      "     4\t\"DOUBLE-QUOTE\td.ʌ1.b.ʌ0.l.k.w.oʊ1.t\r",
      "\r\n",
      "     5\t\"END-OF-QUOTE\tɛ1.n.d.ʌ0.v.k.w.oʊ1.t\r",
      "\r\n",
      "     6\t\"END-QUOTE\tɛ1.n.d.k.w.oʊ1.t\r",
      "\r\n",
      "     7\t\"IN-QUOTES\tɪ1.n.k.w.oʊ1.t.s\r",
      "\r\n",
      "     8\t\"QUOTE\tk.w.oʊ1.t\r",
      "\r\n",
      "     9\t\"UNQUOTE\tʌ1.n.k.w.oʊ1.t\r",
      "\r\n",
      "    10\t#HASH-MARK\th.æ1.m.ɑ2.ɹ.k\r",
      "\r\n",
      "    11\t#POUND-SIGN\tp.aʊ1.n.d.s.aɪ2.n\r",
      "\r\n",
      "    12\t#SHARP-SIGN\tʃ.ɑ1.ɹ.p.s.aɪ2.n\r",
      "\r\n",
      "    13\t%PERCENT\tp.ɚ0.s.ɛ1.n.t\r",
      "\r\n",
      "    14\t&AMPERSAND\tæ1.m.p.ɚ0.s.æ2.n.d\r",
      "\r\n",
      "    15\t'ALLO\tɑ2.l.oʊ1\r",
      "\r\n",
      "    16\t'APOSTROPHE\tʌ0.p.ɑ1.s.t.ɹ.ʌ0.f.i0\r",
      "\r\n",
      "    17\t'BOUT\tb.aʊ1.t\r",
      "\r\n",
      "    18\t'CAUSE\tk.ʌ0.z\r",
      "\r\n",
      "    19\t'COURSE\tk.ɔ1.ɹ.s\r",
      "\r\n",
      "    20\t'CUSE\tk.j.u1.z\r",
      "\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!cat -n LTR_CMU_stressed.tsv | head -20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
