{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.744412Z",
     "start_time": "2019-05-14T20:14:56.742181Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import data</a></span></li><li><span><a href=\"#Project-down-to-orthography-and-transcription-columns\" data-toc-modified-id=\"Project-down-to-orthography-and-transcription-columns-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Project down to orthography and transcription columns</a></span></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any given notebook like this is designed to produce a `.tsv` file with two columns from an arbitrary source\n",
    " - orthographic wordforms\n",
    " - transcribed wordforms\n",
    " \n",
    "i.e. to define a relation between orthographic wordforms and transcribed wordforms.\n",
    "\n",
    "The transcribed lexicon relation file can then be used somewhat more uniformly by downstream processing notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.820299Z",
     "start_time": "2019-05-14T20:14:56.748286Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import chdir, getcwd, listdir, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.826020Z",
     "start_time": "2019-05-14T20:14:56.821828Z"
    }
   },
   "outputs": [],
   "source": [
    "lexiconDataInFilename = 'newdic_IPA.tsv'\n",
    "\n",
    "lexiconDataOutFilename = 'LTR_newdic_destressed.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.836424Z",
     "start_time": "2019-05-14T20:14:56.826874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cube/home/AD/emeinhar/wr/LTR_newdic_destressed'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.839700Z",
     "start_time": "2019-05-14T20:14:56.837954Z"
    }
   },
   "outputs": [],
   "source": [
    "orthography_out_fieldname = 'Orthographic_Wordform'\n",
    "transcription_out_fieldname = 'Transcription'\n",
    "fieldnames_out = (orthography_out_fieldname, transcription_out_fieldname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.846922Z",
     "start_time": "2019-05-14T20:14:56.840995Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.942595Z",
     "start_time": "2019-05-14T20:14:56.847796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19528"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['Transcription', 'stressInfoA', 'stressInfoB', 'Orthography', 'Frequency', 'PoSs'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Transcription', 'ə'),\n",
       "             ('stressInfoA', '_'),\n",
       "             ('stressInfoB', 'S1'),\n",
       "             ('Orthography', 'a'),\n",
       "             ('Frequency', '23178'),\n",
       "             ('PoSs', '(N IA VB PP)')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_in = []\n",
    "with open(lexiconDataInFilename) as csvfile:\n",
    "    my_reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "    for row in my_reader:\n",
    "        #print(row)\n",
    "        lexicon_in.append(row)\n",
    "\n",
    "len(lexicon_in)\n",
    "lexicon_in[0].keys()\n",
    "lexicon_in[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project down to orthography and transcription columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.945242Z",
     "start_time": "2019-05-14T20:14:56.943597Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.951809Z",
     "start_time": "2019-05-14T20:14:56.946247Z"
    }
   },
   "outputs": [],
   "source": [
    "def project(raw_row):\n",
    "    new_row = OrderedDict()\n",
    "    new_row[orthography_out_fieldname] = raw_row['Orthography']\n",
    "    new_row[transcription_out_fieldname] = raw_row['Transcription']\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:56.973056Z",
     "start_time": "2019-05-14T20:14:56.952729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19528"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Orthographic_Wordform', 'a'), ('Transcription', 'ə')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_out = list(map(project,\n",
    "                       lexicon_in))\n",
    "len(lexicon_out)\n",
    "lexicon_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:57.027118Z",
     "start_time": "2019-05-14T20:14:56.974121Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(lexiconDataOutFilename, 'w', newline='\\n') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames_out, delimiter='\\t')\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(lexicon_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:57.031394Z",
     "start_time": "2019-05-14T20:14:57.028289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/cube/home/AD/emeinhar/wr/LTR_newdic_destressed'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['LTR_newdic_destressed.tsv',\n",
       " 'newdic_IPA.tsv',\n",
       " 'Making a Transcribed Lexicon Relation - newdic.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()\n",
    "listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T20:14:57.146039Z",
     "start_time": "2019-05-14T20:14:57.032361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: LTR_newdic.tsv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat -n LTR_newdic.tsv | head -20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
