{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:18:52.686218Z",
     "start_time": "2018-03-31T23:18:52.674785Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Motivation/Problem-Statement\" data-toc-modified-id=\"Motivation/Problem-Statement-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation/Problem Statement</a></div><div class=\"lev2 toc-item\"><a href=\"#Code-requirements\" data-toc-modified-id=\"Code-requirements-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Code requirements</a></div><div class=\"lev2 toc-item\"><a href=\"#Exposition-/-other-notebooks\" data-toc-modified-id=\"Exposition-/-other-notebooks-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exposition / other notebooks</a></div><div class=\"lev2 toc-item\"><a href=\"#Boilerplate-code-for-representing-and-manipulating-probability-distributions\" data-toc-modified-id=\"Boilerplate-code-for-representing-and-manipulating-probability-distributions-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Boilerplate code for representing and manipulating probability distributions</a></div><div class=\"lev1 toc-item\"><a href=\"#Developing-a-model-of-a-BSC-with-input-signals-of-varying-length-and-a-'uniphone'-noise/channel-distribution\" data-toc-modified-id=\"Developing-a-model-of-a-BSC-with-input-signals-of-varying-length-and-a-'uniphone'-noise/channel-distribution-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Developing a model of a BSC with input signals of varying length and a 'uniphone' noise/channel distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#Defining-p(X_0^f)-and-related-input-pmfs\" data-toc-modified-id=\"Defining-p(X_0^f)-and-related-input-pmfs-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Defining $p(X_0^f)$ and related input pmfs</a></div><div class=\"lev3 toc-item\"><a href=\"#Convenient-values/functions-defiend-in-terms-of-p(X_0^f)-(prefixes,-suffixes,-etc.)\" data-toc-modified-id=\"Convenient-values/functions-defiend-in-terms-of-p(X_0^f)-(prefixes,-suffixes,-etc.)-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Convenient values/functions defiend in terms of $p(X_0^f)$ (prefixes, suffixes, etc.)</a></div><div class=\"lev2 toc-item\"><a href=\"#Defining-p(Y_j|x_j)-and-related-channel-pmfs\" data-toc-modified-id=\"Defining-p(Y_j|x_j)-and-related-channel-pmfs-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Defining $p(Y_j|x_j)$ and related channel pmfs</a></div><div class=\"lev2 toc-item\"><a href=\"#Defining-hat{p}(\\widehat{x}_0^j|x_0^i)\" data-toc-modified-id=\"Defining-hat{p}(\\widehat{x}_0^j|x_0^i)-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Defining $\\hat{p}(\\widehat{x}_0^j|x_0^i)$</a></div><div class=\"lev1 toc-item\"><a href=\"#Generating-test-lexicons-and-noise-distributions\" data-toc-modified-id=\"Generating-test-lexicons-and-noise-distributions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Generating test lexicons and noise distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#Generating-p(X_0^f)\" data-toc-modified-id=\"Generating-p(X_0^f)-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Generating $p(X_0^f)$</a></div><div class=\"lev2 toc-item\"><a href=\"#Generating-p(Y_i|x_i)\" data-toc-modified-id=\"Generating-p(Y_i|x_i)-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generating $p(Y_i|x_i)$</a></div><div class=\"lev1 toc-item\"><a href=\"#Generating-model-code\" data-toc-modified-id=\"Generating-model-code-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Generating model code</a></div><div class=\"lev2 toc-item\"><a href=\"#Input/source-model...\" data-toc-modified-id=\"Input/source-model...-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Input/source model...</a></div><div class=\"lev2 toc-item\"><a href=\"#Channel-model...\" data-toc-modified-id=\"Channel-model...-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Channel model...</a></div><div class=\"lev2 toc-item\"><a href=\"#Total-model...\" data-toc-modified-id=\"Total-model...-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Total model...</a></div><div class=\"lev2 toc-item\"><a href=\"#Testing-the-generated-code-on-the-generated-lexicon-and-noise-distributions\" data-toc-modified-id=\"Testing-the-generated-code-on-the-generated-lexicon-and-noise-distributions-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Testing the generated code on the generated lexicon and noise distributions</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation/Problem Statement\n",
    "\n",
    "The goal of this collection of notebooks ('Model Notebook k', $k \\in \\{0, 1, 2, 3\\}$) is to document/develop code for calculations related to an isolated word recognition task where:\n",
    "\n",
    " - A *lexicon* $\\mathcal{L}$ is a set of **wordforms**  $w$, where a **wordform** is a finite sequence $s_0, s_1, s_2 ... s_f$ of segments, and $s_0^i$ denotes the prefix of some wordform $w \\in \\mathcal{L}$ such that $f = |w| - 1$ and such that $w$ begins with segments $s_0, s_1, ..., s_i$, where $0 \\leq i \\leq f$.\n",
    " - In a single episode of the task, a **speaker** samples a wordform $w = s_0^f$ from $\\mathcal{L} \\sim p(s_0^f)$.\n",
    " - The speaker incrementally produces their intended wordform (one segment at a time, for our purposes) and the **listener** incrementally perceives $\\sigma_0^i \\sim p(\\sigma_0^i | s_0^i)$.\n",
    " - The listener considers what they have perceived so far $\\sigma_0^i$ and reasons about what the most likely actual intended wordform of the speaker is $\\sim p(\\hat{s_0^f}|\\sigma_0^i) \\propto p(\\sigma_0^i|s_0^f) p(s_0^f) = p(\\sigma_0^i|s_0^i) p(s_0^i)$.\n",
    "\n",
    "\n",
    "In particular, we want, for each possible intended wordform $s_0^f \\in \\mathcal{L}$, for each possible prefix $s_0^i$ of $s_0^f$, the listener's expected distribution over the speaker's intended wordform given the actual prefix produced so far $s_0^i$, where the expectation is taken with respect to possible perceived sequences $\\sigma_0^i$: \n",
    "\n",
    "$$p(\\hat{s_0^f}|s_0^i) = \\sum_\\limits{\\sigma_0^i} p(s_0^f|\\sigma_0^i)p(\\sigma_0^i|s_0^i) \\propto \\sum_\\limits{\\sigma_0^i} p(\\sigma_0^i|\\hat{s_0^f})p(\\hat{s_0^f})p(\\sigma_0^i|s_0^i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code requirements\n",
    "\n",
    "The code for calculating \n",
    "$$p(\\hat{s_0^f}|s_0^i) = \\sum_\\limits{\\sigma_0^i} p(s_0^f|\\sigma_0^i)p(\\sigma_0^i|s_0^i) \\propto \\sum_\\limits{\\sigma_0^i} p(\\sigma_0^i|\\hat{s_0^f})p(\\hat{s_0^f})p(\\sigma_0^i|s_0^i)$$\n",
    "needs to take only two basic inputs:\n",
    "\n",
    " - a prior distribution over the lexicon $p(s_0^f) = p(\\hat{s_0^f})$.\n",
    " - an incrementally defined channel distribution $p(\\sigma_0^i|s_0^i) = p(\\sigma_0^i|\\hat{s_0^i})$, defined (for now) in terms of a uniphone channel distribution $p(\\sigma_i|s_i)$, where the distribution over what segment the listener perceives as the $i$th one depends (by assumption) *only* on the actual $i$th segment $s_i$ the speaker produced (if they've actually produced it at the time we're asking about).\n",
    "\n",
    "from which it needs to generate all relevant code and representations of probability distributions or means of estimating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposition / other notebooks\n",
    "\n",
    "*Notebook 0* introduces the model being developed and implemented, the organization of other notebooks in the collection, and introduces the adapted form of Peter Norvig's code for conveniently representing and manipulating probability distributions that I make use of in other notebooks.\n",
    "\n",
    "*This notebook*, *Notebook 1* introduces the final model implementation and the derivations underlying its implementation and does so using randomly generated but highly constrained binary lexicons with a simple noise model. It is intended to introduce the model implementation/derivation in a context where the behavior and purpose (and basic correctness) of code is discernable by going through the notebook and the generated example.\n",
    "\n",
    "*Notebook 2* is more for testing purposes. It contains multiple implementations of the model. One is defined entirely in terms of the abstractions Peter Norvig provides -- abstractions that cannot scale but which were easy to use and whose correctness I have high confidence in. The second implementation is the one presented in notebooks 1 and 3. \n",
    "\n",
    "*Notebook 3* is a demonstration notebook where real data is loaded and largely the same queries as here calculated, plus some timing experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate code for representing and manipulating probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:18:57.400612Z",
     "start_time": "2018-03-31T23:18:56.717850Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#from \n",
    "#    http://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb\n",
    "#    http://nbviewer.jupyter.org/url/norvig.com/ipython/ProbabilityParadox.ipynb\n",
    "#with slight modification.\n",
    "\n",
    "from fractions import Fraction\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def P(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "    \n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...};\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...};\n",
    "    in both cases only with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}\n",
    "\n",
    "# class ProbDist(dict):\n",
    "class ProbDist(Counter):\n",
    "    \"A Probability Distribution; an {outcome: probability} mapping where probabilities sum to 1.\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        total = sum(self.values())\n",
    "        if isinstance(total, int): \n",
    "            total = Fraction(total, 1)\n",
    "        for key in self: # Make probabilities sum to 1.\n",
    "            self[key] = self[key] / total\n",
    "            \n",
    "    def __and__(self, predicate): # Call this method by writing `probdist & predicate`\n",
    "        \"A new ProbDist, restricted to the outcomes of this ProbDist for which the predicate is true.\"\n",
    "        return ProbDist({e:self[e] for e in self if predicate(e)})\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for k in self:\n",
    "            if isinstance(self[k], Fraction):\n",
    "                s+=\"{0}: {2}/{3} = {1}\\n\".format(transcriptionReprHack(k), float(self[k]), self[k].numerator, self[k].denominator)\n",
    "            else:\n",
    "                s+=\"{0}: {1}\\n\".format(transcriptionReprHack(k), float(self[k]))\n",
    "        return s\n",
    "\n",
    "dottedStringToTuple = lambda ds: tuple(ds.split('.'))\n",
    "tupleToDottedString = lambda t: '.'.join(t)\n",
    "\n",
    "def transcriptionReprHack(k):\n",
    "    if type(k) == type(tuple()):\n",
    "        if all(map(lambda el: type(el) == type(''), k)):\n",
    "            return tupleToDottedString(k)\n",
    "    return k.__repr__()    \n",
    "\n",
    "def Uniform(outcomes): return ProbDist({e: 1 for e in outcomes})\n",
    "\n",
    "def joint(A, B):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {(a, b): P(a) * P(b)}\"\"\"\n",
    "    return ProbDist({(a,b): A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "def union(iterable):\n",
    "    return reduce(set.union, iterable)\n",
    "\n",
    "def joint2(iter_of_dists):\n",
    "    #ProbDist({(a,b): A[a] * B[b] for a in A for b in B})\n",
    "    #ProbDist({ab: A[ab[0]] * B[ab[1]] for ab in product(A,B)})\n",
    "    return ProbDist({each : prod(dist[each[i]] for i,dist in enumerate(iter_of_dists)) for each in list(product(*iter_of_dists))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:19:03.018039Z",
     "start_time": "2018-03-31T23:19:02.738839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bookkeeping - don't worry about this function...\n",
    "def getBoundaryVal(dist, i):\n",
    "    #p = {a:1/2, b:1/2} -> 2 items -> 2-1=1 boundaries where \n",
    "    #                   the boundary separating 'a' (item 0) from 'b' (item 1) is at 0+p(a)\n",
    "    #q = {0:1/3, 1:1/3, 2:1/6, 3:1/6} -> 4 items -> 4-1=3 boundaries where \n",
    "    #                   the boundary separating 0 from 1   is at 0 + q(0) = 1/3,\n",
    "    #                   the boundary separating 1 from 2   is at 0 + q(0) + q(1) = 2/3,\n",
    "    #                   the boundary separating 2 from 3   is at 0 + q(0) + q(1) + q(2) = 5/6,\n",
    "    #                ...the boundary separating i from i+1 is at \\sum_{j=0}^{j=i} q(j)\n",
    "    outcomes = list(dist.keys())\n",
    "    if i >= len(outcomes) - 1:\n",
    "        raise Exception(\"Boundary i = {0} out of bounds / does not exist for distribution {1} with {2} outcomes.\".format(i, dist, len(outcomes)))\n",
    "    if i == 0:\n",
    "        return dist[outcomes[0]]\n",
    "    return dist[outcomes[i]] + getBoundaryVal(dist, i-1)\n",
    "\n",
    "#bookkeeping - don't worry about this function...\n",
    "def getSampleOutcomeIndex(randReal, boundariesLeft, currIndex):\n",
    "#     print(\"boundariesLeft: {0}\".format(boundariesLeft))\n",
    "#     print(\"currIndex: {0}\".format(currIndex))\n",
    "    if boundariesLeft == [] or randReal <= boundariesLeft[0]:\n",
    "        return currIndex\n",
    "    return getSampleOutcomeIndex(randReal, boundariesLeft[1:], currIndex + 1)\n",
    "\n",
    "\n",
    "def sampleFrom(dist, num_samples = None):\n",
    "    \"\"\"\n",
    "    Given a distribution (either an {outcome: probability} mapping where the \n",
    "    probabilities sum to 1 or an implicit definition of a distribution via a thunk), \n",
    "    this returns a single sample from the distribution, unless num_samples is specified, \n",
    "    in which case a generator with num_samples samples is returned.\n",
    "    \"\"\"\n",
    "    if num_samples == None:\n",
    "        if callable(dist):\n",
    "            return dist()\n",
    "        elif isinstance(dist, ProbDist):\n",
    "            outcomes = list(dist.keys())\n",
    "        #     print(\"outcomes: {0}\".format(outcomes))\n",
    "\n",
    "            boundaries = [getBoundaryVal(dist, i) for i in range(len(outcomes)-1)]\n",
    "        #     print(\"boundaries: {0}\".format(boundaries))\n",
    "\n",
    "            randVal = random.random() #random real from unit interval\n",
    "        #     print(\"randval: {0}\".format(randVal))\n",
    "\n",
    "            sampledOutcomeIndex = getSampleOutcomeIndex(randVal, boundaries, 0)\n",
    "        #     print(\"sampledOutcomeIndex: {0}\".format(sampledOutcomeIndex))\n",
    "            if not (sampledOutcomeIndex >= 0 and sampledOutcomeIndex < len(outcomes)):\n",
    "                print('sampledOutcomeIndex: {0}'.format(sampledOutcomeIndex))\n",
    "                print('len(outcomes): {0}'.format(len(outcomes)))\n",
    "                if len(outcomes) == 0:\n",
    "                    print('len(outcomes) == 0! dist:')\n",
    "                    print(type(dist))\n",
    "                    print(dist)\n",
    "            assert(sampledOutcomeIndex >= 0 and sampledOutcomeIndex < len(outcomes))\n",
    "\n",
    "            sampledOutcome = outcomes[sampledOutcomeIndex]\n",
    "        #     print(\"sampledOutcome: {0}\".format(sampledOutcome))\n",
    "            return sampledOutcome\n",
    "    else:\n",
    "        if callable(dist):\n",
    "            return (dist() for each in range(num_samples))\n",
    "        elif isinstance(dist, ProbDist):\n",
    "            return (sampleFrom(dist, num_samples = None) for each in range(num_samples))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def frequencies(samples):\n",
    "    return Counter(samples)\n",
    "\n",
    "def makeSampler(dist):\n",
    "    \"\"\"\n",
    "    Given a ProbDist, returns a thunk that when called, returns one sample from dist.\n",
    "    \"\"\"\n",
    "    return lambda: sampleFrom(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:19:04.070879Z",
     "start_time": "2018-03-31T23:19:04.064619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftEdge = '⋊'\n",
    "rightEdge = '⋉'\n",
    "edgeSymbols = set([leftEdge, rightEdge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a model of a BSC with input signals of varying length and a 'uniphone' noise/channel distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 'word recognition model' with a small lexicon over a tiny segment inventory ($\\{0,1\\}$) and a simple channel distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more detail, by \"BSC with sequential input\" I really mean something easy to program and similar to my eventual application/goal:\n",
    " - The sender picks a sequence $X_0^f$ (e.g. 'cigarette') from a finite list of input sequences according to a commonly known distribution $p(X_0^f)$\n",
    "     - here, the list of sequences has somewhere between 2-5 sequences\n",
    "     - here, each sequence is 1-5 symbols long (not including word boundary symbols)\n",
    "       - Note that for $0 \\leq i \\leq f$, $x_i$ is *never* a word boundary symbol, but $x_{-1}$ and $x_{f+1}$ are the left and right word edge symbols.\n",
    "     - here, each symbol in a given sequence is chosen by sampling from a distribution $p(X_i)$ over a single symbol (not including word boundary symbols)\n",
    "     - here, $p(X_0^f)$ is the uniform distribution for ease of implementation\n",
    " - Here and in the uniphone noise model for word recognition, the channel output for the $ith$ symbol in any input sequence depends only on the actual $ith$ input symbol:\n",
    "     - $p(y_0^i|x_0^i) = \\prod_\\limits{j=0}^{j=i} p(y_j|x_j)$\n",
    "     - Word boundary symbols are assumed to always be perfectly transmitted.\n",
    " - As the production of the sender/speaker's intended sequence/wordform $x_0^f$ unfolds, only some prefix of it $x_0^i$ has actually been produced so far.\n",
    " - Given that $x_0^i$ has been produced/sent, the receiver/listener perceives some possibly noise-corrupted sequence (e.g. 'shigarette') and uses their beliefs about what signals/wordforms are more or less likely to be produced and how channel noise works to *estimate* what the speaker's intended wordform $\\hat{x_0^f}$ is (or any prefix thereof $\\hat{x_0^j}$) - e.g. 'shigarette' isn't a word of English, but 'cigarette' is and [s] can relatively easily be misheard (or misproduced) as [ʃ], so the speaker's most likely intended wordform is 'cigarette'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the exact equation for the receiver/listener's incremental degree of belief that the sender/speaker's intended input sequence is $\\hat{x}_0^f$ given that the speaker has actually produced $x_0^i$ of their actual intended sequence/wordform $x_0^f$:\n",
    "\n",
    "$$p(\\hat{x_0^f}|x_0^i) = \\sum_\\limits{y_0^i} p(\\hat{x}_0^f|y_0^i)p(y_0^i|x_0^i) = \\sum_\\limits{y_0^i} \\frac{p(y_0^i|\\hat{x_0^f})p(\\hat{x_0^f})}{p(y_0^i)}p(y_0^i|x_0^i) = \\sum_\\limits{y_0^i} \\frac{p(y_0^i|\\hat{x_0^i})p(\\hat{x_0^f})}{p(y_0^i)}p(y_0^i|x_0^i) $$\n",
    "where \n",
    " - $p(\\hat{X}_0^f) = p(X_0^f)$\n",
    " - $p(y_0^i|\\hat{x}_0^i) = p(y_0^i|x_0^i) = \\prod_\\limits{j=0}^{j=i} p(y_j|x_j)$, and where $p(y_j|x_j)$ doesn't depend on $j$ / is independent of $j$ given $x_j$.\n",
    " - $p(y_0^i) = \\sum_\\limits{x_0^i} p(y_0^i|x_0^i)p(x_0^i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MC estimator $\\hat{p}(\\hat{x}_0^f|x_0^i)$ is calcualted as follows:\n",
    "\n",
    "$$\\hat{p}(\\hat{x_0^f}|x_0^i) = \\frac{1}{n} \\sum_\\limits{n \\text{ samples from } p(Y_0^i|x_0^i)}  p(\\hat{x}_0^f|y_0^i) = \\frac{1}{n} \\sum_\\limits{n \\text{ samples from } p(Y_0^i|x_0^i)} \\frac{p(y_0^i|\\hat{x_0^f})p(\\hat{x_0^f})}{p(y_0^i)} = \\frac{1}{n} \\sum_\\limits{n \\text{ samples from } p(Y_0^i|x_0^i)} \\frac{p(y_0^i|\\hat{x_0^i})p(\\hat{x_0^f})}{p(y_0^i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the two key defining objects are $p(X_0^f)$ (defined via $p(X_i)$ and a procedure for constructing lexicons from $p(X_i)$) and $p(Y_i|X_i)$, and I'll be using them to calculate:\n",
    " - $p(y_0^i|x_0^i)$ and a function for sampling from $p(Y_0^i|x_0^i)$\n",
    " - $p(y_0^i)$\n",
    " - a Monte Carlo estimator $\\hat{p}(\\widehat{x}_0^j|x_0^i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining $p(X_0^f)$ and related input pmfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:20:56.535997Z",
     "start_time": "2018-03-31T23:20:56.407787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numInputs = |'lexicon'| ≤ 5\n",
      "inputs = 'lexicon' = {('⋊', 1, 0, '⋉'), ('⋊', 0, 1, 1, 1, '⋉'), ('⋊', 1, 1, 0, 0, '⋉'), ('⋊', 1, '⋉')}\n",
      "p(X_0^f) = prior over the lexicon = uniform:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProbDist({('⋊', 0, 1, 1, 1, '⋉'): Fraction(1, 4),\n",
       "          ('⋊', 1, '⋉'): Fraction(1, 4),\n",
       "          ('⋊', 1, 0, '⋉'): Fraction(1, 4),\n",
       "          ('⋊', 1, 1, 0, 0, '⋉'): Fraction(1, 4)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining p(X_0^f) as a dist\n",
    "\n",
    "bits = set([0, 1])\n",
    "\n",
    "useEdgeSymbols = True\n",
    "leftEdge = '⋊'\n",
    "rightEdge = '⋉'\n",
    "edgeSymbols = set([leftEdge, rightEdge])\n",
    "\n",
    "# p(X_i)\n",
    "inputDist_i = Uniform(bits)\n",
    "\n",
    "# function that samples from p(X_i)\n",
    "channelInput_i = makeSampler(inputDist_i)\n",
    "\n",
    "\n",
    "#define support of p(X_0^f), where 0 ≤ f ≤ 4...\n",
    "def generateInputSequence(x_i_sampler):\n",
    "    length = sampleFrom(Uniform(range(1,5)))\n",
    "    return tuple(x_i_sampler() for each in range(length))\n",
    "\n",
    "def padInputSequenceWithBoundaries(inputSeq):\n",
    "  temp = list(inputSeq)\n",
    "  temp = tuple([leftEdge] + temp + [rightEdge])\n",
    "  return temp\n",
    "\n",
    "def trimBoundariesFromSequence(seq):\n",
    "  temp = list(seq)\n",
    "  if temp[0] == leftEdge:\n",
    "    temp = temp[1:]\n",
    "  if temp[-1] == rightEdge:\n",
    "    temp = temp[:-1]\n",
    "  return tuple(temp)\n",
    "\n",
    "#...and the number of sequences n is s.t. 2 ≤ n ≤ 5 \n",
    "numInputs = sampleFrom(Uniform(range(2,6)))\n",
    "print(\"{0} ≤ {1}\".format(\"numInputs = |'lexicon'|\",numInputs))\n",
    "inputs = set([generateInputSequence(channelInput_i) for each in range(numInputs)])\n",
    "if useEdgeSymbols:\n",
    "  inputs = set(map(padInputSequenceWithBoundaries, inputs))\n",
    "print(\"{0} = {1}\".format(\"inputs = 'lexicon'\",inputs))\n",
    "\n",
    "# definition of p(X_0^f)\n",
    "inputDist = Uniform(inputs)\n",
    "print(\"p(X_0^f) = prior over the lexicon = uniform:\")\n",
    "inputDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we've defined $p(X_0^f)$ as a distribution object - we can reason about the whole distribution, calculate probabilities and conditional probabilities, and sample from the distribution/derived conditional distributions using the boilerplate code defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenient values/functions defiend in terms of $p(X_0^f)$ (prefixes, suffixes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:21:24.155558Z",
     "start_time": "2018-03-31T23:21:24.143008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, '⋊', '⋉'}\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "# convenient values and functions defined in terms of inputDist, part 1\n",
    "\n",
    "import itertools\n",
    "inputAlphabet = set(itertools.chain.from_iterable([set(k) for k in list(inputDist.keys())]))\n",
    "print(inputAlphabet)\n",
    "print(inputAlphabet - edgeSymbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:21:28.014191Z",
     "start_time": "2018-03-31T23:21:27.965071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST INPUT = ('⋊', 1, 0, '⋉')\n",
      "Prefixes of ('⋊', 1, 0, '⋉'):\n",
      "{('⋊',), ('⋊', 1, 0, '⋉'), ('⋊', 1, 0), ('⋊', 1)}\n",
      "<= 10 prefixes of lexicon:\n",
      "[('⋊', 1, 1), ('⋊', 1, 0), ('⋊', 1, 0, '⋉'), ('⋊', 0, 1, 1, 1), ('⋊', 1, 1, 0, 0), ('⋊', 0, 1, 1, 1, '⋉'), ('⋊', 0, 1, 1), ('⋊',), ('⋊', 1, 1, 0), ('⋊', 0, 1), ('⋊', 1, 1, 0, 0, '⋉')]\n",
      "TEST PREFIX = ('⋊', 1, 0)\n",
      "('⋊', 1, 0, '⋉') has ('⋊', 1, 0) as prefix?: True\n",
      "('⋊', 0, 1, 1, 1, '⋉') has ('⋊', 1, 0) as prefix?: False\n",
      "('⋊', 1, 1, 0, 0, '⋉') has ('⋊', 1, 0) as prefix?: False\n",
      "('⋊', 1, '⋉') has ('⋊', 1, 0) as prefix?: False\n"
     ]
    }
   ],
   "source": [
    "# convenient values and functions defined in terms of inputDist, part 2\n",
    "def getPrefixes(s):\n",
    "    return set(s[0:i] for i in range(1, len(s)+1))\n",
    "test_input = list(inputs)[0]\n",
    "print('TEST INPUT = {0}'.format(test_input))\n",
    "print('Prefixes of {0}:'.format(test_input))\n",
    "print(getPrefixes(test_input))\n",
    "\n",
    "prefixes = map(getPrefixes, inputs)\n",
    "prefixes = set(itertools.chain.from_iterable(prefixes))\n",
    "print(\"<= 10 prefixes of lexicon:\")\n",
    "print(list(prefixes)[0:11])\n",
    "def getHasPrefix(prefix):\n",
    "    l = len(prefix)\n",
    "    hasAsPrefix = lambda full_input_seq: full_input_seq[0:l] == prefix\n",
    "    return hasAsPrefix\n",
    "test_prefix = list(prefixes)[1]\n",
    "print('TEST PREFIX = {0}'.format(test_prefix))\n",
    "q = getHasPrefix(test_prefix)\n",
    "for each in list(inputs)[0:11]:\n",
    "    print(\"{0} has {1} as prefix?: {2}\".format(each, test_prefix, q(each)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:21:30.590041Z",
     "start_time": "2018-03-31T23:21:30.568978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SUFFIX: (0, '⋉')\n",
      "('⋊', 1, 0, '⋉') has (0, '⋉') as suffix?: True\n",
      "('⋊', 0, 1, 1, 1, '⋉') has (0, '⋉') as suffix?: False\n",
      "('⋊', 1, 1, 0, 0, '⋉') has (0, '⋉') as suffix?: True\n",
      "('⋊', 1, '⋉') has (0, '⋉') as suffix?: False\n"
     ]
    }
   ],
   "source": [
    "# convenient values and functions defined in terms of inputDist 3\n",
    "def getHasSuffix(suffix):\n",
    "    l = len(suffix)\n",
    "    hasAsSuffix = lambda full_input_seq: full_input_seq[-len(suffix):] == suffix\n",
    "    return hasAsSuffix\n",
    "test_suffix = test_input[len(test_input)-2:]\n",
    "print('TEST SUFFIX: {0}'.format(test_suffix))\n",
    "q = getHasSuffix(test_suffix)\n",
    "for each in list(inputs)[0:11]:\n",
    "    print(\"{0} has {1} as suffix?: {2}\".format(each, test_suffix, q(each)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the 3-4 cells above, we can now\n",
    " - calculate the set of all prefixes of a sequence (and therefore of the 'lexicon')\n",
    " - check whether one sequence is a prefix of another sequence\n",
    " - check whether one sequence is a suffix of another sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:21:38.201607Z",
     "start_time": "2018-03-31T23:21:38.132943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 1, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 0, 1, 1, 1, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, 1, 0, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, '⋉'): 1/4 = 0.25\n",
      "\n",
      "TEST PREFIX: ('⋊', 1, 0)\n",
      "p(x_0^i = ('⋊', 1, 0)) = 1/4\n",
      "p(X_0^f| x_0^i = ('⋊', 1, 0)):\n",
      "('⋊', 1, 0, '⋉'): 1/1 = 1.0\n",
      "\n",
      "TEST SUFFIX: (0, '⋉')\n",
      "Let j = i+1:\n",
      " p(x_j^f = (0, '⋉')|x_0^i = ('⋊', 1, 0)) = 0\n"
     ]
    }
   ],
   "source": [
    "# convenient values and functions defined in terms of inputDist 3\n",
    "\n",
    "# convenient calculation of p(x_0^i) as pmf, not as 'dist' \n",
    "def prefixProb(input_prefix):\n",
    "    hasAsPrefix = getHasPrefix(input_prefix)\n",
    "    return P(hasAsPrefix, inputDist)\n",
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, prefixProb(test_prefix)))\n",
    "\n",
    "\n",
    "# definition of p(X_0^f | x_0^i) as dist\n",
    "def inputDist_givenPrefix(prefix):\n",
    "    hasPrefix = getHasPrefix(prefix)\n",
    "    return inputDist & hasPrefix\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(inputDist_givenPrefix(test_prefix))\n",
    "\n",
    "# definition of p(X_{i+1}^f| x_0^i) as pmf, not as 'dist'\n",
    "def suffixProb(input_suffix, input_prefix):\n",
    "    #p(X_0^f | x_0^i)\n",
    "    d = inputDist_givenPrefix(input_prefix)\n",
    "    isExactlyEqualTo = lambda s: s == tuple(list(input_prefix) + list(input_suffix))\n",
    "    return P(isExactlyEqualTo, d)\n",
    "#     hasAsSuffix = getHasSuffix(input_suffix)\n",
    "#     return P(hasAsSuffix, d)\n",
    "print('TEST SUFFIX: {0}'.format(test_suffix))\n",
    "print('Let j = i+1:')\n",
    "print(' p(x_j^f = {0}|x_0^i = {1}) = {2}'.format(test_suffix, test_prefix, suffixProb(test_suffix, test_prefix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now \n",
    " - calculate $p(x_0^i)$\n",
    " - reason about the distribution $p(X_0^f|x_0^i)$\n",
    " - calculate $p(X_{i+1}^f| x_0^i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining $p(Y_j|x_j)$ and related channel pmfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:21:46.992267Z",
     "start_time": "2018-03-31T23:21:46.953605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Y_i|X_i = 0):\n",
      "0: 0.75\n",
      "1: 0.25\n",
      "\n",
      "p(Y_i|X_i = 1):\n",
      "0: 0.25\n",
      "1: 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definition of p(Y_i|X_i) as a dist\n",
    "\n",
    "pError_i = round(random.uniform(0.1,0.4), 2)\n",
    "pNoError_i = 1 - pError_i\n",
    "\n",
    "channelOutput_i_dist = {\n",
    "    0:         ProbDist({0: pNoError_i, 1:pError_i}),\n",
    "    1:         ProbDist({0: pError_i, 1:pNoError_i}),\n",
    "    leftEdge:  ProbDist({leftEdge: 1}),\n",
    "    rightEdge: ProbDist({rightEdge: 1})\n",
    "}\n",
    "\n",
    "# def channelOutput_i_dist(inputSymbol_i):\n",
    "#     if inputSymbol_i == 0:\n",
    "#         return ProbDist({0: pNoError_i, 1:pError_i})\n",
    "#     elif inputSymbol_i == 1:\n",
    "#         return ProbDist({0: pError_i, 1:pNoError_i})\n",
    "#     elif inputSymbol_i == leftEdge or inputSymbol_i == rightEdge:\n",
    "#         return ProbDist({inputSymbol_i: 1})\n",
    "\n",
    "print('p(Y_i|X_i = 0):')\n",
    "# print(channelOutput_i_dist(0))\n",
    "print(channelOutput_i_dist[0])\n",
    "print('p(Y_i|X_i = 1):')\n",
    "# print(channelOutput_i_dist(1))\n",
    "print(channelOutput_i_dist[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reason about the channel distribution at a single 'slice': $p(Y_j|x_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:21:49.047307Z",
     "start_time": "2018-03-31T23:21:49.035491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Y_i):\n",
      "0: 0.25\n",
      "1: 0.25\n",
      "'⋊': 0.25\n",
      "'⋉': 0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definition of p(Y_i) as a dist\n",
    "# channelOutput_i_marginal_dist = ProbDist({y: sum(channelOutput_i_dist(x)[y] for x in inputAlphabet) for y in inputAlphabet})\n",
    "channelOutput_i_marginal_dist = ProbDist({y: sum(channelOutput_i_dist[x][y] for x in inputAlphabet) for y in inputAlphabet})\n",
    "print(\"p(Y_i):\")\n",
    "print(channelOutput_i_marginal_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...as well as the marginal distribution $p(Y_i)$. \n",
    "\n",
    "(Strictly speaking, the notation here is inaccurate/misleading with respect to the use of the index: \n",
    " - for any given lexicon, the marginal distributions e.g. $p(Y_{i=0})$ and $p(Y_{i=1})$ can be different because $p(X_{i=0})$ and $p(X_{i=1})$ will in general be different\n",
    " - as well, word edge symbols have an a priori known index and are always perfectly transmitted -- i.e. $p(Y_i)$ depends on $i$, \n",
    "\n",
    "In spite of such facts, the function defined above doesn't make use of $i$-like information at all, but that's as intended -- it's supposed to represent the marginal distribution over $Y$ given some $x$ and no other information.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning to the channel distribution (defined below)...\n",
    "\n",
    "$p(y_0^i|\\hat{x_0^i}) = p(y_0^i|x_0^i) = \\prod_\\limits{j=0}^{j=i} p(y_j|x_j)$, and where $p(y_j|x_j)$ doesn't depend on $j$ / is independent of $j$ given $x_j$, but what should $$p(y_0^j|x_0^i)$$ be calculated?\n",
    "\n",
    "There are three cases:\n",
    " - $|y_0^j| = |x_0^i|$, where everything is simple: $p(y_0^i|x_0^i) = \\prod_\\limits{k=0}^{k=i} p(y_k|x_k)$\n",
    " - $|y_0^j| < |x_0^i|$, where we truncate irrelevant information (viz. the value of $x_{j+1}^i$) about the actually produced prefix: $p(y_0^j|x_0^i) = p(y_0^j|x_0^j) =  \\prod_\\limits{k=0}^{k=j} p(y_k|x_k)$\n",
    " - $|y_0^j| > |x_0^i|$, where we marginalize over future continuations of the actually produced prefix: $p(y_0^i|x_0^i) = \\sum_\\limits{x_{i+1}^j} p(x_{i+1}^j, y_0^j|x_0^i) = \\sum_\\limits{x_{i+1}^j} p(y_0^j|x_0^j)p(x_{i+1}^j|x_0^i) = \\sum_\\limits{\\{x_0^j \\, | \\, x_0^i \\text{ is a prefix}\\}} p(y_0^j|x_0^j)\\frac{p(x_0^j)}{p(x_0^i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:25:33.473632Z",
     "start_time": "2018-03-31T23:25:33.248390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 1, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 0, 1, 1, 1, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, 1, 0, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, '⋉'): 1/4 = 0.25\n",
      "\n",
      "TEST INPUT full: ('⋊', 1, 0, '⋉')\n",
      "TEST OUTPUT full: ('⋊', 1, 0, '⋉')\n",
      "p(y_0^j = ('⋊', 1, 0, '⋉')| x_0^i = ('⋊', 1, 0, '⋉')) = 0.5625\n",
      "len((1, 0)) = 2\n",
      "p(no_error_i) = 0.75\n",
      "0.75^(len((1, 0))) = 0.5625\n",
      " \n",
      "TEST INPUT prefix: ('⋊', 1)\n",
      "TEST OUTPUT prefix: ('⋊', 1)\n",
      "p(y_0^j = ('⋊', 1)| x_0^i = ('⋊', 1)) = 0.75\n",
      " \n",
      "TEST INPUT prefix: ('⋊', 1)\n",
      "TEST OUTPUT prefix: ('⋊', 1, 0)\n",
      "p(y_0^j = ('⋊', 1, 0)| x_0^i = ('⋊', 1)) = 0.25\n",
      " \n",
      "TEST INPUT prefix: ('⋊', 1, 0)\n",
      "TEST OUTPUT prefix: ('⋊', 1)\n",
      "p(y_0^j = ('⋊', 1)| x_0^i = ('⋊', 1, 0)) = 0.75\n"
     ]
    }
   ],
   "source": [
    "# definition of p(y_0^j|x_0^i) as a pmf but not as a 'dist', assuming uniphone noise/channel model\n",
    "def channelOutput_prefix_prob(inputPrefix, outputPrefix):\n",
    "    if len(outputPrefix) == len(inputPrefix):\n",
    "    #         |y_0^j|    ==      |x_0^i|\n",
    "#         slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist(x_i))\n",
    "        slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist[x_i])\n",
    "        return prod(slice_prob(y, x) for y,x in zip(outputPrefix, inputPrefix))\n",
    "    elif len(outputPrefix) < len(inputPrefix): #truncate excess part of inputPrefix\n",
    "              #|y_0^j|     <      |x_0^i|\n",
    "        return channelOutput_prefix_prob(inputPrefix[:len(outputPrefix)], outputPrefix)\n",
    "    else:\n",
    "              #|y_0^j|     >      |x_0^i|\n",
    "        hasInputPrefixAsPrefix = getHasPrefix(inputPrefix)\n",
    "        my_prefixes = (pref for pref in prefixes if len(pref) == len(outputPrefix) and hasInputPrefixAsPrefix(pref))\n",
    "        #         p(y_0^j|x_0^j)                                 p(x_0^j)          1   / p(x_0^i)\n",
    "        terms = ((channelOutput_prefix_prob(pref, outputPrefix), prefixProb(pref), 1.0 / prefixProb(inputPrefix)) for pref in my_prefixes)\n",
    "        return sum(map(prod, terms))\n",
    "\n",
    "        \n",
    "\n",
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "  \n",
    "test_input_full = list(inputs)[0]\n",
    "test_output_full = list(inputs)[0]\n",
    "print(\"TEST INPUT full: {0}\".format(test_input_full))\n",
    "print(\"TEST OUTPUT full: {0}\".format(test_output_full))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_full, test_input_full, channelOutput_prefix_prob(test_input_full, test_output_full)))\n",
    "print('len({0}) = {1}'.format(trimBoundariesFromSequence(test_input_full), len(trimBoundariesFromSequence(test_input_full))))\n",
    "print('p(no_error_i) = {0}'.format(pNoError_i))\n",
    "print('{2}^(len({0})) = {1}'.format(trimBoundariesFromSequence(test_input_full), pNoError_i ** len(trimBoundariesFromSequence(test_input_full)), pNoError_i))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = list(inputs)[0][0:2]\n",
    "test_output_slice = list(inputs)[0][0:2]\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, channelOutput_prefix_prob(test_input_slice, test_output_slice)))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = list(inputs)[0][0:2]\n",
    "test_output_slice = list(inputs)[0][0:3]\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, channelOutput_prefix_prob(test_input_slice, test_output_slice)))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = list(inputs)[0][0:3]\n",
    "test_output_slice = list(inputs)[0][0:2]\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, channelOutput_prefix_prob(test_input_slice, test_output_slice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate $p(y_0^i|x_0^i)$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:25:41.384965Z",
     "start_time": "2018-03-31T23:25:41.365975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 1, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 0, 1, 1, 1, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, 1, 0, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, '⋉'): 1/4 = 0.25\n",
      "\n",
      "TEST INPUT prefix: ('⋊', 1, 0)\n",
      "10 samples from p(Y_0^i|x_0^i = ('⋊', 1, 0)): [('⋊', 1, 0), ('⋊', 1, 0), ('⋊', 1, 0), ('⋊', 0, 0), ('⋊', 0, 0), ('⋊', 1, 0), ('⋊', 1, 0), ('⋊', 1, 0), ('⋊', 1, 0), ('⋊', 1, 1)]\n"
     ]
    }
   ],
   "source": [
    "# definition of sampler from p(Y_0^i|x_0^i), assuming uniphone noise/channel model\n",
    "def channelOutput_prefix_sampler(inputPrefix):\n",
    "#     return tuple([sampleFrom(channelOutput_i_dist(x_i)) for x_i in inputPrefix])\n",
    "    return tuple([sampleFrom(channelOutput_i_dist[x_i]) for x_i in inputPrefix])\n",
    "\n",
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print('10 samples from p(Y_0^i|x_0^i = {0}): {1}'.format(test_input_slice, list(sampleFrom(lambda : channelOutput_prefix_sampler(test_input_slice), 10)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and sample from $p(Y_0^i|x_0^i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:25:44.919719Z",
     "start_time": "2018-03-31T23:25:44.883284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 1, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 0, 1, 1, 1, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, 1, 0, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, '⋉'): 1/4 = 0.25\n",
      "\n",
      "TEST OUTPUT prefix = ('⋊', 1)\n",
      "p(y_0^i = ('⋊', 1)) = 0.625\n"
     ]
    }
   ],
   "source": [
    "# calculation of p(y_0^i) as a pmf but not as a 'dist'\n",
    "#   marginalizes over all prefixes of input sequences with length matching y_0^i \n",
    "def channelOutput_prefix_marginal_prob(outputPrefix):\n",
    "\n",
    "    l = len(outputPrefix)\n",
    "    my_prefixes = (prefix for prefix in prefixes if len(prefix) == l)\n",
    "        \n",
    "    #\\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i)\n",
    "    terms = ((prefixProb(input_prefix), channelOutput_prefix_prob(input_prefix, outputPrefix)) for input_prefix in my_prefixes)\n",
    "    probs = map(prod, terms)\n",
    "#     probs = (prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes)\n",
    "#     probs = [prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes] #only for testing; use generator exp otherwise\n",
    "#     print('terms of \\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i):')\n",
    "#     print(probs)\n",
    "    return sum(probs)\n",
    "\n",
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "\n",
    "print('TEST OUTPUT prefix = {0}'.format(test_output_slice))\n",
    "print('p(y_0^i = {0}) = {1}'.format(test_output_slice, channelOutput_prefix_marginal_prob(test_output_slice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate $p(y_0^i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining $\\hat{p}(\\widehat{x}_0^j|x_0^i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\hat{x_0^j}|x_0^i)$ is a more general object to calculate than $p(\\hat{x_0^f}|x_0^i)$. \n",
    "\n",
    "$p(\\hat{x_0^j}|x_0^i)$ has two cases: $|\\hat{x}_0^j| \\geq |x_0^i|$ and $|\\hat{x}_0^j| < |x_0^i|$.\n",
    "\n",
    "Assuming $|\\hat{x}_0^j| \\geq |x_0^i|$:\n",
    "$$p(\\hat{x_0^j}|x_0^i) = \\sum_\\limits{y_0^i} p(\\hat{x_0^j}|y_0^i)p(y_0^i|x_0^i) = \\sum_\\limits{y_0^i} \\frac{p(y_0^i|\\hat{x_0^j})p(\\hat{x_0^j})}{p(y_0^i)}p(y_0^i|x_0^i) = \\sum_\\limits{y_0^i} \\frac{p(y_0^i|\\hat{x_0^i})p(\\hat{x_0^j})}{p(y_0^i)}p(y_0^i|x_0^i) $$\n",
    "\n",
    "Assuming $|\\hat{x}_0^j| < |x_0^i|$:\n",
    "$$p(\\hat{x_0^j}|x_0^i) = \\sum_\\limits{\\hat{x_{j+1}^i}} p(\\hat{x_0^j}, \\hat{x_{j+1}^i}|x_0^i) = \\sum_\\limits{\\hat{x_{j+1}^i}} p(\\hat{x_0^i}|x_0^i) = \\sum_\\limits{\\{\\hat{x_0^i} \\, | \\, \\hat{x_0^j} \\text{ is a prefix}\\}} p(\\hat{x_0^i}|x_0^i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:25:51.288171Z",
     "start_time": "2018-03-31T23:25:50.003104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 1, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 0, 1, 1, 1, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, 1, 0, 0, '⋉'): 1/4 = 0.25\n",
      "('⋊', 1, '⋉'): 1/4 = 0.25\n",
      "\n",
      "est p(x-hat_0^j = ('⋊', 1)| x_0^i = ('⋊', 1, 0)) = 0.7974505494505422\n",
      " \n",
      "est p(x-hat_0^j = ('⋊', 1, 0)| x_0^i = ('⋊', 1, 0)) = 0.5186109890109841\n",
      " \n",
      "est p(x-hat_0^j = ('⋊', 1, 0, '⋉')| x_0^i = ('⋊', 1, 0)) = 0.49687912087911534\n",
      " \n",
      "est p(x-hat_0^j = ('⋊', 1, 0)| x_0^i = ('⋊', 1, 0, '⋉')) = 1.0\n"
     ]
    }
   ],
   "source": [
    "# mc estimate of p(x-hat_0^j|x_0^i) as pmf, not as 'dist', assuming uniphone error probs\n",
    "#                         x_0^i             x-hat_0^j\n",
    "def est_channelInput_prob(true_inputPrefix, poss_inputPrefix, num_samples = None):\n",
    "    if num_samples == None:\n",
    "        num_samples = 1000\n",
    "    \n",
    "#     print('true x_0^i: {0}'.format(true_inputPrefix))\n",
    "#     print('x-hat_0^j: {0}'.format(poss_inputPrefix))\n",
    "#     print('num samples: {0}'.format(num_samples))\n",
    "    \n",
    "    lenTruePrefix = len(true_inputPrefix) #|x_0^i|\n",
    "    lenPossPrefix = len(poss_inputPrefix) #|x-hat_0^j|\n",
    "\n",
    "    #if |x-hat_0^j|  < |x_0^i|, then calculate \\sum_\\limits{x-hat_0^i | x-hat_0^j is a prefix} p(x-hat_0^i|x_0^i)\n",
    "    if lenPossPrefix < lenTruePrefix:\n",
    "        hasPossPrefixAsPrefix = getHasPrefix(poss_inputPrefix)\n",
    "        my_prefixes = (pref for pref in prefixes if len(pref) == lenTruePrefix and hasPossPrefixAsPrefix(pref))\n",
    "        probs = (est_channelInput_prob(true_inputPrefix, pref) for pref in my_prefixes)\n",
    "        return sum(probs)\n",
    "\n",
    "    #if |x-hat_0^j| ≥ |x_0^i|, then proceed 'normally'...\n",
    "    \n",
    "    #samples from p(Y_0^i|x_0^i)\n",
    "    samples = sampleFrom(lambda: channelOutput_prefix_sampler(true_inputPrefix), num_samples)\n",
    "#     samples = list(sampleFrom(lambda: channelOutput_prefix_sampler(true_inputPrefix), num_samples)) # only for debugging - otherwise use generator exp\n",
    "#     print('samples from p(Y_0^i|x_0^i):')\n",
    "#     print(samples)\n",
    "#     likelihoods = [channelOutput_prefix_prob(poss_inputPrefix, outputPrefix) for outputPrefix in samples]\n",
    "#     print('likelihoods p(y_0^i|x-hat_0^i):')\n",
    "#     print(likelihoods)\n",
    "#     priorOfOutputs = [channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples]\n",
    "#     print('priorOfOutputs p(y_0^i):')\n",
    "#     print(priorOfOutputs)\n",
    "    \n",
    "    #p(x-hat_0^j)\n",
    "    poss_inputPrefix_prob = prefixProb(poss_inputPrefix)\n",
    "#     print('p(x-hat_0^j) = {0}'.format( poss_inputPrefix_prob ))\n",
    "    \n",
    "    #terms in \\sum_{samples y_0^i from p(Y_0^i|x_0^i)} p(y_0^i|x-hat_0^i) * p(x-hat_0^j) / p(y_0^i)\n",
    "    terms = (channelOutput_prefix_prob(poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples)\n",
    "#     for outputPrefix in samples:\n",
    "#       print('y_0^i: {0}'.format(outputPrefix))\n",
    "#       print('term: {0} * {1} / {2}'.format(channelOutput_prefix_prob(poss_inputPrefix, outputPrefix), poss_inputPrefix_prob, channelOutput_prefix_marginal_prob(outputPrefix)))\n",
    "#     terms = [channelOutput_prefix_prob(poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples] #use only for debugging, otherwise use generator exp\n",
    "#     print('terms in sum:')\n",
    "#     print(terms)\n",
    "    est = sum(terms) / num_samples\n",
    "    \n",
    "    return est\n",
    "\n",
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(('⋊', 1), test_input_slice, est_channelInput_prob(test_input_slice, ('⋊', 1))))\n",
    "print(' ')\n",
    "\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(test_input_slice, test_input_slice, est_channelInput_prob(test_input_slice, test_input_slice)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(test_input_full, test_input_slice, est_channelInput_prob(test_input_slice, test_input_full)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(test_input_slice, test_input_full, est_channelInput_prob(test_input_full, test_input_slice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating test lexicons and noise distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating $p(X_0^f)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a codebook = set of channel input sequences = lexicon of bitstrings, we need to decide\n",
    " - how big or small lexicons can be\n",
    " - how big or small words can be\n",
    " - what the marginal distribution over symbols is within a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:35:19.954774Z",
     "start_time": "2018-03-31T23:35:19.826559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution over symbols at each index of a word:\n",
      "0: 1/2 = 0.5\n",
      "1: 1/2 = 0.5\n",
      "\n",
      "Length of input sequences = codewords = wordforms should be between 1 and 5 (inclusive).\n",
      "Size of lexicon = # of possible channel inputs should be between 2 and 5 (inclusive).\n"
     ]
    }
   ],
   "source": [
    "# Boilerplate...\n",
    "\n",
    "# Symbols\n",
    "\n",
    "bits = set([0, 1])\n",
    "\n",
    "# p(X_i)\n",
    "inputDist_i = Uniform(bits)\n",
    "print('Distribution over symbols at each index of a word:')\n",
    "print(inputDist_i)\n",
    "\n",
    "#min, max length of a channel input sequence (codeword = wordform)\n",
    "min_input_seq_length = 1\n",
    "max_input_seq_length = 5\n",
    "print('Length of input sequences = codewords = wordforms should be between {0} and {1} (inclusive).'.format(min_input_seq_length, max_input_seq_length))\n",
    "\n",
    "#min, max number of channel input sequences (= codewords = wordforms)\n",
    "min_inputs = 2\n",
    "max_inputs = 5\n",
    "print('Size of lexicon = # of possible channel inputs should be between {0} and {1} (inclusive).'.format(min_inputs, max_inputs))\n",
    "\n",
    "#define element of support of p(X_0^f), where min_num_symbols_per_word - 1 ≤ f ≤ max_num_symbols_per_word...\n",
    "def generateInputSequence(x_i_sampler, min_length, max_length):\n",
    "    length = sampleFrom(Uniform(range(min_length, max_length)))\n",
    "    return tuple(x_i_sampler() for each in range(length))\n",
    "\n",
    "def padInputSequenceWithBoundaries(inputSeq):\n",
    "    temp = list(inputSeq)\n",
    "    temp = tuple([leftEdge] + temp + [rightEdge])\n",
    "    return temp\n",
    "\n",
    "def trimBoundariesFromSequence(seq):\n",
    "    temp = list(seq)\n",
    "    if temp[0] == leftEdge:\n",
    "        temp = temp[1:]\n",
    "    if temp[-1] == rightEdge:\n",
    "        temp = temp[:-1]\n",
    "    return tuple(temp)\n",
    "\n",
    "\n",
    "def generate_input_dist(min_num_words, max_num_words, \n",
    "                        min_num_symbols_per_word, max_num_symbols_per_word,\n",
    "                        input_dist_i,\n",
    "                        useEdgeSymbols = None):\n",
    "    if useEdgeSymbols == None:\n",
    "        useEdgeSymbols = True\n",
    "    \n",
    "    # function that samples from p(X_i)\n",
    "    channelInput_i = makeSampler(inputDist_i)\n",
    "    \n",
    "    \n",
    "    numInputs = sampleFrom(Uniform(range(min_num_words, max_num_words)))\n",
    "#     print(\"{0} ≤ {1}\".format(\"numInputs = |'lexicon'|\",numInputs))\n",
    "    \n",
    "    # the possible of values X_0^f\n",
    "    inputs = set([generateInputSequence(channelInput_i, min_num_symbols_per_word, max_num_symbols_per_word) for each in range(numInputs)])\n",
    "    if useEdgeSymbols:\n",
    "        inputs = set(map(padInputSequenceWithBoundaries, inputs))\n",
    "#     print(\"{0} = {1}\".format(\"inputs = 'lexicon'\",inputs))\n",
    "\n",
    "    if len(inputs) < min_num_words:\n",
    "        return generate_input_dist(min_num_words, max_num_words, \n",
    "                        min_num_symbols_per_word, max_num_symbols_per_word,\n",
    "                        input_dist_i, useEdgeSymbols)    \n",
    "    \n",
    "    # assume uniform dist over inputs\n",
    "    dist = Uniform(inputs)\n",
    "    \n",
    "    my_inputAlphabet = union(map(set,dist.keys()))\n",
    "    alphabet_minus_edges = set([each for each in my_inputAlphabet if each not in edgeSymbols])\n",
    "    if len(alphabet_minus_edges) == 1:\n",
    "        return generate_input_dist(min_num_words, max_num_words, \n",
    "                        min_num_symbols_per_word, max_num_symbols_per_word,\n",
    "                        input_dist_i, useEdgeSymbols)   \n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:35:20.958294Z",
     "start_time": "2018-03-31T23:35:20.951732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Randomly generated input distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "          ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(' ')\n",
    "print('Randomly generated input distribution:')\n",
    "inputDist = generate_input_dist(min_inputs, max_inputs, min_input_seq_length, max_input_seq_length, True)\n",
    "inputDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating $p(Y_i|x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:38:33.707857Z",
     "start_time": "2018-03-31T23:38:33.658769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel output distribution at any given index:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ProbDist({0: 0.85, 1: 0.15}),\n",
       " 1: ProbDist({0: 0.15, 1: 0.85}),\n",
       " '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       " '⋊': ProbDist({'⋊': Fraction(1, 1)})}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definition of p(Y_i|X_i) as a conditional distribution\n",
    "\n",
    "def generate_error_probability():\n",
    "    return round(random.uniform(0.1,0.4), 2)\n",
    "\n",
    "def generate_channel_dist_i(all_channel_input_symbols, error_prob = None):\n",
    "    assert len(all_channel_input_symbols) > 1, \"There must be >1 channel input symbol in {0}.\".format(all_channel_input_symbols)\n",
    "\n",
    "    #Edge symbols are assumed to be perfectly transmitted and no non-edge symbol is ever confused with a word edge.\n",
    "    inputAlphabet_withoutEdges = [each for each in all_channel_input_symbols if each not in edgeSymbols]\n",
    "    \n",
    "    if error_prob == None:\n",
    "        pError_i = generate_error_probability()\n",
    "    else:\n",
    "        assert error_prob >= 0.0 and error_prob <= 1.0, 'Error probability {0} must be >= 0 and <= 1.0!'.format(error_prob)\n",
    "    pNoError_i = 1 - pError_i\n",
    "    pEachError_i = pError_i / (len(inputAlphabet_withoutEdges) - 1)\n",
    "#     print('P(error) = {0}'.format(pError_i))\n",
    "\n",
    "    \n",
    "    getProb = lambda key_x, other_x: pNoError_i if key_x == other_x else pEachError_i\n",
    "    \n",
    "    #constructs p(Y_i|x_i) for a particular x_i where \n",
    "    #  p(y_i|x_i) = pNoError_i iff y_i = x_i\n",
    "    #  p(y_i|x_i) = 1 / n, where n = the number of symbols y_i != x_i\n",
    "    getConditionalChannelDist = lambda key_x: ProbDist({x:getProb(key_x,x) for x in inputAlphabet_withoutEdges})\n",
    "\n",
    "    channel_dist_i = {x:getConditionalChannelDist(x) for x in inputAlphabet_withoutEdges}\n",
    "    \n",
    "    #Now we fix left edge and right edge symbols so that they are always perfectly transmitted:\n",
    "    channel_dist_i[leftEdge] = ProbDist({leftEdge: 1})\n",
    "    channel_dist_i[rightEdge] = ProbDist({rightEdge: 1})\n",
    "    \n",
    "    return channel_dist_i\n",
    "\n",
    "\n",
    "# channelOutput_i_dist = {\n",
    "#     0:         ProbDist({0: pNoError_i, 1:pError_i}),\n",
    "#     1:         ProbDist({0: pError_i, 1:pNoError_i}),\n",
    "#     leftEdge:  ProbDist({leftEdge: 1}),\n",
    "#     rightEdge: ProbDist({rightEdge: 1})\n",
    "# }\n",
    "print('Channel output distribution at any given index:')\n",
    "inputAlphabet = union(map(set,inputDist.keys()))\n",
    "channelOutput_i_dist = generate_channel_dist_i( inputAlphabet )\n",
    "channelOutput_i_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating model code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/source model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:38:52.230405Z",
     "start_time": "2018-03-31T23:38:51.826816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating functions and values derived from p(X_0^f)...\n",
    "\n",
    "import itertools\n",
    "\n",
    "def getPrefixes(s):\n",
    "    return set(s[0:i] for i in range(1, len(s)+1))\n",
    "\n",
    "def getHasPrefix(prefix):\n",
    "    l = len(prefix)\n",
    "    hasAsPrefix = lambda full_input_seq: full_input_seq[0:l] == prefix\n",
    "    return hasAsPrefix\n",
    "  \n",
    "def getHasSuffix(suffix):\n",
    "    l = len(suffix)\n",
    "    hasAsSuffix = lambda full_input_seq: full_input_seq[-len(suffix):] == suffix\n",
    "    return hasAsSuffix\n",
    "\n",
    "def padInputSequenceWithBoundaries(inputSeq):\n",
    "    temp = list(inputSeq)\n",
    "    temp = tuple([leftEdge] + temp + [rightEdge])\n",
    "    return temp\n",
    "\n",
    "def trimBoundariesFromSequence(seq):\n",
    "    temp = list(seq)\n",
    "    if temp[0] == leftEdge:\n",
    "        temp = temp[1:]\n",
    "    if temp[-1] == rightEdge:\n",
    "        temp = temp[:-1]\n",
    "    return tuple(temp)\n",
    "\n",
    "def generateInputModel(inputDist, pad_with_boundaries = None):\n",
    "    if pad_with_boundaries == None:\n",
    "        pad_with_boundaries = False\n",
    "    model = {} #FIXME consider changing to a namedtuple/frozendict (possibly just before returning a value)\n",
    "    \n",
    "    if pad_with_boundaries:\n",
    "        old_map = list(inputDist.items())\n",
    "        old_inputs = list(map(lambda p: p[0], old_map))\n",
    "#         old_inputs = list(inputDist.keys())\n",
    "        old_values = [v for k,v in old_map]\n",
    "        new_inputs = list(map(padInputSequenceWithBoundaries, old_inputs))\n",
    "        assert(list(map(trimBoundariesFromSequence, new_inputs)) == old_inputs)\n",
    "        assert(list(zip(old_inputs, old_values)) == old_map)\n",
    "        new_map = dict(list(zip(new_inputs, old_values)))\n",
    "        inputDist = new_map\n",
    "    \n",
    "    model['inputDist'] = inputDist\n",
    "    model['p(X_0^f)'] = inputDist\n",
    "    \n",
    "    inputs = list(inputDist.keys())\n",
    "    model['inputs'] = inputs\n",
    "    \n",
    "    \n",
    "    inputAlphabet = set(itertools.chain.from_iterable([set(k) for k in inputs ]))\n",
    "#   print(inputAlphabet)\n",
    "#   print(inputAlphabet - edgeSymbols)\n",
    "#     if pad_with_boundaries and (leftEdge not in inputAlphabet):\n",
    "#         inputAlphabet += [leftEdge]\n",
    "#     if pad_with_boundaries and (rightEdge not in inputAlphabet):\n",
    "#         inputAlphabet += [rightEdge]\n",
    "    model['inputAlphabet'] = inputAlphabet\n",
    "    \n",
    "\n",
    "    prefixes = map(getPrefixes, inputs)\n",
    "    prefixes = set(itertools.chain.from_iterable(prefixes))\n",
    "#   print(\"<= 10 prefixes of lexicon:\")\n",
    "#   print(list(prefixes)[0:11])\n",
    "    model['prefixes'] = prefixes\n",
    "  \n",
    "    \n",
    "    # convenient calculation of p(x_0^i) as pmf, not as 'dist'\n",
    "    def prefixProb(input_prefix):\n",
    "        hasAsPrefix = getHasPrefix(input_prefix)\n",
    "        return P(hasAsPrefix, inputDist)\n",
    "    model['prefixProb'] = prefixProb\n",
    "    model['p(x_0^i)'] = prefixProb\n",
    "    \n",
    "    \n",
    "    # definition of p(X_0^f | x_0^i) as dist\n",
    "    def inputDist_givenPrefix(prefix):\n",
    "        hasPrefix = getHasPrefix(prefix)\n",
    "        return inputDist & hasPrefix\n",
    "    model['inputDist_givenPrefix'] = inputDist_givenPrefix\n",
    "    model['p(X_0^f | x_0^i)'] = inputDist_givenPrefix\n",
    "    \n",
    "    \n",
    "    # definition of p(x_{i+1}^f | x_0^i) as pmf, not as 'dist'\n",
    "    def suffixProb(input_suffix, input_prefix):\n",
    "        #p(X_0^f | x_0^i)\n",
    "        d = inputDist_givenPrefix(input_prefix)\n",
    "        isExactlyEqualTo = lambda s: s == tuple(list(input_prefix) + list(input_suffix))\n",
    "        return P(isExactlyEqualTo, d)\n",
    "    model['suffixProb'] = suffixProb\n",
    "    model['p(x_{i+1}^f | x_0^i)'] = suffixProb\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:38:52.542888Z",
     "start_time": "2018-03-31T23:38:52.519611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "Derived values/functions...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inputAlphabet': {0, 1, '⋉', '⋊'},\n",
       " 'inputDist': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'inputDist_givenPrefix': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'inputs': [('⋊', 0, 0, 1, '⋉'), ('⋊', 0, 0, '⋉')],\n",
       " 'p(X_0^f | x_0^i)': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'p(X_0^f)': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'p(x_0^i)': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'p(x_{i+1}^f | x_0^i)': <function __main__.generateInputModel.<locals>.suffixProb>,\n",
       " 'prefixProb': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'prefixes': {('⋊', 0),\n",
       "  ('⋊', 0, 0),\n",
       "  ('⋊', 0, 0, '⋉'),\n",
       "  ('⋊', 0, 0, 1),\n",
       "  ('⋊', 0, 0, 1, '⋉'),\n",
       "  ('⋊',)},\n",
       " 'suffixProb': <function __main__.generateInputModel.<locals>.suffixProb>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('p(X_0^f):')\n",
    "print(inputDist)\n",
    "print('Derived values/functions...')\n",
    "generateInputModel(inputDist, pad_with_boundaries = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:04.544929Z",
     "start_time": "2018-03-31T23:39:04.285011Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating functions and values derived from p(Y_i|x_i)...\n",
    "\n",
    "\n",
    "def generateChannelModel(channelOutput_i_dist, inputModel):\n",
    "    \n",
    "    model = {} #FIXME consider changing to a namedtuple/frozendict (possibly just before returning a value)\n",
    "    \n",
    "    model['channelOutput_i_dist'] = channelOutput_i_dist\n",
    "    model['p(Y_i|x_i)'] = channelOutput_i_dist\n",
    "    \n",
    "    \n",
    "    # definition of p(Y_i) as a dist\n",
    "    sourceInputAlphabet = inputModel['inputAlphabet']\n",
    "    \n",
    "    \n",
    "    getKeys = lambda d: set(d.keys()) #assumes they're hashable\n",
    "#     getVals = lambda d: set(d.values()) #assumes they're hashable\n",
    "    channelInputAlphabet = getKeys(channelOutput_i_dist)\n",
    "    \n",
    "    getOutputSymbols = lambda cond_channel_dist: getKeys(cond_channel_dist)\n",
    "    outputSymbolsByInput = map(lambda eachInputSymbol: getOutputSymbols(channelOutput_i_dist[eachInputSymbol]), channelOutput_i_dist)\n",
    "    channelOutputAlphabet = reduce(set.union, outputSymbolsByInput)\n",
    "    \n",
    "    totalAlphabet = reduce(set.union, [channelOutputAlphabet, channelInputAlphabet, sourceInputAlphabet])\n",
    "    \n",
    "    \n",
    "#     channelOutput_i_marginal_dist = ProbDist({y: sum(channelOutput_i_dist(x)[y] for x in inputAlphabet) for y in inputAlphabet})\n",
    "    channelOutput_i_marginal_dist = ProbDist({y: sum(channelOutput_i_dist[x].get(y, 0.0) for x in channelInputAlphabet) for y in channelOutputAlphabet})\n",
    "    model['channelOutput_i_marginal_dist'] = channelOutput_i_marginal_dist\n",
    "    model['p(Y_i)'] = channelOutput_i_marginal_dist\n",
    "    \n",
    "    \n",
    "    # definition of p(y_0^j|x_0^i) as a pmf but not as a 'dist', assuming uniphone noise/channel model\n",
    "    prefixes = inputModel['prefixes']\n",
    "    def channelOutput_prefix_prob(inputPrefix, outputPrefix):\n",
    "        if len(outputPrefix) == len(inputPrefix):\n",
    "        #         |y_0^j|    ==      |x_0^i|\n",
    "#             slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist(x_i))\n",
    "            slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist[x_i])\n",
    "            return prod(slice_prob(y, x) for y,x in zip(outputPrefix, inputPrefix))\n",
    "        elif len(outputPrefix) < len(inputPrefix): #truncate excess part of inputPrefix\n",
    "                  #|y_0^j|     <      |x_0^i|\n",
    "            return channelOutput_prefix_prob(inputPrefix[:len(outputPrefix)], outputPrefix)\n",
    "        else:\n",
    "                  #|y_0^j|     >      |x_0^i|\n",
    "            hasInputPrefixAsPrefix = getHasPrefix(inputPrefix)\n",
    "            my_prefixes = (pref for pref in prefixes if len(pref) == len(outputPrefix) and hasInputPrefixAsPrefix(pref))\n",
    "            #         p(y_0^j|x_0^j)                                 p(x_0^j)          1   / p(x_0^i)\n",
    "            terms = ((channelOutput_prefix_prob(pref, outputPrefix), inputModel['prefixProb'](pref), 0.0 if inputModel['prefixProb'](inputPrefix) == 0.0 else 1.0 / inputModel['prefixProb'](inputPrefix) ) for pref in my_prefixes)\n",
    "            return sum(map(prod, terms))\n",
    "    model['p(y_0^j|x_0^i)'] = channelOutput_prefix_prob\n",
    "    model['channelOutput_prefix_prob'] = channelOutput_prefix_prob\n",
    "\n",
    "\n",
    "    # definition of sampler from p(Y_0^i|x_0^i), assuming uniphone noise/channel model\n",
    "    def channelOutput_prefix_sampler(inputPrefix):\n",
    "#         return tuple([sampleFrom(channelOutput_i_dist(x_i)) for x_i in inputPrefix])\n",
    "        return tuple([sampleFrom(channelOutput_i_dist[x_i]) for x_i in inputPrefix])\n",
    "    model['sample from p(Y_0^i|x_0^i)'] = channelOutput_prefix_sampler\n",
    "    model['channelOutput_prefix_sampler'] = channelOutput_prefix_sampler\n",
    "\n",
    "    \n",
    "    # calculation of p(y_0^i) as a pmf but not as a 'dist'\n",
    "    #   marginalizes over all prefixes of input sequences with length matching y_0^i \n",
    "    def channelOutput_prefix_marginal_prob(outputPrefix):\n",
    "\n",
    "        l = len(outputPrefix)\n",
    "        my_prefixes = (prefix for prefix in prefixes if len(prefix) == l)\n",
    "\n",
    "        #\\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i)\n",
    "        terms = ((inputModel['prefixProb'](input_prefix), channelOutput_prefix_prob(input_prefix, outputPrefix)) for input_prefix in my_prefixes)\n",
    "        probs = map(prod, terms)\n",
    "    #     probs = (prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes)\n",
    "    #     probs = [prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes] #only for testing; use generator exp otherwise\n",
    "    #     print('terms of \\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i):')\n",
    "    #     print(probs)\n",
    "        return sum(probs)\n",
    "    model['p(y_0^i)'] = channelOutput_prefix_marginal_prob\n",
    "    model['channelOutput_prefix_marginal_prob'] = channelOutput_prefix_marginal_prob\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:06.233584Z",
     "start_time": "2018-03-31T23:39:06.209777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "p(Y_i|X_i = 0):\n",
      "0: 0.85\n",
      "1: 0.15\n",
      "\n",
      "p(Y_i|X_i = 1):\n",
      "0: 0.15\n",
      "1: 0.85\n",
      "\n",
      "Derived values/functions...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inputAlphabet': {0, 1, '⋉', '⋊'},\n",
       " 'inputDist': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'inputDist_givenPrefix': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'inputs': [('⋊', 0, 0, 1, '⋉'), ('⋊', 0, 0, '⋉')],\n",
       " 'p(X_0^f | x_0^i)': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'p(X_0^f)': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'p(x_0^i)': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'p(x_{i+1}^f | x_0^i)': <function __main__.generateInputModel.<locals>.suffixProb>,\n",
       " 'prefixProb': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'prefixes': {('⋊', 0),\n",
       "  ('⋊', 0, 0),\n",
       "  ('⋊', 0, 0, '⋉'),\n",
       "  ('⋊', 0, 0, 1),\n",
       "  ('⋊', 0, 0, 1, '⋉'),\n",
       "  ('⋊',)},\n",
       " 'suffixProb': <function __main__.generateInputModel.<locals>.suffixProb>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('p(X_0^f):')\n",
    "print(inputDist)\n",
    "\n",
    "print('p(Y_i|X_i = 0):')\n",
    "# print(channelOutput_i_dist(0))\n",
    "print(channelOutput_i_dist[0])\n",
    "print('p(Y_i|X_i = 1):')\n",
    "# print(channelOutput_i_dist(1))\n",
    "print(channelOutput_i_dist[1])\n",
    "\n",
    "print('Derived values/functions...')\n",
    "myInputModel = generateInputModel(inputDist)\n",
    "myInputModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:12.288496Z",
     "start_time": "2018-03-31T23:39:12.277506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channelOutput_i_dist': {0: ProbDist({0: 0.85, 1: 0.15}),\n",
       "  1: ProbDist({0: 0.15, 1: 0.85}),\n",
       "  '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       "  '⋊': ProbDist({'⋊': Fraction(1, 1)})},\n",
       " 'channelOutput_i_marginal_dist': ProbDist({0: 0.25,\n",
       "           1: 0.25,\n",
       "           '⋉': 0.25,\n",
       "           '⋊': 0.25}),\n",
       " 'channelOutput_prefix_marginal_prob': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_marginal_prob>,\n",
       " 'channelOutput_prefix_prob': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_prob>,\n",
       " 'channelOutput_prefix_sampler': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_sampler>,\n",
       " 'p(Y_i)': ProbDist({0: 0.25, 1: 0.25, '⋉': 0.25, '⋊': 0.25}),\n",
       " 'p(Y_i|x_i)': {0: ProbDist({0: 0.85, 1: 0.15}),\n",
       "  1: ProbDist({0: 0.15, 1: 0.85}),\n",
       "  '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       "  '⋊': ProbDist({'⋊': Fraction(1, 1)})},\n",
       " 'p(y_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_marginal_prob>,\n",
       " 'p(y_0^j|x_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_prob>,\n",
       " 'sample from p(Y_0^i|x_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_sampler>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myChannelModel = generateChannelModel(channelOutput_i_dist, myInputModel)\n",
    "myChannelModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:15.453371Z",
     "start_time": "2018-03-31T23:39:15.262373Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "#Hoeffding's inequality w.r.t. mc estimate p-hat(x-hat_0^j|x_0^i):\n",
    "# Let  X = p-hat(x-hat_0^j|x_0^i)\n",
    "#      𝛍 = p(x-hat_0^j|x_0^i)\n",
    "#      n = the number of samples that go into calculating X\n",
    "# then\n",
    "#      p(|X - 𝛍| > 𝛆) ≤ exp(2n𝛆²)\n",
    "#\n",
    "#  E.g. for n = 1000, 𝛆 = 0.01\n",
    "#      p(|X - 𝛍| > 𝛆) ≤ ≈0.82\n",
    "#\n",
    "#       for n = 1000, 𝛆 = 0.03\n",
    "#     p(|X - 𝛍| > 𝛆) ≤ ≈0.165\n",
    "#\n",
    "#       for n = 1000, 𝛆 = 0.05\n",
    "#     p(|X - 𝛍| > 𝛆) ≤ ≈0.0068\n",
    "#\n",
    "#       for n = 1000, 𝛆 = 0.1\n",
    "#     p(|X - 𝛍| > 𝛆) ≤ ≈2.06*10^-9\n",
    "def hoeffdingProb(epsilon, num_samples):\n",
    "    upperBound = exp(-2.0 * num_samples * epsilon * epsilon)\n",
    "    return upperBound\n",
    "\n",
    "def generateTotalModel(inputDist, channelOutput_i_dist, pad_with_boundaries = None):\n",
    "    if pad_with_boundaries == None:\n",
    "        pad_with_boundaries = False\n",
    "    \n",
    "    inputModel = generateInputModel(inputDist, pad_with_boundaries = pad_with_boundaries)\n",
    "    channelModel = generateChannelModel(channelOutput_i_dist, inputModel)\n",
    "    model = {**inputModel, **channelModel} #FIXME consider changing to a namedtuple/frozendict (possibly just before returning a value)\n",
    "\n",
    "    # receiver/listener model\n",
    "    #  = mc estimate of p(x-hat_0^j|x_0^i) as pmf, not as 'dist', assuming uniphone error probs\n",
    "    #                         x_0^i             x-hat_0^j\n",
    "    def est_channelInput_prob(true_inputPrefix, poss_inputPrefix, num_samples = None):\n",
    "        if num_samples == None:\n",
    "            num_samples = 1000\n",
    "\n",
    "    #     print('true x_0^i: {0}'.format(true_inputPrefix))\n",
    "    #     print('x-hat_0^j: {0}'.format(poss_inputPrefix))\n",
    "    #     print('num samples: {0}'.format(num_samples))\n",
    "\n",
    "        lenTruePrefix = len(true_inputPrefix) #|x_0^i|\n",
    "        lenPossPrefix = len(poss_inputPrefix) #|x-hat_0^j|\n",
    "\n",
    "        #if |x-hat_0^j|  < |x_0^i|, then calculate \\sum_\\limits{x-hat_0^i | x-hat_0^j is a prefix} p(x-hat_0^i|x_0^i)\n",
    "        if lenPossPrefix < lenTruePrefix:\n",
    "            hasPossPrefixAsPrefix = getHasPrefix(poss_inputPrefix)\n",
    "            my_prefixes = (pref for pref in model['prefixes'] if len(pref) == lenTruePrefix and hasPossPrefixAsPrefix(pref))\n",
    "            probs = (est_channelInput_prob(true_inputPrefix, pref) for pref in my_prefixes)\n",
    "            return sum(probs)\n",
    "\n",
    "        #if |x-hat_0^j| ≥ |x_0^i|, then proceed 'normally'...\n",
    "\n",
    "        #samples from p(Y_0^i|x_0^i)\n",
    "        samples = sampleFrom(lambda: model['channelOutput_prefix_sampler'](true_inputPrefix), num_samples)\n",
    "    #     samples = list(sampleFrom(lambda: channelOutput_prefix_sampler(true_inputPrefix), num_samples)) # only for debugging - otherwise use generator exp\n",
    "    #     print('samples from p(Y_0^i|x_0^i):')\n",
    "    #     print(samples)\n",
    "    #     likelihoods = [channelOutput_prefix_prob(poss_inputPrefix, outputPrefix) for outputPrefix in samples]\n",
    "    #     print('likelihoods p(y_0^i|x-hat_0^i):')\n",
    "    #     print(likelihoods)\n",
    "    #     priorOfOutputs = [channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples]\n",
    "    #     print('priorOfOutputs p(y_0^i):')\n",
    "    #     print(priorOfOutputs)\n",
    "\n",
    "        #p(x-hat_0^j)\n",
    "        poss_inputPrefix_prob = model['prefixProb'](poss_inputPrefix)\n",
    "    #     print('p(x-hat_0^j) = {0}'.format( poss_inputPrefix_prob ))\n",
    "\n",
    "        #terms in \\sum_{samples y_0^i from p(Y_0^i|x_0^i)} p(y_0^i|x-hat_0^i) * p(x-hat_0^j) / p(y_0^i)\n",
    "#         terms = (model['channelOutput_prefix_prob'](poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / model['channelOutput_prefix_marginal_prob'](outputPrefix) for outputPrefix in samples)\n",
    "        terms = ((model['channelOutput_prefix_prob'](poss_inputPrefix, outputPrefix), 0.0 if model['channelOutput_prefix_marginal_prob'](outputPrefix) == 0.0 else poss_inputPrefix_prob / model['channelOutput_prefix_marginal_prob'](outputPrefix) ) for outputPrefix in samples)\n",
    "    #     for outputPrefix in samples:\n",
    "    #       print('y_0^i: {0}'.format(outputPrefix))\n",
    "    #       print('term: {0} * {1} / {2}'.format(channelOutput_prefix_prob(poss_inputPrefix, outputPrefix), poss_inputPrefix_prob, channelOutput_prefix_marginal_prob(outputPrefix)))\n",
    "    #     terms = [channelOutput_prefix_prob(poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples] #use only for debugging, otherwise use generator exp\n",
    "    #     print('terms in sum:')\n",
    "    #     print(terms)\n",
    "#         est = sum(terms) / num_samples\n",
    "        est = sum(map(prod,terms)) / num_samples\n",
    "\n",
    "        return est\n",
    "    model['p-hat(x-hat_0^j|x_0^i)'] = est_channelInput_prob\n",
    "    model['est_channelInput_prob'] = est_channelInput_prob\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channelOutput_i_dist': {0: ProbDist({0: 0.85, 1: 0.15}),\n",
       "  1: ProbDist({0: 0.15, 1: 0.85}),\n",
       "  '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       "  '⋊': ProbDist({'⋊': Fraction(1, 1)})},\n",
       " 'channelOutput_i_marginal_dist': ProbDist({0: 0.25,\n",
       "           1: 0.25,\n",
       "           '⋉': 0.25,\n",
       "           '⋊': 0.25}),\n",
       " 'channelOutput_prefix_marginal_prob': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_marginal_prob>,\n",
       " 'channelOutput_prefix_prob': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_prob>,\n",
       " 'channelOutput_prefix_sampler': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_sampler>,\n",
       " 'est_channelInput_prob': <function __main__.generateTotalModel.<locals>.est_channelInput_prob>,\n",
       " 'inputAlphabet': {0, 1, '⋉', '⋊'},\n",
       " 'inputDist': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'inputDist_givenPrefix': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'inputs': [('⋊', 0, 0, 1, '⋉'), ('⋊', 0, 0, '⋉')],\n",
       " 'p(X_0^f | x_0^i)': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'p(X_0^f)': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'p(Y_i)': ProbDist({0: 0.25, 1: 0.25, '⋉': 0.25, '⋊': 0.25}),\n",
       " 'p(Y_i|x_i)': {0: ProbDist({0: 0.85, 1: 0.15}),\n",
       "  1: ProbDist({0: 0.15, 1: 0.85}),\n",
       "  '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       "  '⋊': ProbDist({'⋊': Fraction(1, 1)})},\n",
       " 'p(x_0^i)': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'p(x_{i+1}^f | x_0^i)': <function __main__.generateInputModel.<locals>.suffixProb>,\n",
       " 'p(y_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_marginal_prob>,\n",
       " 'p(y_0^j|x_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_prob>,\n",
       " 'p-hat(x-hat_0^j|x_0^i)': <function __main__.generateTotalModel.<locals>.est_channelInput_prob>,\n",
       " 'prefixProb': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'prefixes': {('⋊', 0),\n",
       "  ('⋊', 0, 0),\n",
       "  ('⋊', 0, 0, '⋉'),\n",
       "  ('⋊', 0, 0, 1),\n",
       "  ('⋊', 0, 0, 1, '⋉'),\n",
       "  ('⋊',)},\n",
       " 'sample from p(Y_0^i|x_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_sampler>,\n",
       " 'suffixProb': <function __main__.generateInputModel.<locals>.suffixProb>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateTotalModel(inputDist, channelOutput_i_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the generated code on the generated lexicon and noise distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model inputs are restated below for convenience (and typically at the top of each cell...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:18.674593Z",
     "start_time": "2018-03-31T23:39:18.661688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INPUTS:\n",
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "p(Y_i|X_i = 0):\n",
      "0: 0.85\n",
      "1: 0.15\n",
      "\n",
      "p(Y_i|X_i = 1):\n",
      "0: 0.15\n",
      "1: 0.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MODEL INPUTS:')\n",
    "\n",
    "print('p(X_0^f):')\n",
    "print(inputDist)\n",
    "\n",
    "print('p(Y_i|X_i = 0):')\n",
    "# print(channelOutput_i_dist(0))\n",
    "print(channelOutput_i_dist[0])\n",
    "print('p(Y_i|X_i = 1):')\n",
    "# print(channelOutput_i_dist(1))\n",
    "print(channelOutput_i_dist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:20.874745Z",
     "start_time": "2018-03-31T23:39:20.851643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DERIVED VALUES/FUNCTIONS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'channelOutput_i_dist': {0: ProbDist({0: 0.85, 1: 0.15}),\n",
       "  1: ProbDist({0: 0.15, 1: 0.85}),\n",
       "  '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       "  '⋊': ProbDist({'⋊': Fraction(1, 1)})},\n",
       " 'channelOutput_i_marginal_dist': ProbDist({0: 0.25,\n",
       "           1: 0.25,\n",
       "           '⋉': 0.25,\n",
       "           '⋊': 0.25}),\n",
       " 'channelOutput_prefix_marginal_prob': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_marginal_prob>,\n",
       " 'channelOutput_prefix_prob': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_prob>,\n",
       " 'channelOutput_prefix_sampler': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_sampler>,\n",
       " 'est_channelInput_prob': <function __main__.generateTotalModel.<locals>.est_channelInput_prob>,\n",
       " 'inputAlphabet': {0, 1, '⋉', '⋊'},\n",
       " 'inputDist': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'inputDist_givenPrefix': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'inputs': [('⋊', 0, 0, 1, '⋉'), ('⋊', 0, 0, '⋉')],\n",
       " 'p(X_0^f | x_0^i)': <function __main__.generateInputModel.<locals>.inputDist_givenPrefix>,\n",
       " 'p(X_0^f)': ProbDist({('⋊', 0, 0, '⋉'): Fraction(1, 2),\n",
       "           ('⋊', 0, 0, 1, '⋉'): Fraction(1, 2)}),\n",
       " 'p(Y_i)': ProbDist({0: 0.25, 1: 0.25, '⋉': 0.25, '⋊': 0.25}),\n",
       " 'p(Y_i|x_i)': {0: ProbDist({0: 0.85, 1: 0.15}),\n",
       "  1: ProbDist({0: 0.15, 1: 0.85}),\n",
       "  '⋉': ProbDist({'⋉': Fraction(1, 1)}),\n",
       "  '⋊': ProbDist({'⋊': Fraction(1, 1)})},\n",
       " 'p(x_0^i)': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'p(x_{i+1}^f | x_0^i)': <function __main__.generateInputModel.<locals>.suffixProb>,\n",
       " 'p(y_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_marginal_prob>,\n",
       " 'p(y_0^j|x_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_prob>,\n",
       " 'p-hat(x-hat_0^j|x_0^i)': <function __main__.generateTotalModel.<locals>.est_channelInput_prob>,\n",
       " 'prefixProb': <function __main__.generateInputModel.<locals>.prefixProb>,\n",
       " 'prefixes': {('⋊', 0),\n",
       "  ('⋊', 0, 0),\n",
       "  ('⋊', 0, 0, '⋉'),\n",
       "  ('⋊', 0, 0, 1),\n",
       "  ('⋊', 0, 0, 1, '⋉'),\n",
       "  ('⋊',)},\n",
       " 'sample from p(Y_0^i|x_0^i)': <function __main__.generateChannelModel.<locals>.channelOutput_prefix_sampler>,\n",
       " 'suffixProb': <function __main__.generateInputModel.<locals>.suffixProb>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('DERIVED VALUES/FUNCTIONS:')\n",
    "\n",
    "total_model = generateTotalModel(inputDist, channelOutput_i_dist)\n",
    "total_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines a variety of test inputs, prefixes, and suffixes (usually restated when used later)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:24.830488Z",
     "start_time": "2018-03-31T23:39:24.801833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST INPUTS:\n",
      "an_input: ('⋊', 0, 0, '⋉')\n",
      "prefix_a: ('⋊', 0)\n",
      "prefix_b: ('⋊', 0, 0)\n",
      "prefix_c: ('⋊', 0, 0, '⋉')\n",
      "prefix_d: ('⋊', 0)\n",
      "suffix_a: (0, 0, '⋉')\n",
      "suffix_b: (1, '⋉')\n",
      "suffix_c: (0, '⋉')\n"
     ]
    }
   ],
   "source": [
    "print('TEST INPUTS:')\n",
    "an_input = total_model['inputs'][1]\n",
    "prefix_a = an_input[0:2]\n",
    "prefix_b = an_input[0:3]\n",
    "prefix_c = an_input[0:4]\n",
    "prefix_d = an_input[:-2]\n",
    "suffix_a = an_input[-3:]\n",
    "suffix_b = tuple([1,'⋉'])\n",
    "suffix_c = an_input[-2:]\n",
    "\n",
    "print('an_input: {0}'.format(an_input))\n",
    "print('prefix_a: {0}'.format(prefix_a))\n",
    "print('prefix_b: {0}'.format(prefix_b))\n",
    "print('prefix_c: {0}'.format(prefix_c))\n",
    "print('prefix_d: {0}'.format(prefix_d))\n",
    "print('suffix_a: {0}'.format(suffix_a))\n",
    "print('suffix_b: {0}'.format(suffix_b))\n",
    "print('suffix_c: {0}'.format(suffix_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two cells below show properties of the input distribution $p(X_0^f)$ and calculations derived from it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:26.871577Z",
     "start_time": "2018-03-31T23:39:26.848157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of the lexicon:\n",
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "inputs:\n",
      "[('⋊', 0, 0, 1, '⋉'), ('⋊', 0, 0, '⋉')]\n",
      "input alphabet:\n",
      "{0, 1, '⋊', '⋉'}\n",
      "input alphabet - edge symbols:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<= 10 prefixes of lexicon:\n",
      "[('⋊', 0, 0, '⋉'), ('⋊', 0, 0), ('⋊',), ('⋊', 0, 0, 1, '⋉'), ('⋊', 0, 0, 1), ('⋊', 0)]\n"
     ]
    }
   ],
   "source": [
    "print('Properties of the lexicon:')\n",
    "print('p(X_0^f):')\n",
    "print(inputDist)\n",
    "print('inputs:')\n",
    "print(total_model['inputs'])\n",
    "\n",
    "print('input alphabet:')\n",
    "print(total_model['inputAlphabet'])\n",
    "print('input alphabet - edge symbols:')\n",
    "total_model['inputAlphabet'] - edgeSymbols\n",
    "\n",
    "print(\"<= 10 prefixes of lexicon:\")\n",
    "print(list(total_model['prefixes'])[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...like \n",
    " - the probability the speaker's intended wordform has a particular prefix $p(x_0^i)$.\n",
    " - the distribution over full wordforms given a specific prefix $p(X_0^f|x_0^i)$.\n",
    " - the probability of a particular suffix given a particular prefix $p(x_{i+1}^f|x_0^i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:29.382220Z",
     "start_time": "2018-03-31T23:39:29.309371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefixes/suffixes:\n",
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "TEST PREFIX: ('⋊', 0)\n",
      "p(x_0^i = ('⋊', 0)) = 1\n",
      "p(X_0^f| x_0^i = ('⋊', 0)):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "TEST PREFIX: ('⋊', 0, 0)\n",
      "p(x_0^i = ('⋊', 0, 0)) = 1\n",
      "p(X_0^f| x_0^i = ('⋊', 0, 0)):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "TEST PREFIX: ('⋊', 0, 0, '⋉')\n",
      "p(x_0^i = ('⋊', 0, 0, '⋉')) = 1/2\n",
      "p(X_0^f| x_0^i = ('⋊', 0, 0, '⋉')):\n",
      "('⋊', 0, 0, '⋉'): 1/1 = 1.0\n",
      "\n",
      "TEST PREFIX: ('⋊', 0, 0, '⋉')\n",
      "TEST SUFFIX: (0, 0, '⋉')\n",
      "Let j = i+1:\n",
      " p(x_j^f = (0, 0, '⋉')|x_0^i = ('⋊', 0, 0, '⋉')) = 0\n",
      "TEST PREFIX: ('⋊', 0)\n",
      "TEST SUFFIX: (0, '⋉')\n",
      "Let j = i+1:\n",
      " p(x_j^f = (0, '⋉')|x_0^i = ('⋊', 0)) = 1/2\n"
     ]
    }
   ],
   "source": [
    "print('Prefixes/suffixes:')\n",
    "\n",
    "print('p(X_0^f):')\n",
    "print(inputDist)\n",
    "test_prefix = prefix_a\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, total_model['prefixProb'](test_prefix)))\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(total_model['inputDist_givenPrefix'](test_prefix))\n",
    "test_prefix = prefix_b\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, total_model['prefixProb'](test_prefix)))\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(total_model['inputDist_givenPrefix'](test_prefix))\n",
    "test_prefix = prefix_c\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, total_model['prefixProb'](test_prefix)))\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(total_model['inputDist_givenPrefix'](test_prefix))\n",
    "\n",
    "test_suffix = suffix_a\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('TEST SUFFIX: {0}'.format(test_suffix))\n",
    "print('Let j = i+1:')\n",
    "print(' p(x_j^f = {0}|x_0^i = {1}) = {2}'.format(test_suffix, test_prefix, total_model['suffixProb'](test_suffix, test_prefix)))\n",
    "test_prefix = prefix_d\n",
    "test_suffix = suffix_c\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('TEST SUFFIX: {0}'.format(test_suffix))\n",
    "print('Let j = i+1:')\n",
    "print(' p(x_j^f = {0}|x_0^i = {1}) = {2}'.format(test_suffix, test_prefix, total_model['suffixProb'](test_suffix, test_prefix)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the channel distribution over a single segment $p(Y|X = x)$ and the marginal distribution $p(Y)$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:33.732046Z",
     "start_time": "2018-03-31T23:39:33.716531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of the channel distribution over a single segment...\n",
      "p(Y_i|X_i = 0):\n",
      "0: 0.85\n",
      "1: 0.15\n",
      "\n",
      "p(Y_i|X_i = 1):\n",
      "0: 0.15\n",
      "1: 0.85\n",
      "\n",
      "p(Y_i):\n",
      "0: 0.25\n",
      "1: 0.25\n",
      "'⋊': 0.25\n",
      "'⋉': 0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Properties of the channel distribution over a single segment...')\n",
    "print('p(Y_i|X_i = 0):')\n",
    "# print(channelOutput_i_dist(0))\n",
    "print(channelOutput_i_dist[0])\n",
    "print('p(Y_i|X_i = 1):')\n",
    "# print(channelOutput_i_dist(1))\n",
    "print(channelOutput_i_dist[1])\n",
    "\n",
    "print(\"p(Y_i):\")\n",
    "print(total_model['channelOutput_i_marginal_dist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are example calculations related to the following channel distribution over prefixes:\n",
    " - $p(y_0^i|x_0^i)$\n",
    " - $p(y_0^j|x_0^i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:38.765740Z",
     "start_time": "2018-03-31T23:39:38.682761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of the channel distribution over prefixes...\n",
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "TEST INPUT full: ('⋊', 0, 0, '⋉')\n",
      "TEST OUTPUT full: ('⋊', 0, 0, '⋉')\n",
      "p(y_0^i = ('⋊', 0, 0, '⋉')| x_0^i = ('⋊', 0, 0, '⋉')) = 0.7224999999999999\n",
      "len((0, 0)) = 2\n",
      "p(no_error_i) = 0.75\n",
      "0.75^(len((0, 0))) = 0.5625\n",
      " \n",
      "TEST INPUT prefix: ('⋊', 0)\n",
      "TEST OUTPUT prefix: ('⋊', 0)\n",
      "p(y_0^i = ('⋊', 0)| x_0^i = ('⋊', 0)) = 0.85\n",
      " \n",
      "TEST INPUT prefix: ('⋊', 0)\n",
      "TEST OUTPUT prefix: ('⋊', 0, 0)\n",
      "p(y_0^j = ('⋊', 0, 0)| x_0^i = ('⋊', 0)) = 0.7224999999999999\n",
      " \n",
      "TEST INPUT prefix: ('⋊', 0, 0)\n",
      "TEST OUTPUT prefix: ('⋊', 0)\n",
      "p(y_0^j = ('⋊', 0)| x_0^i = ('⋊', 0, 0)) = 0.85\n"
     ]
    }
   ],
   "source": [
    "print('Properties of the channel distribution over prefixes...')\n",
    "\n",
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "  \n",
    "test_input_full = an_input\n",
    "test_output_full = an_input\n",
    "print(\"TEST INPUT full: {0}\".format(test_input_full))\n",
    "print(\"TEST OUTPUT full: {0}\".format(test_output_full))\n",
    "print('p(y_0^i = {0}| x_0^i = {1}) = {2}'.format(test_output_full, test_input_full, total_model['channelOutput_prefix_prob'](test_input_full, test_output_full)))\n",
    "print('len({0}) = {1}'.format(trimBoundariesFromSequence(test_input_full), len(trimBoundariesFromSequence(test_input_full))))\n",
    "print('p(no_error_i) = {0}'.format(pNoError_i))\n",
    "print('{2}^(len({0})) = {1}'.format(trimBoundariesFromSequence(test_input_full), pNoError_i ** len(trimBoundariesFromSequence(test_input_full)), pNoError_i))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = prefix_a\n",
    "test_output_slice = prefix_a\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^i = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, total_model['channelOutput_prefix_prob'](test_input_slice, test_output_slice)))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = prefix_a\n",
    "test_output_slice = prefix_b\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, total_model['channelOutput_prefix_prob'](test_input_slice, test_output_slice)))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = prefix_b\n",
    "test_output_slice = prefix_a\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, total_model['channelOutput_prefix_prob'](test_input_slice, test_output_slice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are samples from $p(Y_0^i|x_0^i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:53.937837Z",
     "start_time": "2018-03-31T23:39:53.928816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST INPUT prefix: ('⋊', 0, 0)\n",
      "10 samples from p(Y_0^i|x_0^i = ('⋊', 0, 0)): [('⋊', 0, 0), ('⋊', 0, 0), ('⋊', 0, 1), ('⋊', 0, 0), ('⋊', 0, 1), ('⋊', 0, 0), ('⋊', 0, 0), ('⋊', 0, 0), ('⋊', 0, 0), ('⋊', 1, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST INPUT prefix: {0}\".format(prefix_b))\n",
    "print('10 samples from p(Y_0^i|x_0^i = {0}): {1}'.format(prefix_b, list(sampleFrom(lambda : total_model['channelOutput_prefix_sampler'](prefix_b), 10)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example calculation of $p(y_0^i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:54.928966Z",
     "start_time": "2018-03-31T23:39:54.922279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST OUTPUT prefix = ('⋊', 0, 0)\n",
      "p(y_0^i = ('⋊', 0, 0)) = 0.7224999999999999\n"
     ]
    }
   ],
   "source": [
    "print('TEST OUTPUT prefix = {0}'.format(prefix_b))\n",
    "print('p(y_0^i = {0}) = {1}'.format(prefix_b, total_model['channelOutput_prefix_marginal_prob'](prefix_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below are example calculations of $p(\\hat{x}_0^j| x_0^i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:39:57.982044Z",
     "start_time": "2018-03-31T23:39:56.554039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "('⋊', 0, 0, 1, '⋉'): 1/2 = 0.5\n",
      "('⋊', 0, 0, '⋉'): 1/2 = 0.5\n",
      "\n",
      "est p(x-hat_0^j = ('⋊', 1)| x_0^i = ('⋊', 0, 0)) = 0\n",
      " \n",
      "est p(x-hat_0^j = ('⋊', 0, 0)| x_0^i = ('⋊', 0, 0)) = 1.0\n",
      " \n",
      "est p(x-hat_0^j = ('⋊', 0, 0, '⋉')| x_0^i = ('⋊', 0, 0)) = 0.5\n",
      " \n",
      "est p(x-hat_0^j = ('⋊', 0, 0)| x_0^i = ('⋊', 0, 0, '⋉')) = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(('⋊', 1), prefix_b, total_model['est_channelInput_prob'](prefix_b, ('⋊', 1))))\n",
    "print(' ')\n",
    "\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_b, prefix_b, total_model['est_channelInput_prob'](prefix_b, prefix_b)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(an_input, prefix_b, total_model['est_channelInput_prob'](prefix_b, an_input)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_b, an_input, total_model['est_channelInput_prob'](an_input, prefix_b)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "330px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
