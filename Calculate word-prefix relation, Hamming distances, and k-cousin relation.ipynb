{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:42.507369Z",
     "start_time": "2019-09-12T19:17:42.503851Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Use\" data-toc-modified-id=\"Use-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Use</a></span></li><li><span><a href=\"#Import-libraries-and-data\" data-toc-modified-id=\"Import-libraries-and-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import libraries and data</a></span></li><li><span><a href=\"#Basic-representations---words-and-prefixes\" data-toc-modified-id=\"Basic-representations---words-and-prefixes-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Basic representations - words and prefixes</a></span></li><li><span><a href=\"#Basic-vectorized-representations\" data-toc-modified-id=\"Basic-vectorized-representations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Basic vectorized representations</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-hot-representations\" data-toc-modified-id=\"One-hot-representations-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>One-hot representations</a></span></li><li><span><a href=\"#Padding-and-trimming-to-create-a-fixed-size-representation\" data-toc-modified-id=\"Padding-and-trimming-to-create-a-fixed-size-representation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Padding and trimming to create a fixed-size representation</a></span></li></ul></li><li><span><a href=\"#Prefixes\" data-toc-modified-id=\"Prefixes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Prefixes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generating-prefixes\" data-toc-modified-id=\"Generating-prefixes-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Generating prefixes</a></span></li><li><span><a href=\"#Generating-padded/trimmed-prefixes\" data-toc-modified-id=\"Generating-padded/trimmed-prefixes-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Generating padded/trimmed prefixes</a></span></li><li><span><a href=\"#Detecting-whether-p-is-a-prefix-of-w\" data-toc-modified-id=\"Detecting-whether-p-is-a-prefix-of-w-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Detecting whether <code>p</code> is a prefix of <code>w</code></a></span></li><li><span><a href=\"#Generating-a-prefix-word-relation\" data-toc-modified-id=\"Generating-a-prefix-word-relation-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Generating a <code>prefix-word</code> relation</a></span></li><li><span><a href=\"#The-(p,w,l)-relation-where-w-trimmed-to-l-is-p\" data-toc-modified-id=\"The-(p,w,l)-relation-where-w-trimmed-to-l-is-p-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>The <code>(p,w,l)</code> relation where <code>w</code> trimmed to <code>l</code> is <code>p</code></a></span></li></ul></li><li><span><a href=\"#Hamming-distance\" data-toc-modified-id=\"Hamming-distance-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hamming distance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distance-between-symbol-vectors\" data-toc-modified-id=\"Distance-between-symbol-vectors-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Distance between symbol vectors</a></span></li><li><span><a href=\"#Hamming-distance-between-stacks-of-symbol-vectors-(strings)\" data-toc-modified-id=\"Hamming-distance-between-stacks-of-symbol-vectors-(strings)-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Hamming distance between stacks of symbol vectors (strings)</a></span></li><li><span><a href=\"#Distance-between-a-string-and-a-stack-of-strings\" data-toc-modified-id=\"Distance-between-a-string-and-a-stack-of-strings-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Distance between a string and a stack of strings</a></span></li><li><span><a href=\"#Hamming-distance-between-every-pair-of-strings-in-a-stack\" data-toc-modified-id=\"Hamming-distance-between-every-pair-of-strings-in-a-stack-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Hamming distance between every pair of strings in a stack</a></span></li></ul></li><li><span><a href=\"#$k$-cousin-calculation\" data-toc-modified-id=\"$k$-cousin-calculation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>$k$-cousin calculation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Definitions,-motivation,-and-calculation-sketch\" data-toc-modified-id=\"Definitions,-motivation,-and-calculation-sketch-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Definitions, motivation, and calculation sketch</a></span></li></ul></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a finite set of strings (wordforms) $L$, we may want to efficiently calculate for subsequent use\n",
    " - the natural relation between the set of prefixes $P$ (of $L$) and $L$ indicating which prefixes are prefixes of a given string $s \\in L$ and which strings $s \\in L$ have a given $p \\in P$ as a prefix\n",
    " - the matrix of Hamming distances between all pairs of strings (full wordforms) in $L$\n",
    " - the matrix of Hamming distances between all pairs of prefixes of strings in $L$\n",
    " - the \"$k$-cousin\" function/relation between strings in $L$ and prefixes of strings of $L$. (See the $k$-cousin calculation section header for more of an explanation.)\n",
    "\n",
    "This notebook documents vectorized and otherwise parallelized code for such calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given \n",
    " - a filepath $p$ to *either*\n",
    "    - a conditional distribution on segmental wordforms given an orthographic wordform $p(W|V)$\n",
    "    - an unconditioned distribution on segmental wordforms $p(W)$\n",
    " - an output filepath prefix $o$\n",
    " \n",
    "this notebook calculates and writes to file \n",
    " - what the prefix relation of $W$ is\n",
    " - what the Hamming distance between all pairs of wordforms in $W$ is\n",
    "   - **NB:** for storage and time complexity reasons, $-1$ is used instead of $\\infty$ to represent distance between strings of differing length. ($\\infty$ requires floats, where everything else here is nicely represented using (u)int8 types; the same note applies to the other two output matrices representing Hamming distance information.) \n",
    " - what the Hamming distance between all pairs of prefixes of $W$ is\n",
    " - what the $k$-cousin relation/function between all prefixes of $W$ and $W$ is\n",
    "   - **NB:** the matrix describing this is memory-mapped, unlike the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:42.584763Z",
     "start_time": "2019-09-12T19:17:42.521091Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import getcwd, chdir, listdir, path, mkdir, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:46.172525Z",
     "start_time": "2019-09-12T19:17:42.586709Z"
    }
   },
   "outputs": [],
   "source": [
    "from boilerplate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:46.177868Z",
     "start_time": "2019-09-12T19:17:46.175161Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:46.185381Z",
     "start_time": "2019-09-12T19:17:46.179303Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "p = ''\n",
    "# p = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_pX0X1X2.json'\n",
    "\n",
    "o = ''\n",
    "# o = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2'\n",
    "\n",
    "g = ''\n",
    "# g = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:46.192056Z",
     "start_time": "2019-09-12T19:17:46.186586Z"
    }
   },
   "outputs": [],
   "source": [
    "if g == '' or g == 'True' or g == True:\n",
    "    g = True\n",
    "elif g == 'False' or g == False:\n",
    "    g = False\n",
    "else:\n",
    "    raise Exception(f\"g must be one of {'', 'True', 'False'}, got {g} instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:46.218319Z",
     "start_time": "2019-09-12T19:17:46.193229Z"
    }
   },
   "outputs": [],
   "source": [
    "from probdist import *\n",
    "from string_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:46.338256Z",
     "start_time": "2019-09-12T19:17:46.219796Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "J = -1\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def par(gen_expr):\n",
    "    return Parallel(n_jobs=J, backend=BACKEND, verbose=V, prefer=PREFER)(gen_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:47.924871Z",
     "start_time": "2019-09-12T19:17:46.340509Z"
    }
   },
   "outputs": [],
   "source": [
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:48.041834Z",
     "start_time": "2019-09-12T19:17:47.926641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        868M        8.2G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:48.076031Z",
     "start_time": "2019-09-12T19:17:48.043501Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'pW_V' in p:\n",
    "    pW_V = condDistsAsProbDists(importProbDist(p))\n",
    "elif 'pX0X1X2' in p:\n",
    "    pW = ProbDist(importProbDist(p))\n",
    "else:\n",
    "    raise Exception(f\"Unknown type of 'p' parameter = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:48.190564Z",
     "start_time": "2019-09-12T19:17:48.077085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        871M        8.2G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:48.195064Z",
     "start_time": "2019-09-12T19:17:48.192491Z"
    }
   },
   "outputs": [],
   "source": [
    "testing = False\n",
    "benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:48.245297Z",
     "start_time": "2019-09-12T19:17:48.196194Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dtype = np.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:49.502601Z",
     "start_time": "2019-09-12T19:17:48.246754Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:53.546821Z",
     "start_time": "2019-09-12T19:17:49.504347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2070\n",
      "Total Memory: 8367.439872\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "#     if g and l:\n",
    "#         print(\"Disabling 'parallelize' flag...\")\n",
    "#         l = False\n",
    "#     import cupy\n",
    "    \n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    total_mem_MB = torch.cuda.get_device_properties(device).total_memory / 1e6\n",
    "    print('Total Memory: {0}'.format(total_mem_MB) )\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(torch.cuda.get_device_name(1))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(1)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_cached(1)/1024**3,1), 'GB')\n",
    "elif g:\n",
    "    print(\"g set to 'True', but torch cannot find a GPU. Setting g to 'False'.\")\n",
    "    g = False\n",
    "else:\n",
    "    pass\n",
    "#     raise Exception(f\"g set to 'True' but torch cannot find a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:53.551789Z",
     "start_time": "2019-09-12T19:17:53.548193Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "my_device = cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:53.560036Z",
     "start_time": "2019-09-12T19:17:53.553119Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda_ft = torch.cuda.FloatTensor\n",
    "cuda_dt = torch.cuda.DoubleTensor\n",
    "\n",
    "ft = torch.FloatTensor\n",
    "dt = torch.DoubleTensor\n",
    "\n",
    "my_ft = ft\n",
    "my_dt = dt\n",
    "\n",
    "my_type = my_ft\n",
    "# my_type = my_dt\n",
    "\n",
    "torch.set_default_tensor_type(my_type)\n",
    "\n",
    "my_cpu_type = torch.int8\n",
    "my_cuda_type = torch.float16\n",
    "# my_tt = torch.float32\n",
    "# my_tt = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic representations - words and prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are reference objects we will work with and use to check vectorized calculations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:53.577809Z",
     "start_time": "2019-09-12T19:17:53.561480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6737"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'pW_V' in p:\n",
    "    # Vs = set(pW_V.keys())\n",
    "    Ws = union(mapValues(lambda dist: set(conditions(dist)), \n",
    "                         pW_V).values())\n",
    "elif 'pX0X1X2' in p:\n",
    "    Ws = set(conditions(pW))\n",
    "else:\n",
    "    raise Exception(f\"Unknown type of 'p' parameter = {p}\")\n",
    "\n",
    "# len(Vs)\n",
    "len(Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:53.585472Z",
     "start_time": "2019-09-12T19:17:53.579358Z"
    }
   },
   "outputs": [],
   "source": [
    "Ws_t = tuple(sorted(list(Ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.063831Z",
     "start_time": "2019-09-12T19:17:53.586669Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0030s.) Setting batch_size=132.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6737 out of 6737 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21180"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#≈200s on CMU on solomonoff\n",
    "Ps = union(list(par(delayed(getPrefixes)(w) for w in Ws)))\n",
    "# Ps = union(par(delayed(getPrefixes)(w) for w in Ws))\n",
    "# Ps = union([getPrefixes(w) for w in Ws])\n",
    "Ps_t = tuple(sorted(list(Ps)))\n",
    "len(Ps_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic vectorized representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to work with \n",
    " 1. one-hot vector-based representations of strings\n",
    " 2. fixed-dimension representations of strings\n",
    "\n",
    "To support #2, we will want to pad or trim (i.e. de-suffix = remove material corresponding to the right edge of the string) one-hot representations of string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.072192Z",
     "start_time": "2019-09-12T19:17:55.065566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_uint8(arr):\n",
    "    return arr.astype(np.uint8)\n",
    "\n",
    "np.ones(3).dtype\n",
    "to_uint8(np.ones(3)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.103096Z",
     "start_time": "2019-09-12T19:17:55.073755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([18,  9,  6, 12], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = lexiconToInventory(Ws)\n",
    "len(Xs)\n",
    "\n",
    "Xmap = seqsToIndexMap(Xs)\n",
    "XOHmap = seqsToOneHotMap(Xs)\n",
    "# XOHmap = mapValues(to_uint8, seqsToOneHotMap(Xs))\n",
    "\n",
    "def dsToUniphoneIndices(ds, uniphoneToIndexMap):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    return np.array([uniphoneToIndexMap[uniphone] for uniphone in uniphoneSeq], dtype=np.uint8)\n",
    "\n",
    "def dsToUniphoneOHs(ds, uniphoneToOHmap):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    return np.array([uniphoneToOHmap[uniphone] for uniphone in uniphoneSeq], dtype=np.uint8)\n",
    "\n",
    "dsToUniphoneIndices('t.i.f.l', Xmap)\n",
    "dsToUniphoneOHs('t.i.f.l', XOHmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.111502Z",
     "start_time": "2019-09-12T19:17:55.106224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t.i.f.l'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHXmap = oneHotToSeqMap(Xs)\n",
    "\n",
    "def OHsToDS(OHs, OHtoUniphoneMap):\n",
    "    return t2ds([OHtoUniphoneMap(OH)\n",
    "                 for OH in OHs if OH.sum() > 0])\n",
    "\n",
    "#should give us back what we put in\n",
    "OHsToDS(dsToUniphoneOHs('t.i.f.l', XOHmap),\n",
    "        OHXmap)\n",
    "\n",
    "#should yield the empty string\n",
    "OHsToDS(np.array([0]), OHXmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.117390Z",
     "start_time": "2019-09-12T19:17:55.113142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w = choice(Ws_t); random_w\n",
    "len(ds2t(random_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.124455Z",
     "start_time": "2019-09-12T19:17:55.118514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 15, 27, 12, 39, 39], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsToUniphoneIndices(random_w, Xmap)\n",
    "random_w_OH = dsToUniphoneOHs(random_w, XOHmap)\n",
    "random_w_OH.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and trimming to create a fixed-size representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The padding one-hot vector is **the zero vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.136938Z",
     "start_time": "2019-09-12T19:17:55.125986Z"
    }
   },
   "outputs": [],
   "source": [
    "def padWord(w_OHs, goal_length):\n",
    "    l = w_OHs.shape[0]\n",
    "    if l > goal_length:\n",
    "        raise Exception(f\"word length = {l} > goal length = {goal_length}\")\n",
    "    if l == goal_length:\n",
    "        return w_OHs\n",
    "    return np.pad(w_OHs,\n",
    "                  ((0, goal_length - l), (0,0)),\n",
    "                  mode='constant',\n",
    "                  constant_values=0)\n",
    "\n",
    "\n",
    "def trimWord(w_OHs, goal_length):\n",
    "    l = w_OHs.shape[0]\n",
    "    if l < goal_length:\n",
    "        raise Exception(f\"word length = {l} < goal length = {goal_length}\")\n",
    "    if l == goal_length:\n",
    "        return w_OHs\n",
    "    return w_OHs[:goal_length]\n",
    "\n",
    "\n",
    "def adjustWord(w_OHs, goal_length):\n",
    "    l = w_OHs.shape[0]\n",
    "    if l == goal_length:\n",
    "        return w_OHs\n",
    "    elif l < goal_length:\n",
    "        return padWord(w_OHs, goal_length)\n",
    "    else:\n",
    "        return trimWord(w_OHs, goal_length)\n",
    "\n",
    "    \n",
    "def lexiconToFixedSizeOHs(Ws, fixed_size = None):\n",
    "    maxL = max({len(ds2t(w)) for w in Ws})\n",
    "    if fixed_size is None:\n",
    "        fixed_size = maxL    \n",
    "    \n",
    "    Ws_OH = (dsToUniphoneOHs(w, XOHmap) for w in Ws)\n",
    "    Ws_OH_adjusted = np.array([adjustWord(w_OH, fixed_size) for w_OH in Ws_OH])\n",
    "    return Ws_OH_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.145301Z",
     "start_time": "2019-09-12T19:17:55.138500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w_OH\n",
    "random_w_OH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.152394Z",
     "start_time": "2019-09-12T19:17:55.146396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padWord(random_w_OH, random_w_OH.shape[0] + 1)\n",
    "assert np.array_equal(padWord(random_w_OH, random_w_OH.shape[0] + 1), \n",
    "                      adjustWord(random_w_OH, random_w_OH.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.159641Z",
     "start_time": "2019-09-12T19:17:55.153952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimWord(random_w_OH, random_w_OH.shape[0] - 1)\n",
    "assert np.array_equal(trimWord(random_w_OH, random_w_OH.shape[0] - 1), \n",
    "                      adjustWord(random_w_OH, random_w_OH.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.205779Z",
     "start_time": "2019-09-12T19:17:55.161150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.657302"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.001657302"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_npf = lexiconToFixedSizeOHs(Ws_t)\n",
    "Ws_npf.dtype\n",
    "Ws_npf.shape #:: (|Ws|, maxL, |Xs|) = (n, L_bar, s)\n",
    "Ws_npf.nbytes / 1e6\n",
    "Ws_npf.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.218877Z",
     "start_time": "2019-09-12T19:17:55.206977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.01055"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.024390243902439025"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_sf = sparse.COO.from_numpy(Ws_npf)\n",
    "Ws_sf.dtype\n",
    "Ws_sf.shape\n",
    "Ws_sf.nbytes / 1e6\n",
    "Ws_sf.density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to detect and/or undo padding/trimming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:17:55.223614Z",
     "start_time": "2019-09-12T19:17:55.220059Z"
    }
   },
   "outputs": [],
   "source": [
    "#Recall: a padded OH matrix will have at least one row that is a zero vector\n",
    "def isPaddedOHstack(p_OH):\n",
    "    return not np.product( np.sum(p_OH, axis=1) )\n",
    "\n",
    "def unpad(padded_p_OH):\n",
    "#     if not isPaddedOHstack(p_OH):\n",
    "#         return padded_p_OH\n",
    "    rowIsUnPadded = np.sum(padded_p_OH, axis=1)\n",
    "    isPadded = not np.product(rowIsUnPadded)\n",
    "    if not isPadded:\n",
    "        return padded_p_OH\n",
    "    nonPaddingRows = np.array([padded_p_OH_row \n",
    "                               for i, padded_p_OH_row in enumerate(padded_p_OH) \n",
    "                               if rowIsUnPadded[i]])\n",
    "    return nonPaddingRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:14.089101Z",
     "start_time": "2019-09-12T19:21:14.085815Z"
    }
   },
   "outputs": [],
   "source": [
    "def containsAnyPaddedOHstacks(L_OHs):\n",
    "    return any(map(isPaddedOHstack, L_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:23.473632Z",
     "start_time": "2019-09-12T19:21:23.416802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containsAnyPaddedOHstacks(Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:34.789893Z",
     "start_time": "2019-09-12T19:21:34.727822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.b.aɪ.⋉.⋉'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.b.aɪ.⋉.⋉'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.b.aɪ.⋉.⋉'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = Ws_t[0]; w0\n",
    "w0_l = len(ds2t(Ws_t[0])); w0_l\n",
    "\n",
    "# random_w_OH = dsToUniphoneOHs(random_w, XOHmap)\n",
    "unpadded_w0_OH_rep = dsToUniphoneOHs(w0, XOHmap); unpadded_w0_OH_rep.shape\n",
    "OHsToDS(unpadded_w0_OH_rep, OHXmap)\n",
    "assert not isPaddedOHstack(unpadded_w0_OH_rep)\n",
    "\n",
    "padded_w0_OH_rep = Ws_npf[0]; padded_w0_OH_rep.shape\n",
    "OHsToDS(padded_w0_OH_rep, OHXmap)\n",
    "assert isPaddedOHstack(padded_w0_OH_rep) or not containsAnyPaddedOHstacks(Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:36.301240Z",
     "start_time": "2019-09-12T19:21:36.295735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_w0_OH_rep.shape\n",
    "padded_w0_OH_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:36.961531Z",
     "start_time": "2019-09-12T19:21:36.955265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1], dtype=uint64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(padded_w0_OH_rep, axis=1)\n",
    "np.sum(padded_w0_OH_rep, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:37.670204Z",
     "start_time": "2019-09-12T19:21:37.663626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trueLength(possibly_padded_OHs):\n",
    "    return np.sum(possibly_padded_OHs, axis=1).sum()\n",
    "\n",
    "def unpaddedMask(possibly_padded_OHs):\n",
    "    return np.sum(possibly_padded_OHs, axis=1)\n",
    "\n",
    "trueLength(padded_w0_OH_rep)\n",
    "assert trueLength(padded_w0_OH_rep) == unpadded_w0_OH_rep.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:39.143878Z",
     "start_time": "2019-09-12T19:21:39.134531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_OH\n",
    "a_prefix_of_random_w_OH = random_w_OH[:-3] # <- that's a prefix\n",
    "a_prefix_of_random_w = OHsToDS(a_prefix_of_random_w_OH, OHXmap)\n",
    "a_prefix_of_random_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:39.695491Z",
     "start_time": "2019-09-12T19:21:39.686467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2, 41)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(random_w))\n",
    "random_w_OH.shape\n",
    "random_w_OH[:2].shape\n",
    "random_w_OH[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:41.958935Z",
     "start_time": "2019-09-12T19:21:41.948444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(6, 41), (5, 41), (4, 41), (3, 41), (2, 41), (1, 41)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPrefixes_OH(w_OH):\n",
    "    return [w_OH] + [w_OH[:-i] for i in range(1,len(w_OH))]\n",
    "\n",
    "random_w_OH.shape\n",
    "lmap(lambda m: m.shape, getPrefixes_OH(random_w_OH))\n",
    "lmap(lambda m: np.array_equal(m, random_w_OH), getPrefixes_OH(random_w_OH)) #< only the leftmost value should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:41.973908Z",
     "start_time": "2019-09-12T19:21:41.960538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengths = {len(ds2t(w)) for w in Ws}\n",
    "wordlengths\n",
    "wordlengths = tuple(range(min(wordlengths), max(wordlengths)+1))\n",
    "wordlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:44.819063Z",
     "start_time": "2019-09-12T19:21:44.803187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 41)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w_OH.shape\n",
    "max(wordlengths)\n",
    "diff = max(wordlengths) - random_w_OH.shape[0]; diff\n",
    "\n",
    "random_w_OH_padded = np.pad(random_w_OH, \n",
    "                            ((0, max(wordlengths) - random_w_OH.shape[0]), (0,0)), \n",
    "                            mode='constant', \n",
    "                            constant_values=0.0)\n",
    "random_w_OH_padded.shape\n",
    "assert np.array_equal(random_w_OH_padded[:random_w_OH.shape[0]],\n",
    "                      random_w_OH)\n",
    "random_w_OH_padded[random_w_OH.shape[0]:].shape\n",
    "assert np.array_equal(random_w_OH_padded[random_w_OH.shape[0]:], \n",
    "                      np.zeros((diff, random_w_OH.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating padded/trimmed prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's incorporate padding and trimming..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:46.894623Z",
     "start_time": "2019-09-12T19:21:46.890699Z"
    }
   },
   "outputs": [],
   "source": [
    "def getPrefixes_OH(w_OH, padded_length=None):\n",
    "    unpadded = [w_OH] + [w_OH[:-i] for i in range(1,len(w_OH))]\n",
    "    if padded_length is None:\n",
    "        return unpadded\n",
    "    return list(map(lambda p_OH: padWord(p_OH, padded_length), unpadded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:47.552993Z",
     "start_time": "2019-09-12T19:21:47.539119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(6, 41), (5, 41), (4, 41), (3, 41), (2, 41), (1, 41)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(6, 41), (6, 41), (6, 41), (6, 41), (6, 41), (6, 41)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_OH.shape\n",
    "list(map(lambda m: m.shape, getPrefixes_OH(random_w_OH)))\n",
    "list(map(lambda m: np.array_equal(m, random_w_OH), getPrefixes_OH(random_w_OH)))  #< only the leftmost value should be True\n",
    "list(map(lambda m: m.shape, getPrefixes_OH(random_w_OH, max(wordlengths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:48.442098Z",
     "start_time": "2019-09-12T19:21:48.435749Z"
    }
   },
   "outputs": [],
   "source": [
    "padded_prefixes_random_w_OH = getPrefixes_OH(random_w_OH, max(wordlengths))\n",
    "\n",
    "padded_prefixes_random_w_OH2 = lmap(partial(adjustWord, goal_length=max(wordlengths)), \n",
    "                                    getPrefixes_OH(random_w_OH))\n",
    "\n",
    "# type(padded_prefixes_random_w_OH)\n",
    "# type(padded_prefixes_random_w_OH2)\n",
    "assert len(padded_prefixes_random_w_OH) == len(padded_prefixes_random_w_OH2)\n",
    "\n",
    "for pair in zip(padded_prefixes_random_w_OH, padded_prefixes_random_w_OH2):\n",
    "    assert np.array_equal(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-use the `adjustWord` function and return a fixed dimension ndarray..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:50.457491Z",
     "start_time": "2019-09-12T19:21:50.450300Z"
    }
   },
   "outputs": [],
   "source": [
    "#FINAL version\n",
    "def getPrefixes_OH(w_OH, goal_length=None):\n",
    "    my_prefixes = [w_OH] + [w_OH[:-i] for i in range(1,len(w_OH))]\n",
    "    if goal_length is None:\n",
    "        return my_prefixes\n",
    "    return np.array(lmap(partial(adjustWord, goal_length=goal_length),\n",
    "                         my_prefixes))\n",
    "\n",
    "padded_prefixes_random_w_OH3 = getPrefixes_OH(random_w_OH, max(wordlengths))\n",
    "\n",
    "for pair in zip(padded_prefixes_random_w_OH2, padded_prefixes_random_w_OH3):\n",
    "    assert np.array_equal(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downstream calculations probably only actually want/need prefixes of length 3 or more (because triphones...), but let's let downstream notebooks / contexts of use take care of that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:52.457316Z",
     "start_time": "2019-09-12T19:21:52.454839Z"
    }
   },
   "outputs": [],
   "source": [
    "only_viable_prefixes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:53.181972Z",
     "start_time": "2019-09-12T19:21:53.177126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if only_viable_prefixes:\n",
    "    prefixlengths = range(3, max(wordlengths)+1)\n",
    "else:\n",
    "    prefixlengths = range(1, max(wordlengths)+1)\n",
    "prefixlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:53.920241Z",
     "start_time": "2019-09-12T19:21:53.915377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixlengths\n",
    "len(list(prefixlengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:55.508875Z",
     "start_time": "2019-09-12T19:21:55.503957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengths\n",
    "len(wordlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sequence of fixed-length representations of the lexicon of increasing size:\n",
    " - `Ps_l[i]` :: (|Ws|, i, |Xs|)\n",
    " - `Ps_l[i][j]` :: (i, |Xs|) is the matrix representing wordform `i` padded or trimmed to be length `i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:56.200705Z",
     "start_time": "2019-09-12T19:21:55.842402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0538s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   6 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#32s CMU/solomonoff\n",
    "#13s CMU/sidious\n",
    "Ps_l = [None for each in range(min(prefixlengths))] + list(par(delayed(lexiconToFixedSizeOHs)(Ws_t, l) for l in prefixlengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:21:59.464098Z",
     "start_time": "2019-09-12T19:21:59.460041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 4, 41)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_l[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:00.154577Z",
     "start_time": "2019-09-12T19:22:00.150393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(wordlengths); max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:01.134116Z",
     "start_time": "2019-09-12T19:22:01.121218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 1, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 2, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 3, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 4, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 5, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.005800557"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in prefixlengths:\n",
    "    Ps_l[l].shape\n",
    "\n",
    "sum([Ps_l[l].nbytes / 1e9 for l in prefixlengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:03.729817Z",
     "start_time": "2019-09-12T19:22:03.724681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHsToDS(Ps_l[5][Ws_t.index(random_w)], OHXmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:04.254338Z",
     "start_time": "2019-09-12T19:22:04.239915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3054"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "Ws_t.index(random_w)\n",
    "OHsToDS(Ws_npf[Ws_t.index(random_w)], OHXmap)\n",
    "for l in prefixlengths:\n",
    "    OHsToDS(Ps_l[l][Ws_t.index(random_w)], OHXmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:43.973959Z",
     "start_time": "2019-09-12T19:22:43.960613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1], dtype=uint64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_l = choice(list(wordlengths))\n",
    "random_l\n",
    "\n",
    "Ps_l[random_l][Ws_t.index(random_w)].shape\n",
    "np.sum(Ps_l[random_l][Ws_t.index(random_w)], axis=1)\n",
    "np.product( np.sum(Ps_l[random_l][Ws_t.index(random_w)], axis=1) )\n",
    "not np.product( np.sum(Ps_l[random_l][Ws_t.index(random_w)], axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:49.531501Z",
     "start_time": "2019-09-12T19:22:49.519238Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrievePrefixes(w_idx=None, w=None, Ws_t=None, Ps_t=None, max_l=None, asType='indices'):\n",
    "    if asType == 'indices' and Ps_t is None:\n",
    "        raise Exception(\"Must specify sorted prefix iterable if asType = 'indices'\")\n",
    "    if w_idx is None and (w is None or Ws_t is None):\n",
    "        raise Exception(\"Not enough information provided to specify a wordform index.\")\n",
    "    \n",
    "    if max_l is None and Ws_t is not None:\n",
    "        max_l = max({len(ds2t(w)) for w in Ws_t})\n",
    "    if max_l is None and Ws_t is None:\n",
    "        max_l = max({len(ds2t(w)) for w in Ps_t})\n",
    "    \n",
    "    \n",
    "    if w_idx is None:\n",
    "        w_idx = Ws_t.index(w)\n",
    "    \n",
    "    prefixSuperset = [Ps_l[l][w_idx] for l in range(min(prefixlengths), max_l+1)]\n",
    "    if asType == 'padded OHs':\n",
    "        return prefixSuperSet\n",
    "    \n",
    "    isPadded = np.array([isPaddedOHstack(p_OH) for p_OH in prefixSuperset])\n",
    "    uniqueOHs = [p_OH for i, p_OH in enumerate(prefixSuperset) if not isPadded[i]]\n",
    "    if asType == 'OHs':\n",
    "        return uniqueOHs\n",
    "    \n",
    "    uniqueStrings = list(map(lambda p_OH: OHsToDS(p_OH, OHXmap), uniqueOHs))\n",
    "    if asType == 'ds':\n",
    "        return uniqueStrings\n",
    "    \n",
    "    uniqueIndices = list(map(lambda p: Ps_t.index(p), uniqueStrings))\n",
    "    if asType == 'indices':\n",
    "        return uniqueIndices\n",
    "    raise Exception('Function should have returned something before now...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:51.778362Z",
     "start_time": "2019-09-12T19:22:51.768338Z"
    }
   },
   "outputs": [],
   "source": [
    "my_max_l = max({len(ds2t(w)) for w in Ws_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:52.334692Z",
     "start_time": "2019-09-12T19:22:52.313181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'⋊.p.ʌ.z.⋉.⋉',\n",
       " '⋊.ɹ.æ.s.⋉.⋉',\n",
       " '⋊.m.k.oʊ.⋉.⋉',\n",
       " '⋊.ɚ.m.j.⋉.⋉',\n",
       " '⋊.ɛ.v.ɪ.⋉.⋉',\n",
       " '⋊.i.ə.n.⋉.⋉',\n",
       " '⋊.k.d.eɪ.⋉.⋉',\n",
       " '⋊.i.n.i.⋉.⋉',\n",
       " '⋊.oʊ.k.oʊ.⋉.⋉',\n",
       " '⋊.eɪ.tʃ.d.⋉.⋉',\n",
       " '⋊.k.b.ʌ.⋉.⋉',\n",
       " '⋊.s.t.u.⋉.⋉',\n",
       " '⋊.ʌ.l.tʃ.⋉.⋉',\n",
       " '⋊.f.t.l.⋉.⋉',\n",
       " '⋊.m.ɪ.ŋ.⋉.⋉',\n",
       " '⋊.ŋ.l.i.⋉.⋉',\n",
       " '⋊.k.æ.k.⋉.⋉',\n",
       " '⋊.ŋ.g.ɚ.⋉.⋉',\n",
       " '⋊.s.g.ʌ.⋉.⋉',\n",
       " '⋊.z.ɪ.k.⋉.⋉',\n",
       " '⋊.j.u.ʃ.⋉.⋉',\n",
       " '⋊.k.oʊ.s.⋉.⋉',\n",
       " '⋊.i.z.d.⋉.⋉',\n",
       " '⋊.s.k.ɪ.⋉.⋉',\n",
       " '⋊.w.aɪ.i.⋉.⋉',\n",
       " '⋊.s.l.ə.⋉.⋉',\n",
       " '⋊.aɪ.t.ɹ.⋉.⋉',\n",
       " '⋊.g.eɪ.m.⋉.⋉',\n",
       " '⋊.l.p.ɑ.⋉.⋉',\n",
       " '⋊.ɪ.n.u.⋉.⋉',\n",
       " '⋊.aɪ.t.m.⋉.⋉',\n",
       " '⋊.ɪ.d.ɚ.⋉.⋉',\n",
       " '⋊.θ.i.d.⋉.⋉',\n",
       " '⋊.k.ɚ.k.⋉.⋉',\n",
       " '⋊.ɑ.ŋ.t.⋉.⋉',\n",
       " '⋊.p.ɚ.tʃ.⋉.⋉',\n",
       " '⋊.n.i.ɪ.⋉.⋉',\n",
       " '⋊.w.eɪ.f.⋉.⋉',\n",
       " '⋊.s.ə.z.⋉.⋉',\n",
       " '⋊.æ.d.ɹ.⋉.⋉',\n",
       " '⋊.ɪ.z.eɪ.⋉.⋉',\n",
       " '⋊.l.ɚ.dʒ.⋉.⋉',\n",
       " '⋊.l.oʊ.ʒ.⋉.⋉',\n",
       " '⋊.s.i.aɪ.⋉.⋉',\n",
       " '⋊.ŋ.g.ɪ.⋉.⋉',\n",
       " '⋊.t.ɚ.b.⋉.⋉',\n",
       " '⋊.b.ɚ.l.⋉.⋉',\n",
       " '⋊.ʌ.b.d.⋉.⋉',\n",
       " '⋊.i.ð.z.⋉.⋉',\n",
       " '⋊.u.m.ə.⋉.⋉',\n",
       " '⋊.s.oʊ.m.⋉.⋉',\n",
       " '⋊.ɹ.æ.v.⋉.⋉',\n",
       " '⋊.ʃ.ə.z.⋉.⋉',\n",
       " '⋊.p.ʌ.n.⋉.⋉',\n",
       " '⋊.g.ə.z.⋉.⋉',\n",
       " '⋊.b.ɑ.d.⋉.⋉',\n",
       " '⋊.dʒ.m.ɪ.⋉.⋉',\n",
       " '⋊.u.b.i.⋉.⋉',\n",
       " '⋊.b.ɪ.z.⋉.⋉',\n",
       " '⋊.æ.t.l.⋉.⋉',\n",
       " '⋊.ɚ.g.ɹ.⋉.⋉',\n",
       " '⋊.i.θ.ɪ.⋉.⋉',\n",
       " '⋊.j.u.θ.⋉.⋉',\n",
       " '⋊.i.ɛ.v.⋉.⋉',\n",
       " '⋊.aɪ.l.d.⋉.⋉',\n",
       " '⋊.t.aɪ.b.⋉.⋉',\n",
       " '⋊.ʃ.ɑ.k.⋉.⋉',\n",
       " '⋊.d.eɪ.ɹ.⋉.⋉',\n",
       " '⋊.dʒ.ɪ.ŋ.⋉.⋉',\n",
       " '⋊.k.w.i.⋉.⋉',\n",
       " '⋊.ə.b.ɪ.⋉.⋉',\n",
       " '⋊.b.æ.z.⋉.⋉',\n",
       " '⋊.b.ɪ.ʃ.⋉.⋉',\n",
       " '⋊.k.ɪ.p.⋉.⋉',\n",
       " '⋊.v.ɚ.w.⋉.⋉',\n",
       " '⋊.l.d.ɪ.⋉.⋉',\n",
       " '⋊.oʊ.g.ɚ.⋉.⋉',\n",
       " '⋊.v.eɪ.ʃ.⋉.⋉',\n",
       " '⋊.d.æ.l.⋉.⋉',\n",
       " '⋊.z.ɪ.m.⋉.⋉',\n",
       " '⋊.ɛ.f.ɪ.⋉.⋉',\n",
       " '⋊.aɪ.θ.ɑ.⋉.⋉',\n",
       " '⋊.u.k.i.⋉.⋉',\n",
       " '⋊.d.æ.d.⋉.⋉',\n",
       " '⋊.n.d.z.⋉.⋉',\n",
       " '⋊.aʊ.t.d.⋉.⋉',\n",
       " '⋊.oʊ.ɹ.t.⋉.⋉',\n",
       " '⋊.oʊ.n.h.⋉.⋉',\n",
       " '⋊.i.ə.dʒ.⋉.⋉',\n",
       " '⋊.v.ɪ.ʒ.⋉.⋉',\n",
       " '⋊.ɚ.v.ɪ.⋉.⋉',\n",
       " '⋊.s.ɛ.g.⋉.⋉',\n",
       " '⋊.u.ɪ.k.⋉.⋉',\n",
       " '⋊.eɪ.n.f.⋉.⋉',\n",
       " '⋊.tʃ.ɪ.s.⋉.⋉',\n",
       " '⋊.n.d.ʊ.⋉.⋉',\n",
       " '⋊.d.ɚ.n.⋉.⋉',\n",
       " '⋊.p.aʊ.d.⋉.⋉',\n",
       " '⋊.l.i.s.⋉.⋉',\n",
       " '⋊.ɪ.ŋ.k.⋉.⋉',\n",
       " '⋊.ə.g.n.⋉.⋉',\n",
       " '⋊.ɚ.dʒ.ə.⋉.⋉',\n",
       " '⋊.f.aɪ.ɪ.⋉.⋉',\n",
       " '⋊.l.oʊ.ð.⋉.⋉',\n",
       " '⋊.n.ʌ.θ.⋉.⋉',\n",
       " '⋊.ʌ.ŋ.z.⋉.⋉',\n",
       " '⋊.i.tʃ.ɪ.⋉.⋉',\n",
       " '⋊.ə.l.v.⋉.⋉',\n",
       " '⋊.ɹ.u.aʊ.⋉.⋉',\n",
       " '⋊.ɚ.p.ɪ.⋉.⋉',\n",
       " '⋊.s.w.i.⋉.⋉',\n",
       " '⋊.ɛ.v.æ.⋉.⋉',\n",
       " '⋊.g.eɪ.v.⋉.⋉',\n",
       " '⋊.u.p.l.⋉.⋉',\n",
       " '⋊.n.ɪ.s.⋉.⋉',\n",
       " '⋊.ɹ.ɛ.t.⋉.⋉',\n",
       " '⋊.dʒ.ə.l.⋉.⋉',\n",
       " '⋊.ŋ.s.t.⋉.⋉',\n",
       " '⋊.m.ɔɪ.l.⋉.⋉',\n",
       " '⋊.f.ɑ.k.⋉.⋉',\n",
       " '⋊.ɛ.g.ə.⋉.⋉',\n",
       " '⋊.ə.p.h.⋉.⋉',\n",
       " '⋊.ə.n.æ.⋉.⋉',\n",
       " '⋊.b.ɚ.k.⋉.⋉',\n",
       " '⋊.k.ə.p.⋉.⋉',\n",
       " '⋊.s.ɚ.ɹ.⋉.⋉',\n",
       " '⋊.n.p.i.⋉.⋉',\n",
       " '⋊.aɪ.m.d.⋉.⋉',\n",
       " '⋊.ɛ.k.j.⋉.⋉',\n",
       " '⋊.ə.s.aɪ.⋉.⋉',\n",
       " '⋊.s.j.u.⋉.⋉',\n",
       " '⋊.ɚ.h.aʊ.⋉.⋉',\n",
       " '⋊.z.i.ɪ.⋉.⋉',\n",
       " '⋊.eɪ.d.ɑ.⋉.⋉',\n",
       " '⋊.n.ə.p.⋉.⋉',\n",
       " '⋊.n.θ.ɹ.⋉.⋉',\n",
       " '⋊.ɪ.v.ɛ.⋉.⋉',\n",
       " '⋊.j.ə.t.⋉.⋉',\n",
       " '⋊.s.ɚ.v.⋉.⋉',\n",
       " '⋊.i.m.z.⋉.⋉',\n",
       " '⋊.k.ə.k.⋉.⋉',\n",
       " '⋊.k.ɹ.ɑ.⋉.⋉',\n",
       " '⋊.dʒ.ɚ.d.⋉.⋉',\n",
       " '⋊.ɪ.tʃ.i.⋉.⋉',\n",
       " '⋊.i.j.u.⋉.⋉',\n",
       " '⋊.ʊ.ɹ.ɚ.⋉.⋉',\n",
       " '⋊.æ.b.n.⋉.⋉',\n",
       " '⋊.ɛ.s.ɚ.⋉.⋉',\n",
       " '⋊.ə.g.ə.⋉.⋉',\n",
       " '⋊.ɪ.n.aʊ.⋉.⋉',\n",
       " '⋊.oʊ.k.l.⋉.⋉',\n",
       " '⋊.b.ɚ.s.⋉.⋉',\n",
       " '⋊.l.ə.l.⋉.⋉',\n",
       " '⋊.f.eɪ.l.⋉.⋉',\n",
       " '⋊.d.oʊ.d.⋉.⋉',\n",
       " '⋊.n.t.æ.⋉.⋉',\n",
       " '⋊.t.l.ɚ.⋉.⋉',\n",
       " '⋊.ɑ.s.ɛ.⋉.⋉',\n",
       " '⋊.dʒ.i.k.⋉.⋉',\n",
       " '⋊.θ.ɹ.ɑ.⋉.⋉',\n",
       " '⋊.dʒ.ɪ.m.⋉.⋉',\n",
       " '⋊.eɪ.t.ə.⋉.⋉',\n",
       " '⋊.oʊ.f.i.⋉.⋉',\n",
       " '⋊.k.ɑ.b.⋉.⋉',\n",
       " '⋊.ɹ.oʊ.ɪ.⋉.⋉',\n",
       " '⋊.l.ə.w.⋉.⋉',\n",
       " '⋊.s.m.u.⋉.⋉',\n",
       " '⋊.v.ɪ.l.⋉.⋉',\n",
       " '⋊.ʌ.n.s.⋉.⋉',\n",
       " '⋊.ɪ.dʒ.ə.⋉.⋉',\n",
       " '⋊.k.θ.ɹ.⋉.⋉',\n",
       " '⋊.ə.m.b.⋉.⋉',\n",
       " '⋊.p.ɹ.aɪ.⋉.⋉',\n",
       " '⋊.oʊ.ɹ.ð.⋉.⋉',\n",
       " '⋊.n.f.eɪ.⋉.⋉',\n",
       " '⋊.ɑ.θ.s.⋉.⋉',\n",
       " '⋊.eɪ.l.ɹ.⋉.⋉',\n",
       " '⋊.p.i.g.⋉.⋉',\n",
       " '⋊.ɪ.t.eɪ.⋉.⋉',\n",
       " '⋊.t.ʌ.k.⋉.⋉',\n",
       " '⋊.g.oʊ.s.⋉.⋉',\n",
       " '⋊.aɪ.æ.ŋ.⋉.⋉',\n",
       " '⋊.l.ɪ.g.⋉.⋉',\n",
       " '⋊.i.f.l.⋉.⋉',\n",
       " '⋊.ɹ.ɛ.tʃ.⋉.⋉',\n",
       " '⋊.ɪ.t.ɛ.⋉.⋉',\n",
       " '⋊.ɑ.ð.ɚ.⋉.⋉',\n",
       " '⋊.eɪ.tʃ.b.⋉.⋉',\n",
       " '⋊.aɪ.m.ɪ.⋉.⋉',\n",
       " '⋊.n.d.s.⋉.⋉',\n",
       " '⋊.b.ɑ.ð.⋉.⋉',\n",
       " '⋊.ɑ.k.j.⋉.⋉',\n",
       " '⋊.z.ɛ.p.⋉.⋉',\n",
       " '⋊.ɚ.s.ə.⋉.⋉',\n",
       " '⋊.ɛ.s.p.⋉.⋉',\n",
       " '⋊.b.v.i.⋉.⋉',\n",
       " '⋊.l.ʃ.u.⋉.⋉',\n",
       " '⋊.h.æ.tʃ.⋉.⋉',\n",
       " '⋊.ɪ.ɹ.ə.⋉.⋉',\n",
       " '⋊.d.ʊ.ɹ.⋉.⋉',\n",
       " '⋊.ɑ.k.l.⋉.⋉',\n",
       " '⋊.g.ɛ.n.⋉.⋉',\n",
       " '⋊.t.i.m.⋉.⋉',\n",
       " '⋊.p.ɹ.æ.⋉.⋉',\n",
       " '⋊.i.t.aɪ.⋉.⋉',\n",
       " '⋊.ʌ.tʃ.l.⋉.⋉',\n",
       " '⋊.l.ɛ.ŋ.⋉.⋉',\n",
       " '⋊.ʒ.ɚ.d.⋉.⋉',\n",
       " '⋊.f.i.n.⋉.⋉',\n",
       " '⋊.oʊ.t.ə.⋉.⋉',\n",
       " '⋊.oʊ.t.l.⋉.⋉',\n",
       " '⋊.f.u.d.⋉.⋉',\n",
       " '⋊.t.oʊ.z.⋉.⋉',\n",
       " '⋊.ɑ.tʃ.ɑ.⋉.⋉',\n",
       " '⋊.n.u.t.⋉.⋉',\n",
       " '⋊.g.ɹ.ɪ.⋉.⋉',\n",
       " '⋊.eɪ.d.z.⋉.⋉',\n",
       " '⋊.g.ɛ.s.⋉.⋉',\n",
       " '⋊.s.oʊ.f.⋉.⋉',\n",
       " '⋊.n.ʃ.ɪ.⋉.⋉',\n",
       " '⋊.s.ə.m.⋉.⋉',\n",
       " '⋊.b.ɑ.k.⋉.⋉',\n",
       " '⋊.i.f.k.⋉.⋉',\n",
       " '⋊.l.i.ə.⋉.⋉',\n",
       " '⋊.tʃ.ɪ.k.⋉.⋉',\n",
       " '⋊.θ.i.ɚ.⋉.⋉',\n",
       " '⋊.oʊ.m.ɛ.⋉.⋉',\n",
       " '⋊.p.i.v.⋉.⋉',\n",
       " '⋊.ɚ.m.l.⋉.⋉',\n",
       " '⋊.g.j.ʊ.⋉.⋉',\n",
       " '⋊.l.v.ɚ.⋉.⋉',\n",
       " '⋊.n.l.ɑ.⋉.⋉',\n",
       " '⋊.g.eɪ.θ.⋉.⋉',\n",
       " '⋊.w.ɑ.tʃ.⋉.⋉',\n",
       " '⋊.ɹ.ʌ.ʃ.⋉.⋉',\n",
       " '⋊.ɛ.ʃ.w.⋉.⋉',\n",
       " '⋊.eɪ.t.m.⋉.⋉',\n",
       " '⋊.p.u.n.⋉.⋉',\n",
       " '⋊.tʃ.eɪ.ɹ.⋉.⋉',\n",
       " '⋊.æ.s.ɛ.⋉.⋉',\n",
       " '⋊.b.l.æ.⋉.⋉',\n",
       " '⋊.ɹ.aɪ.tʃ.⋉.⋉',\n",
       " '⋊.dʒ.oʊ.z.⋉.⋉',\n",
       " '⋊.ɹ.ə.dʒ.⋉.⋉',\n",
       " '⋊.æ.tʃ.ə.⋉.⋉',\n",
       " '⋊.ɪ.v.j.⋉.⋉',\n",
       " '⋊.aɪ.k.aɪ.⋉.⋉',\n",
       " '⋊.i.æ.s.⋉.⋉',\n",
       " '⋊.n.v.ɑ.⋉.⋉',\n",
       " '⋊.ɛ.n.b.⋉.⋉',\n",
       " '⋊.ɹ.s.t.⋉.⋉',\n",
       " '⋊.ɪ.m.i.⋉.⋉',\n",
       " '⋊.æ.m.j.⋉.⋉',\n",
       " '⋊.ə.v.w.⋉.⋉',\n",
       " '⋊.ɚ.f.ɪ.⋉.⋉',\n",
       " '⋊.ɚ.k.s.⋉.⋉',\n",
       " '⋊.æ.l.p.⋉.⋉',\n",
       " '⋊.ɪ.s.tʃ.⋉.⋉',\n",
       " '⋊.ɑ.p.t.⋉.⋉',\n",
       " '⋊.n.oʊ.ʃ.⋉.⋉',\n",
       " '⋊.p.eɪ.dʒ.⋉.⋉',\n",
       " '⋊.v.ɚ.θ.⋉.⋉',\n",
       " '⋊.t.æ.ʃ.⋉.⋉',\n",
       " '⋊.ɚ.f.ɛ.⋉.⋉',\n",
       " '⋊.ɛ.f.ɹ.⋉.⋉',\n",
       " '⋊.ɛ.n.ɹ.⋉.⋉',\n",
       " '⋊.b.aɪ.d.⋉.⋉',\n",
       " '⋊.k.ɔɪ.n.⋉.⋉',\n",
       " '⋊.oʊ.f.ɚ.⋉.⋉',\n",
       " '⋊.h.oʊ.p.⋉.⋉',\n",
       " '⋊.i.d.b.⋉.⋉',\n",
       " '⋊.w.ɪ.n.⋉.⋉',\n",
       " '⋊.i.k.ɛ.⋉.⋉',\n",
       " '⋊.z.ə.b.⋉.⋉',\n",
       " '⋊.d.i.æ.⋉.⋉',\n",
       " '⋊.l.t.n.⋉.⋉',\n",
       " '⋊.s.u.t.⋉.⋉',\n",
       " '⋊.ʌ.s.ə.⋉.⋉',\n",
       " '⋊.æ.l.i.⋉.⋉',\n",
       " '⋊.s.l.eɪ.⋉.⋉',\n",
       " '⋊.dʒ.ɑ.ɹ.⋉.⋉',\n",
       " '⋊.m.w.ɑ.⋉.⋉',\n",
       " '⋊.ɪ.t.æ.⋉.⋉',\n",
       " '⋊.ʊ.t.n.⋉.⋉',\n",
       " '⋊.tʃ.ɑ.l.⋉.⋉',\n",
       " '⋊.v.ɚ.ɹ.⋉.⋉',\n",
       " '⋊.eɪ.ʒ.i.⋉.⋉',\n",
       " '⋊.p.i.ə.⋉.⋉',\n",
       " '⋊.ɪ.h.ɛ.⋉.⋉',\n",
       " '⋊.t.ʌ.d.⋉.⋉',\n",
       " '⋊.ɪ.p.s.⋉.⋉',\n",
       " '⋊.t.ɪ.l.⋉.⋉',\n",
       " '⋊.n.d.ɑ.⋉.⋉',\n",
       " '⋊.k.ɑ.w.⋉.⋉',\n",
       " '⋊.f.b.i.⋉.⋉',\n",
       " '⋊.ɹ.tʃ.ɪ.⋉.⋉',\n",
       " '⋊.n.h.ʌ.⋉.⋉',\n",
       " '⋊.d.ɑ.p.⋉.⋉',\n",
       " '⋊.b.eɪ.n.⋉.⋉',\n",
       " '⋊.oʊ.s.m.⋉.⋉',\n",
       " '⋊.ɹ.ɪ.ð.⋉.⋉',\n",
       " '⋊.l.aʊ.n.⋉.⋉',\n",
       " '⋊.s.oʊ.t.⋉.⋉',\n",
       " '⋊.ʊ.l.f.⋉.⋉',\n",
       " '⋊.ŋ.t.aɪ.⋉.⋉',\n",
       " '⋊.i.dʒ.d.⋉.⋉',\n",
       " '⋊.æ.m.b.⋉.⋉',\n",
       " '⋊.æ.ð.z.⋉.⋉',\n",
       " '⋊.ɛ.n.θ.⋉.⋉',\n",
       " '⋊.aʊ.dʒ.ɪ.⋉.⋉',\n",
       " '⋊.ʃ.ə.l.⋉.⋉',\n",
       " '⋊.i.p.ɚ.⋉.⋉',\n",
       " '⋊.ɪ.p.j.⋉.⋉',\n",
       " '⋊.ə.n.ə.⋉.⋉',\n",
       " '⋊.ɑ.f.ɛ.⋉.⋉',\n",
       " '⋊.t.æ.b.⋉.⋉',\n",
       " '⋊.l.ð.oʊ.⋉.⋉',\n",
       " '⋊.æ.d.ə.⋉.⋉',\n",
       " '⋊.h.ɑ.p.⋉.⋉',\n",
       " '⋊.l.ʌ.ŋ.⋉.⋉',\n",
       " '⋊.t.aɪ.f.⋉.⋉',\n",
       " '⋊.m.æ.tʃ.⋉.⋉',\n",
       " '⋊.m.ɚ.m.⋉.⋉',\n",
       " '⋊.k.j.ɑ.⋉.⋉',\n",
       " '⋊.ʒ.ə.ɹ.⋉.⋉',\n",
       " '⋊.l.eɪ.ɹ.⋉.⋉',\n",
       " '⋊.ʌ.b.t.⋉.⋉',\n",
       " '⋊.p.l.ɪ.⋉.⋉',\n",
       " '⋊.u.θ.f.⋉.⋉',\n",
       " '⋊.j.u.t.⋉.⋉',\n",
       " '⋊.m.aʊ.i.⋉.⋉',\n",
       " '⋊.k.l.ɑ.⋉.⋉',\n",
       " '⋊.g.ɪ.l.⋉.⋉',\n",
       " '⋊.b.i.oʊ.⋉.⋉',\n",
       " '⋊.h.ɛ.l.⋉.⋉',\n",
       " '⋊.b.i.g.⋉.⋉',\n",
       " '⋊.b.u.s.⋉.⋉',\n",
       " '⋊.t.u.ʃ.⋉.⋉',\n",
       " '⋊.s.h.aɪ.⋉.⋉',\n",
       " '⋊.ɛ.g.ɹ.⋉.⋉',\n",
       " '⋊.t.eɪ.l.⋉.⋉',\n",
       " '⋊.n.ɪ.p.⋉.⋉',\n",
       " '⋊.d.ɚ.s.⋉.⋉',\n",
       " '⋊.s.ʌ.d.⋉.⋉',\n",
       " '⋊.n.eɪ.ʃ.⋉.⋉',\n",
       " '⋊.n.f.ə.⋉.⋉',\n",
       " '⋊.k.s.w.⋉.⋉',\n",
       " '⋊.æ.p.ɚ.⋉.⋉',\n",
       " '⋊.n.h.ɚ.⋉.⋉',\n",
       " '⋊.t.m.æ.⋉.⋉',\n",
       " '⋊.eɪ.v.ɪ.⋉.⋉',\n",
       " '⋊.n.ɑ.m.⋉.⋉',\n",
       " '⋊.eɪ.z.d.⋉.⋉',\n",
       " '⋊.dʒ.ɚ.n.⋉.⋉',\n",
       " '⋊.v.ɪ.dʒ.⋉.⋉',\n",
       " '⋊.θ.ə.s.⋉.⋉',\n",
       " '⋊.ɪ.g.ɑ.⋉.⋉',\n",
       " '⋊.ʊ.l.z.⋉.⋉',\n",
       " '⋊.i.oʊ.l.⋉.⋉',\n",
       " '⋊.tʃ.ɪ.p.⋉.⋉',\n",
       " '⋊.j.ɛ.p.⋉.⋉',\n",
       " '⋊.n.ɔɪ.n.⋉.⋉',\n",
       " '⋊.ə.n.aʊ.⋉.⋉',\n",
       " '⋊.p.ɑ.v.⋉.⋉',\n",
       " '⋊.dʒ.ɔɪ.ɪ.⋉.⋉',\n",
       " '⋊.l.ɪ.v.⋉.⋉',\n",
       " '⋊.ɛ.l.ɛ.⋉.⋉',\n",
       " '⋊.p.ɚ.h.⋉.⋉',\n",
       " '⋊.d.i.v.⋉.⋉',\n",
       " '⋊.oʊ.ɑ.p.⋉.⋉',\n",
       " '⋊.ɪ.k.ɪ.⋉.⋉',\n",
       " '⋊.ɛ.p.ə.⋉.⋉',\n",
       " '⋊.dʒ.ə.h.⋉.⋉',\n",
       " '⋊.m.ə.ɹ.⋉.⋉',\n",
       " '⋊.d.p.ɔɪ.⋉.⋉',\n",
       " '⋊.eɪ.l.g.⋉.⋉',\n",
       " '⋊.ɚ.n.ʃ.⋉.⋉',\n",
       " '⋊.ə.w.oʊ.⋉.⋉',\n",
       " '⋊.n.æ.dʒ.⋉.⋉',\n",
       " '⋊.u.l.ɹ.⋉.⋉',\n",
       " '⋊.m.ə.l.⋉.⋉',\n",
       " '⋊.s.k.i.⋉.⋉',\n",
       " '⋊.ɔɪ.ɪ.dʒ.⋉.⋉',\n",
       " '⋊.ʌ.f.s.⋉.⋉',\n",
       " '⋊.p.ɚ.p.⋉.⋉',\n",
       " '⋊.m.ə.m.⋉.⋉',\n",
       " '⋊.h.ɑ.f.⋉.⋉',\n",
       " '⋊.ɑ.l.w.⋉.⋉',\n",
       " '⋊.ɚ.t.i.⋉.⋉',\n",
       " '⋊.d.eɪ.l.⋉.⋉',\n",
       " '⋊.f.ɔɪ.l.⋉.⋉',\n",
       " '⋊.m.i.l.⋉.⋉',\n",
       " '⋊.ɪ.v.n.⋉.⋉',\n",
       " '⋊.oʊ.p.ɪ.⋉.⋉',\n",
       " '⋊.ɚ.k.p.⋉.⋉',\n",
       " '⋊.ʃ.ɑ.n.⋉.⋉',\n",
       " '⋊.ʌ.ʃ.i.⋉.⋉',\n",
       " '⋊.ɹ.ɑ.l.⋉.⋉',\n",
       " '⋊.ɹ.eɪ.ə.⋉.⋉',\n",
       " '⋊.i.s.ɑ.⋉.⋉',\n",
       " '⋊.oʊ.h.i.⋉.⋉',\n",
       " '⋊.d.ʌ.b.⋉.⋉',\n",
       " '⋊.æ.ŋ.z.⋉.⋉',\n",
       " '⋊.ɑ.n.ɪ.⋉.⋉',\n",
       " '⋊.i.k.i.⋉.⋉',\n",
       " '⋊.n.p.aʊ.⋉.⋉',\n",
       " '⋊.g.m.ɪ.⋉.⋉',\n",
       " '⋊.t.eɪ.b.⋉.⋉',\n",
       " '⋊.n.ɑ.p.⋉.⋉',\n",
       " '⋊.ɛ.θ.s.⋉.⋉',\n",
       " '⋊.ɪ.ʃ.i.⋉.⋉',\n",
       " '⋊.ð.ə.ɹ.⋉.⋉',\n",
       " '⋊.ə.l.oʊ.⋉.⋉',\n",
       " '⋊.d.oʊ.ɹ.⋉.⋉',\n",
       " '⋊.oʊ.l.l.⋉.⋉',\n",
       " '⋊.ɪ.ð.ɪ.⋉.⋉',\n",
       " '⋊.t.l.ʊ.⋉.⋉',\n",
       " '⋊.ɑ.ŋ.d.⋉.⋉',\n",
       " '⋊.aɪ.ɹ.p.⋉.⋉',\n",
       " '⋊.ɑ.l.s.⋉.⋉',\n",
       " '⋊.θ.p.ɪ.⋉.⋉',\n",
       " '⋊.eɪ.t.l.⋉.⋉',\n",
       " '⋊.ɪ.d.ɑ.⋉.⋉',\n",
       " '⋊.ɚ.t.aɪ.⋉.⋉',\n",
       " '⋊.m.n.æ.⋉.⋉',\n",
       " '⋊.t.oʊ.v.⋉.⋉',\n",
       " '⋊.s.p.eɪ.⋉.⋉',\n",
       " '⋊.n.u.ɚ.⋉.⋉',\n",
       " '⋊.ə.dʒ.u.⋉.⋉',\n",
       " '⋊.oʊ.n.z.⋉.⋉',\n",
       " '⋊.v.aɪ.d.⋉.⋉',\n",
       " '⋊.w.oʊ.k.⋉.⋉',\n",
       " '⋊.i.m.ə.⋉.⋉',\n",
       " '⋊.ɹ.i.z.⋉.⋉',\n",
       " '⋊.s.t.b.⋉.⋉',\n",
       " '⋊.b.aɪ.ɑ.⋉.⋉',\n",
       " '⋊.ɚ.h.ɑ.⋉.⋉',\n",
       " '⋊.n.eɪ.d.⋉.⋉',\n",
       " '⋊.ə.s.ɚ.⋉.⋉',\n",
       " '⋊.ð.eɪ.ɹ.⋉.⋉',\n",
       " '⋊.ɛ.d.n.⋉.⋉',\n",
       " '⋊.eɪ.t.ɪ.⋉.⋉',\n",
       " '⋊.n.s.t.⋉.⋉',\n",
       " '⋊.aɪ.z.ə.⋉.⋉',\n",
       " '⋊.ʌ.d.n.⋉.⋉',\n",
       " '⋊.p.t.eɪ.⋉.⋉',\n",
       " '⋊.oʊ.ɛ.d.⋉.⋉',\n",
       " '⋊.eɪ.k.ɪ.⋉.⋉',\n",
       " '⋊.b.s.k.⋉.⋉',\n",
       " '⋊.ə.n.v.⋉.⋉',\n",
       " '⋊.z.ɪ.t.⋉.⋉',\n",
       " '⋊.w.i.d.⋉.⋉',\n",
       " '⋊.dʒ.ə.ɹ.⋉.⋉',\n",
       " '⋊.m.ɚ.ɹ.⋉.⋉',\n",
       " '⋊.aɪ.g.æ.⋉.⋉',\n",
       " '⋊.w.ɑ.k.⋉.⋉',\n",
       " '⋊.ɹ.i.d.⋉.⋉',\n",
       " '⋊.k.ɑ.d.⋉.⋉',\n",
       " '⋊.i.b.eɪ.⋉.⋉',\n",
       " '⋊.oʊ.v.ɑ.⋉.⋉',\n",
       " '⋊.eɪ.æ.n.⋉.⋉',\n",
       " '⋊.d.ɹ.eɪ.⋉.⋉',\n",
       " '⋊.ɹ.æ.ŋ.⋉.⋉',\n",
       " '⋊.g.oʊ.l.⋉.⋉',\n",
       " '⋊.w.ɚ.d.⋉.⋉',\n",
       " '⋊.d.eɪ.n.⋉.⋉',\n",
       " '⋊.h.i.d.⋉.⋉',\n",
       " '⋊.h.æ.f.⋉.⋉',\n",
       " '⋊.aɪ.n.æ.⋉.⋉',\n",
       " '⋊.d.ɚ.w.⋉.⋉',\n",
       " '⋊.aɪ.t.n.⋉.⋉',\n",
       " '⋊.æ.ʃ.i.⋉.⋉',\n",
       " '⋊.s.l.æ.⋉.⋉',\n",
       " '⋊.n.æ.n.⋉.⋉',\n",
       " '⋊.n.tʃ.ɚ.⋉.⋉',\n",
       " '⋊.k.k.eɪ.⋉.⋉',\n",
       " '⋊.ɑ.ɹ.n.⋉.⋉',\n",
       " '⋊.s.m.oʊ.⋉.⋉',\n",
       " '⋊.g.l.ɑ.⋉.⋉',\n",
       " '⋊.b.eɪ.t.⋉.⋉',\n",
       " '⋊.oʊ.s.n.⋉.⋉',\n",
       " '⋊.d.ɚ.ɹ.⋉.⋉',\n",
       " '⋊.ə.t.w.⋉.⋉',\n",
       " '⋊.s.f.ə.⋉.⋉',\n",
       " '⋊.n.j.u.⋉.⋉',\n",
       " '⋊.m.n.ɪ.⋉.⋉',\n",
       " '⋊.ɪ.n.eɪ.⋉.⋉',\n",
       " '⋊.aɪ.n.ɪ.⋉.⋉',\n",
       " '⋊.l.ɪ.f.⋉.⋉',\n",
       " '⋊.ɹ.ɚ.z.⋉.⋉',\n",
       " '⋊.s.ʌ.tʃ.⋉.⋉',\n",
       " '⋊.k.ə.s.⋉.⋉',\n",
       " '⋊.oʊ.ə.l.⋉.⋉',\n",
       " '⋊.ɹ.ɪ.ʃ.⋉.⋉',\n",
       " '⋊.ɹ.ʌ.p.⋉.⋉',\n",
       " '⋊.ɪ.m.ɚ.⋉.⋉',\n",
       " '⋊.m.ɪ.dʒ.⋉.⋉',\n",
       " '⋊.ɑ.v.ə.⋉.⋉',\n",
       " '⋊.ɛ.ŋ.k.⋉.⋉',\n",
       " '⋊.w.ɪ.s.⋉.⋉',\n",
       " '⋊.ɹ.oʊ.ə.⋉.⋉',\n",
       " '⋊.ŋ.ɚ.z.⋉.⋉',\n",
       " '⋊.ə.dʒ.ʌ.⋉.⋉',\n",
       " '⋊.tʃ.b.æ.⋉.⋉',\n",
       " '⋊.n.ɚ.s.⋉.⋉',\n",
       " '⋊.s.i.eɪ.⋉.⋉',\n",
       " '⋊.u.z.eɪ.⋉.⋉',\n",
       " '⋊.g.l.aɪ.⋉.⋉',\n",
       " '⋊.ʃ.i.l.⋉.⋉',\n",
       " '⋊.p.æ.m.⋉.⋉',\n",
       " '⋊.i.ɪ.t.⋉.⋉',\n",
       " '⋊.s.p.ʌ.⋉.⋉',\n",
       " '⋊.ɑ.t.s.⋉.⋉',\n",
       " '⋊.ɹ.aʊ.tʃ.⋉.⋉',\n",
       " '⋊.w.ɚ.k.⋉.⋉',\n",
       " '⋊.s.w.ʊ.⋉.⋉',\n",
       " '⋊.d.aɪ.d.⋉.⋉',\n",
       " '⋊.p.æ.tʃ.⋉.⋉',\n",
       " '⋊.ʃ.ɹ.ʊ.⋉.⋉',\n",
       " '⋊.l.s.i.⋉.⋉',\n",
       " '⋊.ɪ.k.j.⋉.⋉',\n",
       " '⋊.p.l.ɔɪ.⋉.⋉',\n",
       " '⋊.t.u.t.⋉.⋉',\n",
       " '⋊.s.m.ə.⋉.⋉',\n",
       " '⋊.k.i.oʊ.⋉.⋉',\n",
       " '⋊.s.u.m.⋉.⋉',\n",
       " '⋊.i.t.ɛ.⋉.⋉',\n",
       " '⋊.ɪ.k.u.⋉.⋉',\n",
       " '⋊.i.v.p.⋉.⋉',\n",
       " '⋊.p.ɛ.ʃ.⋉.⋉',\n",
       " '⋊.m.æ.ʃ.⋉.⋉',\n",
       " '⋊.l.ɑ.d.⋉.⋉',\n",
       " '⋊.u.p.ɑ.⋉.⋉',\n",
       " '⋊.j.u.ə.⋉.⋉',\n",
       " '⋊.k.s.p.⋉.⋉',\n",
       " '⋊.l.ə.s.⋉.⋉',\n",
       " '⋊.ɹ.oʊ.v.⋉.⋉',\n",
       " '⋊.aɪ.d.l.⋉.⋉',\n",
       " '⋊.t.i.b.⋉.⋉',\n",
       " '⋊.f.ʃ.u.⋉.⋉',\n",
       " '⋊.u.l.h.⋉.⋉',\n",
       " '⋊.ɛ.s.ɛ.⋉.⋉',\n",
       " '⋊.j.ə.n.⋉.⋉',\n",
       " '⋊.ɪ.z.i.⋉.⋉',\n",
       " '⋊.ʃ.ɛ.p.⋉.⋉',\n",
       " '⋊.f.l.i.⋉.⋉',\n",
       " '⋊.g.ə.p.⋉.⋉',\n",
       " '⋊.l.ɔɪ.m.⋉.⋉',\n",
       " '⋊.ɔɪ.ɚ.z.⋉.⋉',\n",
       " '⋊.ɚ.l.ʊ.⋉.⋉',\n",
       " '⋊.ɔɪ.d.ɪ.⋉.⋉',\n",
       " '⋊.t.aɪ.n.⋉.⋉',\n",
       " '⋊.ɑ.m.p.⋉.⋉',\n",
       " '⋊.w.u.p.⋉.⋉',\n",
       " '⋊.ɹ.ɛ.dʒ.⋉.⋉',\n",
       " '⋊.s.ʌ.m.⋉.⋉',\n",
       " '⋊.ʌ.g.ʒ.⋉.⋉',\n",
       " '⋊.æ.s.i.⋉.⋉',\n",
       " '⋊.p.ɛ.d.⋉.⋉',\n",
       " '⋊.b.s.ə.⋉.⋉',\n",
       " '⋊.ɛ.n.ɚ.⋉.⋉',\n",
       " '⋊.ɛ.p.m.⋉.⋉',\n",
       " '⋊.ɪ.dʒ.m.⋉.⋉',\n",
       " '⋊.ʌ.g.l.⋉.⋉',\n",
       " '⋊.l.k.i.⋉.⋉',\n",
       " '⋊.i.ə.ɹ.⋉.⋉',\n",
       " '⋊.dʒ.eɪ.n.⋉.⋉',\n",
       " '⋊.l.u.ʃ.⋉.⋉',\n",
       " '⋊.h.ɛ.d.⋉.⋉',\n",
       " '⋊.f.æ.s.⋉.⋉',\n",
       " '⋊.u.m.z.⋉.⋉',\n",
       " '⋊.s.t.ɚ.⋉.⋉',\n",
       " '⋊.n.d.aʊ.⋉.⋉',\n",
       " '⋊.ɹ.s.ɛ.⋉.⋉',\n",
       " '⋊.eɪ.tʃ.ɚ.⋉.⋉',\n",
       " '⋊.i.p.æ.⋉.⋉',\n",
       " '⋊.h.æ.k.⋉.⋉',\n",
       " '⋊.ə.k.oʊ.⋉.⋉',\n",
       " '⋊.u.d.w.⋉.⋉',\n",
       " '⋊.s.i.dʒ.⋉.⋉',\n",
       " '⋊.f.ɛ.b.⋉.⋉',\n",
       " '⋊.d.ɑ.m.⋉.⋉',\n",
       " '⋊.i.g.ɪ.⋉.⋉',\n",
       " '⋊.d.i.b.⋉.⋉',\n",
       " '⋊.dʒ.ʌ.m.⋉.⋉',\n",
       " '⋊.oʊ.ɑ.l.⋉.⋉',\n",
       " '⋊.v.ʌ.l.⋉.⋉',\n",
       " '⋊.ɪ.v.aɪ.⋉.⋉',\n",
       " '⋊.n.k.ʌ.⋉.⋉',\n",
       " '⋊.d.θ.ɚ.⋉.⋉',\n",
       " '⋊.f.ɑ.ð.⋉.⋉',\n",
       " '⋊.d.ɹ.u.⋉.⋉',\n",
       " '⋊.s.eɪ.t.⋉.⋉',\n",
       " '⋊.ɚ.m.ə.⋉.⋉',\n",
       " '⋊.f.s.p.⋉.⋉',\n",
       " '⋊.w.aɪ.ɪ.⋉.⋉',\n",
       " '⋊.tʃ.ɪ.d.⋉.⋉',\n",
       " '⋊.tʃ.u.d.⋉.⋉',\n",
       " '⋊.s.n.i.⋉.⋉',\n",
       " '⋊.ə.m.ʌ.⋉.⋉',\n",
       " '⋊.f.ɑ.t.⋉.⋉',\n",
       " '⋊.u.s.ɚ.⋉.⋉',\n",
       " '⋊.ɑ.t.ɛ.⋉.⋉',\n",
       " '⋊.u.ɚ.t.⋉.⋉',\n",
       " '⋊.m.f.ɛ.⋉.⋉',\n",
       " '⋊.p.s.k.⋉.⋉',\n",
       " '⋊.z.ɪ.b.⋉.⋉',\n",
       " '⋊.ɛ.d.ɚ.⋉.⋉',\n",
       " '⋊.i.tʃ.t.⋉.⋉',\n",
       " '⋊.n.ʌ.g.⋉.⋉',\n",
       " '⋊.ə.l.u.⋉.⋉',\n",
       " '⋊.ə.b.ə.⋉.⋉',\n",
       " '⋊.dʒ.ə.p.⋉.⋉',\n",
       " '⋊.ɛ.s.k.⋉.⋉',\n",
       " '⋊.n.m.ə.⋉.⋉',\n",
       " '⋊.s.ɪ.tʃ.⋉.⋉',\n",
       " '⋊.ɹ.ɑ.ɪ.⋉.⋉',\n",
       " '⋊.p.ə.n.⋉.⋉',\n",
       " '⋊.ɪ.t.ə.⋉.⋉',\n",
       " '⋊.p.ə.h.⋉.⋉',\n",
       " '⋊.ɑ.dʒ.ɚ.⋉.⋉',\n",
       " '⋊.oʊ.w.ʌ.⋉.⋉',\n",
       " '⋊.w.ʌ.ð.⋉.⋉',\n",
       " '⋊.d.z.ə.⋉.⋉',\n",
       " '⋊.oʊ.z.ɑ.⋉.⋉',\n",
       " '⋊.aɪ.æ.g.⋉.⋉',\n",
       " '⋊.k.b.ʊ.⋉.⋉',\n",
       " '⋊.æ.n.oʊ.⋉.⋉',\n",
       " '⋊.ɛ.m.ə.⋉.⋉',\n",
       " '⋊.h.aɪ.t.⋉.⋉',\n",
       " '⋊.j.u.l.⋉.⋉',\n",
       " '⋊.ɹ.eɪ.s.⋉.⋉',\n",
       " '⋊.p.eɪ.ɹ.⋉.⋉',\n",
       " '⋊.ɛ.t.ɪ.⋉.⋉',\n",
       " '⋊.j.ɛ.t.⋉.⋉',\n",
       " '⋊.eɪ.f.ə.⋉.⋉',\n",
       " '⋊.ɪ.n.æ.⋉.⋉',\n",
       " '⋊.ɹ.aɪ.s.⋉.⋉',\n",
       " '⋊.s.eɪ.b.⋉.⋉',\n",
       " '⋊.i.ɛ.m.⋉.⋉',\n",
       " '⋊.ɑ.b.z.⋉.⋉',\n",
       " '⋊.ʃ.oʊ.z.⋉.⋉',\n",
       " '⋊.i.m.oʊ.⋉.⋉',\n",
       " '⋊.ɑ.l.n.⋉.⋉',\n",
       " '⋊.v.p.oʊ.⋉.⋉',\n",
       " '⋊.dʒ.ʌ.n.⋉.⋉',\n",
       " '⋊.ŋ.k.i.⋉.⋉',\n",
       " '⋊.i.b.ə.⋉.⋉',\n",
       " '⋊.d.ʃ.i.⋉.⋉',\n",
       " '⋊.oʊ.æ.k.⋉.⋉',\n",
       " '⋊.oʊ.t.æ.⋉.⋉',\n",
       " '⋊.n.z.i.⋉.⋉',\n",
       " '⋊.oʊ.z.i.⋉.⋉',\n",
       " '⋊.f.u.l.⋉.⋉',\n",
       " '⋊.b.ʌ.m.⋉.⋉',\n",
       " '⋊.ɑ.d.i.⋉.⋉',\n",
       " '⋊.m.ɔɪ.n.⋉.⋉',\n",
       " '⋊.t.ɛ.n.⋉.⋉',\n",
       " '⋊.ɑ.d.ɪ.⋉.⋉',\n",
       " '⋊.ɚ.t.ɚ.⋉.⋉',\n",
       " '⋊.v.ə.k.⋉.⋉',\n",
       " '⋊.oʊ.ɹ.p.⋉.⋉',\n",
       " '⋊.oʊ.f.aɪ.⋉.⋉',\n",
       " '⋊.ʃ.ɪ.t.⋉.⋉',\n",
       " '⋊.m.u.v.⋉.⋉',\n",
       " '⋊.aʊ.ɚ.l.⋉.⋉',\n",
       " '⋊.d.eɪ.k.⋉.⋉',\n",
       " '⋊.eɪ.ʒ.ə.⋉.⋉',\n",
       " '⋊.aɪ.oʊ.t.⋉.⋉',\n",
       " '⋊.i.n.eɪ.⋉.⋉',\n",
       " '⋊.ŋ.k.ɹ.⋉.⋉',\n",
       " '⋊.n.m.eɪ.⋉.⋉',\n",
       " '⋊.b.eɪ.l.⋉.⋉',\n",
       " '⋊.d.u.n.⋉.⋉',\n",
       " '⋊.f.s.ɛ.⋉.⋉',\n",
       " '⋊.k.i.n.⋉.⋉',\n",
       " '⋊.ɪ.n.l.⋉.⋉',\n",
       " '⋊.ɛ.k.t.⋉.⋉',\n",
       " '⋊.oʊ.ə.b.⋉.⋉',\n",
       " '⋊.ɛ.g.l.⋉.⋉',\n",
       " '⋊.n.i.ɑ.⋉.⋉',\n",
       " '⋊.ɹ.ɛ.p.⋉.⋉',\n",
       " '⋊.ɛ.k.eɪ.⋉.⋉',\n",
       " '⋊.ɚ.ð.ɪ.⋉.⋉',\n",
       " '⋊.p.u.l.⋉.⋉',\n",
       " '⋊.ɚ.tʃ.ɑ.⋉.⋉',\n",
       " '⋊.l.ɹ.i.⋉.⋉',\n",
       " '⋊.i.n.d.⋉.⋉',\n",
       " '⋊.i.eɪ.tʃ.⋉.⋉',\n",
       " '⋊.ə.f.ɹ.⋉.⋉',\n",
       " '⋊.ð.ɛ.n.⋉.⋉',\n",
       " '⋊.j.ə.l.⋉.⋉',\n",
       " '⋊.k.eɪ.n.⋉.⋉',\n",
       " '⋊.s.t.m.⋉.⋉',\n",
       " '⋊.ɚ.m.aɪ.⋉.⋉',\n",
       " '⋊.oʊ.d.ɚ.⋉.⋉',\n",
       " '⋊.ʃ.eɪ.m.⋉.⋉',\n",
       " '⋊.p.aɪ.p.⋉.⋉',\n",
       " '⋊.ɪ.ŋ.s.⋉.⋉',\n",
       " '⋊.ɚ.θ.w.⋉.⋉',\n",
       " '⋊.i.v.æ.⋉.⋉',\n",
       " '⋊.ɑ.m.ə.⋉.⋉',\n",
       " '⋊.ə.n.dʒ.⋉.⋉',\n",
       " '⋊.i.z.ɪ.⋉.⋉',\n",
       " '⋊.b.ʌ.k.⋉.⋉',\n",
       " '⋊.m.w.aɪ.⋉.⋉',\n",
       " '⋊.t.p.ʊ.⋉.⋉',\n",
       " '⋊.l.s.eɪ.⋉.⋉',\n",
       " '⋊.eɪ.b.ɑ.⋉.⋉',\n",
       " '⋊.k.æ.θ.⋉.⋉',\n",
       " '⋊.d.w.eɪ.⋉.⋉',\n",
       " '⋊.eɪ.s.b.⋉.⋉',\n",
       " '⋊.ɑ.ʃ.ɪ.⋉.⋉',\n",
       " '⋊.ə.m.ɑ.⋉.⋉',\n",
       " '⋊.ɑ.n.t.⋉.⋉',\n",
       " '⋊.ʌ.d.θ.⋉.⋉',\n",
       " '⋊.i.p.ɪ.⋉.⋉',\n",
       " '⋊.æ.l.j.⋉.⋉',\n",
       " '⋊.p.t.i.⋉.⋉',\n",
       " '⋊.s.i.æ.⋉.⋉',\n",
       " '⋊.n.aɪ.v.⋉.⋉',\n",
       " '⋊.l.ɑ.k.⋉.⋉',\n",
       " '⋊.n.i.k.⋉.⋉',\n",
       " '⋊.l.aɪ.m.⋉.⋉',\n",
       " '⋊.s.tʃ.i.⋉.⋉',\n",
       " '⋊.oʊ.p.i.⋉.⋉',\n",
       " '⋊.n.u.h.⋉.⋉',\n",
       " '⋊.eɪ.b.i.⋉.⋉',\n",
       " '⋊.ɪ.s.ɹ.⋉.⋉',\n",
       " '⋊.θ.æ.tʃ.⋉.⋉',\n",
       " '⋊.l.ɪ.m.⋉.⋉',\n",
       " '⋊.ɑ.v.i.⋉.⋉',\n",
       " '⋊.u.ɑ.ɹ.⋉.⋉',\n",
       " '⋊.w.ɛ.dʒ.⋉.⋉',\n",
       " '⋊.ɪ.f.ʌ.⋉.⋉',\n",
       " '⋊.aɪ.ɪ.n.⋉.⋉',\n",
       " '⋊.p.ɪ.d.⋉.⋉',\n",
       " '⋊.z.i.ɚ.⋉.⋉',\n",
       " '⋊.d.ɹ.æ.⋉.⋉',\n",
       " '⋊.ɚ.m.ɔɪ.⋉.⋉',\n",
       " '⋊.ɛ.l.k.⋉.⋉',\n",
       " '⋊.ɔɪ.f.ɹ.⋉.⋉',\n",
       " '⋊.i.l.oʊ.⋉.⋉',\n",
       " '⋊.eɪ.f.l.⋉.⋉',\n",
       " '⋊.p.k.ɑ.⋉.⋉',\n",
       " '⋊.k.ʃ.ɚ.⋉.⋉',\n",
       " '⋊.æ.l.ə.⋉.⋉',\n",
       " '⋊.ɪ.t.l.⋉.⋉',\n",
       " '⋊.v.i.ɚ.⋉.⋉',\n",
       " '⋊.oʊ.l.t.⋉.⋉',\n",
       " '⋊.d.ɪ.t.⋉.⋉',\n",
       " '⋊.ə.m.ɛ.⋉.⋉',\n",
       " '⋊.l.æ.f.⋉.⋉',\n",
       " '⋊.ɪ.v.ɚ.⋉.⋉',\n",
       " '⋊.eɪ.f.g.⋉.⋉',\n",
       " '⋊.u.p.ɚ.⋉.⋉',\n",
       " '⋊.k.ɚ.v.⋉.⋉',\n",
       " '⋊.d.f.ɹ.⋉.⋉',\n",
       " '⋊.ɪ.ʃ.l.⋉.⋉',\n",
       " '⋊.s.aɪ.f.⋉.⋉',\n",
       " '⋊.l.u.d.⋉.⋉',\n",
       " '⋊.aɪ.ə.g.⋉.⋉',\n",
       " '⋊.v.aɪ.n.⋉.⋉',\n",
       " '⋊.t.s.m.⋉.⋉',\n",
       " '⋊.m.ʌ.d.⋉.⋉',\n",
       " '⋊.s.ʌ.n.⋉.⋉',\n",
       " '⋊.ɪ.n.h.⋉.⋉',\n",
       " '⋊.eɪ.k.eɪ.⋉.⋉',\n",
       " '⋊.ʊ.f.ɪ.⋉.⋉',\n",
       " '⋊.h.oʊ.ɹ.⋉.⋉',\n",
       " '⋊.ɛ.k.w.⋉.⋉',\n",
       " '⋊.w.aɪ.ɛ.⋉.⋉',\n",
       " '⋊.oʊ.b.ɑ.⋉.⋉',\n",
       " '⋊.p.i.i.⋉.⋉',\n",
       " '⋊.i.w.ɛ.⋉.⋉',\n",
       " '⋊.aɪ.v.ɪ.⋉.⋉',\n",
       " '⋊.ʌ.p.ɹ.⋉.⋉',\n",
       " '⋊.j.u.ɚ.⋉.⋉',\n",
       " '⋊.ɹ.n.d.⋉.⋉',\n",
       " '⋊.ɹ.ə.ɹ.⋉.⋉',\n",
       " '⋊.n.i.p.⋉.⋉',\n",
       " '⋊.l.dʒ.ɚ.⋉.⋉',\n",
       " '⋊.h.æ.z.⋉.⋉',\n",
       " '⋊.aɪ.z.ɪ.⋉.⋉',\n",
       " '⋊.θ.æ.ŋ.⋉.⋉',\n",
       " '⋊.m.f.ɪ.⋉.⋉',\n",
       " '⋊.ɪ.b.ɚ.⋉.⋉',\n",
       " '⋊.oʊ.ɹ.oʊ.⋉.⋉',\n",
       " '⋊.ə.d.ə.⋉.⋉',\n",
       " '⋊.s.ə.f.⋉.⋉',\n",
       " '⋊.p.s.aɪ.⋉.⋉',\n",
       " '⋊.z.ɪ.l.⋉.⋉',\n",
       " '⋊.l.eɪ.f.⋉.⋉',\n",
       " '⋊.v.ɪ.k.⋉.⋉',\n",
       " '⋊.z.n.i.⋉.⋉',\n",
       " '⋊.s.p.ɔɪ.⋉.⋉',\n",
       " '⋊.n.ə.l.⋉.⋉',\n",
       " '⋊.tʃ.u.ɪ.⋉.⋉',\n",
       " '⋊.ɹ.tʃ.i.⋉.⋉',\n",
       " '⋊.n.eɪ.k.⋉.⋉',\n",
       " '⋊.z.n.t.⋉.⋉',\n",
       " '⋊.ʌ.l.ʃ.⋉.⋉',\n",
       " '⋊.i.ɛ.l.⋉.⋉',\n",
       " '⋊.s.eɪ.m.⋉.⋉',\n",
       " '⋊.k.ɑ.k.⋉.⋉',\n",
       " '⋊.n.k.ə.⋉.⋉',\n",
       " '⋊.ɪ.k.eɪ.⋉.⋉',\n",
       " '⋊.ɹ.d.i.⋉.⋉',\n",
       " '⋊.f.ə.m.⋉.⋉',\n",
       " '⋊.ə.b.s.⋉.⋉',\n",
       " '⋊.n.æ.l.⋉.⋉',\n",
       " '⋊.æ.ʃ.t.⋉.⋉',\n",
       " '⋊.dʒ.ɚ.m.⋉.⋉',\n",
       " '⋊.t.w.ɑ.⋉.⋉',\n",
       " '⋊.h.u.l.⋉.⋉',\n",
       " '⋊.ɹ.t.f.⋉.⋉',\n",
       " '⋊.f.ɑ.ɹ.⋉.⋉',\n",
       " '⋊.ɹ.l.aɪ.⋉.⋉',\n",
       " '⋊.t.k.ɑ.⋉.⋉',\n",
       " '⋊.n.i.æ.⋉.⋉',\n",
       " '⋊.ɪ.d.æ.⋉.⋉',\n",
       " '⋊.l.i.z.⋉.⋉',\n",
       " '⋊.h.ʌ.ŋ.⋉.⋉',\n",
       " '⋊.d.ɪ.s.⋉.⋉',\n",
       " '⋊.oʊ.tʃ.ɪ.⋉.⋉',\n",
       " '⋊.f.ɪ.l.⋉.⋉',\n",
       " '⋊.dʒ.ɑ.n.⋉.⋉',\n",
       " '⋊.k.aɪ.d.⋉.⋉',\n",
       " '⋊.v.eɪ.k.⋉.⋉',\n",
       " '⋊.eɪ.z.ɚ.⋉.⋉',\n",
       " '⋊.d.f.oʊ.⋉.⋉',\n",
       " '⋊.h.ɑ.k.⋉.⋉',\n",
       " '⋊.θ.æ.n.⋉.⋉',\n",
       " '⋊.ɛ.p.s.⋉.⋉',\n",
       " '⋊.ɹ.æ.m.⋉.⋉',\n",
       " '⋊.ə.m.z.⋉.⋉',\n",
       " '⋊.l.eɪ.d.⋉.⋉',\n",
       " '⋊.æ.v.z.⋉.⋉',\n",
       " '⋊.ʃ.m.ə.⋉.⋉',\n",
       " '⋊.ɪ.ɹ.æ.⋉.⋉',\n",
       " '⋊.k.ɛ.p.⋉.⋉',\n",
       " '⋊.eɪ.t.i.⋉.⋉',\n",
       " '⋊.aʊ.t.w.⋉.⋉',\n",
       " '⋊.ð.h.oʊ.⋉.⋉',\n",
       " '⋊.d.ɛ.z.⋉.⋉',\n",
       " '⋊.ɹ.ɛ.θ.⋉.⋉',\n",
       " '⋊.p.k.oʊ.⋉.⋉',\n",
       " '⋊.i.m.ɚ.⋉.⋉',\n",
       " '⋊.v.oʊ.l.⋉.⋉',\n",
       " '⋊.t.ɚ.f.⋉.⋉',\n",
       " '⋊.u.ə.b.⋉.⋉',\n",
       " '⋊.ɑ.s.t.⋉.⋉',\n",
       " '⋊.aɪ.k.t.⋉.⋉',\n",
       " '⋊.s.k.aɪ.⋉.⋉',\n",
       " '⋊.d.aɪ.z.⋉.⋉',\n",
       " '⋊.s.oʊ.ɚ.⋉.⋉',\n",
       " '⋊.ʌ.b.w.⋉.⋉',\n",
       " '⋊.p.s.t.⋉.⋉',\n",
       " '⋊.t.s.aɪ.⋉.⋉',\n",
       " '⋊.d.ɹ.ʌ.⋉.⋉',\n",
       " '⋊.eɪ.ə.n.⋉.⋉',\n",
       " '⋊.l.p.eɪ.⋉.⋉',\n",
       " '⋊.k.t.ə.⋉.⋉',\n",
       " '⋊.ɑ.m.i.⋉.⋉',\n",
       " '⋊.ɹ.oʊ.w.⋉.⋉',\n",
       " '⋊.oʊ.k.ɑ.⋉.⋉',\n",
       " '⋊.p.ɑ.z.⋉.⋉',\n",
       " '⋊.æ.f.eɪ.⋉.⋉',\n",
       " '⋊.w.ə.l.⋉.⋉',\n",
       " '⋊.u.d.ɪ.⋉.⋉',\n",
       " '⋊.i.n.ɚ.⋉.⋉',\n",
       " '⋊.ɹ.ʃ.ə.⋉.⋉',\n",
       " '⋊.ɹ.g.ɹ.⋉.⋉',\n",
       " '⋊.t.ɚ.tʃ.⋉.⋉',\n",
       " '⋊.s.g.ɪ.⋉.⋉',\n",
       " '⋊.g.n.ɛ.⋉.⋉',\n",
       " '⋊.ɑ.t.g.⋉.⋉',\n",
       " '⋊.m.s.t.⋉.⋉',\n",
       " '⋊.i.oʊ.t.⋉.⋉',\n",
       " '⋊.t.i.eɪ.⋉.⋉',\n",
       " '⋊.ɪ.l.ʌ.⋉.⋉',\n",
       " '⋊.ə.ʃ.i.⋉.⋉',\n",
       " '⋊.b.aʊ.z.⋉.⋉',\n",
       " '⋊.i.g.z.⋉.⋉',\n",
       " '⋊.d.v.ə.⋉.⋉',\n",
       " '⋊.w.ʌ.n.⋉.⋉',\n",
       " '⋊.ɹ.b.aɪ.⋉.⋉',\n",
       " '⋊.b.eɪ.s.⋉.⋉',\n",
       " '⋊.i.h.ʊ.⋉.⋉',\n",
       " '⋊.k.h.i.⋉.⋉',\n",
       " '⋊.s.p.ə.⋉.⋉',\n",
       " '⋊.eɪ.n.s.⋉.⋉',\n",
       " '⋊.n.aɪ.ə.⋉.⋉',\n",
       " '⋊.d.æ.m.⋉.⋉',\n",
       " '⋊.l.ɪ.ɹ.⋉.⋉',\n",
       " '⋊.ɹ.oʊ.f.⋉.⋉',\n",
       " '⋊.æ.tʃ.ɚ.⋉.⋉',\n",
       " '⋊.n.s.eɪ.⋉.⋉',\n",
       " '⋊.w.ɚ.t.⋉.⋉',\n",
       " '⋊.aʊ.s.ɪ.⋉.⋉',\n",
       " '⋊.ɑ.d.ə.⋉.⋉',\n",
       " '⋊.ɪ.f.ɪ.⋉.⋉',\n",
       " '⋊.m.n.i.⋉.⋉',\n",
       " '⋊.n.aʊ.n.⋉.⋉',\n",
       " '⋊.ɹ.ʊ.k.⋉.⋉',\n",
       " '⋊.eɪ.d.eɪ.⋉.⋉',\n",
       " '⋊.h.aʊ.l.⋉.⋉',\n",
       " '⋊.d.ɛ.ʃ.⋉.⋉',\n",
       " '⋊.ɛ.k.tʃ.⋉.⋉',\n",
       " '⋊.t.aɪ.ɹ.⋉.⋉',\n",
       " '⋊.t.n.ɪ.⋉.⋉',\n",
       " '⋊.k.s.oʊ.⋉.⋉',\n",
       " '⋊.ɪ.tʃ.m.⋉.⋉',\n",
       " '⋊.f.i.v.⋉.⋉',\n",
       " '⋊.ɑ.m.d.⋉.⋉',\n",
       " '⋊.ɪ.h.eɪ.⋉.⋉',\n",
       " '⋊.p.h.ɛ.⋉.⋉',\n",
       " '⋊.p.ɪ.ʃ.⋉.⋉',\n",
       " '⋊.l.ɑ.ŋ.⋉.⋉',\n",
       " '⋊.ɔɪ.ə.l.⋉.⋉',\n",
       " '⋊.ə.w.i.⋉.⋉',\n",
       " '⋊.l.ɛ.t.⋉.⋉',\n",
       " '⋊.p.l.oʊ.⋉.⋉',\n",
       " '⋊.d.aɪ.m.⋉.⋉',\n",
       " '⋊.w.ʌ.ŋ.⋉.⋉',\n",
       " '⋊.ʃ.ɪ.ŋ.⋉.⋉',\n",
       " '⋊.m.aʊ.ð.⋉.⋉',\n",
       " '⋊.eɪ.n.aɪ.⋉.⋉',\n",
       " '⋊.ɚ.ð.ɚ.⋉.⋉',\n",
       " '⋊.t.ɛ.ʃ.⋉.⋉',\n",
       " '⋊.l.f.ɪ.⋉.⋉',\n",
       " '⋊.ɑ.d.oʊ.⋉.⋉',\n",
       " '⋊.ɚ.ɛ.k.⋉.⋉',\n",
       " '⋊.t.s.v.⋉.⋉',\n",
       " '⋊.t.i.ɚ.⋉.⋉',\n",
       " '⋊.k.j.ə.⋉.⋉',\n",
       " '⋊.d.i.l.⋉.⋉',\n",
       " '⋊.ɑ.ɪ.ŋ.⋉.⋉',\n",
       " '⋊.n.ɑ.v.⋉.⋉',\n",
       " '⋊.n.ɪ.b.⋉.⋉',\n",
       " '⋊.ɑ.b.s.⋉.⋉',\n",
       " '⋊.l.ɔɪ.i.⋉.⋉',\n",
       " '⋊.t.i.tʃ.⋉.⋉',\n",
       " '⋊.m.i.n.⋉.⋉',\n",
       " '⋊.h.eɪ.ʃ.⋉.⋉',\n",
       " '⋊.n.ɛ.f.⋉.⋉',\n",
       " '⋊.ɚ.n.z.⋉.⋉',\n",
       " '⋊.tʃ.ɚ.z.⋉.⋉',\n",
       " '⋊.i.æ.t.⋉.⋉',\n",
       " '⋊.ə.n.ɑ.⋉.⋉',\n",
       " '⋊.dʒ.ɪ.t.⋉.⋉',\n",
       " '⋊.ɑ.f.ɪ.⋉.⋉',\n",
       " '⋊.w.ɑ.ʃ.⋉.⋉',\n",
       " '⋊.æ.l.ɪ.⋉.⋉',\n",
       " '⋊.u.ɪ.ŋ.⋉.⋉',\n",
       " '⋊.dʒ.æ.m.⋉.⋉',\n",
       " '⋊.t.ə.g.⋉.⋉',\n",
       " '⋊.ɹ.m.z.⋉.⋉',\n",
       " '⋊.ɹ.ɛ.s.⋉.⋉',\n",
       " '⋊.w.eɪ.d.⋉.⋉',\n",
       " '⋊.i.l.eɪ.⋉.⋉',\n",
       " '⋊.u.z.ɚ.⋉.⋉',\n",
       " '⋊.d.aʊ.t.⋉.⋉',\n",
       " '⋊.ɑ.l.t.⋉.⋉',\n",
       " '⋊.dʒ.i.ɪ.⋉.⋉',\n",
       " '⋊.aʊ.tʃ.t.⋉.⋉',\n",
       " '⋊.l.ɚ.k.⋉.⋉',\n",
       " '⋊.tʃ.ɪ.m.⋉.⋉',\n",
       " '⋊.p.ɑ.k.⋉.⋉',\n",
       " '⋊.ʌ.v.i.⋉.⋉',\n",
       " '⋊.θ.oʊ.ɹ.⋉.⋉',\n",
       " '⋊.ɹ.l.i.⋉.⋉',\n",
       " '⋊.eɪ.ʃ.ə.⋉.⋉',\n",
       " '⋊.ŋ.g.l.⋉.⋉',\n",
       " '⋊.k.l.æ.⋉.⋉',\n",
       " '⋊.tʃ.i.p.⋉.⋉',\n",
       " '⋊.f.ɚ.t.⋉.⋉',\n",
       " '⋊.ɚ.k.oʊ.⋉.⋉',\n",
       " '⋊.ɛ.l.v.⋉.⋉',\n",
       " '⋊.t.ɛ.s.⋉.⋉',\n",
       " '⋊.f.ɹ.oʊ.⋉.⋉',\n",
       " '⋊.aɪ.s.ə.⋉.⋉',\n",
       " '⋊.tʃ.ɪ.f.⋉.⋉',\n",
       " '⋊.ɛ.l.t.⋉.⋉',\n",
       " '⋊.z.ʌ.l.⋉.⋉',\n",
       " '⋊.ɪ.z.ʊ.⋉.⋉',\n",
       " '⋊.h.ɛ.z.⋉.⋉',\n",
       " '⋊.k.l.ʌ.⋉.⋉',\n",
       " '⋊.l.m.d.⋉.⋉',\n",
       " '⋊.æ.m.ɑ.⋉.⋉',\n",
       " '⋊.g.ɚ.t.⋉.⋉',\n",
       " '⋊.ʃ.oʊ.ɪ.⋉.⋉',\n",
       " '⋊.m.i.æ.⋉.⋉',\n",
       " '⋊.ɔɪ.n.ɪ.⋉.⋉',\n",
       " '⋊.oʊ.d.ə.⋉.⋉',\n",
       " '⋊.m.æ.t.⋉.⋉',\n",
       " '⋊.aʊ.ɪ.ŋ.⋉.⋉',\n",
       " '⋊.ɚ.d.z.⋉.⋉',\n",
       " '⋊.eɪ.ɑ.f.⋉.⋉',\n",
       " '⋊.aʊ.d.z.⋉.⋉',\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.p.ʌ.z.⋉.⋉'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_wordforms = {w for w in Ws if len(ds2t(w)) == my_max_l}; longest_wordforms\n",
    "longest_wordform = list(longest_wordforms)[0]; longest_wordform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:53.403727Z",
     "start_time": "2019-09-12T19:22:53.392632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊', '⋊.oʊ', '⋊.oʊ.ɑ', '⋊.oʊ.ɑ.l', '⋊.oʊ.ɑ.l.⋉', '⋊.oʊ.ɑ.l.⋉.⋉']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 9159, 9597, 9601, 9602, 9603]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "retrievePrefixes(w=random_w, Ws_t=Ws_t, max_l=my_max_l, asType='ds')\n",
    "retrievePrefixes(w=random_w, Ws_t=Ws_t, Ps_t=Ps_t, max_l=my_max_l, asType='indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:54.452075Z",
     "start_time": "2019-09-12T19:22:54.441071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.p.ʌ.z.⋉.⋉'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊', '⋊.p', '⋊.p.ʌ', '⋊.p.ʌ.z', '⋊.p.ʌ.z.⋉', '⋊.p.ʌ.z.⋉.⋉']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 9756, 10442, 10461, 10462, 10463]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_wordform\n",
    "retrievePrefixes(w=longest_wordform, Ws_t=Ws_t, max_l=my_max_l, asType='ds')\n",
    "retrievePrefixes(w=longest_wordform, Ws_t=Ws_t, Ps_t=Ps_t, max_l=my_max_l, asType='indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting whether `p` is a prefix of `w`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:22:58.792150Z",
     "start_time": "2019-09-12T19:22:58.788186Z"
    }
   },
   "outputs": [],
   "source": [
    "#naive implementation\n",
    "# could be made more efficient if that's important\n",
    "def is_a_prefix(p_OH, w_OH):\n",
    "    unpadded_p_OH, unpadded_w_OH = unpad(p_OH), unpad(w_OH)\n",
    "    p_l = unpadded_p_OH.shape[0]\n",
    "    w_l = unpadded_w_OH.shape[0]\n",
    "    if p_l > w_l:\n",
    "#         print('case 1')\n",
    "        return False\n",
    "    elif p_l == w_l:\n",
    "#         print('case 2')\n",
    "        return np.array_equal(unpadded_p_OH, unpadded_w_OH)\n",
    "    else: #p_l < w_l\n",
    "#         print('case 3')\n",
    "        trimmed_w_OH = unpadded_w_OH[:p_l]\n",
    "        return np.array_equal(unpadded_p_OH, trimmed_w_OH)\n",
    "#         return np.array_equal(np.dot(unpadded_p_OH, \n",
    "#                                      trimmed_w_OH.T),\n",
    "#                               np.eye(p_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:00.765408Z",
     "start_time": "2019-09-12T19:23:00.744001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 41)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.n.i'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 41)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "a_prefix_of_random_w\n",
    "random_w_OH.shape\n",
    "a_prefix_of_random_w_OH.shape\n",
    "assert (a_prefix_of_random_w in getPrefixes(random_w)) == is_a_prefix(a_prefix_of_random_w_OH, random_w_OH)\n",
    "lmap(lambda p: is_a_prefix(p, random_w_OH),\n",
    "     getPrefixes_OH(random_w_OH))\n",
    "' '\n",
    "random_other_p = choice(list(getPrefixes(choice(Ws_t))));\n",
    "random_w\n",
    "random_other_p\n",
    "random_other_p_OH = dsToUniphoneOHs(random_other_p, XOHmap)\n",
    "random_other_p_OH.shape\n",
    "\n",
    "assert (random_other_p in getPrefixes(random_w)) == is_a_prefix(random_other_p_OH, random_w_OH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a `prefix-word` relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:03.547017Z",
     "start_time": "2019-09-12T19:23:03.542718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_relation_shape = (len(Ws_t), len(Ps_t))\n",
    "prefix_relation_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:04.269722Z",
     "start_time": "2019-09-12T19:23:04.265075Z"
    }
   },
   "outputs": [],
   "source": [
    "def prefixIndicesToOHslice(prefix_idxs, num_Ps_t):\n",
    "    '''\n",
    "    Takes a list of prefix indices (e.g. that are prefixes of some w)\n",
    "    and returns a (dense) binary vector where those indices are 1 and\n",
    "    others are zero.\n",
    "    '''\n",
    "    my_slice = np.zeros(shape=(num_Ps_t,), dtype=np.uint8)\n",
    "#     for idx in prefix_idxs:\n",
    "#         my_slice[idx] = 1.0\n",
    "#     return my_slice\n",
    "#     return np.put(my_slice, prefix_idxs, 1) #<<< returns None because numpy is stateful AF\n",
    "    np.put(my_slice, prefix_idxs, 1)\n",
    "    return my_slice\n",
    "\n",
    "# retrievePrefixes(w_idx, Ps_t, asType='indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:07.637716Z",
     "start_time": "2019-09-12T19:23:06.135520Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0049s.) Setting batch_size=80.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0886s.) Setting batch_size=360.\n",
      "[Parallel(n_jobs=-1)]: Done 6737 out of 6737 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slice_calc(w_idx):\n",
    "    return prefixIndicesToOHslice(retrievePrefixes(w_idx=w_idx, \n",
    "                                                   Ps_t=Ps_t,\n",
    "                                                   max_l=my_max_l,\n",
    "                                                   asType='indices'), \n",
    "                                  len(Ps_t))\n",
    "\n",
    "# ≈3m on CMU on solomonoff\n",
    "# 50s CMU / sidious\n",
    "prefix_relation_np = np.stack(list(par(delayed(slice_calc)(w_idx)\n",
    "                                       for w_idx in np.arange(prefix_relation_shape[0]))))#, \n",
    "#                               dtype=np.uint8)\n",
    "\n",
    "# prefix_relation_np = np.stack([prefixIndexListToSlice(retrievePrefixes(w_idx=w_idx, \n",
    "#                                                                        Ps_t=Ps_t, \n",
    "#                                                                        asType='indices'), \n",
    "#                                                       len(Ps_t))\n",
    "#                                for w_idx in np.arange(prefix_relation_shape[1])])\n",
    "prefix_relation_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `(p,w,l)` relation where `w` trimmed to `l` is `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The logical place for this calculation is here, but the motivation is given in the section on $k$-cousins.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:10.198768Z",
     "start_time": "2019-09-12T19:23:10.196302Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_to_l = {p:len(ds2t(p)) for p in Ps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:10.360449Z",
     "start_time": "2019-09-12T19:23:10.354739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Ws_t), len(Ps_t))\n",
    "prefix_relation_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll want to be able to retrieve the indices or strings of wordforms for each prefix such that that prefix is a prefix of those wordforms..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:12.561387Z",
     "start_time": "2019-09-12T19:23:12.558710Z"
    }
   },
   "outputs": [],
   "source": [
    "# #est 30m on cmu+solomonoff\n",
    "\n",
    "# #maps each prefix p to an array of wordform indices s.t.\n",
    "# # p is a prefix of each of the wordforms with those indices\n",
    "# # p_to_w_idxs = {p:prefix_relation_np[:,Ps_t.index(p)].nonzero()[0]\n",
    "# #                for p in tqdm(Ps)}\n",
    "\n",
    "# #est 17m on cmu/solomonoff\n",
    "# # def p_to_w_idx_calc(p):\n",
    "# #     return p, prefix_relation_np[:,Ps_t.index(p)].nonzero()[0]\n",
    "\n",
    "# # p_to_w_idxs = dict(par(delayed(p_to_w_idx_calc)(p)\n",
    "# #                        for p in Ps))\n",
    "\n",
    "# def p_to_w_idxs(p):\n",
    "#     return prefix_relation_np[:,Ps_t.index(p)].nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:12.693234Z",
     "start_time": "2019-09-12T19:23:12.690997Z"
    }
   },
   "outputs": [],
   "source": [
    "# random_w\n",
    "# a_prefix_of_random_w\n",
    "# ' '\n",
    "# Ws_t.index(random_w)\n",
    "# p_to_w_idxs(a_prefix_of_random_w)\n",
    "# lmap(lambda w_idx: Ws_t[w_idx], \n",
    "#      p_to_w_idxs(a_prefix_of_random_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:12.823347Z",
     "start_time": "2019-09-12T19:23:12.820620Z"
    }
   },
   "outputs": [],
   "source": [
    "#est 30-90m cmu+solomonoff\n",
    "# p_to_ws = {p:set(map(lambda w_idx: Ws_t[w_idx],\n",
    "#                      p_to_w_idxs(p)))\n",
    "#            for p in tqdm(Ps, total=len(Ps))}\n",
    "\n",
    "#est ?\n",
    "# def p_to_ws_calc(p):\n",
    "#     return p, set(map(lambda w_idx: Ws_t[w_idx],\n",
    "#                       p_to_w_idxs(p)))\n",
    "\n",
    "# p_to_ws = dict(par(delayed(p_to_ws_calc)(p)\n",
    "#                    for p in Ps))\n",
    "\n",
    "# def p_to_ws(p):\n",
    "#     return set(map(lambda w_idx: Ws_t[w_idx],\n",
    "#                    p_to_w_idxs(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:12.959686Z",
     "start_time": "2019-09-12T19:23:12.957279Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_to_ws(a_prefix_of_random_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:13.098132Z",
     "start_time": "2019-09-12T19:23:13.095512Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #est 10-15m cmu+solomonoff\n",
    "# #maps each prefix index to an arbitray wordform index s.t.\n",
    "# # that prefix is a prefix of that wordform\n",
    "# # p_idx_to_w_idx = np.array([p_to_w_idxs(Ps_t[p_idx])[0]\n",
    "# #                            for p_idx in tqdm(np.arange(len(Ps_t)), total=len(Ps_t))], \n",
    "# #                           dtype=np.int8)\n",
    "\n",
    "# def p_idx_to_w_idx_calc(p_idx):\n",
    "#     indices = p_to_w_idxs(Ps_t[p_idx])\n",
    "#     if len(indices) > 0:\n",
    "#         return indices[0]\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# # ≈6m cmu+solomonoff\n",
    "# # ?m cmu+sidious\n",
    "# # ≈1.3m cmu+wittgenstein\n",
    "# p_idx_to_w_idx = np.array(list(par(delayed(p_idx_to_w_idx_calc)(p_idx)\n",
    "#                                    for p_idx in np.arange(len(Ps_t)))), \n",
    "#                           dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:14.715826Z",
     "start_time": "2019-09-12T19:23:14.713488Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(Ps_t)\n",
    "# p_idx_to_w_idx.shape\n",
    "# p_idx_to_w_idx.dtype\n",
    "# p_idx_to_w_idx.nbytes / 1e9 #FIXME reconsider dtype\n",
    "# p_idx_to_w_idx[Ps_t.index(a_prefix_of_random_w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:14.862014Z",
     "start_time": "2019-09-12T19:23:14.859807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t[0]\n",
    "# p_idx_to_w_idx[0]\n",
    "# Ws_t[p_idx_to_w_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:15.025597Z",
     "start_time": "2019-09-12T19:23:15.023416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t[2]\n",
    "# p_idx_to_w_idx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:15.203867Z",
     "start_time": "2019-09-12T19:23:15.201780Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.where(p_idx_to_w_idx == -1)[0]\n",
    "# assert np.where(p_idx_to_w_idx == -1)[0].size == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:15.355088Z",
     "start_time": "2019-09-12T19:23:15.353034Z"
    }
   },
   "outputs": [],
   "source": [
    "# w_idx_to_p_idx = {p_idx_to_w_idx[p_idx]:p_idx\n",
    "#                   for p_idx in tqdm(range(len(Ps_t)), total=len(Ps_t))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:15.451982Z",
     "start_time": "2019-09-12T19:23:15.450036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_t[232]\n",
    "# w_idx_to_p_idx[232]\n",
    "# Ps_t[w_idx_to_p_idx[232]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:17.189776Z",
     "start_time": "2019-09-12T19:23:15.738519Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0037s.) Setting batch_size=108.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0444s.) Setting batch_size=972.\n",
      "[Parallel(n_jobs=-1)]: Done 1900 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3736 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 40422 out of 40422 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "# w_idx_to_l_to_p_idx = {(p_idx_to_w_idx[p_idx], p_to_l[Ps_t[p_idx]]):p_idx\n",
    "#                        for p_idx in tqdm(range(len(Ps_t)), total=len(Ps_t))}\n",
    "\n",
    "# w_idx_to_l_to_p_idx2 = {(w_idx, l): Ps_t.index( t2ds(ds2t(Ws_t[w_idx])[:l]) )\n",
    "#                         for w_idx in tqdm(range(len(Ws_t)), total=len(Ws_t)) for l in range(1, len(ds2t(Ws_t[w_idx])))}\n",
    "\n",
    "# w_idx_to_l_to_p_idx3 = {(Ws_t.index(w), len(ds2t(p))): Ps_t.index(p)\n",
    "#                         for w in tqdm(Ws_t) for p in getPrefixes(w)}\n",
    "\n",
    "# ≈10m on CMU/wittgenstein\n",
    "# w_idx_to_l_to_p_idx = {(Ws_t.index(w), len(ds2t(p))): Ps_t.index(p)\n",
    "#                         for w in tqdm(Ws_t) for p in getPrefixes(w)}\n",
    "\n",
    "def w_idx_to_l_to_p_idx_calc(w, p):\n",
    "    return ((Ws_t.index(w), len(ds2t(p))), Ps_t.index(p))\n",
    "\n",
    "# ≈1.3m cmu+wittgenstein\n",
    "w_idx_to_l_to_p_idx = dict(par(delayed(w_idx_to_l_to_p_idx_calc)(w,p)\n",
    "                               for w in Ws_t for p in getPrefixes(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:17.194327Z",
     "start_time": "2019-09-12T19:23:17.191721Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(w_idx_to_l_to_p_idx)\n",
    "# # len(w_idx_to_l_to_p_idx2)\n",
    "# len(w_idx_to_l_to_p_idx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:18.983721Z",
     "start_time": "2019-09-12T19:23:18.974674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9603"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "len(ds2t(random_w))\n",
    "associated_p_idx = w_idx_to_l_to_p_idx[(Ws_t.index(random_w), len(ds2t(random_w)))]; associated_p_idx\n",
    "Ps_t[associated_p_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:19.148329Z",
     "start_time": "2019-09-12T19:23:19.138048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.d.ə.s.⋉.⋉'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1469, 1973, 2001, 2002, 2003]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊', '⋊.d', '⋊.d.ə', '⋊.d.ə.s', '⋊.d.ə.s.⋉', '⋊.d.ə.s.⋉.⋉']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform_idx = choice(range(len(Ws_t)))\n",
    "Ws_t[random_wordform_idx]\n",
    "[w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) for l in prefixlengths if w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) != None]\n",
    "lmap(lambda p_idx: Ps_t[p_idx],\n",
    "     [w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) for l in prefixlengths if w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:19.270962Z",
     "start_time": "2019-09-12T19:23:19.262090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ʌ.s.p.⋉'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20777"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_prefix = choice(Ps_t); random_prefix\n",
    "random_prefix_idx = Ps_t.index(random_prefix); random_prefix_idx\n",
    "random_prefix_l = len(ds2t(random_prefix)); random_prefix_l\n",
    "# p_to_l[random_prefix]\n",
    "# associated_w_idx = p_idx_to_w_idx[random_prefix_idx]; associated_w_idx\n",
    "# Ws_t[associated_w_idx]\n",
    "# Ps_l[random_prefix_l][associated_w_idx].shape\n",
    "# w_idx_to_l_to_p_idx[(associated_w_idx, random_prefix_l)]\n",
    "# Ps_t[w_idx_to_l_to_p_idx[(associated_w_idx, random_prefix_l)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:22.387263Z",
     "start_time": "2019-09-12T19:23:22.383315Z"
    }
   },
   "outputs": [],
   "source": [
    "random_prefixes = choices(Ps_t, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:22.593131Z",
     "start_time": "2019-09-12T19:23:22.586366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.n.i'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.ɪ.ɹ.i.⋉',\n",
       " '⋊.u.k.l.⋉.⋉',\n",
       " '⋊.d.l.ɪ.⋉.⋉',\n",
       " '⋊.ʃ.oʊ.d',\n",
       " '⋊.w.ʊ.d.⋉.⋉',\n",
       " '⋊.g.dʒ.ɛ',\n",
       " '⋊.h.ə.b.⋉.⋉',\n",
       " '⋊.aɪ.t.æ.⋉',\n",
       " '⋊.aɪ.p.ə.⋉',\n",
       " '⋊.m.oʊ.ʃ']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_other_p\n",
    "some_random_prefixes = random_prefixes[:10]; some_random_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:23.462469Z",
     "start_time": "2019-09-12T19:23:23.458654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_other_p_OH.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:23.976795Z",
     "start_time": "2019-09-12T19:23:23.973961Z"
    }
   },
   "outputs": [],
   "source": [
    "# length_mismatch_constant = np.inf\n",
    "length_mismatch_constant = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between symbol vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:26.459450Z",
     "start_time": "2019-09-12T19:23:26.454691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = np.zeros(shape=XOHmap['f'].shape, dtype=my_dtype)\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:26.626770Z",
     "start_time": "2019-09-12T19:23:26.605713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOHmap['f'] #a\n",
    "XOHmap['g'] #b\n",
    "\n",
    "diff_V = XOHmap['f'] - XOHmap['g']; diff_V #will be the zero vector iff a = b\n",
    "sum_V = XOHmap['f'] + XOHmap['g']; sum_V\n",
    "prod_V = XOHmap['f'] * XOHmap['g']; prod_V #a * b will be the zero vector iff a ≠ b and a * b = a = b iff a = b\n",
    "dot_prod_V = np.dot(XOHmap['f'], XOHmap['g']); dot_prod_V #a.b will be 0 iff a ≠ b and a.b = 1 iff a = b\n",
    "np.dot(XOHmap['f'], XOHmap['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:27.205091Z",
     "start_time": "2019-09-12T19:23:27.201069Z"
    }
   },
   "outputs": [],
   "source": [
    "random_OHs = choices(list(map(lambda x: XOHmap[x], Xs)), k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:27.621533Z",
     "start_time": "2019-09-12T19:23:27.617723Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not np.array_equal(choice(random_OHs), choice(random_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:28.105552Z",
     "start_time": "2019-09-12T19:23:28.101846Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not np.array_equal(choice(random_OHs) - choice(random_OHs), zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:28.495649Z",
     "start_time": "2019-09-12T19:23:28.491769Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not (choice(random_OHs) - choice(random_OHs)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:28.855393Z",
     "start_time": "2019-09-12T19:23:28.851861Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not (choice(random_OHs) - choice(random_OHs)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:29.121543Z",
     "start_time": "2019-09-12T19:23:29.117909Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit (choice(random_OHs) * choice(random_OHs)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:29.406856Z",
     "start_time": "2019-09-12T19:23:29.403203Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit np.dot(choice(random_OHs), choice(random_OHs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Unsurprising) conclusion on checking for vector equality: `np.dot` is about 2-3 times as fast as methods involving element-wise array equality checking or sums and differences possibly involving the zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:29.908144Z",
     "start_time": "2019-09-12T19:23:29.904691Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_s_np(x_OH, y_OH):\n",
    "    '''\n",
    "    Hamming distance between symbol x and symbol y,\n",
    "    where both symbols are one-hot vectors.\n",
    "    '''\n",
    "    return not np.dot(x_OH, y_OH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:30.378224Z",
     "start_time": "2019-09-12T19:23:30.358305Z"
    }
   },
   "outputs": [],
   "source": [
    "for each_OH in random_OHs:\n",
    "    assert d_s_np(each_OH, each_OH) == 0 and np.array_equal(each_OH, each_OH)\n",
    "    random_OH = choice(random_OHs)\n",
    "    assert d_s_np(each_OH, random_OH) == (not np.array_equal(each_OH, random_OH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming distance between stacks of symbol vectors (strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:31.576961Z",
     "start_time": "2019-09-12T19:23:31.571911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,3)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:31.683814Z",
     "start_time": "2019-09-12T19:23:31.581746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Direct comparison for equality:'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Difference:'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hadamard product:'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Dot product:'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=uint64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=uint64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=uint64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=uint64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Direct comparison for equality:'\n",
    "np.array_equal(dsToUniphoneOHs('t.i.f', XOHmap), dsToUniphoneOHs('t.i.f', XOHmap)) #true\n",
    "np.array_equal(dsToUniphoneOHs('t.i.f', XOHmap), dsToUniphoneOHs('t.i.g', XOHmap)) #false\n",
    "\n",
    "'Difference:'\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.f', XOHmap)).sum()\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.f', XOHmap)).prod()\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap).astype(np.int64) - dsToUniphoneOHs('t.i.g', XOHmap).astype(np.int64)).sum()\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.g', XOHmap)).prod()\n",
    "# (dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.g', XOHmap)).sum()\n",
    "\n",
    "'Hadamard product:'\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('t.i.f', XOHmap)).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('t.i.g', XOHmap)).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('d.i.g', XOHmap)).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('d.u.g', XOHmap)).sum()\n",
    "\n",
    "'Dot product:'\n",
    "np.dot(dsToUniphoneOHs('t.i.f', XOHmap),\n",
    "       dsToUniphoneOHs('t.i.f', XOHmap).T)\n",
    "dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.f', XOHmap).T\n",
    "dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.g', XOHmap).T\n",
    "dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.f', XOHmap).T\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.f', XOHmap).T).sum(axis=0)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.f', XOHmap).T).sum(axis=1)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.g', XOHmap).T).sum(axis=0)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.g', XOHmap).T).sum(axis=1)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum(axis=0)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum(axis=1)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum(axis=0).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:32.271262Z",
     "start_time": "2019-09-12T19:23:32.262818Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_w_np_hadamard(x_OHs, y_OHs):\n",
    "    '''\n",
    "    Hamming distance between stacks of symbols x and y,\n",
    "    where both stacks are of one-hot vectors.\n",
    "    '''\n",
    "    l = x_OHs.shape[0]\n",
    "    \n",
    "    return l - (x_OHs * y_OHs).sum()\n",
    "\n",
    "# turns out to be both incorrect and scales poorly\n",
    "# def d_w_np_dot(x_OHs, y_OHs):\n",
    "#     '''\n",
    "#     Hamming distance between stacks of symbols x and y,\n",
    "#     where both stacks are of one-hot vectors.\n",
    "#     '''\n",
    "#     l = x_OHs.shape[0]\n",
    "    \n",
    "#     return l - (x_OHs @ y_OHs.T).sum()\n",
    "\n",
    "def d_w_np_direct(x_OHs, y_OHs):\n",
    "    '''\n",
    "    Hamming distance between stacks of symbols x and y,\n",
    "    where both stacks are of one-hot vectors.\n",
    "    '''\n",
    "    l = x_OHs.shape[0]\n",
    "    return np.array([(not np.array_equal(x_OHs[i], y_OHs[i])) for i in range(l)]).sum()\n",
    "\n",
    "d_s_npu = np.vectorize(d_s_np, otypes=[np.uint8], signature=\"(s),(s)->()\")\n",
    "\n",
    "def d_w_np_u(x_OHs, y_OHs):\n",
    "    return d_s_npu(x_OHs, y_OHs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:36.794669Z",
     "start_time": "2019-09-12T19:23:36.750245Z"
    }
   },
   "outputs": [],
   "source": [
    "num_random_fixed_size_OHs = 1000\n",
    "\n",
    "my_fixed_size = 20 #longer length = more revealing\n",
    "\n",
    "random_fixed_size_OHs = [np.stack([choice(random_OHs) for each in range(my_fixed_size)])\n",
    "                         for each in range(num_random_fixed_size_OHs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:36.920551Z",
     "start_time": "2019-09-12T19:23:36.916040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 41)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_fixed_size_OHs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:37.054542Z",
     "start_time": "2019-09-12T19:23:37.050789Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #indicates overhead of choosing random inputs\n",
    "    %timeit (choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:37.417616Z",
     "start_time": "2019-09-12T19:23:37.414071Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_w_np_hadamard(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:37.773744Z",
     "start_time": "2019-09-12T19:23:37.771773Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# d_w_np_dot(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:38.234518Z",
     "start_time": "2019-09-12T19:23:38.230898Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_w_np_direct(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:38.390813Z",
     "start_time": "2019-09-12T19:23:38.387407Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_w_np_u(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for correctness..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:39.129810Z",
     "start_time": "2019-09-12T19:23:39.119968Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for my_hamming_distance_function in (d_w_np_direct, d_w_np_hadamard, d_w_np_u):\n",
    "    # for my_hamming_distance_function in (d_w_np_direct, d_w_np_hadamard, d_w_np_dot, d_w_np_u):\n",
    "        print(f'Checking {str(my_hamming_distance_function)}')\n",
    "        for each_OHstack in random_fixed_size_OHs:\n",
    "        #     my_hamming_distance_function = d_w_np_hadamard\n",
    "    #         my_hamming_distance_function = d_w_np_direct\n",
    "        #     my_hamming_distance_function = \n",
    "            if not (my_hamming_distance_function(each_OHstack, each_OHstack) == 0 and np.array_equal(each_OHstack, each_OHstack) == True):\n",
    "                each_s = OHsToDS(each_OHstack, OHXmap)\n",
    "                print(f'each_s = {each_s}')\n",
    "                print(f'd_h = {d_h(each_s, each_s)}')\n",
    "                print(f'my_hamming_distance_function(each_OHstack, each_OHstack) = {my_hamming_distance_function(each_OHstack, each_OHstack)}')\n",
    "            assert my_hamming_distance_function(each_OHstack, each_OHstack) == 0 and np.array_equal(each_OHstack, each_OHstack) == True\n",
    "\n",
    "            random_OHstack = choice(random_fixed_size_OHs)\n",
    "            each_s = OHsToDS(each_OHstack, OHXmap)\n",
    "            random_s = OHsToDS(random_OHstack, OHXmap)\n",
    "\n",
    "            if not (my_hamming_distance_function(each_OHstack, random_OHstack) == d_h(each_s, random_s)):\n",
    "                print(f'each_s = {each_s}', f'random_s = {random_s}')\n",
    "                pprint_aligned_DSs(align_DSs([each_s, random_s]))\n",
    "                print(f'd_h = {d_h(each_s, random_s)}')\n",
    "                print(f'my_hamming_distance_function(each_OHstack, random_OHstack) = {my_hamming_distance_function(each_OHstack, random_OHstack)}')\n",
    "            assert my_hamming_distance_function(each_OHstack, random_OHstack) == d_h(each_s, random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** The Hadamard product scales very well for checking Hamming distance between two (unpadded one-hot) strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:39.954755Z",
     "start_time": "2019-09-12T19:23:39.950961Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_h_np(x_OHs, y_OHs):\n",
    "    '''\n",
    "    Hamming distance between sequences of symbols x and y,\n",
    "    where both symbols are represented by one-hot vectors and\n",
    "    neither is a padded stack.\n",
    "    '''\n",
    "    l = x_OHs.shape[0]\n",
    "    if l != y_OHs.shape[0]:\n",
    "        return length_mismatch_constant\n",
    "#         return np.infty\n",
    "    return l - (x_OHs * y_OHs).sum(dtype=my_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accommodate padded OH vectors, we need mechanisms for accounting for padding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:23:41.190021Z",
     "start_time": "2019-09-12T19:23:41.183313Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_h_np(x_OHs, y_OHs, paddedOHs=False):\n",
    "    '''\n",
    "    Hamming distance between sequences of symbols x and y,\n",
    "    where both symbols are represented by one-hot vectors.\n",
    "    '''\n",
    "    if paddedOHs:\n",
    "        x_l = trueLength(x_OHs)\n",
    "        y_l = trueLength(y_OHs)\n",
    "        if x_l != y_l:\n",
    "            return length_mismatch_constant\n",
    "#             return np.infty\n",
    "        else: #true lengths *are* the same...\n",
    "            true_l = x_l\n",
    "#             x_pl = x_OHs.shape[0]\n",
    "#             y_pl = y_OHs.shape[0]\n",
    "            \n",
    "            #correct but involves the creation of new OH stacks\n",
    "#             trimmed_x_OHs, trimmed_y_OHs = adjustWord(x_OHs, true_l), adjustWord(y_OHs, true_l)\n",
    "#             return true_l - (trimmed_x_OHs * trimmed_y_OHs).sum()\n",
    "\n",
    "            return true_l - ((x_OHs[:true_l] * y_OHs[:true_l])).sum(dtype=my_dtype)\n",
    "            \n",
    "    l = x_OHs.shape[0]\n",
    "    if l != y_OHs.shape[0]:\n",
    "        return -1\n",
    "#         return np.infty\n",
    "    return l - (x_OHs * y_OHs).sum(dtype=my_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:08.329437Z",
     "start_time": "2019-09-12T19:24:08.242551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.b.aɪ.⋉.⋉'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.b.aɪ.⋉.⋉'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.b.aɪ.⋉.⋉'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.n.i'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 41)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 41)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w0 = Ws_t[0]; w0\n",
    "w0\n",
    "# w0_l = len(ds2t(Ws_t[0])); \n",
    "w0_l\n",
    "' '\n",
    "# unpadded_w0_OH_rep = dsToUniphoneOHs(w0, XOHmap); unpadded_w0_OH_rep.shape\n",
    "unpadded_w0_OH_rep.shape\n",
    "OHsToDS(unpadded_w0_OH_rep, OHXmap)\n",
    "assert not isPaddedOHstack(unpadded_w0_OH_rep)\n",
    "' '\n",
    "# padded_w0_OH_rep = Ws_npf[0]; padded_w0_OH_rep.shape\n",
    "padded_w0_OH_rep.shape\n",
    "OHsToDS(padded_w0_OH_rep, OHXmap)\n",
    "assert isPaddedOHstack(padded_w0_OH_rep) or not containsAnyPaddedOHstacks(Ws_npf)\n",
    "' '\n",
    "d_h_np(unpadded_w0_OH_rep, unpadded_w0_OH_rep)\n",
    "d_h_np(unpadded_w0_OH_rep, padded_w0_OH_rep, True)\n",
    "d_h_np(padded_w0_OH_rep, padded_w0_OH_rep, True)\n",
    "' '\n",
    "random_other_p\n",
    "random_other_p_OH.shape\n",
    "random_other_p_OH_padded = adjustWord(random_other_p_OH, 20)\n",
    "random_other_p_OH_padded.shape\n",
    "assert isPaddedOHstack(random_other_p_OH_padded) or not containsAnyPaddedOHstacks(Ws_npf)\n",
    "d_h(w0, random_other_p)\n",
    "d_h_np(padded_w0_OH_rep, random_other_p_OH_padded, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:11.140426Z",
     "start_time": "2019-09-12T19:24:11.135617Z"
    }
   },
   "outputs": [],
   "source": [
    "num_random_padded_OHs = 1000\n",
    "\n",
    "random_padded_OHs = [choice(Ws_npf)\n",
    "                     for each in range(num_random_padded_OHs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:11.682488Z",
     "start_time": "2019-09-12T19:24:11.678695Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_d_h(u,v):\n",
    "    result = d_h(u,v)\n",
    "    if result == np.inf:\n",
    "        return length_mismatch_constant\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:12.214802Z",
     "start_time": "2019-09-12T19:24:12.209848Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for each_OH_stack in random_padded_OHs:\n",
    "        other_OH_stack = choice(random_padded_OHs)\n",
    "\n",
    "        each_s  = OHsToDS(each_OH_stack, OHXmap)\n",
    "        other_s = OHsToDS(other_OH_stack, OHXmap)\n",
    "\n",
    "        if trueLength(each_OH_stack) == trueLength(other_OH_stack):\n",
    "            print('matching true lengths...') #more useful tests\n",
    "\n",
    "        assert my_d_h(each_s, other_s) == d_h_np(each_OH_stack, other_OH_stack, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:12.786761Z",
     "start_time": "2019-09-12T19:24:12.783291Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np(choice(random_padded_OHs), choice(random_padded_OHs), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between a string and a stack of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is correct, modulo accounting for padded stacks. (In those cases, levenshtein distance enters the calculation...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:13.852962Z",
     "start_time": "2019-09-12T19:24:13.780319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_idx = Ws_t.index(random_w)\n",
    "random_w_OHf = Ws_npf[random_w_idx]; random_w_OHf.shape\n",
    "Ws_npf.shape\n",
    "np.array(lmap(lambda w_OHf: d_h_np(random_w_OHf, w_OHf, False),\n",
    "              Ws_npf))\n",
    "\n",
    "random_w_OHf.shape[0] - np.einsum('nls->n', random_w_OHf * Ws_npf)\n",
    "random_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', random_w_OHf, Ws_npf))\n",
    "random_w_OHf.shape[0] - np.einsum('nls->n', (random_w_OHf * Ws_sf).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:19.282445Z",
     "start_time": "2019-09-12T19:24:19.280079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_npfProd = np.einsum('mls,nls->mnls', Ws_npf, Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:19.549605Z",
     "start_time": "2019-09-12T19:24:19.547422Z"
    }
   },
   "outputs": [],
   "source": [
    "# only correct for random_w_OHf\n",
    "# Ws_npfReduc = random_w_OHf.shape[0] - np.einsum('mnls->mn', Ws_npfProd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:19.717603Z",
     "start_time": "2019-09-12T19:24:19.715265Z"
    }
   },
   "outputs": [],
   "source": [
    "# random_w_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:19.864635Z",
     "start_time": "2019-09-12T19:24:19.862603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_npfReduc[random_w_idx]\n",
    "# np.array_equal(Ws_npfReduc[random_w_idx], random_w_OHf.shape[0] - np.einsum('nls->n', random_w_OHf * Ws_npf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify these calculations to account for padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:20.565331Z",
     "start_time": "2019-09-12T19:24:20.552322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 6, 6, 6], dtype=int8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueLength(random_w_OHf)\n",
    "Ws_npf.shape\n",
    "Ws_npf_trueLengths = np.sum(Ws_npf, axis=2, dtype=my_dtype).sum(axis=1, dtype=my_dtype)\n",
    "Ws_npf_trueLengths.shape\n",
    "Ws_npf_trueLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:21.166117Z",
     "start_time": "2019-09-12T19:24:21.154104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 6734, 6735, 6736])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueLength_match = Ws_npf_trueLengths == trueLength(random_w_OHf); trueLength_match.nonzero()[0]\n",
    "trueLength_mismatch = Ws_npf_trueLengths != trueLength(random_w_OHf); trueLength_mismatch\n",
    "# Ws_npf_trueLengths[0], trueLength_mismatch[0]\n",
    "# Ws_npf_trueLengths[1], trueLength_mismatch[1]\n",
    "# Ws_npf_trueLengths[2], trueLength_mismatch[2]\n",
    "random_w_OHf_distance_mask = np.ones(Ws_npf_trueLengths.shape)\n",
    "np.putmask(random_w_OHf_distance_mask, trueLength_mismatch, length_mismatch_constant)\n",
    "random_w_OHf_distance_mask\n",
    "random_w_OHf_distance_mask[trueLength_match]\n",
    "# random_w_OHf_distance_mask[0]\n",
    "# random_w_OHf_distance_mask[1]\n",
    "# random_w_OHf_distance_mask[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:22.283097Z",
     "start_time": "2019-09-12T19:24:22.278087Z"
    }
   },
   "outputs": [],
   "source": [
    "def OHstack_to_trueLength_mask(paddedOHstack, trueLengths):\n",
    "    mask = np.ones(trueLengths.shape)\n",
    "    np.putmask(mask, trueLengths != trueLength(paddedOHstack), length_mismatch_constant)\n",
    "    return mask.astype(my_dtype)\n",
    "\n",
    "assert np.array_equal(random_w_OHf_distance_mask,\n",
    "                      OHstack_to_trueLength_mask(random_w_OHf, Ws_npf_trueLengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:24.770939Z",
     "start_time": "2019-09-12T19:24:24.603804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.ɑ.l.⋉.⋉'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 3., 3., 3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 3., 3., 3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 3., 3., 3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 3., 3., 3.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_idx = Ws_t.index(random_w)\n",
    "random_w_OHf = Ws_npf[random_w_idx]; random_w_OHf.shape\n",
    "Ws_npf.shape\n",
    "np.array(lmap(lambda w_OHf: d_h_np(random_w_OHf, w_OHf, True),\n",
    "              Ws_npf))\n",
    "\n",
    "(random_w_OHf.shape[0] - np.einsum('nls->n', random_w_OHf * Ws_npf)) * random_w_OHf_distance_mask\n",
    "(random_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', random_w_OHf, Ws_npf))) * random_w_OHf_distance_mask\n",
    "(random_w_OHf.shape[0] - np.einsum('nls->n', (random_w_OHf * Ws_sf).todense())) * random_w_OHf_distance_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:24.775657Z",
     "start_time": "2019-09-12T19:24:24.772256Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit -r 10 -n 10 np.array(lmap(lambda w_OHf: d_h_np(choice(Ws_npf), w_OHf), Ws_npf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:24.894921Z",
     "start_time": "2019-09-12T19:24:24.890479Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rand_w_OHf = choice(Ws_npf)\n",
    "    %timeit -r 10 -n 10 rand_w_OHf.shape[0] - np.einsum('nls->n', rand_w_OHf * Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:25.476015Z",
     "start_time": "2019-09-12T19:24:25.471365Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rand_w_OHf = choice(Ws_npf)\n",
    "    %timeit -r 10 -n 10 rand_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', rand_w_OHf, Ws_npf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:25.820562Z",
     "start_time": "2019-09-12T19:24:25.816187Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rand_w_OHf = choice(Ws_npf)\n",
    "    %timeit -r 10 -n 10 rand_w_OHf.shape[0] - np.einsum('nls->n', (rand_w_OHf * Ws_sf).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:26.208955Z",
     "start_time": "2019-09-12T19:24:26.147242Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_w_OHf = choice(Ws_npf)\n",
    "\n",
    "map_result = np.array(lmap(lambda w_OHf: d_h_np(rand_w_OHf, w_OHf),\n",
    "                           Ws_npf))\n",
    "\n",
    "einsum_hadamard_result = rand_w_OHf.shape[0] - np.einsum('nls->n', rand_w_OHf * Ws_npf)\n",
    "\n",
    "einsum_einsum_result = rand_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', rand_w_OHf, Ws_npf))\n",
    "\n",
    "einsum_hadamard_sparse_result = rand_w_OHf.shape[0] - np.einsum('nls->n', (rand_w_OHf * Ws_sf).todense())\n",
    "\n",
    "assert np.array_equal(map_result, einsum_hadamard_result)\n",
    "assert np.array_equal(map_result, einsum_einsum_result)\n",
    "assert np.array_equal(map_result, einsum_hadamard_sparse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:26.688680Z",
     "start_time": "2019-09-12T19:24:26.673153Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_h_np_string_to_strings(x_OHs, L_OHs, paddedOHs=False, L_OHs_trueLengths=None, use_GPU=False):\n",
    "    memTrigger()\n",
    "    if not use_GPU:\n",
    "        x_OHs = x_OHs.astype(my_dtype)\n",
    "        L_OHs = L_OHs.astype(my_dtype)\n",
    "        l = x_OHs.shape[0]\n",
    "        if not paddedOHs:\n",
    "            return l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)\n",
    "        else:\n",
    "            true_l = trueLength(x_OHs)\n",
    "            if L_OHs_trueLengths is None:\n",
    "                L_OHs_trueLengths = np.sum(L_OHs, axis=2, dtype=np.uint8).sum(axis=1, dtype=np.uint8)\n",
    "            trueLength_mask = OHstack_to_trueLength_mask(x_OHs, L_OHs_trueLengths)\n",
    "            return (true_l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)) * trueLength_mask\n",
    "    else:\n",
    "        if not paddedOHs:\n",
    "            l = x_OHs.shape[0]\n",
    "            x_OHs_t = x_OHs\n",
    "            L_OHs_t = L_OHs\n",
    "#             x_OHs_t = torch.from_numpy(x_OHs)#.type(torch.float16)\n",
    "#             L_OHs_t = torch.from_numpy(L_OHs)#.type(torch.float16)\n",
    "            return l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype)\n",
    "#             return l - torch.einsum('nls->n', x_OHs_t.type(torch.float16).cuda() * L_OHs_t.type(torch.float16).cuda())\n",
    "        else:\n",
    "            x_OHs_t = x_OHs\n",
    "            L_OHs_t = L_OHs\n",
    "#             true_l = torch.sum(x_OHs_t, dim=1).sum()\n",
    "            true_l = trueLength(x_OHs_t.numpy())\n",
    "#             true_l = trueLength(x_OHs_t)\n",
    "            if L_OHs_trueLengths is None:\n",
    "                L_OHs_trueLengths = np.sum(L_OHs.numpy(), axis=2, dtype=np.uint8).sum(axis=1, dtype=np.uint8)\n",
    "#                 L_OHs_trueLengths = torch.sum(L_OHs_t, dim=2, dtype=torch.int32).sum(dim=1, dtype=torch.int32)\n",
    "            trueLength_mask = OHstack_to_trueLength_mask(x_OHs_t.numpy(), L_OHs_trueLengths)\n",
    "#             trueLength_mask = torch.from_numpy(OHstack_to_trueLength_mask(x_OHs_t.numpy(), L_OHs_trueLengths.numpy()))\n",
    "#             trueLength_mask = OHstack_to_trueLength_mask(x_OHs_t, L_OHs_trueLengths)\n",
    "            return (true_l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype)) * trueLength_mask\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "# def d_h_np_string_to_strings(x_OHs, L_OHs, paddedOHs=False, L_OHs_trueLengths=None, use_GPU=False):\n",
    "# # def d_h_np_string_to_strings(x_OHs, L_OHs, paddedOHs=False, L_OHs_trueLengths=None, my_dtype=None):\n",
    "# #     if my_dtype is None:\n",
    "# #         my_dtype = np.uint8\n",
    "# #         my_dtype = np.int8\n",
    "#     x_OHs = x_OHs.astype(my_dtype)\n",
    "#     L_OHs = L_OHs.astype(my_dtype)\n",
    "#     l = x_OHs.shape[0]\n",
    "#     if not paddedOHs:\n",
    "#         if not use_GPU:\n",
    "#             return l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)\n",
    "#         else:\n",
    "#             x_OHs_t = torch.from_numpy(x_OHs)#.type(torch.float16)\n",
    "#             L_OHs_t = torch.from_numpy(L_OHs)#.type(torch.float16)\n",
    "#             return l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype)\n",
    "# #             return l - torch.einsum('nls->n', x_OHs_t.type(torch.float16).cuda() * L_OHs_t.type(torch.float16).cuda())\n",
    "# #             l_t\n",
    "# #             raise Exception('under construction')\n",
    "#     else:\n",
    "#         true_l = trueLength(x_OHs)\n",
    "#         if L_OHs_trueLengths is None:\n",
    "#             L_OHs_trueLengths = np.sum(L_OHs, axis=2, dtype=my_dtype).sum(axis=1, dtype=my_dtype)\n",
    "#         trueLength_mask = OHstack_to_trueLength_mask(x_OHs, L_OHs_trueLengths)\n",
    "#         if not use_GPU:\n",
    "#             return (true_l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)) * trueLength_mask\n",
    "#         else:\n",
    "# #             true_l_t = \n",
    "#             x_OHs_t = torch.from_numpy(x_OHs)#.type(torch.float16)\n",
    "#             L_OHs_t = torch.from_numpy(L_OHs)#.type(torch.float16)\n",
    "#             L_OHs_trueLengths_t = torch.from_numpy(L_OHs_trueLengths)#.type(torch.float16)\n",
    "#             trueLength_mask_t = torch.from_numpy(trueLength_mask)#.type(torch.float16)\n",
    "#             return (true_l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype))\n",
    "# #             raise Exception('under construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:27.186721Z",
     "start_time": "2019-09-12T19:24:27.172896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.t.aɪ.g.⋉.⋉'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_w_OHf.shape\n",
    "rand_w = OHsToDS(rand_w_OHf, OHXmap); rand_w\n",
    "\n",
    "d_h_np_string_to_strings(rand_w_OHf, Ws_npf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:27.931201Z",
     "start_time": "2019-09-12T19:24:27.926732Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    rand_w_dists = d_h_np_string_to_strings(rand_w_OHf, Ws_npf, True)\n",
    "\n",
    "    for i, each_OH in enumerate(Ws_npf):\n",
    "        if trueLength(each_OH) == trueLength(rand_w_OHf):\n",
    "            each_w = OHsToDS(each_OH, OHXmap)\n",
    "            assert d_h(rand_w, each_w) == rand_w_dists[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:28.418945Z",
     "start_time": "2019-09-12T19:24:28.415447Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np_string_to_strings(choice(Ws_npf), Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:28.909250Z",
     "start_time": "2019-09-12T19:24:28.905551Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np_string_to_strings(choice(Ws_npf), Ws_npf, True, Ws_npf_trueLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:29.291991Z",
     "start_time": "2019-09-12T19:24:29.288526Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np_string_to_strings(choice(Ws_npf), Ws_npf, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Fortunately, it looks like applying a mask to account for padding has a small cost provided you pre-calculate the true lengths of every padded vector in the stack of strings you are computing distances with respect to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming distance between every pair of strings in a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:30.411499Z",
     "start_time": "2019-09-12T19:24:30.409207Z"
    }
   },
   "outputs": [],
   "source": [
    "# map_result2 = np.array(lmap(lambda key_w_OHf: np.array(lmap(lambda w_OHf: d_h_np(key_w_OHf, w_OHf, True),\n",
    "#                                                             Ws_npf)),\n",
    "#                             Ws_npf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:30.853233Z",
     "start_time": "2019-09-12T19:24:30.849333Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    #≈4m cmu+wittgenstein\n",
    "    map_result3 = np.stack([d_h_np_string_to_strings(key_w_OHf, Ws_npf, True, Ws_npf_trueLengths)\n",
    "                            for key_w_OHf in tqdm(Ws_npf)])\n",
    "    map_result3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:31.748298Z",
     "start_time": "2019-09-12T19:24:31.744286Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    map_result3[random_w_idx]\n",
    "    (map_result3 != length_mismatch_constant).nonzero()\n",
    "    word_idx_pairs_w_finite_hamming_distance = lzip(*(map_result3 != length_mismatch_constant).nonzero())\n",
    "    choices(word_idx_pairs_w_finite_hamming_distance, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:32.246070Z",
     "start_time": "2019-09-12T19:24:32.241466Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for idx_u, idx_v in choices(word_idx_pairs_w_finite_hamming_distance, k=100):\n",
    "        print('------------------------')\n",
    "        pprint_aligned_DSs(align_DSs([OHsToDS(Ws_npf[idx_u], OHXmap), \n",
    "                                      OHsToDS(Ws_npf[idx_v], OHXmap)]))\n",
    "        map_result3[idx_u, idx_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:34.284203Z",
     "start_time": "2019-09-12T19:24:34.280605Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    assert np.array_equal(map_result3[random_w_idx], \n",
    "                          d_h_np_string_to_strings(random_w_OHf, Ws_npf, True))\n",
    "    del map_result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:35.227185Z",
     "start_time": "2019-09-12T19:24:35.202634Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_hadamard_product_block(row_indices, A, B):\n",
    "    return np.einsum('mls,nls->mnls', A[row_indices], B, dtype=my_dtype)\n",
    "# def construct_hadamard_product_block(A_slice, B_slice):\n",
    "#     return np.einsum('mls,nls->mnls', A_slice, B_slice)\n",
    "\n",
    "def calculate_block_sum(block):\n",
    "    return np.einsum('mnls->mn', block, dtype=my_dtype)\n",
    "\n",
    "def block_sum_op(row_indices, A, B, l):\n",
    "    memTrigger()\n",
    "    return l - calculate_block_sum(construct_hadamard_product_block(row_indices, A, B))\n",
    "\n",
    "def construct_hadamard_product_block_t(A_block, B, use_GPU=True):\n",
    "    return torch.einsum('mls,nls->mnls', A_block, B).type(my_cpu_type)\n",
    "#     return torch.einsum('mls,nls->mnls', A_block, B)#.type(my_cpu_type)\n",
    "\n",
    "def calculate_block_sum_t(block):\n",
    "#     print(f\"block.dtype = {block.dtype}\")\n",
    "#     print(f\"block.device = {block.device}\")\n",
    "#     block_sum = torch.einsum('mnls->mn', block).type(my_cpu_type)\n",
    "#     print(f\"block_sum.dtype = {block_sum.dtype}\")\n",
    "#     print(f\"block_sum.device = {block_sum.device}\")\n",
    "#     print('computed block_sum.')\n",
    "#     return block_sum\n",
    "    return torch.einsum('mnls->mn', block).type(my_cpu_type)\n",
    "#     return torch.einsum('mnls->mn', block)#.type(my_cpu_type)\n",
    "\n",
    "def block_sum_op_t(A_block, B, l, use_GPU=True):\n",
    "# def block_sum_op_t(row_indices, A, B, l, use_GPU=True):\n",
    "    memTrigger()\n",
    "    torch.cuda.empty_cache()\n",
    "#     print(f'row_indices.dtype = {row_indices.dtype}')\n",
    "#     print(f'A.dtype = {A.dtype}')\n",
    "#     print(f'B.dtype = {B.dtype}')\n",
    "#     print(f'l.dtype = {l.dtype}')\n",
    "\n",
    "#     A_c = A[row_indices].cuda()\n",
    "#     B_c = B.cuda()\n",
    "#     prodBlock = construct_hadamard_product_block_t(A_c, B_c)\n",
    "\n",
    "#     print(f\"prodBlock.dtype = {prodBlock.dtype}\")\n",
    "#     print(f\"prodBlock.device = {prodBlock.device}\")\n",
    "\n",
    "#     blockSum_c = calculate_block_sum_t(prodBlock)\n",
    "#     blockSum = blockSum_c.cpu()\n",
    "#     print(f\"blockSum.dtype = {blockSum.dtype}\")\n",
    "#     print(f\"l.dtype = {l.dtype}\")\n",
    "#     result = l - blockSum.type(my_cpu_type)\n",
    "    \n",
    "#     return result\n",
    "#     return l - (calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda())).cpu())\n",
    "#     return l - calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda())).cpu().type(my_cpu_type)\n",
    "#     return l - calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda())).cpu()\n",
    "#     return (l.cuda() - calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda()))).cpu()\n",
    "#     return (l.cuda() - calculate_block_sum_t(construct_hadamard_product_block_t(A_block.cuda(), B.cuda()))).cpu()\n",
    "    return l - (calculate_block_sum_t(construct_hadamard_product_block_t(A_block.cuda(), B.cuda()))).cpu()\n",
    "\n",
    "def H_d_np(L_OHs, paddedOHs=False, parallel=False, use_GPU=False, wec=False, wec_block_size=100):\n",
    "# def H_d_np(L_OHs, paddedOHs=False, parallel=False, my_dtype=None):\n",
    "#     if my_dtype is None:\n",
    "#         my_dtype = np.uint8\n",
    "#         my_dtype = np.int8\n",
    "    L_OHs = L_OHs.astype(my_dtype)\n",
    "    L_OHs_trueLengths = np.sum(L_OHs, axis=2, dtype=np.uint8).sum(axis=1, dtype=np.uint8)\n",
    "    if not parallel and not use_GPU:\n",
    "        if not wec:\n",
    "    #         return np.stack([d_h_np_string_to_strings(key_w_OHf, L_OHs, paddedOHs=paddedOHs, my_dtype=my_dtype)\n",
    "            return np.stack([d_h_np_string_to_strings(key_w_OHf, L_OHs, paddedOHs=paddedOHs, L_OHs_trueLengths=L_OHs_trueLengths).astype(my_dtype)\n",
    "                             for key_w_OHf in tqdm(L_OHs)]).astype(my_dtype)\n",
    "        else:\n",
    "            m = L_OHs_trueLengths.shape[0]\n",
    "            n = m\n",
    "            stampedNote('Start wec')\n",
    "            lengthTerm = np.einsum('m,mn->mn', L_OHs_trueLengths.astype(my_dtype), np.ones((m,n), dtype=my_dtype))\n",
    "            stampedNote(f'lengthTerm.nbytes / 1e9 = {lengthTerm.nbytes / 1e9}')\n",
    "            print(f'{lengthTerm.dtype}')\n",
    "            \n",
    "            block_length = wec_block_size\n",
    "            num_blocks = int(np.rint( m / block_length ))\n",
    "            block_onsets = [block_index * block_length \n",
    "                            for block_index in range(num_blocks)]\n",
    "            block_ends = block_onsets[1:] + [m]\n",
    "            block_startStop_pairs = tuple(zip(block_onsets, block_ends))\n",
    "            V = 1\n",
    "            P_d = np.concatenate(list(par(delayed(block_sum_op)(np.arange(block_start, block_end), L_OHs, L_OHs, lengthTerm[np.arange(block_start, block_end)])\n",
    "                                          for block_start, block_end in tqdm(block_startStop_pairs, \n",
    "                                                                             total=len(block_startStop_pairs)))))\n",
    "            V = 10\n",
    "            return P_d\n",
    "#             prodTerm = np.einsum('mij,nij->mnij', L_OHs, L_OHs) #memory error, naturally\n",
    "#             stampedNote(f'prodTerm.nbytes / 1e9 = {prodTerm.nbytes / 1e9}')\n",
    "#             print(f'{prodTerm.dtype}')\n",
    "            \n",
    "#             reducTerm = np.einsum('mnls->mn', prodTerm)\n",
    "#             del prodTerm\n",
    "#             stampedNote(f'reducTerm.nbytes / 1e9 = {reducTerm.nbytes / 1e9}')\n",
    "#             print(f'{reducTerm.dtype}')\n",
    "            \n",
    "#             result = lengthTerm - reducTerm\n",
    "#             del lengthTerm\n",
    "#             del reducTerm\n",
    "#             return result\n",
    "    elif parallel and not use_GPU:\n",
    "#         return np.stack(par(delayed(d_h_np_string_to_strings)(key_w_OHf, L_OHs, paddedOHs=paddedOHs, my_dtype=my_dtype)\n",
    "        return np.stack(par(delayed(d_h_np_string_to_strings)(key_w_OHf, L_OHs, paddedOHs=paddedOHs, L_OHs_trueLengths=L_OHs_trueLengths)\n",
    "                            for key_w_OHf in L_OHs)).astype(my_dtype)\n",
    "    else:\n",
    "        if not wec:\n",
    "            return np.stack([d_h_np_string_to_strings(torch.from_numpy(key_w_OHf), torch.from_numpy(L_OHs), paddedOHs=paddedOHs, L_OHs_trueLengths=torch.from_numpy(L_OHs_trueLengths), use_GPU=True)\n",
    "                             for key_w_OHf in tqdm(L_OHs)]).astype(my_dtype)\n",
    "        else:\n",
    "            torch.cuda.empty_cache()\n",
    "            m = L_OHs_trueLengths.shape[0]\n",
    "            n = m\n",
    "            stampedNote('Start wec')\n",
    "            lengthTerm = np.einsum('m,mn->mn', L_OHs_trueLengths.astype(my_dtype), np.ones((m,n), dtype=my_dtype))\n",
    "            stampedNote(f'lengthTerm.nbytes / 1e9 = {lengthTerm.nbytes / 1e9}')\n",
    "            print(f'{lengthTerm.dtype}')\n",
    "            lengthTerm = torch.from_numpy(lengthTerm)\n",
    "            \n",
    "            block_length = wec_block_size\n",
    "            num_blocks = int(np.rint( m / block_length ))\n",
    "            block_onsets = [block_index * block_length \n",
    "                            for block_index in range(num_blocks)]\n",
    "            block_ends = block_onsets[1:] + [m]\n",
    "            block_startStop_pairs = tuple(zip(block_onsets, block_ends))\n",
    "            blockRanges = tuple([torch.arange(block_start, block_end)\n",
    "                                 for block_start, block_end in block_startStop_pairs])\n",
    "            \n",
    "            L_OHs_t = torch.from_numpy(L_OHs)\n",
    "            \n",
    "#             P_d = np.concatenate([block_sum_op_t(torch.arange(block_start, block_end), L_OHs_t, L_OHs_t, lengthTerm[torch.arange(block_start, block_end)]).numpy()\n",
    "#                                   for block_start, block_end in tqdm(block_startStop_pairs, \n",
    "#                                                                      total=len(block_startStop_pairs))])\n",
    "            P_d = np.concatenate([block_sum_op_t(L_OHs_t[block_range], L_OHs_t, lengthTerm[block_range]).numpy()\n",
    "                                          for block_range in tqdm(blockRanges, \n",
    "                                                                  total=len(blockRanges))])\n",
    "            return P_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:35.983470Z",
     "start_time": "2019-09-12T19:24:35.854624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.1G        7.9G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:38.430640Z",
     "start_time": "2019-09-12T19:24:36.498392Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0114s.) Setting batch_size=34.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1387s.) Setting batch_size=98.\n",
      "[Parallel(n_jobs=-1)]: Done 642 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1220 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 6737 out of 6737 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6737)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.045387169"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ≈2.5m cmu+wittgenstein\n",
    "# 36s NXT_swbd+wittgenstein\n",
    "H_d_np_W = H_d_np(Ws_npf, paddedOHs=True, parallel=True)\n",
    "H_d_np_W.shape\n",
    "H_d_np_W.nbytes / 1e9\n",
    "H_d_np_W.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:40.229596Z",
     "start_time": "2019-09-12T19:24:40.098646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.2G        7.8G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:40.286407Z",
     "start_time": "2019-09-12T19:24:40.282298Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if g and testing:\n",
    "    # ≈2.5m cmu+wittgenstein\n",
    "    torch.cuda.empty_cache()\n",
    "    H_d_np_W_g = H_d_np(Ws_npf, paddedOHs=True, parallel=False, use_GPU=True)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:40.755289Z",
     "start_time": "2019-09-12T19:24:40.750807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 6, 41)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_npf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:41.288319Z",
     "start_time": "2019-09-12T19:24:41.158237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.2G        7.9G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:41.654397Z",
     "start_time": "2019-09-12T19:24:41.648500Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    # ≈0.5m NXT_swbd+wittgenstein, for block size 25 and memory overhead is ? (peak=?GB)\n",
    "    # ≈1.8m cmu+wittgenstein, for block size 100 and memory overhead is ENOROMOUS (peak=90-95GB)\n",
    "    # ≈1.7m cmu+wittgenstein, for block size 50 and memory overhead is tolerable (peak=45-50GB)\n",
    "    # ≈1.9m cmu+wittgenstein, for block size 25 and memory overhead is tolerable (peak=25-27GB)\n",
    "    H_d_np_W_wec = H_d_np(Ws_npf, paddedOHs=True, parallel=False, use_GPU=False, wec=True, wec_block_size=25)\n",
    "\n",
    "if g and testing:\n",
    "    # 28s NXT_swbd+wittgenstein, block size 10, peak GPU mem usage = 1.6GB\n",
    "    # ≈3m cmu+wittgenstein, for block size 5, peak GPU mem usage = 1.8GB \n",
    "    # ≈3.4m cmu+wittgenstein, for block size 20, peak GPU mem usage = 5.4GB \n",
    "    # ≈2.6m cmu+wittgenstein, for block size 10, peak GPU mem usage = 3.0GB \n",
    "    # ≈1m cmu+wittgenstein, for block size 10, peak GPU mem usage = 5.6GB \n",
    "    torch.cuda.empty_cache()\n",
    "    H_d_np_W_wec = H_d_np(Ws_npf, paddedOHs=True, parallel=False, use_GPU=True, wec=True, wec_block_size=10)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:42.342342Z",
     "start_time": "2019-09-12T19:24:42.211787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.2G        7.9G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:42.876944Z",
     "start_time": "2019-09-12T19:24:42.874587Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if testing:\n",
    "#     #using the multiprocessing backend ensures parallelization preserves order\n",
    "#     H_d_np_W_noPar = H_d_np(Ws_npf, paddedOHs=True, parallel=False)\n",
    "#     assert np.array_equal(H_d_np_W, H_d_np_W_noPar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:43.491620Z",
     "start_time": "2019-09-12T19:24:43.488983Z"
    }
   },
   "outputs": [],
   "source": [
    "# !free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:44.672137Z",
     "start_time": "2019-09-12T19:24:44.039307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 6, 41)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.00521028"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_npf = lexiconToFixedSizeOHs(Ps_t)\n",
    "Ps_npf.shape\n",
    "Ps_npf.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:44.805305Z",
     "start_time": "2019-09-12T19:24:44.673334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.2G        7.8G        105M        116G        123G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:45.534884Z",
     "start_time": "2019-09-12T19:24:45.527170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6737"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21180"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.10117685676351182"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "len(Ps_t)\n",
    "(len(Ws_t) * len(Ws_t)) / (len(Ps_t) * len(Ps_t))\n",
    "\n",
    "#wrong by about an order of magnitude for cmu?\n",
    "#est amount of memory required for H_d_np_P as a multiple of the memory required for H_d_np_W\n",
    "# 1 / ((len(Ws_t) * len(Ws_t)) / (len(Ps_t) * len(Ps_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:46.310967Z",
     "start_time": "2019-09-12T19:24:46.304827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045387169"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "123.32780456542969"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(H_d_np_W.nbytes / 1e9)\n",
    "\n",
    "#wrong by about an order of magnitude for cmu?\n",
    "#est amount of memory required for H_d_np_P in GB\n",
    "# H_d_np_P_est_space_GB = (H_d_np_W.nbytes / 1e9) * (1 / ((len(Ws_t) * len(Ws_t)) / (len(Ps_t) * len(Ps_t))))\n",
    "# H_d_np_P_est_space_GB\n",
    "\n",
    "\n",
    "memAvailable()\n",
    "# (H_d_np_W.nbytes / 1e9) / memTotal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:46.940913Z",
     "start_time": "2019-09-12T19:24:46.937290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:47.560364Z",
     "start_time": "2019-09-12T19:24:47.556648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_P.npy'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o + '_H_d_P' + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:24:48.099181Z",
     "start_time": "2019-09-12T19:24:48.096414Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:10.755333Z",
     "start_time": "2019-09-12T19:24:55.218578Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start wec @ 12:24:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1412 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengthTerm.nbytes / 1e9 = 0.4485924 @ 12:24:55\n",
      "int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "  0%|          | 1/1412 [00:00<14:21,  1.64it/s][Parallel(n_jobs=-1)]: Batch computation too fast (0.1084s.) Setting batch_size=2.\n",
      "  5%|▍         | 64/1412 [00:00<09:37,  2.34it/s][Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.2s\n",
      "  7%|▋         | 99/1412 [00:00<04:39,  4.70it/s][Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.4s\n",
      "  9%|▊         | 123/1412 [00:01<03:13,  6.65it/s][Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      " 10%|█         | 142/1412 [00:01<02:15,  9.34it/s][Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.6s\n",
      " 12%|█▏        | 170/1412 [00:01<01:35, 13.05it/s][Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.7s\n",
      " 16%|█▌        | 221/1412 [00:01<00:39, 29.79it/s][Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    1.3s\n",
      " 18%|█▊        | 250/1412 [00:02<00:24, 47.70it/s][Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    1.6s\n",
      " 21%|██        | 295/1412 [00:02<00:16, 66.54it/s][Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    2.1s\n",
      " 23%|██▎       | 323/1412 [00:02<00:12, 88.19it/s][Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.3s\n",
      " 25%|██▌       | 360/1412 [00:03<00:13, 77.14it/s][Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:    2.8s\n",
      " 29%|██▉       | 416/1412 [00:03<00:13, 74.66it/s] [Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    3.3s\n",
      " 33%|███▎      | 461/1412 [00:04<00:08, 107.98it/s][Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    3.7s\n",
      " 36%|███▌      | 506/1412 [00:04<00:09, 97.66it/s] [Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    4.1s\n",
      " 39%|███▉      | 554/1412 [00:05<00:10, 81.97it/s] [Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    4.7s\n",
      " 43%|████▎     | 601/1412 [00:05<00:08, 90.57it/s] [Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    5.2s\n",
      " 47%|████▋     | 658/1412 [00:06<00:07, 97.40it/s][Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:    5.7s\n",
      " 50%|████▉     | 704/1412 [00:06<00:08, 83.75it/s][Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:    6.3s\n",
      " 55%|█████▍    | 771/1412 [00:07<00:07, 90.83it/s] [Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:    7.0s\n",
      " 59%|█████▉    | 833/1412 [00:08<00:06, 87.72it/s] [Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:    7.5s\n",
      " 63%|██████▎   | 886/1412 [00:08<00:04, 106.84it/s][Parallel(n_jobs=-1)]: Done 770 tasks      | elapsed:    8.1s\n",
      " 67%|██████▋   | 952/1412 [00:09<00:04, 102.77it/s][Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:    8.7s\n",
      " 72%|███████▏  | 1022/1412 [00:09<00:03, 104.09it/s][Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:    9.4s\n",
      " 77%|███████▋  | 1088/1412 [00:10<00:03, 102.23it/s][Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:   10.1s\n",
      " 81%|████████  | 1140/1412 [00:11<00:03, 77.03it/s] [Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:   10.8s\n",
      " 86%|████████▌ | 1215/1412 [00:12<00:02, 80.27it/s][Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:   11.5s\n",
      " 92%|█████████▏| 1300/1412 [00:12<00:01, 99.37it/s][Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:   12.3s\n",
      " 97%|█████████▋| 1376/1412 [00:13<00:00, 84.63it/s][Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:   13.0s\n",
      "100%|██████████| 1412/1412 [00:13<00:00, 100.93it/s]\n",
      "[Parallel(n_jobs=-1)]: Done 1412 out of 1412 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4485924"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if true:\n",
    "if len(Ps_t) > 60000 and (memAvailable() < 160):\n",
    "# if H_d_np_P_est_space_GB > 100 or (memAvailable() - H_d_np_P_est_space_GB) < 5:\n",
    "    print('Constructing H_d_np_W via memory mapping *now*...')\n",
    "    \n",
    "    H_d_np_P_fp = o + '_H_d_P' + '.npy'\n",
    "    H_d_np_P = np.memmap(H_d_np_P_fp, dtype=my_dtype, mode='w+', shape=(len(Ps_t), len(Ps_t)))\n",
    "    if g:\n",
    "        H_d_np_P[:] = H_d_np(Ps_npf, paddedOHs=True, parallel=False, use_GPU=True)\n",
    "    else:\n",
    "        H_d_np_P[:] = H_d_np(Ps_npf, paddedOHs=True, parallel=True)\n",
    "        \n",
    "    H_d_P_md = {'W':{'from fp':p,\n",
    "                     'changes':'sorted',\n",
    "                     'size':len(Ws_t)},\n",
    "                     'P':{'from_fp':p,\n",
    "                          'changes':'extracted from W, sorted',\n",
    "                          'size':len(Ps_t)}}\n",
    "    exportMatrixMetadata(o + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         o + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         H_d_np_P,\n",
    "                         H_d_P_md,\n",
    "                         'Step 4b',\n",
    "                         'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                        {'Storage':'file is MEMORY MAPPED.'})\n",
    "        \n",
    "    alreadyMemoryMapped_H_d_p = True\n",
    "else:\n",
    "    alreadyMemoryMapped_H_d_p = False\n",
    "#     paddedOHs, parallel, use_GPU, wec, wec_block_size\n",
    "\n",
    "\n",
    "    #10.5m = 91.5cps NXT_swbd+wittgenstein, peak memory usage @ ?/54941 calcs ≈GB (baseline 25-27GB), peak GPU RAM usage 6.7GB\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, True, True, 15)\n",
    "\n",
    "    #≈35cps cmu+wittgenstein, peak memory usage @ ≈12940/129403 calcs ≈29.5GB (baseline 13GB), peak GPU RAM use 5.6GB\n",
    "    #8.83m = 103.6cps NXT_swbd+wittgenstein, peak memory usage @ ?/54941 calcs ≈GB (baseline 25-27GB), peak GPU RAM usage 2.7GB\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, True, True, 5)\n",
    "    \n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, True, True, 3) #≈33cps cmu+wittgenstein, peak memory usage @ 12942/129403 calcs ≈37.8GB (baseline 21GB), peak GPU RAM use 3.7GB\n",
    "\n",
    "\n",
    "    #5.5m = 166.5cps NXT_swbd+wittgenstein, peak memory usage ≈102GB, (baseline 34GB)\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 45)\n",
    "\n",
    "    #5.5m = 166.5cps NXT_swbd+wittgenstein, peak memory usage ≈73GB, (baseline 28-30GB)\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 25)\n",
    "\n",
    "    #4.5cps (67.5cps?) cmu+wittgenstein, peak memory usage @ 300/129403 calcs ≈98GB\n",
    "    #5.5m = 166.5cps NXT_swbd+wittgenstein, peak memory usage ≈56GB (baseline 28GB)\n",
    "    H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 15)\n",
    "\n",
    "    #6.6cps (66cps?) cmu+wittgenstein, peak memory usage @ 1246/129403 calcs ≈58GB\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 10) \n",
    "\n",
    "#     if g:\n",
    "#         #≈53 cps cmu+wittgenstein, peak memory usage @ ≈12940/129403 calcs ≈10.8GB (baseline 7GB), peak GPU RAM usage 1.7GB\n",
    "#         #7.13m = 128 cps NXT_swbd+wittgenstein, peak GPU RAM usage 1.1GB\n",
    "#         H_d_np_P = H_d_np(Ps_npf, True, False, True) \n",
    "#     else:\n",
    "#         #57 cps cmu+wittgenstein, w/ 129403 calcs to do for cmu\n",
    "#         #7.9m = 115.9 cps NXT_swbd+wittgenstein w/ 54941 calcs to do\n",
    "#         H_d_np_P = H_d_np(Ps_npf, True, True) \n",
    "    \n",
    "    H_d_np_P.shape\n",
    "    H_d_np_P.nbytes / 1e9\n",
    "    H_d_np_P.dtype\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:12.126829Z",
     "start_time": "2019-09-12T19:25:12.123204Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    (H_d_np_P == np.nan).nonzero() #should be empty\n",
    "    assert (H_d_np_P == np.nan).nonzero()[0].size == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:12.455130Z",
     "start_time": "2019-09-12T19:25:12.291182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        2.0G        7.0G        105M        116G        122G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-cousin calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions, motivation, and calculation sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $s$ be a finite-length string over $\\Sigma$ and let $L$ be a finite set of strings over $\\Sigma$.\n",
    "\n",
    "**k-sphere**: $s'$ is in the *exact* $k$-sphere of $s$ w.r.t. $L$ iff $s' \\in L \\land $ the Hamming distance of $s'$ from $s$ is *exactly* $k$.\n",
    "\n",
    "**k-cousin**: string $p$ is an *exact* $k$-cousin of segmental wordform $w$ wr.t. $L$ iff\n",
    " - $w \\in L$\n",
    " - $p \\in \\text{prefixes}(L)$\n",
    " - $\\exists p' \\in \\text{exact-}k\\text{-sphere}(p) \\cap \\text{prefixes}(w)$\n",
    " - i.e. if $w$, when trimmed to length $|p|$ to produce prefix $p'$ has exactly Hamming distance $k$ from $p$, then $p$ and $w$ are exactly $k$-cousins.\n",
    " - *NB:* if $|w| < p$, then $p$ and $w$ are $\\infty$-cousins, since the Hamming distance between the closest prefix $p' = w$ of $w$ and $p$ is $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**: Consider incremental word recognition:\n",
    " - for low $k$, the exact $k$-cousins of a prefix $p$ are complete wordforms that are more plausible full intended wordforms causing $p$ than higher exact $k$-cousins\n",
    " - for low $k$, the exact $k$-cousins of a wordform $w$ are prefixes that are more likely incremental misperceptions or misproductions of $w$ than higher $k$-cousins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculation sketch**:\n",
    " 1. Calculate the pairwise Hamming distances between all pairs of prefixes.\n",
    " 2. Given a mapping (calculated earlier) from every wordform (index) $w$ and length $l$ to the prefix (index) $p$ that results when $w$ is trimmed to length $l$, we can trivially calculate for every prefix-wordform pair $p', w'$ the exact $k$ s.t. $p'$ and $w$ are exact $k$-cousins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:15.084647Z",
     "start_time": "2019-09-12T19:25:15.080646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_d_np_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:15.453199Z",
     "start_time": "2019-09-12T19:25:15.451122Z"
    }
   },
   "outputs": [],
   "source": [
    "# P_idxs_of_Ws_t = np.array([w_idx_to_p_idx[w_idx] for w_idx in range(len(Ws_t))])\n",
    "# assert Ws_t == tuple([Ps_t[p_idx] for p_idx in P_idxs_of_Ws_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:15.784557Z",
     "start_time": "2019-09-12T19:25:15.773079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,     7,    10, ..., 21171, 21175, 21178])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_idxs_of_trimmed_Ws_t = lambda l: np.array([w_idx_to_l_to_p_idx.get((w_idx, l), None)\n",
    "                                             for w_idx in range(len(Ws_t))])\n",
    "P_idxs_of_trimmed_Ws_t(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:18.065787Z",
     "start_time": "2019-09-12T19:25:18.061190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cousin_function_np_shape = (len(Ps_t), len(Ws_t))\n",
    "k_cousin_function_np_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:18.631591Z",
     "start_time": "2019-09-12T19:25:18.626198Z"
    }
   },
   "outputs": [],
   "source": [
    "H_d_np_col_retrieval = lambda p_idx, p_idxs_or_Nones: np.array([H_d_np_P[p_idx, p_idx_prime]\n",
    "                                                                if p_idx_prime is not None else length_mismatch_constant\n",
    "                                                                for p_idx_prime in p_idxs_or_Nones])\n",
    "def H_d_np_col_retrieval_par(p_idx):\n",
    "    return np.array([H_d_np_P[p_idx, p_idx_prime]\n",
    "                     if p_idx_prime is not None else length_mismatch_constant\n",
    "                     for p_idx_prime in P_idxs_of_trimmed_Ws_t( len(ds2t(Ps_t[p_idx])) )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:27.170324Z",
     "start_time": "2019-09-12T19:25:19.395467Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0181s.) Setting batch_size=22.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1427s.) Setting batch_size=60.\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 812 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1230 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1952 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3212 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4472 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5852 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7232 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 8732 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 10232 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 11852 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 13472 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 15212 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 16952 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 21180 out of 21180 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.14268966"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#67s NXT_swbd+wittgenstein, w/ baseline memory usage 39GB, peak ≈45GB?\n",
    "k_cousin_function_np = np.stack(par(delayed(H_d_np_col_retrieval_par)(p_idx)\n",
    "                                    for p_idx in range(len(Ps_t)))).astype(my_dtype)\n",
    "\n",
    "#7.5m NXT_swbd + wittgenstein\n",
    "# k_cousin_function_np = np.stack([H_d_np_col_retrieval(p_idx, P_idxs_of_trimmed_Ws_t( len(ds2t(p)) ))\n",
    "#                                 for p_idx, p in tqdm(enumerate(Ps_t), total=len(Ps_t))]).astype(my_dtype)\n",
    "# k_cousin_function_np = np.stack([H_d_np_P[p_idx, P_idxs_of_trimmed_Ws_t( len(ds2t(p)) )]\n",
    "#                                 for p_idx, p in tqdm(enumerate(Ps_t), total=len(Ps_t))])\n",
    "k_cousin_function_np.shape\n",
    "k_cousin_function_np.nbytes / 1e9\n",
    "k_cousin_function_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:27.176833Z",
     "start_time": "2019-09-12T19:25:27.171621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.k.l'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_pref = choice(Ps_t)\n",
    "while rand_pref[-1] == rightEdge:\n",
    "    rand_pref = choice(Ps_t)\n",
    "rand_pref\n",
    "\n",
    "rand_pref_idx = Ps_t.index(rand_pref)\n",
    "rand_pref_idx\n",
    "\n",
    "rand_pref_l = len(ds2t(rand_pref))\n",
    "rand_pref_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:29.858726Z",
     "start_time": "2019-09-12T19:25:28.857875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6737/6737 [00:00<00:00, 6814.14it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_arr = []\n",
    "for w_idx in tqdm(range(len(Ws_t))):\n",
    "    w = Ws_t[w_idx]\n",
    "    w_l = len(ds2t(w))\n",
    "    if w_l >= rand_pref_l:\n",
    "        my_p_prime_t = ds2t(w)[:rand_pref_l]\n",
    "        my_p_prime = t2ds(my_p_prime_t)\n",
    "        my_p_prime_idx = Ps_t.index( my_p_prime )\n",
    "#         print(my_p_prime, my_p_prime_idx)\n",
    "        k_val = H_d_np_P[rand_pref_idx, my_p_prime_idx]\n",
    "    else:\n",
    "        k_val = length_mismatch_constant\n",
    "    check_arr.append(k_val)\n",
    "check_arr_np = np.array(check_arr)\n",
    "k_cousin_function_np[rand_pref_idx] == check_arr_np\n",
    "assert np.array_equal(k_cousin_function_np[rand_pref_idx], check_arr_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:30.423977Z",
     "start_time": "2019-09-12T19:26:30.342680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if testing:\n",
    "    rand_pref_5cousins = get_k_cousins(rand_pref, 5, Ws_t, Ps_t, exactlyK = True)\n",
    "    sorted(rand_pref_5cousins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:31.171288Z",
     "start_time": "2019-09-12T19:26:31.159039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=int8)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if testing:\n",
    "    (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0]\n",
    "\n",
    "    k_cousin_function_np[rand_pref_idx, \n",
    "                         (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0]  ]\n",
    "\n",
    "    lmap(lambda w_idx: Ws_t[w_idx], \n",
    "         (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0])\n",
    "\n",
    "    assert sorted(rand_pref_5cousins) == sorted(lmap(lambda w_idx: Ws_t[w_idx], \n",
    "                                                     (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:31.915680Z",
     "start_time": "2019-09-12T19:25:31.905623Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    num_checks = 1000\n",
    "\n",
    "    rand_prefs = []\n",
    "    while len(rand_prefs) < num_checks:\n",
    "        rand_pref = choice(Ps_t)\n",
    "        while rand_pref[-1] == rightEdge:\n",
    "            rand_pref = choice(Ps_t)\n",
    "        rand_prefs.append(rand_pref)\n",
    "\n",
    "    rand_pref_idxs = lmap(lambda p: Ps_t.index(p), \n",
    "                          rand_prefs)\n",
    "    rand_pref_ls = lmap(lambda p: len(ds2t(p)),\n",
    "                        rand_prefs)\n",
    "    rand_ks = [choice([1,2,3,4]) for each in rand_prefs]\n",
    "\n",
    "    for p, p_idx, p_l, k in tqdm(zip(rand_prefs, rand_pref_idxs, rand_pref_ls, rand_ks),\n",
    "                                 total=len(rand_prefs)):\n",
    "        #reference implementation\n",
    "        rand_pref_k_cousins_ref = sorted(get_k_cousins(p, k, Ws_t, Ps_t, exactlyK = True))\n",
    "\n",
    "        rand_pref_k_cousins = sorted(lmap(lambda w_idx: Ws_t[w_idx],\n",
    "                                          (k_cousin_function_np[p_idx] == k).nonzero()[0]))\n",
    "        assert rand_pref_k_cousins_ref == rand_pref_k_cousins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:32.193444Z",
     "start_time": "2019-09-12T19:25:32.186099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.k.l'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_cousins_of_pref(p, k):\n",
    "    p_idx = Ps_t.index(p)\n",
    "    return lmap(lambda w_idx: Ws_t[w_idx],\n",
    "                (k_cousin_function_np[p_idx] == k).nonzero()[0])\n",
    "\n",
    "rand_pref\n",
    "get_k_cousins_of_pref(rand_pref, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to export\n",
    " - the prefix-word relation\n",
    " - the Hamming distance matrix between all pairs of wordforms\n",
    " - the Hamming distance matrix between all pairs of prefixes\n",
    " - the $k$-cousin relation between all pairs of prefixes and wordforms\n",
    " \n",
    "plus associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:48.350033Z",
     "start_time": "2019-09-12T19:26:46.940203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_relation_np.shape\n",
    "len(Ws_t), len(Ps_t)\n",
    "\n",
    "np.save(o + '_prefix_relation' + '.npy', prefix_relation_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:49.918758Z",
     "start_time": "2019-09-12T19:26:49.867522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_prefix_relation.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_prefix_relation.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "prefix_relation_md = {'W':{'from fp':p,\n",
    "                           'changes':'sorted',\n",
    "                           'size':len(Ws_t)},\n",
    "                      'P':{'from_fp':p,\n",
    "                           'changes':'extracted from W, sorted',\n",
    "                           'size':len(Ps_t)}}\n",
    "exportMatrixMetadata(o + '_prefix_relation' + '.npy' + '_metadata.json',\n",
    "                     path.basename(o) + '_prefix_relation' + '.npy' + '_metadata.json',\n",
    "                     prefix_relation_np,\n",
    "                     prefix_relation_md,\n",
    "                     'Step 4b',\n",
    "                     'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:02.929699Z",
     "start_time": "2019-09-12T19:27:02.420858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 6737)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6737)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_d_np_W.shape\n",
    "len(Ws_t), len(Ws_t)\n",
    "\n",
    "np.save(o + '_H_d_W' + '.npy', H_d_np_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:03.428908Z",
     "start_time": "2019-09-12T19:27:03.422679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_W.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_W.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "H_d_W_md = {'W':{'from fp':p,\n",
    "                 'changes':'sorted',\n",
    "                 'size':len(Ws_t)}}\n",
    "exportMatrixMetadata(o + '_H_d_W' + '.npy' + '_metadata.json',\n",
    "                     path.basename(o) + '_H_d_W' + '.npy' + '_metadata.json',\n",
    "                     H_d_np_W,\n",
    "                     H_d_W_md,\n",
    "                     'Step 4b',\n",
    "                     'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:08.244902Z",
     "start_time": "2019-09-12T19:27:04.404118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_P.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_P.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "H_d_np_P.shape\n",
    "len(Ps_t), len(Ps_t)\n",
    "\n",
    "if not alreadyMemoryMapped_H_d_p:\n",
    "    H_d_np_P_mm = np.memmap(o + '_H_d_P' + '.npy', dtype=my_dtype, mode='w+', shape=(len(Ps_t), len(Ps_t)))\n",
    "    H_d_np_P_mm[:] = H_d_np_P\n",
    "#     np.save(path.join(o, o + '_H_d_P' + '.npy'), H_d_np_P)\n",
    "    \n",
    "    H_d_P_md = {'W':{'from fp':p,\n",
    "                     'changes':'sorted',\n",
    "                     'size':len(Ws_t)},\n",
    "                     'P':{'from_fp':p,\n",
    "                          'changes':'extracted from W, sorted',\n",
    "                          'size':len(Ps_t)}}\n",
    "    exportMatrixMetadata(o + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         path.basename(o) + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         H_d_np_P,\n",
    "                         H_d_P_md,\n",
    "                         'Step 4b',\n",
    "                         'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                        {'Storage':'file is MEMORY MAPPED.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:09.545729Z",
     "start_time": "2019-09-12T19:27:08.246317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cousin_function_np.shape\n",
    "len(Ps_t), len(Ws_t)\n",
    "\n",
    "np.save(o + '_k_cousin_function' + '.npy', k_cousin_function_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:09.552193Z",
     "start_time": "2019-09-12T19:27:09.547198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_k_cousin_function.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_k_cousin_function.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "k_cousin_function_md = {'P':{'from_fp':p,\n",
    "                             'changes':'extracted from W, sorted',\n",
    "                             'size':len(Ps_t)},\n",
    "                        'W':{'from fp':p,\n",
    "                             'changes':'sorted',\n",
    "                             'size':len(Ws_t)}}\n",
    "exportMatrixMetadata(o + '_k_cousin_function' + '.npy' + '_metadata.json',\n",
    "                     path.basename(o) + '_k_cousin_function' + '.npy' + '_metadata.json',\n",
    "                     k_cousin_function_np,\n",
    "                     k_cousin_function_md,\n",
    "                     'Step 4b',\n",
    "                     'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                    {})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
