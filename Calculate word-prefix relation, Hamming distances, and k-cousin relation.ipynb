{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:11.996330Z",
     "start_time": "2019-11-01T20:05:11.989411Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Use\" data-toc-modified-id=\"Use-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Use</a></span></li><li><span><a href=\"#Import-libraries-and-data\" data-toc-modified-id=\"Import-libraries-and-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import libraries and data</a></span></li><li><span><a href=\"#Basic-representations---words-and-prefixes\" data-toc-modified-id=\"Basic-representations---words-and-prefixes-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Basic representations - words and prefixes</a></span></li><li><span><a href=\"#Basic-vectorized-representations\" data-toc-modified-id=\"Basic-vectorized-representations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Basic vectorized representations</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-hot-representations\" data-toc-modified-id=\"One-hot-representations-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>One-hot representations</a></span></li><li><span><a href=\"#Padding-and-trimming-to-create-a-fixed-size-representation\" data-toc-modified-id=\"Padding-and-trimming-to-create-a-fixed-size-representation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Padding and trimming to create a fixed-size representation</a></span></li></ul></li><li><span><a href=\"#Prefixes\" data-toc-modified-id=\"Prefixes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Prefixes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generating-prefixes\" data-toc-modified-id=\"Generating-prefixes-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Generating prefixes</a></span></li><li><span><a href=\"#Generating-padded/trimmed-prefixes\" data-toc-modified-id=\"Generating-padded/trimmed-prefixes-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Generating padded/trimmed prefixes</a></span></li><li><span><a href=\"#Detecting-whether-p-is-a-prefix-of-w\" data-toc-modified-id=\"Detecting-whether-p-is-a-prefix-of-w-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Detecting whether <code>p</code> is a prefix of <code>w</code></a></span></li><li><span><a href=\"#Generating-a-prefix-word-relation\" data-toc-modified-id=\"Generating-a-prefix-word-relation-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Generating a <code>prefix-word</code> relation</a></span></li><li><span><a href=\"#The-(p,w,l)-relation-where-w-trimmed-to-l-is-p\" data-toc-modified-id=\"The-(p,w,l)-relation-where-w-trimmed-to-l-is-p-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>The <code>(p,w,l)</code> relation where <code>w</code> trimmed to <code>l</code> is <code>p</code></a></span></li></ul></li><li><span><a href=\"#Hamming-distance\" data-toc-modified-id=\"Hamming-distance-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Hamming distance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distance-between-symbol-vectors\" data-toc-modified-id=\"Distance-between-symbol-vectors-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Distance between symbol vectors</a></span></li><li><span><a href=\"#Hamming-distance-between-stacks-of-symbol-vectors-(strings)\" data-toc-modified-id=\"Hamming-distance-between-stacks-of-symbol-vectors-(strings)-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Hamming distance between stacks of symbol vectors (strings)</a></span></li><li><span><a href=\"#Distance-between-a-string-and-a-stack-of-strings\" data-toc-modified-id=\"Distance-between-a-string-and-a-stack-of-strings-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Distance between a string and a stack of strings</a></span></li><li><span><a href=\"#Hamming-distance-between-every-pair-of-strings-in-a-stack\" data-toc-modified-id=\"Hamming-distance-between-every-pair-of-strings-in-a-stack-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Hamming distance between every pair of strings in a stack</a></span></li></ul></li><li><span><a href=\"#$k$-cousin-calculation\" data-toc-modified-id=\"$k$-cousin-calculation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>$k$-cousin calculation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Definitions,-motivation,-and-calculation-sketch\" data-toc-modified-id=\"Definitions,-motivation,-and-calculation-sketch-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Definitions, motivation, and calculation sketch</a></span></li></ul></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a finite set of strings (wordforms) $L$, we may want to efficiently calculate for subsequent use\n",
    " - the natural relation between the set of prefixes $P$ (of $L$) and $L$ indicating which prefixes are prefixes of a given string $s \\in L$ and which strings $s \\in L$ have a given $p \\in P$ as a prefix\n",
    " - the matrix of Hamming distances between all pairs of strings (full wordforms) in $L$\n",
    " - the matrix of Hamming distances between all pairs of prefixes of strings in $L$\n",
    " - the \"$k$-cousin\" function/relation between strings in $L$ and prefixes of strings of $L$. (See the $k$-cousin calculation section header for more of an explanation.)\n",
    "\n",
    "This notebook documents vectorized and otherwise parallelized code for such calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given \n",
    " - a filepath $p$ to *either*\n",
    "    - a conditional distribution on segmental wordforms given an orthographic wordform $p(W|V)$\n",
    "    - an unconditioned distribution on segmental wordforms $p(W)$\n",
    " - an output filepath prefix $o$\n",
    " \n",
    "this notebook calculates and writes to file \n",
    " - what the prefix relation of $W$ is\n",
    " - what the Hamming distance between all pairs of wordforms in $W$ is\n",
    "   - **NB:** for storage and time complexity reasons, $-1$ is used instead of $\\infty$ to represent distance between strings of differing length. ($\\infty$ requires floats, where everything else here is nicely represented using (u)int8 types; the same note applies to the other two output matrices representing Hamming distance information.) \n",
    " - what the Hamming distance between all pairs of prefixes of $W$ is\n",
    " - what the $k$-cousin relation/function between all prefixes of $W$ and $W$ is\n",
    "   - **NB:** the matrix describing this is memory-mapped, unlike the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.113728Z",
     "start_time": "2019-11-01T20:05:12.004854Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import getcwd, chdir, listdir, path, mkdir, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.821357Z",
     "start_time": "2019-11-01T20:05:12.118146Z"
    }
   },
   "outputs": [],
   "source": [
    "from boilerplate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.833209Z",
     "start_time": "2019-11-01T20:05:12.827396Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.855083Z",
     "start_time": "2019-11-01T20:05:12.837284Z"
    }
   },
   "outputs": [],
   "source": [
    "# import editdistance as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.867099Z",
     "start_time": "2019-11-01T20:05:12.858398Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "p = ''\n",
    "# p = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_trim.pW_V.json'\n",
    "# p = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "# p = 'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_pX0X1X2.json'\n",
    "\n",
    "o = ''\n",
    "# o = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_CMU_destressed_aligned_w_GD_AmE_destressed/LTR_CMU_destressed_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered'\n",
    "# o = 'LTR_NXT_swbd_destressed_aligned_w_GD_AmE_destressed/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_trim'\n",
    "# o = 'CM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2'\n",
    "\n",
    "g = ''\n",
    "# g = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.891431Z",
     "start_time": "2019-11-01T20:05:12.870473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if g == '' or g == 'True' or g == True:\n",
    "    g = True\n",
    "elif g == 'False' or g == False:\n",
    "    g = False\n",
    "else:\n",
    "    raise Exception(f\"g must be one of {'', 'True', 'False'}, got {g} instead.\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.907717Z",
     "start_time": "2019-11-01T20:05:12.893364Z"
    }
   },
   "outputs": [],
   "source": [
    "from probdist import *\n",
    "from string_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:12.952165Z",
     "start_time": "2019-11-01T20:05:12.912051Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "J = -1\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def par(gen_expr):\n",
    "    return Parallel(n_jobs=J, backend=BACKEND, verbose=V, prefer=PREFER)(gen_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:15.116637Z",
     "start_time": "2019-11-01T20:05:12.955280Z"
    }
   },
   "outputs": [],
   "source": [
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:15.248635Z",
     "start_time": "2019-11-01T20:05:15.119967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.3G        182G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:15.343851Z",
     "start_time": "2019-11-01T20:05:15.254233Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'pW_V' in p:\n",
    "    pW_V = condDistsAsProbDists(importProbDist(p))\n",
    "elif 'pX0X1X2' in p:\n",
    "    pW = ProbDist(importProbDist(p))\n",
    "else:\n",
    "    raise Exception(f\"Unknown type of 'p' parameter = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:15.468956Z",
     "start_time": "2019-11-01T20:05:15.346817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.3G        182G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:15.480951Z",
     "start_time": "2019-11-01T20:05:15.474341Z"
    }
   },
   "outputs": [],
   "source": [
    "testing = False\n",
    "benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:15.489543Z",
     "start_time": "2019-11-01T20:05:15.485591Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dtype = np.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:16.442975Z",
     "start_time": "2019-11-01T20:05:15.491908Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:16.461784Z",
     "start_time": "2019-11-01T20:05:16.446117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "#     if g and l:\n",
    "#         print(\"Disabling 'parallelize' flag...\")\n",
    "#         l = False\n",
    "#     import cupy\n",
    "    \n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    total_mem_MB = torch.cuda.get_device_properties(device).total_memory / 1e6\n",
    "    print('Total Memory: {0}'.format(total_mem_MB) )\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(torch.cuda.get_device_name(1))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(1)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_cached(1)/1024**3,1), 'GB')\n",
    "elif g:\n",
    "    print(\"g set to 'True', but torch cannot find a GPU. Setting g to 'False'.\")\n",
    "    g = False\n",
    "else:\n",
    "    pass\n",
    "#     raise Exception(f\"g set to 'True' but torch cannot find a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:16.469210Z",
     "start_time": "2019-11-01T20:05:16.464638Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "my_device = cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:16.478181Z",
     "start_time": "2019-11-01T20:05:16.471871Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda_ft = torch.cuda.FloatTensor\n",
    "cuda_dt = torch.cuda.DoubleTensor\n",
    "\n",
    "ft = torch.FloatTensor\n",
    "dt = torch.DoubleTensor\n",
    "\n",
    "my_ft = ft\n",
    "my_dt = dt\n",
    "\n",
    "my_type = my_ft\n",
    "# my_type = my_dt\n",
    "\n",
    "torch.set_default_tensor_type(my_type)\n",
    "\n",
    "my_cpu_type = torch.int8\n",
    "my_cuda_type = torch.float16\n",
    "# my_tt = torch.float32\n",
    "# my_tt = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic representations - words and prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are reference objects we will work with and use to check vectorized calculations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:17.131327Z",
     "start_time": "2019-11-01T20:05:16.480841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6404"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'pW_V' in p:\n",
    "    # Vs = set(pW_V.keys())\n",
    "    Ws = union(mapValues(lambda dist: set(conditions(dist)), \n",
    "                         pW_V).values())\n",
    "elif 'pX0X1X2' in p:\n",
    "    Ws = set(conditions(pW))\n",
    "else:\n",
    "    raise Exception(f\"Unknown type of 'p' parameter = {p}\")\n",
    "\n",
    "# len(Vs)\n",
    "len(Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:17.142976Z",
     "start_time": "2019-11-01T20:05:17.134426Z"
    }
   },
   "outputs": [],
   "source": [
    "Ws_t = tuple(sorted(list(Ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:20.963290Z",
     "start_time": "2019-11-01T20:05:17.145452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0094s.) Setting batch_size=42.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0427s.) Setting batch_size=392.\n",
      "[Parallel(n_jobs=-1)]: Done 6404 out of 6404 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27882"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#≈200s on CMU on solomonoff\n",
    "Ps = union(list(par(delayed(getPrefixes)(w) for w in Ws)))\n",
    "# Ps = union(par(delayed(getPrefixes)(w) for w in Ws))\n",
    "# Ps = union([getPrefixes(w) for w in Ws])\n",
    "Ps_t = tuple(sorted(list(Ps)))\n",
    "len(Ps_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic vectorized representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to work with \n",
    " 1. one-hot vector-based representations of strings\n",
    " 2. fixed-dimension representations of strings\n",
    "\n",
    "To support #2, we will want to pad or trim (i.e. de-suffix = remove material corresponding to the right edge of the string) one-hot representations of string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:20.976895Z",
     "start_time": "2019-11-01T20:05:20.967099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_uint8(arr):\n",
    "    return arr.astype(np.uint8)\n",
    "\n",
    "np.ones(3).dtype\n",
    "to_uint8(np.ones(3)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.070927Z",
     "start_time": "2019-11-01T20:05:20.985706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([18,  9,  6, 12], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = lexiconToInventory(Ws)\n",
    "len(Xs)\n",
    "\n",
    "Xmap = seqsToIndexMap(Xs)\n",
    "XOHmap = seqsToOneHotMap(Xs)\n",
    "# XOHmap = mapValues(to_uint8, seqsToOneHotMap(Xs))\n",
    "\n",
    "def dsToUniphoneIndices(ds, uniphoneToIndexMap):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    return np.array([uniphoneToIndexMap[uniphone] for uniphone in uniphoneSeq], dtype=np.uint8)\n",
    "\n",
    "def dsToUniphoneOHs(ds, uniphoneToOHmap):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    return np.array([uniphoneToOHmap[uniphone] for uniphone in uniphoneSeq], dtype=np.uint8)\n",
    "\n",
    "dsToUniphoneIndices('t.i.f.l', Xmap)\n",
    "dsToUniphoneOHs('t.i.f.l', XOHmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.086792Z",
     "start_time": "2019-11-01T20:05:21.075408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t.i.f.l'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHXmap = oneHotToSeqMap(Xs)\n",
    "\n",
    "def OHsToDS(OHs, OHtoUniphoneMap):\n",
    "    return t2ds([OHtoUniphoneMap(OH)\n",
    "                 for OH in OHs if OH.sum() > 0])\n",
    "\n",
    "#should give us back what we put in\n",
    "OHsToDS(dsToUniphoneOHs('t.i.f.l', XOHmap),\n",
    "        OHXmap)\n",
    "\n",
    "#should yield the empty string\n",
    "OHsToDS(np.array([0]), OHXmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.096305Z",
     "start_time": "2019-11-01T20:05:21.089268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w = choice(Ws_t); random_w\n",
    "len(ds2t(random_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.105931Z",
     "start_time": "2019-11-01T20:05:21.098605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39,  6, 27, 11, 17,  8, 15, 12, 38, 38], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsToUniphoneIndices(random_w, Xmap)\n",
    "random_w_OH = dsToUniphoneOHs(random_w, XOHmap)\n",
    "random_w_OH.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and trimming to create a fixed-size representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The padding one-hot vector is **the zero vector**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.123058Z",
     "start_time": "2019-11-01T20:05:21.108177Z"
    }
   },
   "outputs": [],
   "source": [
    "def padWord(w_OHs, goal_length):\n",
    "    l = w_OHs.shape[0]\n",
    "    if l > goal_length:\n",
    "        raise Exception(f\"word length = {l} > goal length = {goal_length}\")\n",
    "    if l == goal_length:\n",
    "        return w_OHs\n",
    "    return np.pad(w_OHs,\n",
    "                  ((0, goal_length - l), (0,0)),\n",
    "                  mode='constant',\n",
    "                  constant_values=0)\n",
    "\n",
    "\n",
    "def trimWord(w_OHs, goal_length):\n",
    "    l = w_OHs.shape[0]\n",
    "    if l < goal_length:\n",
    "        raise Exception(f\"word length = {l} < goal length = {goal_length}\")\n",
    "    if l == goal_length:\n",
    "        return w_OHs\n",
    "    return w_OHs[:goal_length]\n",
    "\n",
    "\n",
    "def adjustWord(w_OHs, goal_length):\n",
    "    l = w_OHs.shape[0]\n",
    "    if l == goal_length:\n",
    "        return w_OHs\n",
    "    elif l < goal_length:\n",
    "        return padWord(w_OHs, goal_length)\n",
    "    else:\n",
    "        return trimWord(w_OHs, goal_length)\n",
    "\n",
    "    \n",
    "def lexiconToFixedSizeOHs(Ws, fixed_size = None):\n",
    "    maxL = max({len(ds2t(w)) for w in Ws})\n",
    "    if fixed_size is None:\n",
    "        fixed_size = maxL    \n",
    "    \n",
    "    Ws_OH = (dsToUniphoneOHs(w, XOHmap) for w in Ws)\n",
    "    Ws_OH_adjusted = np.array([adjustWord(w_OH, fixed_size) for w_OH in Ws_OH])\n",
    "    return Ws_OH_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.134547Z",
     "start_time": "2019-11-01T20:05:21.125735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w_OH\n",
    "random_w_OH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.146325Z",
     "start_time": "2019-11-01T20:05:21.136947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padWord(random_w_OH, random_w_OH.shape[0] + 1)\n",
    "assert np.array_equal(padWord(random_w_OH, random_w_OH.shape[0] + 1), \n",
    "                      adjustWord(random_w_OH, random_w_OH.shape[0] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.156925Z",
     "start_time": "2019-11-01T20:05:21.148762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimWord(random_w_OH, random_w_OH.shape[0] - 1)\n",
    "assert np.array_equal(trimWord(random_w_OH, random_w_OH.shape[0] - 1), \n",
    "                      adjustWord(random_w_OH, random_w_OH.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.928209Z",
     "start_time": "2019-11-01T20:05:21.159161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.1232"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0051232"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_npf = lexiconToFixedSizeOHs(Ws_t)\n",
    "Ws_npf.dtype\n",
    "Ws_npf.shape #:: (|Ws|, maxL, |Xs|) = (n, L_bar, s)\n",
    "Ws_npf.nbytes / 1e6\n",
    "Ws_npf.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:21.988486Z",
     "start_time": "2019-11-01T20:05:21.931324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.395975"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.010899242660836977"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_sf = sparse.COO.from_numpy(Ws_npf)\n",
    "Ws_sf.dtype\n",
    "Ws_sf.shape\n",
    "Ws_sf.nbytes / 1e6\n",
    "Ws_sf.density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to detect and/or undo padding/trimming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.002469Z",
     "start_time": "2019-11-01T20:05:21.992198Z"
    }
   },
   "outputs": [],
   "source": [
    "#Recall: a padded OH matrix will have at least one row that is a zero vector\n",
    "def isPaddedOHstack(p_OH):\n",
    "    return not np.product( np.sum(p_OH, axis=1) )\n",
    "\n",
    "def unpad(padded_p_OH):\n",
    "#     if not isPaddedOHstack(p_OH):\n",
    "#         return padded_p_OH\n",
    "    rowIsUnPadded = np.sum(padded_p_OH, axis=1)\n",
    "    isPadded = not np.product(rowIsUnPadded)\n",
    "    if not isPadded:\n",
    "        return padded_p_OH\n",
    "    nonPaddingRows = np.array([padded_p_OH_row \n",
    "                               for i, padded_p_OH_row in enumerate(padded_p_OH) \n",
    "                               if rowIsUnPadded[i]])\n",
    "    return nonPaddingRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.018773Z",
     "start_time": "2019-11-01T20:05:22.004958Z"
    }
   },
   "outputs": [],
   "source": [
    "def containsAnyPaddedOHstacks(L_OHs):\n",
    "    return any(map(isPaddedOHstack, L_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.031304Z",
     "start_time": "2019-11-01T20:05:22.023309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containsAnyPaddedOHstacks(Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.061669Z",
     "start_time": "2019-11-01T20:05:22.034401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11, 40)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = Ws_t[0]; w0\n",
    "w0_l = len(ds2t(Ws_t[0])); w0_l\n",
    "\n",
    "# random_w_OH = dsToUniphoneOHs(random_w, XOHmap)\n",
    "unpadded_w0_OH_rep = dsToUniphoneOHs(w0, XOHmap); unpadded_w0_OH_rep.shape\n",
    "OHsToDS(unpadded_w0_OH_rep, OHXmap)\n",
    "assert not isPaddedOHstack(unpadded_w0_OH_rep)\n",
    "\n",
    "padded_w0_OH_rep = Ws_npf[0]; padded_w0_OH_rep.shape\n",
    "OHsToDS(padded_w0_OH_rep, OHXmap)\n",
    "assert isPaddedOHstack(padded_w0_OH_rep) or not containsAnyPaddedOHstacks(Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.072605Z",
     "start_time": "2019-11-01T20:05:22.063927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_w0_OH_rep.shape\n",
    "padded_w0_OH_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.082704Z",
     "start_time": "2019-11-01T20:05:22.075117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=uint64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(padded_w0_OH_rep, axis=1)\n",
    "np.sum(padded_w0_OH_rep, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.095152Z",
     "start_time": "2019-11-01T20:05:22.085498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trueLength(possibly_padded_OHs):\n",
    "    return np.sum(possibly_padded_OHs, axis=1).sum()\n",
    "\n",
    "def unpaddedMask(possibly_padded_OHs):\n",
    "    return np.sum(possibly_padded_OHs, axis=1)\n",
    "\n",
    "trueLength(padded_w0_OH_rep)\n",
    "assert trueLength(padded_w0_OH_rep) == unpadded_w0_OH_rep.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.108025Z",
     "start_time": "2019-11-01T20:05:22.097305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_OH\n",
    "a_prefix_of_random_w_OH = random_w_OH[:-3] # <- that's a prefix\n",
    "a_prefix_of_random_w = OHsToDS(a_prefix_of_random_w_OH, OHXmap)\n",
    "a_prefix_of_random_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.121975Z",
     "start_time": "2019-11-01T20:05:22.110151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2, 40)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(random_w))\n",
    "random_w_OH.shape\n",
    "random_w_OH[:2].shape\n",
    "random_w_OH[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.138033Z",
     "start_time": "2019-11-01T20:05:22.124215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(10, 40),\n",
       " (9, 40),\n",
       " (8, 40),\n",
       " (7, 40),\n",
       " (6, 40),\n",
       " (5, 40),\n",
       " (4, 40),\n",
       " (3, 40),\n",
       " (2, 40),\n",
       " (1, 40)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPrefixes_OH(w_OH):\n",
    "    return [w_OH] + [w_OH[:-i] for i in range(1,len(w_OH))]\n",
    "\n",
    "random_w_OH.shape\n",
    "lmap(lambda m: m.shape, getPrefixes_OH(random_w_OH))\n",
    "lmap(lambda m: np.array_equal(m, random_w_OH), getPrefixes_OH(random_w_OH)) #< only the leftmost value should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.160550Z",
     "start_time": "2019-11-01T20:05:22.140372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengths = {len(ds2t(w)) for w in Ws}\n",
    "wordlengths\n",
    "wordlengths = tuple(range(min(wordlengths), max(wordlengths)+1))\n",
    "wordlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.187955Z",
     "start_time": "2019-11-01T20:05:22.162886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w_OH.shape\n",
    "max(wordlengths)\n",
    "diff = max(wordlengths) - random_w_OH.shape[0]; diff\n",
    "\n",
    "random_w_OH_padded = np.pad(random_w_OH, \n",
    "                            ((0, max(wordlengths) - random_w_OH.shape[0]), (0,0)), \n",
    "                            mode='constant', \n",
    "                            constant_values=0.0)\n",
    "random_w_OH_padded.shape\n",
    "assert np.array_equal(random_w_OH_padded[:random_w_OH.shape[0]],\n",
    "                      random_w_OH)\n",
    "random_w_OH_padded[random_w_OH.shape[0]:].shape\n",
    "assert np.array_equal(random_w_OH_padded[random_w_OH.shape[0]:], \n",
    "                      np.zeros((diff, random_w_OH.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating padded/trimmed prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's incorporate padding and trimming..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.196798Z",
     "start_time": "2019-11-01T20:05:22.190710Z"
    }
   },
   "outputs": [],
   "source": [
    "def getPrefixes_OH(w_OH, padded_length=None):\n",
    "    unpadded = [w_OH] + [w_OH[:-i] for i in range(1,len(w_OH))]\n",
    "    if padded_length is None:\n",
    "        return unpadded\n",
    "    return list(map(lambda p_OH: padWord(p_OH, padded_length), unpadded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.220924Z",
     "start_time": "2019-11-01T20:05:22.199128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(10, 40),\n",
       " (9, 40),\n",
       " (8, 40),\n",
       " (7, 40),\n",
       " (6, 40),\n",
       " (5, 40),\n",
       " (4, 40),\n",
       " (3, 40),\n",
       " (2, 40),\n",
       " (1, 40)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40),\n",
       " (20, 40)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_OH.shape\n",
    "list(map(lambda m: m.shape, getPrefixes_OH(random_w_OH)))\n",
    "list(map(lambda m: np.array_equal(m, random_w_OH), getPrefixes_OH(random_w_OH)))  #< only the leftmost value should be True\n",
    "list(map(lambda m: m.shape, getPrefixes_OH(random_w_OH, max(wordlengths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.232701Z",
     "start_time": "2019-11-01T20:05:22.223120Z"
    }
   },
   "outputs": [],
   "source": [
    "padded_prefixes_random_w_OH = getPrefixes_OH(random_w_OH, max(wordlengths))\n",
    "\n",
    "padded_prefixes_random_w_OH2 = lmap(partial(adjustWord, goal_length=max(wordlengths)), \n",
    "                                    getPrefixes_OH(random_w_OH))\n",
    "\n",
    "# type(padded_prefixes_random_w_OH)\n",
    "# type(padded_prefixes_random_w_OH2)\n",
    "assert len(padded_prefixes_random_w_OH) == len(padded_prefixes_random_w_OH2)\n",
    "\n",
    "for pair in zip(padded_prefixes_random_w_OH, padded_prefixes_random_w_OH2):\n",
    "    assert np.array_equal(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-use the `adjustWord` function and return a fixed dimension ndarray..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.245806Z",
     "start_time": "2019-11-01T20:05:22.235378Z"
    }
   },
   "outputs": [],
   "source": [
    "#FINAL version\n",
    "def getPrefixes_OH(w_OH, goal_length=None):\n",
    "    my_prefixes = [w_OH] + [w_OH[:-i] for i in range(1,len(w_OH))]\n",
    "    if goal_length is None:\n",
    "        return my_prefixes\n",
    "    return np.array(lmap(partial(adjustWord, goal_length=goal_length),\n",
    "                         my_prefixes))\n",
    "\n",
    "padded_prefixes_random_w_OH3 = getPrefixes_OH(random_w_OH, max(wordlengths))\n",
    "\n",
    "for pair in zip(padded_prefixes_random_w_OH2, padded_prefixes_random_w_OH3):\n",
    "    assert np.array_equal(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downstream calculations probably only actually want/need prefixes of length 3 or more (because triphones...), but let's let downstream notebooks / contexts of use take care of that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.251915Z",
     "start_time": "2019-11-01T20:05:22.248732Z"
    }
   },
   "outputs": [],
   "source": [
    "only_viable_prefixes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.263306Z",
     "start_time": "2019-11-01T20:05:22.254317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 21)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if only_viable_prefixes:\n",
    "    prefixlengths = range(3, max(wordlengths)+1)\n",
    "else:\n",
    "    prefixlengths = range(1, max(wordlengths)+1)\n",
    "prefixlengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.272836Z",
     "start_time": "2019-11-01T20:05:22.266146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 21)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixlengths\n",
    "len(list(prefixlengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:22.282261Z",
     "start_time": "2019-11-01T20:05:22.275453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengths\n",
    "len(wordlengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sequence of fixed-length representations of the lexicon of increasing size:\n",
    " - `Ps_l[i]` :: (|Ws|, i, |Xs|)\n",
    " - `Ps_l[i][j]` :: (i, |Xs|) is the matrix representing wordform `i` padded or trimmed to be length `i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.596600Z",
     "start_time": "2019-11-01T20:05:22.284512Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1622s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  20 | elapsed:    0.2s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:    0.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed:    0.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:    0.7s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  20 | elapsed:    0.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "#32s CMU/solomonoff\n",
    "#13s CMU/sidious\n",
    "Ps_l = [None for each in range(min(prefixlengths))] + list(par(delayed(lexiconToFixedSizeOHs)(Ws_t, l) for l in prefixlengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.605236Z",
     "start_time": "2019-11-01T20:05:23.599065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6404, 4, 40)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_l[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.613352Z",
     "start_time": "2019-11-01T20:05:23.608081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(wordlengths); max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.663033Z",
     "start_time": "2019-11-01T20:05:23.616064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6404, 1, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 2, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 3, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 4, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 5, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 6, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 7, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 8, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 9, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 10, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 11, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 12, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 13, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 14, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 15, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 16, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 17, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 18, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 19, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.053793600000000004"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in prefixlengths:\n",
    "    Ps_l[l].shape\n",
    "\n",
    "sum([Ps_l[l].nbytes / 1e9 for l in prefixlengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.671288Z",
     "start_time": "2019-11-01T20:05:23.665471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHsToDS(Ps_l[5][Ws_t.index(random_w)], OHXmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.734123Z",
     "start_time": "2019-11-01T20:05:23.673855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "Ws_t.index(random_w)\n",
    "OHsToDS(Ws_npf[Ws_t.index(random_w)], OHXmap)\n",
    "for l in prefixlengths:\n",
    "    OHsToDS(Ps_l[l][Ws_t.index(random_w)], OHXmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.765197Z",
     "start_time": "2019-11-01T20:05:23.737403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(14, 40)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_l = choice(list(wordlengths))\n",
    "random_l\n",
    "\n",
    "Ps_l[random_l][Ws_t.index(random_w)].shape\n",
    "np.sum(Ps_l[random_l][Ws_t.index(random_w)], axis=1)\n",
    "np.product( np.sum(Ps_l[random_l][Ws_t.index(random_w)], axis=1) )\n",
    "not np.product( np.sum(Ps_l[random_l][Ws_t.index(random_w)], axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.783529Z",
     "start_time": "2019-11-01T20:05:23.767624Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrievePrefixes(w_idx=None, w=None, Ws_t=None, Ps_t=None, max_l=None, asType='indices'):\n",
    "    if asType == 'indices' and Ps_t is None:\n",
    "        raise Exception(\"Must specify sorted prefix iterable if asType = 'indices'\")\n",
    "    if w_idx is None and (w is None or Ws_t is None):\n",
    "        raise Exception(\"Not enough information provided to specify a wordform index.\")\n",
    "    \n",
    "    if max_l is None and Ws_t is not None:\n",
    "        max_l = max({len(ds2t(w)) for w in Ws_t})\n",
    "    if max_l is None and Ws_t is None:\n",
    "        max_l = max({len(ds2t(w)) for w in Ps_t})\n",
    "    \n",
    "    \n",
    "    if w_idx is None:\n",
    "        w_idx = Ws_t.index(w)\n",
    "    \n",
    "    prefixSuperset = [Ps_l[l][w_idx] for l in range(min(prefixlengths), max_l+1)]\n",
    "    if asType == 'padded OHs':\n",
    "        return prefixSuperSet\n",
    "    \n",
    "    isPadded = np.array([isPaddedOHstack(p_OH) for p_OH in prefixSuperset])\n",
    "    uniqueOHs = [p_OH for i, p_OH in enumerate(prefixSuperset) if not isPadded[i]]\n",
    "    if asType == 'OHs':\n",
    "        return uniqueOHs\n",
    "    \n",
    "    uniqueStrings = list(map(lambda p_OH: OHsToDS(p_OH, OHXmap), uniqueOHs))\n",
    "    if asType == 'ds':\n",
    "        return uniqueStrings\n",
    "    \n",
    "    uniqueIndices = list(map(lambda p: Ps_t.index(p), uniqueStrings))\n",
    "    if asType == 'indices':\n",
    "        return uniqueIndices\n",
    "    raise Exception('Function should have returned something before now...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.799242Z",
     "start_time": "2019-11-01T20:05:23.786059Z"
    }
   },
   "outputs": [],
   "source": [
    "my_max_l = max({len(ds2t(w)) for w in Ws_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.819322Z",
     "start_time": "2019-11-01T20:05:23.801514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n.z.⋉.⋉'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n.z.⋉.⋉'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_wordforms = {w for w in Ws if len(ds2t(w)) == my_max_l}; longest_wordforms\n",
    "longest_wordform = list(longest_wordforms)[0]; longest_wordform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.840517Z",
     "start_time": "2019-11-01T20:05:23.821717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊',\n",
       " '⋊.f',\n",
       " '⋊.f.ɑ',\n",
       " '⋊.f.ɑ.k',\n",
       " '⋊.f.ɑ.k.s',\n",
       " '⋊.f.ɑ.k.s.h',\n",
       " '⋊.f.ɑ.k.s.h.oʊ',\n",
       " '⋊.f.ɑ.k.s.h.oʊ.l',\n",
       " '⋊.f.ɑ.k.s.h.oʊ.l.⋉',\n",
       " '⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 3996, 4684, 4688, 4689, 4690, 4691, 4692, 4693, 4694]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "retrievePrefixes(w=random_w, Ws_t=Ws_t, max_l=my_max_l, asType='ds')\n",
    "retrievePrefixes(w=random_w, Ws_t=Ws_t, Ps_t=Ps_t, max_l=my_max_l, asType='indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.877520Z",
     "start_time": "2019-11-01T20:05:23.843604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n.z.⋉.⋉'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊',\n",
       " '⋊.t',\n",
       " '⋊.t.ɛ',\n",
       " '⋊.t.ɛ.l',\n",
       " '⋊.t.ɛ.l.ɪ',\n",
       " '⋊.t.ɛ.l.ɪ.k',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n.z',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n.z.⋉',\n",
       " '⋊.t.ɛ.l.ɪ.k.ʌ.m.j.u.n.ɪ.k.eɪ.ʃ.ʌ.n.z.⋉.⋉']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 18344,\n",
       " 18846,\n",
       " 18891,\n",
       " 18895,\n",
       " 18904,\n",
       " 18905,\n",
       " 18906,\n",
       " 18907,\n",
       " 18908,\n",
       " 18909,\n",
       " 18910,\n",
       " 18911,\n",
       " 18912,\n",
       " 18913,\n",
       " 18914,\n",
       " 18915,\n",
       " 18916,\n",
       " 18917,\n",
       " 18918]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_wordform\n",
    "retrievePrefixes(w=longest_wordform, Ws_t=Ws_t, max_l=my_max_l, asType='ds')\n",
    "retrievePrefixes(w=longest_wordform, Ws_t=Ws_t, Ps_t=Ps_t, max_l=my_max_l, asType='indices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting whether `p` is a prefix of `w`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.886949Z",
     "start_time": "2019-11-01T20:05:23.880125Z"
    }
   },
   "outputs": [],
   "source": [
    "#naive implementation\n",
    "# could be made more efficient if that's important\n",
    "def is_a_prefix(p_OH, w_OH):\n",
    "    unpadded_p_OH, unpadded_w_OH = unpad(p_OH), unpad(w_OH)\n",
    "    p_l = unpadded_p_OH.shape[0]\n",
    "    w_l = unpadded_w_OH.shape[0]\n",
    "    if p_l > w_l:\n",
    "#         print('case 1')\n",
    "        return False\n",
    "    elif p_l == w_l:\n",
    "#         print('case 2')\n",
    "        return np.array_equal(unpadded_p_OH, unpadded_w_OH)\n",
    "    else: #p_l < w_l\n",
    "#         print('case 3')\n",
    "        trimmed_w_OH = unpadded_w_OH[:p_l]\n",
    "        return np.array_equal(unpadded_p_OH, trimmed_w_OH)\n",
    "#         return np.array_equal(np.dot(unpadded_p_OH, \n",
    "#                                      trimmed_w_OH.T),\n",
    "#                               np.eye(p_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.924171Z",
     "start_time": "2019-11-01T20:05:23.889373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7, 40)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.ʃ.ʊ'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 40)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "a_prefix_of_random_w\n",
    "random_w_OH.shape\n",
    "a_prefix_of_random_w_OH.shape\n",
    "assert (a_prefix_of_random_w in getPrefixes(random_w)) == is_a_prefix(a_prefix_of_random_w_OH, random_w_OH)\n",
    "lmap(lambda p: is_a_prefix(p, random_w_OH),\n",
    "     getPrefixes_OH(random_w_OH))\n",
    "' '\n",
    "random_other_p = choice(list(getPrefixes(choice(Ws_t))));\n",
    "random_w\n",
    "random_other_p\n",
    "random_other_p_OH = dsToUniphoneOHs(random_other_p, XOHmap)\n",
    "random_other_p_OH.shape\n",
    "\n",
    "assert (random_other_p in getPrefixes(random_w)) == is_a_prefix(random_other_p_OH, random_w_OH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a `prefix-word` relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.932334Z",
     "start_time": "2019-11-01T20:05:23.926670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6404, 27882)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_relation_shape = (len(Ws_t), len(Ps_t))\n",
    "prefix_relation_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:23.955969Z",
     "start_time": "2019-11-01T20:05:23.950206Z"
    }
   },
   "outputs": [],
   "source": [
    "def prefixIndicesToOHslice(prefix_idxs, num_Ps_t):\n",
    "    '''\n",
    "    Takes a list of prefix indices (e.g. that are prefixes of some w)\n",
    "    and returns a (dense) binary vector where those indices are 1 and\n",
    "    others are zero.\n",
    "    '''\n",
    "    my_slice = np.zeros(shape=(num_Ps_t,), dtype=np.uint8)\n",
    "#     for idx in prefix_idxs:\n",
    "#         my_slice[idx] = 1.0\n",
    "#     return my_slice\n",
    "#     return np.put(my_slice, prefix_idxs, 1) #<<< returns None because numpy is stateful AF\n",
    "    np.put(my_slice, prefix_idxs, 1)\n",
    "    return my_slice\n",
    "\n",
    "# retrievePrefixes(w_idx, Ps_t, asType='indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.681882Z",
     "start_time": "2019-11-01T20:05:23.961229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0193s.) Setting batch_size=20.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0819s.) Setting batch_size=96.\n",
      "[Parallel(n_jobs=-1)]: Done 404 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1124 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6404 out of 6404 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6404, 27882)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slice_calc(w_idx):\n",
    "    return prefixIndicesToOHslice(retrievePrefixes(w_idx=w_idx, \n",
    "                                                   Ps_t=Ps_t,\n",
    "                                                   max_l=my_max_l,\n",
    "                                                   asType='indices'), \n",
    "                                  len(Ps_t))\n",
    "\n",
    "# ≈3m on CMU on solomonoff\n",
    "# 50s CMU / sidious\n",
    "prefix_relation_np = np.stack(list(par(delayed(slice_calc)(w_idx)\n",
    "                                       for w_idx in np.arange(prefix_relation_shape[0]))))#, \n",
    "#                               dtype=np.uint8)\n",
    "\n",
    "# prefix_relation_np = np.stack([prefixIndexListToSlice(retrievePrefixes(w_idx=w_idx, \n",
    "#                                                                        Ps_t=Ps_t, \n",
    "#                                                                        asType='indices'), \n",
    "#                                                       len(Ps_t))\n",
    "#                                for w_idx in np.arange(prefix_relation_shape[1])])\n",
    "prefix_relation_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `(p,w,l)` relation where `w` trimmed to `l` is `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The logical place for this calculation is here, but the motivation is given in the section on $k$-cousins.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.688429Z",
     "start_time": "2019-11-01T20:05:26.684926Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_to_l = {p:len(ds2t(p)) for p in Ps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.736032Z",
     "start_time": "2019-11-01T20:05:26.691245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6404, 27882)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 27882)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Ws_t), len(Ps_t))\n",
    "prefix_relation_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll want to be able to retrieve the indices or strings of wordforms for each prefix such that that prefix is a prefix of those wordforms..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.748785Z",
     "start_time": "2019-11-01T20:05:26.739233Z"
    }
   },
   "outputs": [],
   "source": [
    "# #est 30m on cmu+solomonoff\n",
    "\n",
    "# #maps each prefix p to an array of wordform indices s.t.\n",
    "# # p is a prefix of each of the wordforms with those indices\n",
    "# # p_to_w_idxs = {p:prefix_relation_np[:,Ps_t.index(p)].nonzero()[0]\n",
    "# #                for p in tqdm(Ps)}\n",
    "\n",
    "# #est 17m on cmu/solomonoff\n",
    "# # def p_to_w_idx_calc(p):\n",
    "# #     return p, prefix_relation_np[:,Ps_t.index(p)].nonzero()[0]\n",
    "\n",
    "# # p_to_w_idxs = dict(par(delayed(p_to_w_idx_calc)(p)\n",
    "# #                        for p in Ps))\n",
    "\n",
    "# def p_to_w_idxs(p):\n",
    "#     return prefix_relation_np[:,Ps_t.index(p)].nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.756644Z",
     "start_time": "2019-11-01T20:05:26.752344Z"
    }
   },
   "outputs": [],
   "source": [
    "# random_w\n",
    "# a_prefix_of_random_w\n",
    "# ' '\n",
    "# Ws_t.index(random_w)\n",
    "# p_to_w_idxs(a_prefix_of_random_w)\n",
    "# lmap(lambda w_idx: Ws_t[w_idx], \n",
    "#      p_to_w_idxs(a_prefix_of_random_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.764455Z",
     "start_time": "2019-11-01T20:05:26.760077Z"
    }
   },
   "outputs": [],
   "source": [
    "#est 30-90m cmu+solomonoff\n",
    "# p_to_ws = {p:set(map(lambda w_idx: Ws_t[w_idx],\n",
    "#                      p_to_w_idxs(p)))\n",
    "#            for p in tqdm(Ps, total=len(Ps))}\n",
    "\n",
    "#est ?\n",
    "# def p_to_ws_calc(p):\n",
    "#     return p, set(map(lambda w_idx: Ws_t[w_idx],\n",
    "#                       p_to_w_idxs(p)))\n",
    "\n",
    "# p_to_ws = dict(par(delayed(p_to_ws_calc)(p)\n",
    "#                    for p in Ps))\n",
    "\n",
    "# def p_to_ws(p):\n",
    "#     return set(map(lambda w_idx: Ws_t[w_idx],\n",
    "#                    p_to_w_idxs(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.770540Z",
     "start_time": "2019-11-01T20:05:26.767614Z"
    }
   },
   "outputs": [],
   "source": [
    "# p_to_ws(a_prefix_of_random_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.776563Z",
     "start_time": "2019-11-01T20:05:26.772991Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #est 10-15m cmu+solomonoff\n",
    "# #maps each prefix index to an arbitray wordform index s.t.\n",
    "# # that prefix is a prefix of that wordform\n",
    "# # p_idx_to_w_idx = np.array([p_to_w_idxs(Ps_t[p_idx])[0]\n",
    "# #                            for p_idx in tqdm(np.arange(len(Ps_t)), total=len(Ps_t))], \n",
    "# #                           dtype=np.int8)\n",
    "\n",
    "# def p_idx_to_w_idx_calc(p_idx):\n",
    "#     indices = p_to_w_idxs(Ps_t[p_idx])\n",
    "#     if len(indices) > 0:\n",
    "#         return indices[0]\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# # ≈6m cmu+solomonoff\n",
    "# # ?m cmu+sidious\n",
    "# # ≈1.3m cmu+wittgenstein\n",
    "# p_idx_to_w_idx = np.array(list(par(delayed(p_idx_to_w_idx_calc)(p_idx)\n",
    "#                                    for p_idx in np.arange(len(Ps_t)))), \n",
    "#                           dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.782005Z",
     "start_time": "2019-11-01T20:05:26.778915Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(Ps_t)\n",
    "# p_idx_to_w_idx.shape\n",
    "# p_idx_to_w_idx.dtype\n",
    "# p_idx_to_w_idx.nbytes / 1e9 #FIXME reconsider dtype\n",
    "# p_idx_to_w_idx[Ps_t.index(a_prefix_of_random_w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.786572Z",
     "start_time": "2019-11-01T20:05:26.784004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t[0]\n",
    "# p_idx_to_w_idx[0]\n",
    "# Ws_t[p_idx_to_w_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.791043Z",
     "start_time": "2019-11-01T20:05:26.788483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t[2]\n",
    "# p_idx_to_w_idx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.796487Z",
     "start_time": "2019-11-01T20:05:26.793268Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.where(p_idx_to_w_idx == -1)[0]\n",
    "# assert np.where(p_idx_to_w_idx == -1)[0].size == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.801280Z",
     "start_time": "2019-11-01T20:05:26.798580Z"
    }
   },
   "outputs": [],
   "source": [
    "# w_idx_to_p_idx = {p_idx_to_w_idx[p_idx]:p_idx\n",
    "#                   for p_idx in tqdm(range(len(Ps_t)), total=len(Ps_t))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:26.806106Z",
     "start_time": "2019-11-01T20:05:26.803402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_t[232]\n",
    "# w_idx_to_p_idx[232]\n",
    "# Ps_t[w_idx_to_p_idx[232]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.084163Z",
     "start_time": "2019-11-01T20:05:26.808216Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0067s.) Setting batch_size=58.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0613s.) Setting batch_size=378.\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2036 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3138 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6800 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 14738 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 22676 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 31370 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 55839 out of 55839 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "# w_idx_to_l_to_p_idx = {(p_idx_to_w_idx[p_idx], p_to_l[Ps_t[p_idx]]):p_idx\n",
    "#                        for p_idx in tqdm(range(len(Ps_t)), total=len(Ps_t))}\n",
    "\n",
    "# w_idx_to_l_to_p_idx2 = {(w_idx, l): Ps_t.index( t2ds(ds2t(Ws_t[w_idx])[:l]) )\n",
    "#                         for w_idx in tqdm(range(len(Ws_t)), total=len(Ws_t)) for l in range(1, len(ds2t(Ws_t[w_idx])))}\n",
    "\n",
    "# w_idx_to_l_to_p_idx3 = {(Ws_t.index(w), len(ds2t(p))): Ps_t.index(p)\n",
    "#                         for w in tqdm(Ws_t) for p in getPrefixes(w)}\n",
    "\n",
    "# ≈10m on CMU/wittgenstein\n",
    "# w_idx_to_l_to_p_idx = {(Ws_t.index(w), len(ds2t(p))): Ps_t.index(p)\n",
    "#                         for w in tqdm(Ws_t) for p in getPrefixes(w)}\n",
    "\n",
    "def w_idx_to_l_to_p_idx_calc(w, p):\n",
    "    return ((Ws_t.index(w), len(ds2t(p))), Ps_t.index(p))\n",
    "\n",
    "# ≈1.3m cmu+wittgenstein\n",
    "w_idx_to_l_to_p_idx = dict(par(delayed(w_idx_to_l_to_p_idx_calc)(w,p)\n",
    "                               for w in Ws_t for p in getPrefixes(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.089537Z",
     "start_time": "2019-11-01T20:05:29.086963Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(w_idx_to_l_to_p_idx)\n",
    "# # len(w_idx_to_l_to_p_idx2)\n",
    "# len(w_idx_to_l_to_p_idx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.109804Z",
     "start_time": "2019-11-01T20:05:29.091503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4694"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "len(ds2t(random_w))\n",
    "associated_p_idx = w_idx_to_l_to_p_idx[(Ws_t.index(random_w), len(ds2t(random_w)))]; associated_p_idx\n",
    "Ps_t[associated_p_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.125813Z",
     "start_time": "2019-11-01T20:05:29.112346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɪ.n.s.æ.n.ʌ.t.i.⋉.⋉'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 23251, 23472, 23722, 23803, 23804, 23805, 23806, 23807, 23808, 23809]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊',\n",
       " '⋊.ɪ',\n",
       " '⋊.ɪ.n',\n",
       " '⋊.ɪ.n.s',\n",
       " '⋊.ɪ.n.s.æ',\n",
       " '⋊.ɪ.n.s.æ.n',\n",
       " '⋊.ɪ.n.s.æ.n.ʌ',\n",
       " '⋊.ɪ.n.s.æ.n.ʌ.t',\n",
       " '⋊.ɪ.n.s.æ.n.ʌ.t.i',\n",
       " '⋊.ɪ.n.s.æ.n.ʌ.t.i.⋉',\n",
       " '⋊.ɪ.n.s.æ.n.ʌ.t.i.⋉.⋉']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform_idx = choice(range(len(Ws_t)))\n",
    "Ws_t[random_wordform_idx]\n",
    "[w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) for l in prefixlengths if w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) != None]\n",
    "lmap(lambda p_idx: Ps_t[p_idx],\n",
    "     [w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) for l in prefixlengths if w_idx_to_l_to_p_idx.get((random_wordform_idx,l), None) != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.137240Z",
     "start_time": "2019-11-01T20:05:29.127739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.m.oʊ.ɹ.ɑ.n.z.⋉'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11279"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_prefix = choice(Ps_t); random_prefix\n",
    "random_prefix_idx = Ps_t.index(random_prefix); random_prefix_idx\n",
    "random_prefix_l = len(ds2t(random_prefix)); random_prefix_l\n",
    "# p_to_l[random_prefix]\n",
    "# associated_w_idx = p_idx_to_w_idx[random_prefix_idx]; associated_w_idx\n",
    "# Ws_t[associated_w_idx]\n",
    "# Ps_l[random_prefix_l][associated_w_idx].shape\n",
    "# w_idx_to_l_to_p_idx[(associated_w_idx, random_prefix_l)]\n",
    "# Ps_t[w_idx_to_l_to_p_idx[(associated_w_idx, random_prefix_l)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.142871Z",
     "start_time": "2019-11-01T20:05:29.139106Z"
    }
   },
   "outputs": [],
   "source": [
    "random_prefixes = choices(Ps_t, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.152281Z",
     "start_time": "2019-11-01T20:05:29.144676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.ʃ.ʊ'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.d.ɪ.p.ɛ.n.d.ʌ',\n",
       " '⋊.ɪ.n.k.ɑ.m.p.ɪ.t.ʌ.n.t',\n",
       " '⋊.b.ɹ.ɪ.t.t.ɑ.n.i.⋉.⋉',\n",
       " '⋊.d.ɪ.s.ʌ.g.ɹ.i.d.⋉',\n",
       " '⋊.aʊ.t.l.ʊ.k.⋉.⋉',\n",
       " '⋊.k.ɪ.ŋ.⋉',\n",
       " '⋊.k.ʌ.s.t.ʌ.m.z.⋉.⋉',\n",
       " '⋊.t.oʊ.l.i',\n",
       " '⋊.p.u.⋉.⋉',\n",
       " '⋊.s.ʌ.b.s.k.ɹ.aɪ.b.⋉']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_other_p\n",
    "some_random_prefixes = random_prefixes[:10]; some_random_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.158120Z",
     "start_time": "2019-11-01T20:05:29.154124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_other_p_OH.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.162970Z",
     "start_time": "2019-11-01T20:05:29.160295Z"
    }
   },
   "outputs": [],
   "source": [
    "# length_mismatch_constant = np.inf\n",
    "length_mismatch_constant = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between symbol vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.170189Z",
     "start_time": "2019-11-01T20:05:29.165011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = np.zeros(shape=XOHmap['f'].shape, dtype=my_dtype)\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.198533Z",
     "start_time": "2019-11-01T20:05:29.172274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOHmap['f'] #a\n",
    "XOHmap['g'] #b\n",
    "\n",
    "diff_V = XOHmap['f'] - XOHmap['g']; diff_V #will be the zero vector iff a = b\n",
    "sum_V = XOHmap['f'] + XOHmap['g']; sum_V\n",
    "prod_V = XOHmap['f'] * XOHmap['g']; prod_V #a * b will be the zero vector iff a ≠ b and a * b = a = b iff a = b\n",
    "dot_prod_V = np.dot(XOHmap['f'], XOHmap['g']); dot_prod_V #a.b will be 0 iff a ≠ b and a.b = 1 iff a = b\n",
    "np.dot(XOHmap['f'], XOHmap['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.204620Z",
     "start_time": "2019-11-01T20:05:29.200664Z"
    }
   },
   "outputs": [],
   "source": [
    "random_OHs = choices(list(map(lambda x: XOHmap[x], Xs)), k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.210324Z",
     "start_time": "2019-11-01T20:05:29.206449Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not np.array_equal(choice(random_OHs), choice(random_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.215982Z",
     "start_time": "2019-11-01T20:05:29.212166Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not np.array_equal(choice(random_OHs) - choice(random_OHs), zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.264643Z",
     "start_time": "2019-11-01T20:05:29.217797Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not (choice(random_OHs) - choice(random_OHs)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.274475Z",
     "start_time": "2019-11-01T20:05:29.268709Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit not (choice(random_OHs) - choice(random_OHs)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.280946Z",
     "start_time": "2019-11-01T20:05:29.276834Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit (choice(random_OHs) * choice(random_OHs)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.287342Z",
     "start_time": "2019-11-01T20:05:29.283142Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit np.dot(choice(random_OHs), choice(random_OHs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Unsurprising) conclusion on checking for vector equality: `np.dot` is about 2-3 times as fast as methods involving element-wise array equality checking or sums and differences possibly involving the zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.293217Z",
     "start_time": "2019-11-01T20:05:29.289373Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_s_np(x_OH, y_OH):\n",
    "    '''\n",
    "    Hamming distance between symbol x and symbol y,\n",
    "    where both symbols are one-hot vectors.\n",
    "    '''\n",
    "    return not np.dot(x_OH, y_OH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.334931Z",
     "start_time": "2019-11-01T20:05:29.295692Z"
    }
   },
   "outputs": [],
   "source": [
    "for each_OH in random_OHs:\n",
    "    assert d_s_np(each_OH, each_OH) == 0 and np.array_equal(each_OH, each_OH)\n",
    "    random_OH = choice(random_OHs)\n",
    "    assert d_s_np(each_OH, random_OH) == (not np.array_equal(each_OH, random_OH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming distance between stacks of symbol vectors (strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.342089Z",
     "start_time": "2019-11-01T20:05:29.337016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,3)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.509490Z",
     "start_time": "2019-11-01T20:05:29.344679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Direct comparison for equality:'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Difference:'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hadamard product:'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Dot product:'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=uint64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=uint64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=uint64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=uint64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Direct comparison for equality:'\n",
    "np.array_equal(dsToUniphoneOHs('t.i.f', XOHmap), dsToUniphoneOHs('t.i.f', XOHmap)) #true\n",
    "np.array_equal(dsToUniphoneOHs('t.i.f', XOHmap), dsToUniphoneOHs('t.i.g', XOHmap)) #false\n",
    "\n",
    "'Difference:'\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.f', XOHmap)).sum()\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.f', XOHmap)).prod()\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap).astype(np.int64) - dsToUniphoneOHs('t.i.g', XOHmap).astype(np.int64)).sum()\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.g', XOHmap)).prod()\n",
    "# (dsToUniphoneOHs('t.i.f', XOHmap) - dsToUniphoneOHs('t.i.g', XOHmap)).sum()\n",
    "\n",
    "'Hadamard product:'\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('t.i.f', XOHmap)).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('t.i.g', XOHmap)).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('d.i.g', XOHmap)).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) * dsToUniphoneOHs('d.u.g', XOHmap)).sum()\n",
    "\n",
    "'Dot product:'\n",
    "np.dot(dsToUniphoneOHs('t.i.f', XOHmap),\n",
    "       dsToUniphoneOHs('t.i.f', XOHmap).T)\n",
    "dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.f', XOHmap).T\n",
    "dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.g', XOHmap).T\n",
    "dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.f', XOHmap).T\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.f', XOHmap).T).sum(axis=0)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.f', XOHmap).T).sum(axis=1)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.g', XOHmap).T).sum(axis=0)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.i.g', XOHmap).T).sum(axis=1)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum(axis=0)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum(axis=1)\n",
    "(dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum(axis=0).sum()\n",
    "3 - (dsToUniphoneOHs('t.i.f', XOHmap) @ dsToUniphoneOHs('t.u.g', XOHmap).T).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.521195Z",
     "start_time": "2019-11-01T20:05:29.511910Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_w_np_hadamard(x_OHs, y_OHs):\n",
    "    '''\n",
    "    Hamming distance between stacks of symbols x and y,\n",
    "    where both stacks are of one-hot vectors.\n",
    "    '''\n",
    "    l = x_OHs.shape[0]\n",
    "    \n",
    "    return l - (x_OHs * y_OHs).sum()\n",
    "\n",
    "# turns out to be both incorrect and scales poorly\n",
    "# def d_w_np_dot(x_OHs, y_OHs):\n",
    "#     '''\n",
    "#     Hamming distance between stacks of symbols x and y,\n",
    "#     where both stacks are of one-hot vectors.\n",
    "#     '''\n",
    "#     l = x_OHs.shape[0]\n",
    "    \n",
    "#     return l - (x_OHs @ y_OHs.T).sum()\n",
    "\n",
    "def d_w_np_direct(x_OHs, y_OHs):\n",
    "    '''\n",
    "    Hamming distance between stacks of symbols x and y,\n",
    "    where both stacks are of one-hot vectors.\n",
    "    '''\n",
    "    l = x_OHs.shape[0]\n",
    "    return np.array([(not np.array_equal(x_OHs[i], y_OHs[i])) for i in range(l)]).sum()\n",
    "\n",
    "d_s_npu = np.vectorize(d_s_np, otypes=[np.uint8], signature=\"(s),(s)->()\")\n",
    "\n",
    "def d_w_np_u(x_OHs, y_OHs):\n",
    "    return d_s_npu(x_OHs, y_OHs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.600189Z",
     "start_time": "2019-11-01T20:05:29.523553Z"
    }
   },
   "outputs": [],
   "source": [
    "num_random_fixed_size_OHs = 1000\n",
    "\n",
    "my_fixed_size = 20 #longer length = more revealing\n",
    "\n",
    "random_fixed_size_OHs = [np.stack([choice(random_OHs) for each in range(my_fixed_size)])\n",
    "                         for each in range(num_random_fixed_size_OHs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.608649Z",
     "start_time": "2019-11-01T20:05:29.602897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_fixed_size_OHs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.616153Z",
     "start_time": "2019-11-01T20:05:29.611352Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #indicates overhead of choosing random inputs\n",
    "    %timeit (choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.622747Z",
     "start_time": "2019-11-01T20:05:29.618568Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_w_np_hadamard(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.627409Z",
     "start_time": "2019-11-01T20:05:29.624792Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# d_w_np_dot(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.633572Z",
     "start_time": "2019-11-01T20:05:29.629497Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_w_np_direct(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.640091Z",
     "start_time": "2019-11-01T20:05:29.635923Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_w_np_u(choice(random_fixed_size_OHs), choice(random_fixed_size_OHs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for correctness..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.654062Z",
     "start_time": "2019-11-01T20:05:29.642568Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for my_hamming_distance_function in (d_w_np_direct, d_w_np_hadamard, d_w_np_u):\n",
    "    # for my_hamming_distance_function in (d_w_np_direct, d_w_np_hadamard, d_w_np_dot, d_w_np_u):\n",
    "        print(f'Checking {str(my_hamming_distance_function)}')\n",
    "        for each_OHstack in random_fixed_size_OHs:\n",
    "        #     my_hamming_distance_function = d_w_np_hadamard\n",
    "    #         my_hamming_distance_function = d_w_np_direct\n",
    "        #     my_hamming_distance_function = \n",
    "            if not (my_hamming_distance_function(each_OHstack, each_OHstack) == 0 and np.array_equal(each_OHstack, each_OHstack) == True):\n",
    "                each_s = OHsToDS(each_OHstack, OHXmap)\n",
    "                print(f'each_s = {each_s}')\n",
    "                print(f'd_h = {d_h(each_s, each_s)}')\n",
    "                print(f'my_hamming_distance_function(each_OHstack, each_OHstack) = {my_hamming_distance_function(each_OHstack, each_OHstack)}')\n",
    "            assert my_hamming_distance_function(each_OHstack, each_OHstack) == 0 and np.array_equal(each_OHstack, each_OHstack) == True\n",
    "\n",
    "            random_OHstack = choice(random_fixed_size_OHs)\n",
    "            each_s = OHsToDS(each_OHstack, OHXmap)\n",
    "            random_s = OHsToDS(random_OHstack, OHXmap)\n",
    "\n",
    "            if not (my_hamming_distance_function(each_OHstack, random_OHstack) == d_h(each_s, random_s)):\n",
    "                print(f'each_s = {each_s}', f'random_s = {random_s}')\n",
    "                pprint_aligned_DSs(align_DSs([each_s, random_s]))\n",
    "                print(f'd_h = {d_h(each_s, random_s)}')\n",
    "                print(f'my_hamming_distance_function(each_OHstack, random_OHstack) = {my_hamming_distance_function(each_OHstack, random_OHstack)}')\n",
    "            assert my_hamming_distance_function(each_OHstack, random_OHstack) == d_h(each_s, random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** The Hadamard product scales very well for checking Hamming distance between two (unpadded one-hot) strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.661069Z",
     "start_time": "2019-11-01T20:05:29.656322Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_h_np(x_OHs, y_OHs):\n",
    "    '''\n",
    "    Hamming distance between sequences of symbols x and y,\n",
    "    where both symbols are represented by one-hot vectors and\n",
    "    neither is a padded stack.\n",
    "    '''\n",
    "    l = x_OHs.shape[0]\n",
    "    if l != y_OHs.shape[0]:\n",
    "        return length_mismatch_constant\n",
    "#         return np.infty\n",
    "    return l - (x_OHs * y_OHs).sum(dtype=my_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accommodate padded OH vectors, we need mechanisms for accounting for padding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.670924Z",
     "start_time": "2019-11-01T20:05:29.663018Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_h_np(x_OHs, y_OHs, paddedOHs=False):\n",
    "    '''\n",
    "    Hamming distance between sequences of symbols x and y,\n",
    "    where both symbols are represented by one-hot vectors.\n",
    "    '''\n",
    "    if paddedOHs:\n",
    "        x_l = trueLength(x_OHs)\n",
    "        y_l = trueLength(y_OHs)\n",
    "        if x_l != y_l:\n",
    "            return length_mismatch_constant\n",
    "#             return np.infty\n",
    "        else: #true lengths *are* the same...\n",
    "            true_l = x_l\n",
    "#             x_pl = x_OHs.shape[0]\n",
    "#             y_pl = y_OHs.shape[0]\n",
    "            \n",
    "            #correct but involves the creation of new OH stacks\n",
    "#             trimmed_x_OHs, trimmed_y_OHs = adjustWord(x_OHs, true_l), adjustWord(y_OHs, true_l)\n",
    "#             return true_l - (trimmed_x_OHs * trimmed_y_OHs).sum()\n",
    "\n",
    "            return true_l - ((x_OHs[:true_l] * y_OHs[:true_l])).sum(dtype=my_dtype)\n",
    "            \n",
    "    l = x_OHs.shape[0]\n",
    "    if l != y_OHs.shape[0]:\n",
    "        return -1\n",
    "#         return np.infty\n",
    "    return l - (x_OHs * y_OHs).sum(dtype=my_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.726495Z",
     "start_time": "2019-11-01T20:05:29.673032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11, 40)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.ʃ.ʊ'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 40)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w0 = Ws_t[0]; w0\n",
    "w0\n",
    "# w0_l = len(ds2t(Ws_t[0])); \n",
    "w0_l\n",
    "' '\n",
    "# unpadded_w0_OH_rep = dsToUniphoneOHs(w0, XOHmap); unpadded_w0_OH_rep.shape\n",
    "unpadded_w0_OH_rep.shape\n",
    "OHsToDS(unpadded_w0_OH_rep, OHXmap)\n",
    "assert not isPaddedOHstack(unpadded_w0_OH_rep)\n",
    "' '\n",
    "# padded_w0_OH_rep = Ws_npf[0]; padded_w0_OH_rep.shape\n",
    "padded_w0_OH_rep.shape\n",
    "OHsToDS(padded_w0_OH_rep, OHXmap)\n",
    "assert isPaddedOHstack(padded_w0_OH_rep) or not containsAnyPaddedOHstacks(Ws_npf)\n",
    "' '\n",
    "d_h_np(unpadded_w0_OH_rep, unpadded_w0_OH_rep)\n",
    "d_h_np(unpadded_w0_OH_rep, padded_w0_OH_rep, True)\n",
    "d_h_np(padded_w0_OH_rep, padded_w0_OH_rep, True)\n",
    "' '\n",
    "random_other_p\n",
    "random_other_p_OH.shape\n",
    "random_other_p_OH_padded = adjustWord(random_other_p_OH, 20)\n",
    "random_other_p_OH_padded.shape\n",
    "assert isPaddedOHstack(random_other_p_OH_padded) or not containsAnyPaddedOHstacks(Ws_npf)\n",
    "d_h(w0, random_other_p)\n",
    "d_h_np(padded_w0_OH_rep, random_other_p_OH_padded, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.733712Z",
     "start_time": "2019-11-01T20:05:29.728374Z"
    }
   },
   "outputs": [],
   "source": [
    "num_random_padded_OHs = 1000\n",
    "\n",
    "random_padded_OHs = [choice(Ws_npf)\n",
    "                     for each in range(num_random_padded_OHs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.740061Z",
     "start_time": "2019-11-01T20:05:29.735864Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_d_h(u,v):\n",
    "    result = d_h(u,v)\n",
    "    if result == np.inf:\n",
    "        return length_mismatch_constant\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.747364Z",
     "start_time": "2019-11-01T20:05:29.742298Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for each_OH_stack in random_padded_OHs:\n",
    "        other_OH_stack = choice(random_padded_OHs)\n",
    "\n",
    "        each_s  = OHsToDS(each_OH_stack, OHXmap)\n",
    "        other_s = OHsToDS(other_OH_stack, OHXmap)\n",
    "\n",
    "        if trueLength(each_OH_stack) == trueLength(other_OH_stack):\n",
    "            print('matching true lengths...') #more useful tests\n",
    "\n",
    "        assert my_d_h(each_s, other_s) == d_h_np(each_OH_stack, other_OH_stack, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.753608Z",
     "start_time": "2019-11-01T20:05:29.749348Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np(choice(random_padded_OHs), choice(random_padded_OHs), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between a string and a stack of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is correct, modulo accounting for padded stacks. (In those cases, levenshtein distance enters the calculation...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.926286Z",
     "start_time": "2019-11-01T20:05:29.755778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([18, 18, 19, ..., 19, 19, 19])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([18, 18, 19, ..., 19, 19, 19], dtype=uint8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([18, 18, 19, ..., 19, 19, 19], dtype=uint8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([18, 18, 19, ..., 19, 19, 19], dtype=uint8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_idx = Ws_t.index(random_w)\n",
    "random_w_OHf = Ws_npf[random_w_idx]; random_w_OHf.shape\n",
    "Ws_npf.shape\n",
    "np.array(lmap(lambda w_OHf: d_h_np(random_w_OHf, w_OHf, False),\n",
    "              Ws_npf))\n",
    "\n",
    "random_w_OHf.shape[0] - np.einsum('nls->n', random_w_OHf * Ws_npf)\n",
    "random_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', random_w_OHf, Ws_npf))\n",
    "random_w_OHf.shape[0] - np.einsum('nls->n', (random_w_OHf * Ws_sf).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.931913Z",
     "start_time": "2019-11-01T20:05:29.929094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_npfProd = np.einsum('mls,nls->mnls', Ws_npf, Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.937244Z",
     "start_time": "2019-11-01T20:05:29.934047Z"
    }
   },
   "outputs": [],
   "source": [
    "# only correct for random_w_OHf\n",
    "# Ws_npfReduc = random_w_OHf.shape[0] - np.einsum('mnls->mn', Ws_npfProd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.943664Z",
     "start_time": "2019-11-01T20:05:29.939682Z"
    }
   },
   "outputs": [],
   "source": [
    "# random_w_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.950320Z",
     "start_time": "2019-11-01T20:05:29.946959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_npfReduc[random_w_idx]\n",
    "# np.array_equal(Ws_npfReduc[random_w_idx], random_w_OHf.shape[0] - np.einsum('nls->n', random_w_OHf * Ws_npf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify these calculations to account for padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:29.976404Z",
     "start_time": "2019-11-01T20:05:29.952891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([11,  9, 13, ...,  8,  7,  4], dtype=int8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueLength(random_w_OHf)\n",
    "Ws_npf.shape\n",
    "Ws_npf_trueLengths = np.sum(Ws_npf, axis=2, dtype=my_dtype).sum(axis=1, dtype=my_dtype)\n",
    "Ws_npf_trueLengths.shape\n",
    "Ws_npf_trueLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.011691Z",
     "start_time": "2019-11-01T20:05:29.978885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  43,   46,   57,   59,   76,   78,   83,  121,  122,  129,  166,\n",
       "        168,  170,  180,  181,  184,  186,  195,  212,  225,  231,  232,\n",
       "        259,  270,  274,  279,  282,  286,  289,  290,  298,  311,  316,\n",
       "        325,  329,  347,  360,  372,  378,  383,  409,  423,  434,  436,\n",
       "        473,  494,  501,  533,  539,  560,  564,  575,  586,  596,  610,\n",
       "        613,  614,  622,  623,  625,  628,  632,  635,  636,  638,  640,\n",
       "        642,  643,  648,  652,  655,  664,  684,  686,  690,  698,  702,\n",
       "        703,  705,  706,  710,  716,  719,  723,  726,  731,  737,  759,\n",
       "        760,  763,  765,  777,  781,  788,  825,  841,  844,  850,  869,\n",
       "        882,  886,  905,  914,  933,  936,  949,  963, 1016, 1023, 1027,\n",
       "       1032, 1033, 1044, 1062, 1065, 1075, 1087, 1102, 1143, 1145, 1167,\n",
       "       1172, 1175, 1179, 1184, 1189, 1196, 1209, 1215, 1221, 1222, 1236,\n",
       "       1239, 1243, 1251, 1291, 1305, 1306, 1310, 1341, 1342, 1349, 1351,\n",
       "       1353, 1359, 1360, 1389, 1393, 1397, 1401, 1424, 1426, 1437, 1444,\n",
       "       1474, 1483, 1489, 1497, 1513, 1520, 1524, 1533, 1540, 1558, 1569,\n",
       "       1571, 1574, 1579, 1585, 1586, 1595, 1605, 1613, 1624, 1630, 1633,\n",
       "       1664, 1665, 1676, 1680, 1697, 1724, 1730, 1732, 1740, 1765, 1774,\n",
       "       1775, 1777, 1785, 1804, 1810, 1827, 1840, 1842, 1852, 1864, 1871,\n",
       "       1873, 1879, 1883, 1901, 1912, 1927, 1932, 1936, 1938, 1945, 1953,\n",
       "       1962, 1963, 1965, 1983, 1991, 1996, 2005, 2009, 2016, 2031, 2041,\n",
       "       2045, 2046, 2052, 2053, 2065, 2073, 2076, 2083, 2101, 2103, 2112,\n",
       "       2125, 2131, 2168, 2169, 2176, 2203, 2207, 2211, 2234, 2252, 2254,\n",
       "       2262, 2265, 2269, 2287, 2292, 2294, 2295, 2303, 2306, 2308, 2311,\n",
       "       2313, 2317, 2321, 2328, 2337, 2343, 2347, 2348, 2360, 2362, 2388,\n",
       "       2406, 2412, 2429, 2431, 2442, 2450, 2465, 2474, 2477, 2503, 2526,\n",
       "       2533, 2545, 2550, 2556, 2574, 2589, 2604, 2620, 2622, 2630, 2649,\n",
       "       2650, 2658, 2664, 2670, 2672, 2682, 2693, 2708, 2739, 2765, 2773,\n",
       "       2784, 2787, 2790, 2794, 2809, 2816, 2823, 2825, 2830, 2831, 2843,\n",
       "       2848, 2851, 2854, 2857, 2879, 2902, 2929, 2938, 2939, 2942, 2947,\n",
       "       2950, 2958, 2960, 2961, 2967, 2970, 2995, 3005, 3008, 3017, 3029,\n",
       "       3042, 3056, 3068, 3083, 3088, 3093, 3117, 3121, 3126, 3127, 3135,\n",
       "       3136, 3142, 3155, 3162, 3180, 3186, 3191, 3197, 3214, 3219, 3228,\n",
       "       3239, 3253, 3260, 3261, 3264, 3272, 3280, 3281, 3283, 3292, 3298,\n",
       "       3308, 3309, 3330, 3331, 3359, 3363, 3365, 3367, 3380, 3386, 3391,\n",
       "       3396, 3403, 3414, 3418, 3421, 3423, 3424, 3427, 3428, 3433, 3434,\n",
       "       3438, 3449, 3460, 3468, 3470, 3471, 3475, 3478, 3484, 3485, 3494,\n",
       "       3498, 3508, 3511, 3529, 3534, 3538, 3550, 3553, 3559, 3561, 3562,\n",
       "       3563, 3590, 3598, 3612, 3614, 3654, 3667, 3679, 3681, 3691, 3693,\n",
       "       3707, 3729, 3740, 3755, 3757, 3767, 3791, 3796, 3801, 3802, 3804,\n",
       "       3820, 3826, 3836, 3839, 3844, 3852, 3859, 3866, 3878, 3893, 3894,\n",
       "       3896, 3906, 3907, 3908, 3917, 3931, 3935, 3938, 3941, 3951, 3955,\n",
       "       3957, 3961, 3967, 3973, 4008, 4015, 4016, 4023, 4033, 4040, 4049,\n",
       "       4050, 4060, 4065, 4069, 4075, 4080, 4087, 4090, 4096, 4097, 4102,\n",
       "       4105, 4115, 4120, 4130, 4143, 4146, 4151, 4152, 4156, 4165, 4166,\n",
       "       4170, 4172, 4175, 4177, 4181, 4184, 4186, 4190, 4198, 4222, 4235,\n",
       "       4237, 4253, 4255, 4258, 4259, 4261, 4264, 4268, 4278, 4290, 4291,\n",
       "       4293, 4295, 4296, 4334, 4337, 4373, 4386, 4445, 4476, 4493, 4507,\n",
       "       4510, 4513, 4518, 4526, 4533, 4543, 4564, 4575, 4610, 4643, 4655,\n",
       "       4656, 4660, 4669, 4684, 4687, 4693, 4698, 4703, 4709, 4710, 4711,\n",
       "       4716, 4734, 4759, 4788, 4789, 4791, 4801, 4819, 4825, 4827, 4839,\n",
       "       4845, 4858, 4859, 4868, 4879, 4887, 4894, 4896, 4910, 4912, 4918,\n",
       "       4937, 4946, 4948, 4957, 4959, 4964, 4972, 4973, 4975, 4978, 4984,\n",
       "       4985, 4987, 4990, 4993, 4996, 4997, 5021, 5025, 5026, 5038, 5050,\n",
       "       5052, 5068, 5074, 5089, 5105, 5121, 5138, 5144, 5155, 5163, 5178,\n",
       "       5182, 5193, 5200, 5224, 5233, 5246, 5247, 5249, 5250, 5253, 5256,\n",
       "       5260, 5262, 5265, 5272, 5273, 5281, 5284, 5286, 5290, 5291, 5293,\n",
       "       5294, 5296, 5302, 5306, 5313, 5314, 5319, 5320, 5322, 5323, 5328,\n",
       "       5331, 5335, 5337, 5340, 5343, 5362, 5367, 5369, 5376, 5379, 5380,\n",
       "       5389, 5393, 5399, 5408, 5414, 5416, 5427, 5432, 5436, 5438, 5448,\n",
       "       5463, 5465, 5484, 5485, 5489, 5492, 5493, 5496, 5506, 5508, 5511,\n",
       "       5519, 5530, 5534, 5539, 5544, 5546, 5561, 5569, 5570, 5571, 5572,\n",
       "       5584, 5587, 5598, 5599, 5606, 5615, 5623, 5655, 5678, 5686, 5689,\n",
       "       5705, 5707, 5710, 5711, 5713, 5732, 5748, 5752, 5757, 5764, 5785,\n",
       "       5790, 5794, 5807, 5830, 5843, 5846, 5850, 5851, 5853, 5854, 5857,\n",
       "       5863, 5864, 5869, 5872, 5876, 5877, 5879, 5884, 5891, 5895, 5898,\n",
       "       5912, 5916, 5920, 5921, 5929, 5936, 5937, 5938, 5944, 5945, 5951,\n",
       "       5953, 5961, 5968, 6018, 6038, 6053, 6076, 6078, 6079, 6083, 6086,\n",
       "       6089, 6095, 6097, 6098, 6099, 6100, 6103, 6104, 6109, 6113, 6117,\n",
       "       6118, 6120, 6124, 6136, 6137, 6140, 6149, 6151, 6160, 6177, 6180,\n",
       "       6195, 6216, 6217, 6233, 6242, 6244, 6254, 6268, 6282, 6285, 6308,\n",
       "       6312, 6325, 6326, 6329, 6330, 6331, 6349, 6358, 6398])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueLength_match = Ws_npf_trueLengths == trueLength(random_w_OHf); trueLength_match.nonzero()[0]\n",
    "trueLength_mismatch = Ws_npf_trueLengths != trueLength(random_w_OHf); trueLength_mismatch\n",
    "# Ws_npf_trueLengths[0], trueLength_mismatch[0]\n",
    "# Ws_npf_trueLengths[1], trueLength_mismatch[1]\n",
    "# Ws_npf_trueLengths[2], trueLength_mismatch[2]\n",
    "random_w_OHf_distance_mask = np.ones(Ws_npf_trueLengths.shape)\n",
    "np.putmask(random_w_OHf_distance_mask, trueLength_mismatch, length_mismatch_constant)\n",
    "random_w_OHf_distance_mask\n",
    "random_w_OHf_distance_mask[trueLength_match]\n",
    "# random_w_OHf_distance_mask[0]\n",
    "# random_w_OHf_distance_mask[1]\n",
    "# random_w_OHf_distance_mask[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.020848Z",
     "start_time": "2019-11-01T20:05:30.014203Z"
    }
   },
   "outputs": [],
   "source": [
    "def OHstack_to_trueLength_mask(paddedOHstack, trueLengths):\n",
    "    mask = np.ones(trueLengths.shape)\n",
    "    np.putmask(mask, trueLengths != trueLength(paddedOHstack), length_mismatch_constant)\n",
    "    return mask.astype(my_dtype)\n",
    "\n",
    "assert np.array_equal(random_w_OHf_distance_mask,\n",
    "                      OHstack_to_trueLength_mask(random_w_OHf, Ws_npf_trueLengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.416538Z",
     "start_time": "2019-11-01T20:05:30.023980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.f.ɑ.k.s.h.oʊ.l.⋉.⋉'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-18., -18., -19., ..., -19., -19., -19.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-18., -18., -19., ..., -19., -19., -19.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-18., -18., -19., ..., -19., -19., -19.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_w\n",
    "random_w_idx = Ws_t.index(random_w)\n",
    "random_w_OHf = Ws_npf[random_w_idx]; random_w_OHf.shape\n",
    "Ws_npf.shape\n",
    "np.array(lmap(lambda w_OHf: d_h_np(random_w_OHf, w_OHf, True),\n",
    "              Ws_npf))\n",
    "\n",
    "(random_w_OHf.shape[0] - np.einsum('nls->n', random_w_OHf * Ws_npf)) * random_w_OHf_distance_mask\n",
    "(random_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', random_w_OHf, Ws_npf))) * random_w_OHf_distance_mask\n",
    "(random_w_OHf.shape[0] - np.einsum('nls->n', (random_w_OHf * Ws_sf).todense())) * random_w_OHf_distance_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.425790Z",
     "start_time": "2019-11-01T20:05:30.419693Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit -r 10 -n 10 np.array(lmap(lambda w_OHf: d_h_np(choice(Ws_npf), w_OHf), Ws_npf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.437873Z",
     "start_time": "2019-11-01T20:05:30.429850Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rand_w_OHf = choice(Ws_npf)\n",
    "    %timeit -r 10 -n 10 rand_w_OHf.shape[0] - np.einsum('nls->n', rand_w_OHf * Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.447658Z",
     "start_time": "2019-11-01T20:05:30.440939Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rand_w_OHf = choice(Ws_npf)\n",
    "    %timeit -r 10 -n 10 rand_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', rand_w_OHf, Ws_npf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.455532Z",
     "start_time": "2019-11-01T20:05:30.450174Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    rand_w_OHf = choice(Ws_npf)\n",
    "    %timeit -r 10 -n 10 rand_w_OHf.shape[0] - np.einsum('nls->n', (rand_w_OHf * Ws_sf).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.641565Z",
     "start_time": "2019-11-01T20:05:30.457805Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_w_OHf = choice(Ws_npf)\n",
    "\n",
    "map_result = np.array(lmap(lambda w_OHf: d_h_np(rand_w_OHf, w_OHf),\n",
    "                           Ws_npf))\n",
    "\n",
    "einsum_hadamard_result = rand_w_OHf.shape[0] - np.einsum('nls->n', rand_w_OHf * Ws_npf)\n",
    "\n",
    "einsum_einsum_result = rand_w_OHf.shape[0] - np.einsum('nls->n', np.einsum('ls,nls->nls', rand_w_OHf, Ws_npf))\n",
    "\n",
    "einsum_hadamard_sparse_result = rand_w_OHf.shape[0] - np.einsum('nls->n', (rand_w_OHf * Ws_sf).todense())\n",
    "\n",
    "assert np.array_equal(map_result, einsum_hadamard_result)\n",
    "assert np.array_equal(map_result, einsum_einsum_result)\n",
    "assert np.array_equal(map_result, einsum_hadamard_sparse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.664087Z",
     "start_time": "2019-11-01T20:05:30.644701Z"
    }
   },
   "outputs": [],
   "source": [
    "def d_h_np_string_to_strings(x_OHs, L_OHs, paddedOHs=False, L_OHs_trueLengths=None, use_GPU=False):\n",
    "    memTrigger()\n",
    "    if not use_GPU:\n",
    "        x_OHs = x_OHs.astype(my_dtype)\n",
    "        L_OHs = L_OHs.astype(my_dtype)\n",
    "        l = x_OHs.shape[0]\n",
    "        if not paddedOHs:\n",
    "            return l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)\n",
    "        else:\n",
    "            true_l = trueLength(x_OHs)\n",
    "            if L_OHs_trueLengths is None:\n",
    "                L_OHs_trueLengths = np.sum(L_OHs, axis=2, dtype=np.uint8).sum(axis=1, dtype=np.uint8)\n",
    "            trueLength_mask = OHstack_to_trueLength_mask(x_OHs, L_OHs_trueLengths)\n",
    "            return (true_l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)) * trueLength_mask\n",
    "    else:\n",
    "        if not paddedOHs:\n",
    "            l = x_OHs.shape[0]\n",
    "            x_OHs_t = x_OHs\n",
    "            L_OHs_t = L_OHs\n",
    "#             x_OHs_t = torch.from_numpy(x_OHs)#.type(torch.float16)\n",
    "#             L_OHs_t = torch.from_numpy(L_OHs)#.type(torch.float16)\n",
    "            return l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype)\n",
    "#             return l - torch.einsum('nls->n', x_OHs_t.type(torch.float16).cuda() * L_OHs_t.type(torch.float16).cuda())\n",
    "        else:\n",
    "            x_OHs_t = x_OHs\n",
    "            L_OHs_t = L_OHs\n",
    "#             true_l = torch.sum(x_OHs_t, dim=1).sum()\n",
    "            true_l = trueLength(x_OHs_t.numpy())\n",
    "#             true_l = trueLength(x_OHs_t)\n",
    "            if L_OHs_trueLengths is None:\n",
    "                L_OHs_trueLengths = np.sum(L_OHs.numpy(), axis=2, dtype=np.uint8).sum(axis=1, dtype=np.uint8)\n",
    "#                 L_OHs_trueLengths = torch.sum(L_OHs_t, dim=2, dtype=torch.int32).sum(dim=1, dtype=torch.int32)\n",
    "            trueLength_mask = OHstack_to_trueLength_mask(x_OHs_t.numpy(), L_OHs_trueLengths)\n",
    "#             trueLength_mask = torch.from_numpy(OHstack_to_trueLength_mask(x_OHs_t.numpy(), L_OHs_trueLengths.numpy()))\n",
    "#             trueLength_mask = OHstack_to_trueLength_mask(x_OHs_t, L_OHs_trueLengths)\n",
    "            return (true_l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype)) * trueLength_mask\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "# def d_h_np_string_to_strings(x_OHs, L_OHs, paddedOHs=False, L_OHs_trueLengths=None, use_GPU=False):\n",
    "# # def d_h_np_string_to_strings(x_OHs, L_OHs, paddedOHs=False, L_OHs_trueLengths=None, my_dtype=None):\n",
    "# #     if my_dtype is None:\n",
    "# #         my_dtype = np.uint8\n",
    "# #         my_dtype = np.int8\n",
    "#     x_OHs = x_OHs.astype(my_dtype)\n",
    "#     L_OHs = L_OHs.astype(my_dtype)\n",
    "#     l = x_OHs.shape[0]\n",
    "#     if not paddedOHs:\n",
    "#         if not use_GPU:\n",
    "#             return l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)\n",
    "#         else:\n",
    "#             x_OHs_t = torch.from_numpy(x_OHs)#.type(torch.float16)\n",
    "#             L_OHs_t = torch.from_numpy(L_OHs)#.type(torch.float16)\n",
    "#             return l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype)\n",
    "# #             return l - torch.einsum('nls->n', x_OHs_t.type(torch.float16).cuda() * L_OHs_t.type(torch.float16).cuda())\n",
    "# #             l_t\n",
    "# #             raise Exception('under construction')\n",
    "#     else:\n",
    "#         true_l = trueLength(x_OHs)\n",
    "#         if L_OHs_trueLengths is None:\n",
    "#             L_OHs_trueLengths = np.sum(L_OHs, axis=2, dtype=my_dtype).sum(axis=1, dtype=my_dtype)\n",
    "#         trueLength_mask = OHstack_to_trueLength_mask(x_OHs, L_OHs_trueLengths)\n",
    "#         if not use_GPU:\n",
    "#             return (true_l - np.einsum('nls->n', x_OHs * L_OHs, dtype=my_dtype)) * trueLength_mask\n",
    "#         else:\n",
    "# #             true_l_t = \n",
    "#             x_OHs_t = torch.from_numpy(x_OHs)#.type(torch.float16)\n",
    "#             L_OHs_t = torch.from_numpy(L_OHs)#.type(torch.float16)\n",
    "#             L_OHs_trueLengths_t = torch.from_numpy(L_OHs_trueLengths)#.type(torch.float16)\n",
    "#             trueLength_mask_t = torch.from_numpy(trueLength_mask)#.type(torch.float16)\n",
    "#             return (true_l - torch.einsum('nls->n', x_OHs_t.cuda() * L_OHs_t.cuda()).cpu().numpy().astype(my_dtype))\n",
    "# #             raise Exception('under construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.694616Z",
     "start_time": "2019-11-01T20:05:30.666988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 40)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.j.u.n.ɪ.f.oʊ.ɹ.m.⋉.⋉'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  8, -10, -10, ..., -10, -10, -10], dtype=int8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_w_OHf.shape\n",
    "rand_w = OHsToDS(rand_w_OHf, OHXmap); rand_w\n",
    "\n",
    "d_h_np_string_to_strings(rand_w_OHf, Ws_npf, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.702938Z",
     "start_time": "2019-11-01T20:05:30.697055Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    rand_w_dists = d_h_np_string_to_strings(rand_w_OHf, Ws_npf, True)\n",
    "\n",
    "    for i, each_OH in enumerate(Ws_npf):\n",
    "        if trueLength(each_OH) == trueLength(rand_w_OHf):\n",
    "            each_w = OHsToDS(each_OH, OHXmap)\n",
    "            assert d_h(rand_w, each_w) == rand_w_dists[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.710088Z",
     "start_time": "2019-11-01T20:05:30.705625Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np_string_to_strings(choice(Ws_npf), Ws_npf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.717098Z",
     "start_time": "2019-11-01T20:05:30.712621Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np_string_to_strings(choice(Ws_npf), Ws_npf, True, Ws_npf_trueLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.723924Z",
     "start_time": "2019-11-01T20:05:30.719359Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit d_h_np_string_to_strings(choice(Ws_npf), Ws_npf, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Fortunately, it looks like applying a mask to account for padding has a small cost provided you pre-calculate the true lengths of every padded vector in the stack of strings you are computing distances with respect to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming distance between every pair of strings in a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.731179Z",
     "start_time": "2019-11-01T20:05:30.726508Z"
    }
   },
   "outputs": [],
   "source": [
    "# map_result2 = np.array(lmap(lambda key_w_OHf: np.array(lmap(lambda w_OHf: d_h_np(key_w_OHf, w_OHf, True),\n",
    "#                                                             Ws_npf)),\n",
    "#                             Ws_npf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.738521Z",
     "start_time": "2019-11-01T20:05:30.733803Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    #≈4m cmu+wittgenstein\n",
    "    map_result3 = np.stack([d_h_np_string_to_strings(key_w_OHf, Ws_npf, True, Ws_npf_trueLengths)\n",
    "                            for key_w_OHf in tqdm(Ws_npf)])\n",
    "    map_result3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.745899Z",
     "start_time": "2019-11-01T20:05:30.740936Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    map_result3[random_w_idx]\n",
    "    (map_result3 != length_mismatch_constant).nonzero()\n",
    "    word_idx_pairs_w_finite_hamming_distance = lzip(*(map_result3 != length_mismatch_constant).nonzero())\n",
    "    choices(word_idx_pairs_w_finite_hamming_distance, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.777493Z",
     "start_time": "2019-11-01T20:05:30.748413Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for idx_u, idx_v in choices(word_idx_pairs_w_finite_hamming_distance, k=100):\n",
    "        print('------------------------')\n",
    "        pprint_aligned_DSs(align_DSs([OHsToDS(Ws_npf[idx_u], OHXmap), \n",
    "                                      OHsToDS(Ws_npf[idx_v], OHXmap)]))\n",
    "        map_result3[idx_u, idx_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.810577Z",
     "start_time": "2019-11-01T20:05:30.780711Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    assert np.array_equal(map_result3[random_w_idx], \n",
    "                          d_h_np_string_to_strings(random_w_OHf, Ws_npf, True))\n",
    "    del map_result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:30.874375Z",
     "start_time": "2019-11-01T20:05:30.814542Z"
    }
   },
   "outputs": [],
   "source": [
    "def construct_hadamard_product_block(row_indices, A, B):\n",
    "    return np.einsum('mls,nls->mnls', A[row_indices], B, dtype=my_dtype)\n",
    "# def construct_hadamard_product_block(A_slice, B_slice):\n",
    "#     return np.einsum('mls,nls->mnls', A_slice, B_slice)\n",
    "\n",
    "def calculate_block_sum(block):\n",
    "    return np.einsum('mnls->mn', block, dtype=my_dtype)\n",
    "\n",
    "def block_sum_op(row_indices, A, B, l):\n",
    "    memTrigger()\n",
    "    return l - calculate_block_sum(construct_hadamard_product_block(row_indices, A, B))\n",
    "\n",
    "def construct_hadamard_product_block_t(A_block, B, use_GPU=True):\n",
    "    return torch.einsum('mls,nls->mnls', A_block, B).type(my_cpu_type)\n",
    "#     return torch.einsum('mls,nls->mnls', A_block, B)#.type(my_cpu_type)\n",
    "\n",
    "def calculate_block_sum_t(block):\n",
    "#     print(f\"block.dtype = {block.dtype}\")\n",
    "#     print(f\"block.device = {block.device}\")\n",
    "#     block_sum = torch.einsum('mnls->mn', block).type(my_cpu_type)\n",
    "#     print(f\"block_sum.dtype = {block_sum.dtype}\")\n",
    "#     print(f\"block_sum.device = {block_sum.device}\")\n",
    "#     print('computed block_sum.')\n",
    "#     return block_sum\n",
    "    return torch.einsum('mnls->mn', block).type(my_cpu_type)\n",
    "#     return torch.einsum('mnls->mn', block)#.type(my_cpu_type)\n",
    "\n",
    "def block_sum_op_t(A_block, B, l, use_GPU=True):\n",
    "# def block_sum_op_t(row_indices, A, B, l, use_GPU=True):\n",
    "    memTrigger()\n",
    "    torch.cuda.empty_cache()\n",
    "#     print(f'row_indices.dtype = {row_indices.dtype}')\n",
    "#     print(f'A.dtype = {A.dtype}')\n",
    "#     print(f'B.dtype = {B.dtype}')\n",
    "#     print(f'l.dtype = {l.dtype}')\n",
    "\n",
    "#     A_c = A[row_indices].cuda()\n",
    "#     B_c = B.cuda()\n",
    "#     prodBlock = construct_hadamard_product_block_t(A_c, B_c)\n",
    "\n",
    "#     print(f\"prodBlock.dtype = {prodBlock.dtype}\")\n",
    "#     print(f\"prodBlock.device = {prodBlock.device}\")\n",
    "\n",
    "#     blockSum_c = calculate_block_sum_t(prodBlock)\n",
    "#     blockSum = blockSum_c.cpu()\n",
    "#     print(f\"blockSum.dtype = {blockSum.dtype}\")\n",
    "#     print(f\"l.dtype = {l.dtype}\")\n",
    "#     result = l - blockSum.type(my_cpu_type)\n",
    "    \n",
    "#     return result\n",
    "#     return l - (calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda())).cpu())\n",
    "#     return l - calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda())).cpu().type(my_cpu_type)\n",
    "#     return l - calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda())).cpu()\n",
    "#     return (l.cuda() - calculate_block_sum_t(construct_hadamard_product_block_t(A[row_indices].cuda(), B.cuda()))).cpu()\n",
    "#     return (l.cuda() - calculate_block_sum_t(construct_hadamard_product_block_t(A_block.cuda(), B.cuda()))).cpu()\n",
    "    return l - (calculate_block_sum_t(construct_hadamard_product_block_t(A_block.cuda(), B.cuda()))).cpu()\n",
    "\n",
    "def H_d_np(L_OHs, paddedOHs=False, parallel=False, use_GPU=False, wec=False, wec_block_size=100):\n",
    "# def H_d_np(L_OHs, paddedOHs=False, parallel=False, my_dtype=None):\n",
    "#     if my_dtype is None:\n",
    "#         my_dtype = np.uint8\n",
    "#         my_dtype = np.int8\n",
    "    L_OHs = L_OHs.astype(my_dtype)\n",
    "    L_OHs_trueLengths = np.sum(L_OHs, axis=2, dtype=np.uint8).sum(axis=1, dtype=np.uint8)\n",
    "    if not parallel and not use_GPU:\n",
    "        if not wec:\n",
    "    #         return np.stack([d_h_np_string_to_strings(key_w_OHf, L_OHs, paddedOHs=paddedOHs, my_dtype=my_dtype)\n",
    "            return np.stack([d_h_np_string_to_strings(key_w_OHf, L_OHs, paddedOHs=paddedOHs, L_OHs_trueLengths=L_OHs_trueLengths).astype(my_dtype)\n",
    "                             for key_w_OHf in tqdm(L_OHs)]).astype(my_dtype)\n",
    "        else:\n",
    "            m = L_OHs_trueLengths.shape[0]\n",
    "            n = m\n",
    "            stampedNote('Start wec')\n",
    "            lengthTerm = np.einsum('m,mn->mn', L_OHs_trueLengths.astype(my_dtype), np.ones((m,n), dtype=my_dtype))\n",
    "            stampedNote(f'lengthTerm.nbytes / 1e9 = {lengthTerm.nbytes / 1e9}')\n",
    "            print(f'{lengthTerm.dtype}')\n",
    "            \n",
    "            block_length = wec_block_size\n",
    "            num_blocks = int(np.rint( m / block_length ))\n",
    "            block_onsets = [block_index * block_length \n",
    "                            for block_index in range(num_blocks)]\n",
    "            block_ends = block_onsets[1:] + [m]\n",
    "            block_startStop_pairs = tuple(zip(block_onsets, block_ends))\n",
    "            V = 1\n",
    "            P_d = np.concatenate(list(par(delayed(block_sum_op)(np.arange(block_start, block_end), L_OHs, L_OHs, lengthTerm[np.arange(block_start, block_end)])\n",
    "                                          for block_start, block_end in tqdm(block_startStop_pairs, \n",
    "                                                                             total=len(block_startStop_pairs)))))\n",
    "            V = 10\n",
    "            return P_d\n",
    "#             prodTerm = np.einsum('mij,nij->mnij', L_OHs, L_OHs) #memory error, naturally\n",
    "#             stampedNote(f'prodTerm.nbytes / 1e9 = {prodTerm.nbytes / 1e9}')\n",
    "#             print(f'{prodTerm.dtype}')\n",
    "            \n",
    "#             reducTerm = np.einsum('mnls->mn', prodTerm)\n",
    "#             del prodTerm\n",
    "#             stampedNote(f'reducTerm.nbytes / 1e9 = {reducTerm.nbytes / 1e9}')\n",
    "#             print(f'{reducTerm.dtype}')\n",
    "            \n",
    "#             result = lengthTerm - reducTerm\n",
    "#             del lengthTerm\n",
    "#             del reducTerm\n",
    "#             return result\n",
    "    elif parallel and not use_GPU:\n",
    "#         return np.stack(par(delayed(d_h_np_string_to_strings)(key_w_OHf, L_OHs, paddedOHs=paddedOHs, my_dtype=my_dtype)\n",
    "        return np.stack(par(delayed(d_h_np_string_to_strings)(key_w_OHf, L_OHs, paddedOHs=paddedOHs, L_OHs_trueLengths=L_OHs_trueLengths)\n",
    "                            for key_w_OHf in L_OHs)).astype(my_dtype)\n",
    "    else:\n",
    "        if not wec:\n",
    "            return np.stack([d_h_np_string_to_strings(torch.from_numpy(key_w_OHf), torch.from_numpy(L_OHs), paddedOHs=paddedOHs, L_OHs_trueLengths=torch.from_numpy(L_OHs_trueLengths), use_GPU=True)\n",
    "                             for key_w_OHf in tqdm(L_OHs)]).astype(my_dtype)\n",
    "        else:\n",
    "            torch.cuda.empty_cache()\n",
    "            m = L_OHs_trueLengths.shape[0]\n",
    "            n = m\n",
    "            stampedNote('Start wec')\n",
    "            lengthTerm = np.einsum('m,mn->mn', L_OHs_trueLengths.astype(my_dtype), np.ones((m,n), dtype=my_dtype))\n",
    "            stampedNote(f'lengthTerm.nbytes / 1e9 = {lengthTerm.nbytes / 1e9}')\n",
    "            print(f'{lengthTerm.dtype}')\n",
    "            lengthTerm = torch.from_numpy(lengthTerm)\n",
    "            \n",
    "            block_length = wec_block_size\n",
    "            num_blocks = int(np.rint( m / block_length ))\n",
    "            block_onsets = [block_index * block_length \n",
    "                            for block_index in range(num_blocks)]\n",
    "            block_ends = block_onsets[1:] + [m]\n",
    "            block_startStop_pairs = tuple(zip(block_onsets, block_ends))\n",
    "            blockRanges = tuple([torch.arange(block_start, block_end)\n",
    "                                 for block_start, block_end in block_startStop_pairs])\n",
    "            \n",
    "            L_OHs_t = torch.from_numpy(L_OHs)\n",
    "            \n",
    "#             P_d = np.concatenate([block_sum_op_t(torch.arange(block_start, block_end), L_OHs_t, L_OHs_t, lengthTerm[torch.arange(block_start, block_end)]).numpy()\n",
    "#                                   for block_start, block_end in tqdm(block_startStop_pairs, \n",
    "#                                                                      total=len(block_startStop_pairs))])\n",
    "            P_d = np.concatenate([block_sum_op_t(L_OHs_t[block_range], L_OHs_t, lengthTerm[block_range]).numpy()\n",
    "                                          for block_range in tqdm(blockRanges, \n",
    "                                                                  total=len(blockRanges))])\n",
    "            return P_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:31.021902Z",
     "start_time": "2019-11-01T20:05:30.877647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.6G        181G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.183940Z",
     "start_time": "2019-11-01T20:05:31.026970Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0656s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 622 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 748 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 886 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1024 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1174 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1324 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1486 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1648 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1822 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1996 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2182 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2368 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2566 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2764 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2974 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3406 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3628 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3862 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4096 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4342 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4588 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4846 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 5104 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 5374 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 5644 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5926 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 6404 out of 6404 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6404, 6404)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.041011216"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ≈2.5m cmu+wittgenstein\n",
    "# 36s NXT_swbd+wittgenstein\n",
    "H_d_np_W = H_d_np(Ws_npf, paddedOHs=True, parallel=True)\n",
    "H_d_np_W.shape\n",
    "H_d_np_W.nbytes / 1e9\n",
    "H_d_np_W.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.329132Z",
     "start_time": "2019-11-01T20:05:36.186936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.6G        181G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.337178Z",
     "start_time": "2019-11-01T20:05:36.331790Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if g and testing:\n",
    "    # ≈2.5m cmu+wittgenstein\n",
    "    torch.cuda.empty_cache()\n",
    "    H_d_np_W_g = H_d_np(Ws_npf, paddedOHs=True, parallel=False, use_GPU=True)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.345458Z",
     "start_time": "2019-11-01T20:05:36.339644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6404, 20, 40)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_npf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.486977Z",
     "start_time": "2019-11-01T20:05:36.348082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.6G        181G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.502801Z",
     "start_time": "2019-11-01T20:05:36.492579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    # ≈0.5m NXT_swbd+wittgenstein, for block size 25 and memory overhead is ? (peak=?GB)\n",
    "    # ≈1.8m cmu+wittgenstein, for block size 100 and memory overhead is ENOROMOUS (peak=90-95GB)\n",
    "    # ≈1.7m cmu+wittgenstein, for block size 50 and memory overhead is tolerable (peak=45-50GB)\n",
    "    # ≈1.9m cmu+wittgenstein, for block size 25 and memory overhead is tolerable (peak=25-27GB)\n",
    "    H_d_np_W_wec = H_d_np(Ws_npf, paddedOHs=True, parallel=False, use_GPU=False, wec=True, wec_block_size=25)\n",
    "\n",
    "if g and testing:\n",
    "    # 28s NXT_swbd+wittgenstein, block size 10, peak GPU mem usage = 1.6GB\n",
    "    # ≈3m cmu+wittgenstein, for block size 5, peak GPU mem usage = 1.8GB \n",
    "    # ≈3.4m cmu+wittgenstein, for block size 20, peak GPU mem usage = 5.4GB \n",
    "    # ≈2.6m cmu+wittgenstein, for block size 10, peak GPU mem usage = 3.0GB \n",
    "    # ≈1m cmu+wittgenstein, for block size 10, peak GPU mem usage = 5.6GB \n",
    "    torch.cuda.empty_cache()\n",
    "    H_d_np_W_wec = H_d_np(Ws_npf, paddedOHs=True, parallel=False, use_GPU=True, wec=True, wec_block_size=10)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.641313Z",
     "start_time": "2019-11-01T20:05:36.505698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.6G        181G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.650907Z",
     "start_time": "2019-11-01T20:05:36.646165Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if testing:\n",
    "#     #using the multiprocessing backend ensures parallelization preserves order\n",
    "#     H_d_np_W_noPar = H_d_np(Ws_npf, paddedOHs=True, parallel=False)\n",
    "#     assert np.array_equal(H_d_np_W, H_d_np_W_noPar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:36.656565Z",
     "start_time": "2019-11-01T20:05:36.653411Z"
    }
   },
   "outputs": [],
   "source": [
    "# !free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.021414Z",
     "start_time": "2019-11-01T20:05:36.658912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27882, 20, 40)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0223056"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_npf = lexiconToFixedSizeOHs(Ps_t)\n",
    "Ps_npf.shape\n",
    "Ps_npf.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.175255Z",
     "start_time": "2019-11-01T20:05:40.025084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           188G        5.7G        181G        4.2M        1.6G        182G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.195070Z",
     "start_time": "2019-11-01T20:05:40.180387Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6404"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "27882"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.052753927818023676"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "len(Ps_t)\n",
    "(len(Ws_t) * len(Ws_t)) / (len(Ps_t) * len(Ps_t))\n",
    "\n",
    "#wrong by about an order of magnitude for cmu?\n",
    "#est amount of memory required for H_d_np_P as a multiple of the memory required for H_d_np_W\n",
    "# 1 / ((len(Ws_t) * len(Ws_t)) / (len(Ps_t) * len(Ps_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.216247Z",
     "start_time": "2019-11-01T20:05:40.198477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041011216"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "182.02001953125"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(H_d_np_W.nbytes / 1e9)\n",
    "\n",
    "#wrong by about an order of magnitude for cmu?\n",
    "#est amount of memory required for H_d_np_P in GB\n",
    "# H_d_np_P_est_space_GB = (H_d_np_W.nbytes / 1e9) * (1 / ((len(Ws_t) * len(Ws_t)) / (len(Ps_t) * len(Ps_t))))\n",
    "# H_d_np_P_est_space_GB\n",
    "\n",
    "\n",
    "memAvailable()\n",
    "# (H_d_np_W.nbytes / 1e9) / memTotal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.223985Z",
     "start_time": "2019-11-01T20:05:40.218624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.231303Z",
     "start_time": "2019-11-01T20:05:40.226687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered_H_d_P.npy'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o + '_H_d_P' + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:05:40.237197Z",
     "start_time": "2019-11-01T20:05:40.233759Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:08:05.691428Z",
     "start_time": "2019-11-01T20:05:48.424954Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1123s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 770 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1330 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1408 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1490 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1572 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1744 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1834 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1924 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2018 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2112 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2210 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2308 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2410 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2512 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2618 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2724 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2834 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2944 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3058 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3172 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3290 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3408 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3530 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3652 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3778 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3904 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4164 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4298 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4432 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4570 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4708 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4850 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5138 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 5284 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5434 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 5584 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5738 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 5892 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6050 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6208 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6370 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 6532 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6698 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6864 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7034 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 7204 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7378 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 7552 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 7730 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 7908 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8090 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 8272 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 8458 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 8644 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 8834 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9024 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9218 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9412 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9610 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9808 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 10010 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 10212 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 10418 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 10624 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 10834 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 11044 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 11258 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 11472 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 11690 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 11908 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 12130 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 12352 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12578 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12804 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 13034 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13264 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13498 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13732 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13970 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14208 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14450 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14692 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14938 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 15184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 15434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 15684 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 15938 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 16450 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16708 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16970 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 17232 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 17498 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 17764 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18304 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18578 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18852 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 19130 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 19408 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 19690 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 19972 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 20258 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 20544 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 20834 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 21124 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 21418 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 21712 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 22010 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 22308 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 22610 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 22912 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 23218 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 23524 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 23834 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 24144 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 24458 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 24772 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 25090 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 25408 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 25730 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 26052 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 26378 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 26704 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 27034 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 27364 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 27698 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 27882 out of 27882 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "# H_d_np_P = H_d_np(Ps_npf, paddedOHs=True, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:08:05.701487Z",
     "start_time": "2019-11-01T20:08:05.695005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27882, 27882)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H_d_np_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:08:05.763637Z",
     "start_time": "2019-11-01T20:08:05.704476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27882"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(Ps_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:08:05.786813Z",
     "start_time": "2019-11-01T20:08:05.766809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊',\n",
       " '⋊.aɪ',\n",
       " '⋊.aɪ.d',\n",
       " '⋊.aɪ.d.i',\n",
       " '⋊.aɪ.d.i.ɑ',\n",
       " '⋊.aɪ.d.i.ɑ.l',\n",
       " '⋊.aɪ.d.i.ɑ.l.ʌ',\n",
       " '⋊.aɪ.d.i.ɑ.l.ʌ.dʒ',\n",
       " '⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i',\n",
       " '⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉',\n",
       " '⋊.aɪ.d.i.ɑ.l.ʌ.dʒ.i.⋉.⋉',\n",
       " '⋊.aɪ.d.i.ʌ',\n",
       " '⋊.aɪ.d.i.ʌ.l',\n",
       " '⋊.aɪ.d.i.ʌ.l.i',\n",
       " '⋊.aɪ.d.i.ʌ.l.i.⋉',\n",
       " '⋊.aɪ.d.i.ʌ.l.i.⋉.⋉',\n",
       " '⋊.aɪ.d.i.ʌ.l.ɪ',\n",
       " '⋊.aɪ.d.i.ʌ.l.ɪ.s',\n",
       " '⋊.aɪ.d.i.ʌ.l.ɪ.s.t',\n",
       " '⋊.aɪ.d.i.ʌ.l.ɪ.s.t.ɪ')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ɑ.l.ʌ.dʒ'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.ʌ.l.i.⋉'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ps_t[:20]\n",
    "# Ps_t[7]\n",
    "# Ps_t[14]\n",
    "# H_d_np_P[7,14]\n",
    "# H_d_np_P[14,7]\n",
    "# lev.eval(Ps_t[7], Ps_t[14])\n",
    "# lev.eval(ds2t(Ps_t[7]), ds2t(Ps_t[14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:08:05.804701Z",
     "start_time": "2019-11-01T20:08:05.794384Z"
    }
   },
   "outputs": [],
   "source": [
    "# def lev_helper(u_idx, v_idx):\n",
    "#     u = ds2t(Ps_t[u_idx])\n",
    "#     v = ds2t(Ps_t[v_idx])\n",
    "#     return (u_idx, v_idx, lev.eval(u,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:08:24.929143Z",
     "start_time": "2019-11-01T20:08:24.922645Z"
    }
   },
   "outputs": [],
   "source": [
    "# L_d_np_P = np.zeros(H_d_np_P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T20:09:18.736532Z",
     "start_time": "2019-11-01T20:09:18.718150Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (0, 6),\n",
       " (0, 7),\n",
       " (0, 8),\n",
       " (0, 9),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (1, 8),\n",
       " (1, 9),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (2, 9),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (3, 7),\n",
       " (3, 8),\n",
       " (3, 9),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (4, 7),\n",
       " (4, 8),\n",
       " (4, 9),\n",
       " (5, 0),\n",
       " (5, 1),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (5, 4),\n",
       " (5, 5),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (5, 8),\n",
       " (5, 9),\n",
       " (6, 0),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (6, 5),\n",
       " (6, 6),\n",
       " (6, 7),\n",
       " (6, 8),\n",
       " (6, 9),\n",
       " (7, 0),\n",
       " (7, 1),\n",
       " (7, 2),\n",
       " (7, 3),\n",
       " (7, 4),\n",
       " (7, 5),\n",
       " (7, 6),\n",
       " (7, 7),\n",
       " (7, 8),\n",
       " (7, 9),\n",
       " (8, 0),\n",
       " (8, 1),\n",
       " (8, 2),\n",
       " (8, 3),\n",
       " (8, 4),\n",
       " (8, 5),\n",
       " (8, 6),\n",
       " (8, 7),\n",
       " (8, 8),\n",
       " (8, 9),\n",
       " (9, 0),\n",
       " (9, 1),\n",
       " (9, 2),\n",
       " (9, 3),\n",
       " (9, 4),\n",
       " (9, 5),\n",
       " (9, 6),\n",
       " (9, 7),\n",
       " (9, 8),\n",
       " (9, 9)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(product(np.arange(10), np.arange(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-01T20:10:05.216Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0181s.) Setting batch_size=22.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0468s.) Setting batch_size=188.\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 790 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1164 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0939s.) Setting batch_size=800.\n",
      "[Parallel(n_jobs=-1)]: Done 3906 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 7478 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 11426 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (41.0168s.) Setting batch_size=400.\n",
      "[Parallel(n_jobs=-1)]: Done 27002 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done 45402 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 60202 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 70202 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.1819s.) Setting batch_size=200.\n",
      "[Parallel(n_jobs=-1)]: Done 80202 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 91002 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 98002 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 103802 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 109602 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1985s.) Setting batch_size=402.\n",
      "[Parallel(n_jobs=-1)]: Done 115802 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (37.6777s.) Setting batch_size=201.\n",
      "[Parallel(n_jobs=-1)]: Done 122810 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 136076 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 146528 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.4853s.) Setting batch_size=100.\n",
      "[Parallel(n_jobs=-1)]: Done 153563 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 160598 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1079s.) Setting batch_size=370.\n",
      "[Parallel(n_jobs=-1)]: Done 165914 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 170424 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184854 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (3.8707s.) Setting batch_size=185.\n",
      "[Parallel(n_jobs=-1)]: Done 199284 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 210199 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1989s.) Setting batch_size=370.\n",
      "[Parallel(n_jobs=-1)]: Done 217784 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (35.7187s.) Setting batch_size=185.\n",
      "[Parallel(n_jobs=-1)]: Done 229439 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 244054 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1996s.) Setting batch_size=370.\n",
      "[Parallel(n_jobs=-1)]: Done 252379 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (4.1344s.) Setting batch_size=185.\n",
      "[Parallel(n_jobs=-1)]: Done 267179 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280129 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1883s.) Setting batch_size=392.\n",
      "[Parallel(n_jobs=-1)]: Done 288824 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (31.1287s.) Setting batch_size=196.\n",
      "[Parallel(n_jobs=-1)]: Done 299545 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 318557 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 328553 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1949s.) Setting batch_size=402.\n",
      "[Parallel(n_jobs=-1)]: Done 338549 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (19.1683s.) Setting batch_size=201.\n",
      "[Parallel(n_jobs=-1)]: Done 358207 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.3167s.) Setting batch_size=100.\n",
      "[Parallel(n_jobs=-1)]: Done 371071 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1794s.) Setting batch_size=222.\n",
      "[Parallel(n_jobs=-1)]: Done 379803 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1970s.) Setting batch_size=450.\n",
      "[Parallel(n_jobs=-1)]: Done 387987 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (25.5087s.) Setting batch_size=225.\n",
      "[Parallel(n_jobs=-1)]: Done 405885 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 426135 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1945s.) Setting batch_size=462.\n",
      "[Parallel(n_jobs=-1)]: Done 439410 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (3.7845s.) Setting batch_size=231.\n",
      "[Parallel(n_jobs=-1)]: Done 462876 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1983s.) Setting batch_size=466.\n",
      "[Parallel(n_jobs=-1)]: Done 480201 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (28.6317s.) Setting batch_size=233.\n",
      "[Parallel(n_jobs=-1)]: Done 497112 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (4.6594s.) Setting batch_size=116.\n",
      "[Parallel(n_jobs=-1)]: Done 522043 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1985s.) Setting batch_size=232.\n",
      "[Parallel(n_jobs=-1)]: Done 534382 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1452s.) Setting batch_size=638.\n",
      "[Parallel(n_jobs=-1)]: Done 543546 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (21.8854s.) Setting batch_size=319.\n",
      "[Parallel(n_jobs=-1)]: Done 567964 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (33.5890s.) Setting batch_size=159.\n",
      "[Parallel(n_jobs=-1)]: Done 599864 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1486s.) Setting batch_size=426.\n",
      "[Parallel(n_jobs=-1)]: Done 614037 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.1997s.) Setting batch_size=213.\n",
      "[Parallel(n_jobs=-1)]: Done 640494 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1934s.) Setting batch_size=440.\n",
      "[Parallel(n_jobs=-1)]: Done 655404 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (22.3278s.) Setting batch_size=220.\n",
      "[Parallel(n_jobs=-1)]: Done 674840 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1999s.) Setting batch_size=440.\n",
      "[Parallel(n_jobs=-1)]: Done 698600 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (24.2353s.) Setting batch_size=220.\n",
      "[Parallel(n_jobs=-1)]: Done 721260 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.6198s.) Setting batch_size=110.\n",
      "[Parallel(n_jobs=-1)]: Done 743040 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1670s.) Setting batch_size=262.\n",
      "[Parallel(n_jobs=-1)]: Done 755140 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1946s.) Setting batch_size=538.\n",
      "[Parallel(n_jobs=-1)]: Done 772358 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (18.3978s.) Setting batch_size=269.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.2086s.) Setting batch_size=134.\n",
      "[Parallel(n_jobs=-1)]: Done 808121 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1381s.) Setting batch_size=388.\n",
      "[Parallel(n_jobs=-1)]: Done 825594 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.4844s.) Setting batch_size=194.\n",
      "[Parallel(n_jobs=-1)]: Done 848118 tasks      | elapsed: 10.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1976s.) Setting batch_size=392.\n",
      "[Parallel(n_jobs=-1)]: Done 869070 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (17.4808s.) Setting batch_size=196.\n",
      "[Parallel(n_jobs=-1)]: Done 895874 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1962s.) Setting batch_size=398.\n",
      "[Parallel(n_jobs=-1)]: Done 911750 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (27.5461s.) Setting batch_size=199.\n",
      "[Parallel(n_jobs=-1)]: Done 939360 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1941s.) Setting batch_size=410.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (23.6422s.) Setting batch_size=205.\n",
      "[Parallel(n_jobs=-1)]: Done 956510 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1994s.) Setting batch_size=410.\n",
      "[Parallel(n_jobs=-1)]: Done 984800 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (18.8695s.) Setting batch_size=205.\n",
      "[Parallel(n_jobs=-1)]: Done 1009605 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.6634s.) Setting batch_size=102.\n",
      "[Parallel(n_jobs=-1)]: Done 1031540 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1970s.) Setting batch_size=206.\n",
      "[Parallel(n_jobs=-1)]: Done 1044328 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1136s.) Setting batch_size=724.\n"
     ]
    }
   ],
   "source": [
    "# L_d_np_P_updates = par(delayed(lev_helper)(u_idx, v_idx) for u_idx, v_idx in list(product(np.arange(len(Ps_t)), np.arange(len(Ps_t)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:10.755333Z",
     "start_time": "2019-09-12T19:24:55.218578Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start wec @ 12:24:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1412 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengthTerm.nbytes / 1e9 = 0.4485924 @ 12:24:55\n",
      "int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "  0%|          | 1/1412 [00:00<14:21,  1.64it/s][Parallel(n_jobs=-1)]: Batch computation too fast (0.1084s.) Setting batch_size=2.\n",
      "  5%|▍         | 64/1412 [00:00<09:37,  2.34it/s][Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.2s\n",
      "  7%|▋         | 99/1412 [00:00<04:39,  4.70it/s][Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.4s\n",
      "  9%|▊         | 123/1412 [00:01<03:13,  6.65it/s][Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      " 10%|█         | 142/1412 [00:01<02:15,  9.34it/s][Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.6s\n",
      " 12%|█▏        | 170/1412 [00:01<01:35, 13.05it/s][Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.7s\n",
      " 16%|█▌        | 221/1412 [00:01<00:39, 29.79it/s][Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    1.3s\n",
      " 18%|█▊        | 250/1412 [00:02<00:24, 47.70it/s][Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    1.6s\n",
      " 21%|██        | 295/1412 [00:02<00:16, 66.54it/s][Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    2.1s\n",
      " 23%|██▎       | 323/1412 [00:02<00:12, 88.19it/s][Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    2.3s\n",
      " 25%|██▌       | 360/1412 [00:03<00:13, 77.14it/s][Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:    2.8s\n",
      " 29%|██▉       | 416/1412 [00:03<00:13, 74.66it/s] [Parallel(n_jobs=-1)]: Done 292 tasks      | elapsed:    3.3s\n",
      " 33%|███▎      | 461/1412 [00:04<00:08, 107.98it/s][Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    3.7s\n",
      " 36%|███▌      | 506/1412 [00:04<00:09, 97.66it/s] [Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    4.1s\n",
      " 39%|███▉      | 554/1412 [00:05<00:10, 81.97it/s] [Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    4.7s\n",
      " 43%|████▎     | 601/1412 [00:05<00:08, 90.57it/s] [Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    5.2s\n",
      " 47%|████▋     | 658/1412 [00:06<00:07, 97.40it/s][Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:    5.7s\n",
      " 50%|████▉     | 704/1412 [00:06<00:08, 83.75it/s][Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:    6.3s\n",
      " 55%|█████▍    | 771/1412 [00:07<00:07, 90.83it/s] [Parallel(n_jobs=-1)]: Done 650 tasks      | elapsed:    7.0s\n",
      " 59%|█████▉    | 833/1412 [00:08<00:06, 87.72it/s] [Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:    7.5s\n",
      " 63%|██████▎   | 886/1412 [00:08<00:04, 106.84it/s][Parallel(n_jobs=-1)]: Done 770 tasks      | elapsed:    8.1s\n",
      " 67%|██████▋   | 952/1412 [00:09<00:04, 102.77it/s][Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:    8.7s\n",
      " 72%|███████▏  | 1022/1412 [00:09<00:03, 104.09it/s][Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:    9.4s\n",
      " 77%|███████▋  | 1088/1412 [00:10<00:03, 102.23it/s][Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:   10.1s\n",
      " 81%|████████  | 1140/1412 [00:11<00:03, 77.03it/s] [Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:   10.8s\n",
      " 86%|████████▌ | 1215/1412 [00:12<00:02, 80.27it/s][Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:   11.5s\n",
      " 92%|█████████▏| 1300/1412 [00:12<00:01, 99.37it/s][Parallel(n_jobs=-1)]: Done 1178 tasks      | elapsed:   12.3s\n",
      " 97%|█████████▋| 1376/1412 [00:13<00:00, 84.63it/s][Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:   13.0s\n",
      "100%|██████████| 1412/1412 [00:13<00:00, 100.93it/s]\n",
      "[Parallel(n_jobs=-1)]: Done 1412 out of 1412 | elapsed:   14.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4485924"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if true:\n",
    "if len(Ps_t) > 60000 and (memAvailable() < 160):\n",
    "# if H_d_np_P_est_space_GB > 100 or (memAvailable() - H_d_np_P_est_space_GB) < 5:\n",
    "    print('Constructing H_d_np_W via memory mapping *now*...')\n",
    "    \n",
    "    H_d_np_P_fp = o + '_H_d_P' + '.npy'\n",
    "    H_d_np_P = np.memmap(H_d_np_P_fp, dtype=my_dtype, mode='w+', shape=(len(Ps_t), len(Ps_t)))\n",
    "    if g:\n",
    "        H_d_np_P[:] = H_d_np(Ps_npf, paddedOHs=True, parallel=False, use_GPU=True)\n",
    "    else:\n",
    "        H_d_np_P[:] = H_d_np(Ps_npf, paddedOHs=True, parallel=True)\n",
    "        \n",
    "    H_d_P_md = {'W':{'from fp':p,\n",
    "                     'changes':'sorted',\n",
    "                     'size':len(Ws_t)},\n",
    "                     'P':{'from_fp':p,\n",
    "                          'changes':'extracted from W, sorted',\n",
    "                          'size':len(Ps_t)}}\n",
    "    exportMatrixMetadata(o + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         o + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         H_d_np_P,\n",
    "                         H_d_P_md,\n",
    "                         'Step 4b',\n",
    "                         'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                        {'Storage':'file is MEMORY MAPPED.'})\n",
    "        \n",
    "    alreadyMemoryMapped_H_d_p = True\n",
    "else:\n",
    "    alreadyMemoryMapped_H_d_p = False\n",
    "#     paddedOHs, parallel, use_GPU, wec, wec_block_size\n",
    "\n",
    "\n",
    "    #10.5m = 91.5cps NXT_swbd+wittgenstein, peak memory usage @ ?/54941 calcs ≈GB (baseline 25-27GB), peak GPU RAM usage 6.7GB\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, True, True, 15)\n",
    "\n",
    "    #≈35cps cmu+wittgenstein, peak memory usage @ ≈12940/129403 calcs ≈29.5GB (baseline 13GB), peak GPU RAM use 5.6GB\n",
    "    #8.83m = 103.6cps NXT_swbd+wittgenstein, peak memory usage @ ?/54941 calcs ≈GB (baseline 25-27GB), peak GPU RAM usage 2.7GB\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, True, True, 5)\n",
    "    \n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, True, True, 3) #≈33cps cmu+wittgenstein, peak memory usage @ 12942/129403 calcs ≈37.8GB (baseline 21GB), peak GPU RAM use 3.7GB\n",
    "\n",
    "\n",
    "    #5.5m = 166.5cps NXT_swbd+wittgenstein, peak memory usage ≈102GB, (baseline 34GB)\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 45)\n",
    "\n",
    "    #5.5m = 166.5cps NXT_swbd+wittgenstein, peak memory usage ≈73GB, (baseline 28-30GB)\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 25)\n",
    "\n",
    "    #4.5cps (67.5cps?) cmu+wittgenstein, peak memory usage @ 300/129403 calcs ≈98GB\n",
    "    #5.5m = 166.5cps NXT_swbd+wittgenstein, peak memory usage ≈56GB (baseline 28GB)\n",
    "    H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 15)\n",
    "\n",
    "    #6.6cps (66cps?) cmu+wittgenstein, peak memory usage @ 1246/129403 calcs ≈58GB\n",
    "#     H_d_np_P = H_d_np(Ps_npf, True, False, False, True, 10) \n",
    "\n",
    "#     if g:\n",
    "#         #≈53 cps cmu+wittgenstein, peak memory usage @ ≈12940/129403 calcs ≈10.8GB (baseline 7GB), peak GPU RAM usage 1.7GB\n",
    "#         #7.13m = 128 cps NXT_swbd+wittgenstein, peak GPU RAM usage 1.1GB\n",
    "#         H_d_np_P = H_d_np(Ps_npf, True, False, True) \n",
    "#     else:\n",
    "#         #57 cps cmu+wittgenstein, w/ 129403 calcs to do for cmu\n",
    "#         #7.9m = 115.9 cps NXT_swbd+wittgenstein w/ 54941 calcs to do\n",
    "#         H_d_np_P = H_d_np(Ps_npf, True, True) \n",
    "    \n",
    "    H_d_np_P.shape\n",
    "    H_d_np_P.nbytes / 1e9\n",
    "    H_d_np_P.dtype\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:12.126829Z",
     "start_time": "2019-09-12T19:25:12.123204Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    (H_d_np_P == np.nan).nonzero() #should be empty\n",
    "    assert (H_d_np_P == np.nan).nonzero()[0].size == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:12.455130Z",
     "start_time": "2019-09-12T19:25:12.291182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        2.0G        7.0G        105M        116G        122G\r\n",
      "Swap:          2.0G        104M        1.9G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-cousin calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions, motivation, and calculation sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $s$ be a finite-length string over $\\Sigma$ and let $L$ be a finite set of strings over $\\Sigma$.\n",
    "\n",
    "**k-sphere**: $s'$ is in the *exact* $k$-sphere of $s$ w.r.t. $L$ iff $s' \\in L \\land $ the Hamming distance of $s'$ from $s$ is *exactly* $k$.\n",
    "\n",
    "**k-cousin**: string $p$ is an *exact* $k$-cousin of segmental wordform $w$ wr.t. $L$ iff\n",
    " - $w \\in L$\n",
    " - $p \\in \\text{prefixes}(L)$\n",
    " - $\\exists p' \\in \\text{exact-}k\\text{-sphere}(p) \\cap \\text{prefixes}(w)$\n",
    " - i.e. if $w$, when trimmed to length $|p|$ to produce prefix $p'$ has exactly Hamming distance $k$ from $p$, then $p$ and $w$ are exactly $k$-cousins.\n",
    " - *NB:* if $|w| < p$, then $p$ and $w$ are $\\infty$-cousins, since the Hamming distance between the closest prefix $p' = w$ of $w$ and $p$ is $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**: Consider incremental word recognition:\n",
    " - for low $k$, the exact $k$-cousins of a prefix $p$ are complete wordforms that are more plausible full intended wordforms causing $p$ than higher exact $k$-cousins\n",
    " - for low $k$, the exact $k$-cousins of a wordform $w$ are prefixes that are more likely incremental misperceptions or misproductions of $w$ than higher $k$-cousins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculation sketch**:\n",
    " 1. Calculate the pairwise Hamming distances between all pairs of prefixes.\n",
    " 2. Given a mapping (calculated earlier) from every wordform (index) $w$ and length $l$ to the prefix (index) $p$ that results when $w$ is trimmed to length $l$, we can trivially calculate for every prefix-wordform pair $p', w'$ the exact $k$ s.t. $p'$ and $w$ are exact $k$-cousins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:15.084647Z",
     "start_time": "2019-09-12T19:25:15.080646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_d_np_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:15.453199Z",
     "start_time": "2019-09-12T19:25:15.451122Z"
    }
   },
   "outputs": [],
   "source": [
    "# P_idxs_of_Ws_t = np.array([w_idx_to_p_idx[w_idx] for w_idx in range(len(Ws_t))])\n",
    "# assert Ws_t == tuple([Ps_t[p_idx] for p_idx in P_idxs_of_Ws_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:15.784557Z",
     "start_time": "2019-09-12T19:25:15.773079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,     7,    10, ..., 21171, 21175, 21178])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_idxs_of_trimmed_Ws_t = lambda l: np.array([w_idx_to_l_to_p_idx.get((w_idx, l), None)\n",
    "                                             for w_idx in range(len(Ws_t))])\n",
    "P_idxs_of_trimmed_Ws_t(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:18.065787Z",
     "start_time": "2019-09-12T19:25:18.061190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cousin_function_np_shape = (len(Ps_t), len(Ws_t))\n",
    "k_cousin_function_np_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:18.631591Z",
     "start_time": "2019-09-12T19:25:18.626198Z"
    }
   },
   "outputs": [],
   "source": [
    "H_d_np_col_retrieval = lambda p_idx, p_idxs_or_Nones: np.array([H_d_np_P[p_idx, p_idx_prime]\n",
    "                                                                if p_idx_prime is not None else length_mismatch_constant\n",
    "                                                                for p_idx_prime in p_idxs_or_Nones])\n",
    "def H_d_np_col_retrieval_par(p_idx):\n",
    "    return np.array([H_d_np_P[p_idx, p_idx_prime]\n",
    "                     if p_idx_prime is not None else length_mismatch_constant\n",
    "                     for p_idx_prime in P_idxs_of_trimmed_Ws_t( len(ds2t(Ps_t[p_idx])) )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:27.170324Z",
     "start_time": "2019-09-12T19:25:19.395467Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0181s.) Setting batch_size=22.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1427s.) Setting batch_size=60.\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 812 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1230 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1952 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3212 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4472 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5852 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7232 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 8732 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 10232 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 11852 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 13472 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 15212 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 16952 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 21180 out of 21180 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.14268966"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#67s NXT_swbd+wittgenstein, w/ baseline memory usage 39GB, peak ≈45GB?\n",
    "k_cousin_function_np = np.stack(par(delayed(H_d_np_col_retrieval_par)(p_idx)\n",
    "                                    for p_idx in range(len(Ps_t)))).astype(my_dtype)\n",
    "\n",
    "#7.5m NXT_swbd + wittgenstein\n",
    "# k_cousin_function_np = np.stack([H_d_np_col_retrieval(p_idx, P_idxs_of_trimmed_Ws_t( len(ds2t(p)) ))\n",
    "#                                 for p_idx, p in tqdm(enumerate(Ps_t), total=len(Ps_t))]).astype(my_dtype)\n",
    "# k_cousin_function_np = np.stack([H_d_np_P[p_idx, P_idxs_of_trimmed_Ws_t( len(ds2t(p)) )]\n",
    "#                                 for p_idx, p in tqdm(enumerate(Ps_t), total=len(Ps_t))])\n",
    "k_cousin_function_np.shape\n",
    "k_cousin_function_np.nbytes / 1e9\n",
    "k_cousin_function_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:27.176833Z",
     "start_time": "2019-09-12T19:25:27.171621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.k.l'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_pref = choice(Ps_t)\n",
    "while rand_pref[-1] == rightEdge:\n",
    "    rand_pref = choice(Ps_t)\n",
    "rand_pref\n",
    "\n",
    "rand_pref_idx = Ps_t.index(rand_pref)\n",
    "rand_pref_idx\n",
    "\n",
    "rand_pref_l = len(ds2t(rand_pref))\n",
    "rand_pref_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:29.858726Z",
     "start_time": "2019-09-12T19:25:28.857875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6737/6737 [00:00<00:00, 6814.14it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_arr = []\n",
    "for w_idx in tqdm(range(len(Ws_t))):\n",
    "    w = Ws_t[w_idx]\n",
    "    w_l = len(ds2t(w))\n",
    "    if w_l >= rand_pref_l:\n",
    "        my_p_prime_t = ds2t(w)[:rand_pref_l]\n",
    "        my_p_prime = t2ds(my_p_prime_t)\n",
    "        my_p_prime_idx = Ps_t.index( my_p_prime )\n",
    "#         print(my_p_prime, my_p_prime_idx)\n",
    "        k_val = H_d_np_P[rand_pref_idx, my_p_prime_idx]\n",
    "    else:\n",
    "        k_val = length_mismatch_constant\n",
    "    check_arr.append(k_val)\n",
    "check_arr_np = np.array(check_arr)\n",
    "k_cousin_function_np[rand_pref_idx] == check_arr_np\n",
    "assert np.array_equal(k_cousin_function_np[rand_pref_idx], check_arr_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:30.423977Z",
     "start_time": "2019-09-12T19:26:30.342680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if testing:\n",
    "    rand_pref_5cousins = get_k_cousins(rand_pref, 5, Ws_t, Ps_t, exactlyK = True)\n",
    "    sorted(rand_pref_5cousins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:31.171288Z",
     "start_time": "2019-09-12T19:26:31.159039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=int8)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if testing:\n",
    "    (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0]\n",
    "\n",
    "    k_cousin_function_np[rand_pref_idx, \n",
    "                         (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0]  ]\n",
    "\n",
    "    lmap(lambda w_idx: Ws_t[w_idx], \n",
    "         (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0])\n",
    "\n",
    "    assert sorted(rand_pref_5cousins) == sorted(lmap(lambda w_idx: Ws_t[w_idx], \n",
    "                                                     (k_cousin_function_np[rand_pref_idx] == 5).nonzero()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:31.915680Z",
     "start_time": "2019-09-12T19:25:31.905623Z"
    }
   },
   "outputs": [],
   "source": [
    "if testing:\n",
    "    num_checks = 1000\n",
    "\n",
    "    rand_prefs = []\n",
    "    while len(rand_prefs) < num_checks:\n",
    "        rand_pref = choice(Ps_t)\n",
    "        while rand_pref[-1] == rightEdge:\n",
    "            rand_pref = choice(Ps_t)\n",
    "        rand_prefs.append(rand_pref)\n",
    "\n",
    "    rand_pref_idxs = lmap(lambda p: Ps_t.index(p), \n",
    "                          rand_prefs)\n",
    "    rand_pref_ls = lmap(lambda p: len(ds2t(p)),\n",
    "                        rand_prefs)\n",
    "    rand_ks = [choice([1,2,3,4]) for each in rand_prefs]\n",
    "\n",
    "    for p, p_idx, p_l, k in tqdm(zip(rand_prefs, rand_pref_idxs, rand_pref_ls, rand_ks),\n",
    "                                 total=len(rand_prefs)):\n",
    "        #reference implementation\n",
    "        rand_pref_k_cousins_ref = sorted(get_k_cousins(p, k, Ws_t, Ps_t, exactlyK = True))\n",
    "\n",
    "        rand_pref_k_cousins = sorted(lmap(lambda w_idx: Ws_t[w_idx],\n",
    "                                          (k_cousin_function_np[p_idx] == k).nonzero()[0]))\n",
    "        assert rand_pref_k_cousins_ref == rand_pref_k_cousins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:25:32.193444Z",
     "start_time": "2019-09-12T19:25:32.186099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.k.l'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_cousins_of_pref(p, k):\n",
    "    p_idx = Ps_t.index(p)\n",
    "    return lmap(lambda w_idx: Ws_t[w_idx],\n",
    "                (k_cousin_function_np[p_idx] == k).nonzero()[0])\n",
    "\n",
    "rand_pref\n",
    "get_k_cousins_of_pref(rand_pref, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to export\n",
    " - the prefix-word relation\n",
    " - the Hamming distance matrix between all pairs of wordforms\n",
    " - the Hamming distance matrix between all pairs of prefixes\n",
    " - the $k$-cousin relation between all pairs of prefixes and wordforms\n",
    " \n",
    "plus associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:48.350033Z",
     "start_time": "2019-09-12T19:26:46.940203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 21180)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_relation_np.shape\n",
    "len(Ws_t), len(Ps_t)\n",
    "\n",
    "np.save(o + '_prefix_relation' + '.npy', prefix_relation_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:26:49.918758Z",
     "start_time": "2019-09-12T19:26:49.867522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_prefix_relation.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_prefix_relation.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "prefix_relation_md = {'W':{'from fp':p,\n",
    "                           'changes':'sorted',\n",
    "                           'size':len(Ws_t)},\n",
    "                      'P':{'from_fp':p,\n",
    "                           'changes':'extracted from W, sorted',\n",
    "                           'size':len(Ps_t)}}\n",
    "exportMatrixMetadata(o + '_prefix_relation' + '.npy' + '_metadata.json',\n",
    "                     path.basename(o) + '_prefix_relation' + '.npy' + '_metadata.json',\n",
    "                     prefix_relation_np,\n",
    "                     prefix_relation_md,\n",
    "                     'Step 4b',\n",
    "                     'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:02.929699Z",
     "start_time": "2019-09-12T19:27:02.420858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6737, 6737)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6737, 6737)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_d_np_W.shape\n",
    "len(Ws_t), len(Ws_t)\n",
    "\n",
    "np.save(o + '_H_d_W' + '.npy', H_d_np_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:03.428908Z",
     "start_time": "2019-09-12T19:27:03.422679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_W.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_W.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "H_d_W_md = {'W':{'from fp':p,\n",
    "                 'changes':'sorted',\n",
    "                 'size':len(Ws_t)}}\n",
    "exportMatrixMetadata(o + '_H_d_W' + '.npy' + '_metadata.json',\n",
    "                     path.basename(o) + '_H_d_W' + '.npy' + '_metadata.json',\n",
    "                     H_d_np_W,\n",
    "                     H_d_W_md,\n",
    "                     'Step 4b',\n",
    "                     'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                    {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:08.244902Z",
     "start_time": "2019-09-12T19:27:04.404118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21180, 21180)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_P.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_H_d_P.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "H_d_np_P.shape\n",
    "len(Ps_t), len(Ps_t)\n",
    "\n",
    "if not alreadyMemoryMapped_H_d_p:\n",
    "    H_d_np_P_mm = np.memmap(o + '_H_d_P' + '.npy', dtype=my_dtype, mode='w+', shape=(len(Ps_t), len(Ps_t)))\n",
    "    H_d_np_P_mm[:] = H_d_np_P\n",
    "#     np.save(path.join(o, o + '_H_d_P' + '.npy'), H_d_np_P)\n",
    "    \n",
    "    H_d_P_md = {'W':{'from fp':p,\n",
    "                     'changes':'sorted',\n",
    "                     'size':len(Ws_t)},\n",
    "                     'P':{'from_fp':p,\n",
    "                          'changes':'extracted from W, sorted',\n",
    "                          'size':len(Ps_t)}}\n",
    "    exportMatrixMetadata(o + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         path.basename(o) + '_H_d_P' + '.npy' + '_metadata.json',\n",
    "                         H_d_np_P,\n",
    "                         H_d_P_md,\n",
    "                         'Step 4b',\n",
    "                         'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                        {'Storage':'file is MEMORY MAPPED.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:09.545729Z",
     "start_time": "2019-09-12T19:27:08.246317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21180, 6737)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cousin_function_np.shape\n",
    "len(Ps_t), len(Ws_t)\n",
    "\n",
    "np.save(o + '_k_cousin_function' + '.npy', k_cousin_function_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T19:27:09.552193Z",
     "start_time": "2019-09-12T19:27:09.547198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata for \n",
      "\tLTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_k_cousin_function.npy_metadata.json\n",
      " to \n",
      "\tCM_AmE_destressed_aligned_w_LTR_NXT_swbd_destressed_pseudocount0.01/LTR_NXT_swbd_destressed_aligned_CM_filtered_LM_filtered_X0X1X2_k_cousin_function.npy_metadata.json\n"
     ]
    }
   ],
   "source": [
    "k_cousin_function_md = {'P':{'from_fp':p,\n",
    "                             'changes':'extracted from W, sorted',\n",
    "                             'size':len(Ps_t)},\n",
    "                        'W':{'from fp':p,\n",
    "                             'changes':'sorted',\n",
    "                             'size':len(Ws_t)}}\n",
    "exportMatrixMetadata(o + '_k_cousin_function' + '.npy' + '_metadata.json',\n",
    "                     path.basename(o) + '_k_cousin_function' + '.npy' + '_metadata.json',\n",
    "                     k_cousin_function_np,\n",
    "                     k_cousin_function_md,\n",
    "                     'Step 4b',\n",
    "                     'Calculate word-prefix relation, Hamming distances, and k-cousin relation.ipynb',\n",
    "                    {})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
