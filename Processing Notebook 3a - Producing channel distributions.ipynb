{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.211066Z",
     "start_time": "2019-02-20T17:42:19.206798Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview-and-requirements\" data-toc-modified-id=\"Overview-and-requirements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview and requirements</a></span></li><li><span><a href=\"#Boilerplate\" data-toc-modified-id=\"Boilerplate-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Boilerplate</a></span></li><li><span><a href=\"#Choose-which-gating-data-to-process-and-what-to-produce\" data-toc-modified-id=\"Choose-which-gating-data-to-process-and-what-to-produce-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Choose which gating data to process and what to produce</a></span></li><li><span><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Import data</a></span></li><li><span><a href=\"#Create-confusability-counts-and-channel-distributions\" data-toc-modified-id=\"Create-confusability-counts-and-channel-distributions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create confusability counts and channel distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Defining-the-sample-space-and-exporting-gate-3-and-gate-6-trials\" data-toc-modified-id=\"Defining-the-sample-space-and-exporting-gate-3-and-gate-6-trials-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Defining the sample space and exporting gate 3 and gate 6 trials</a></span></li><li><span><a href=\"#Define-conditional-distributions-$f_3(Y_0,-Y_1|-X_0;-X_1)$,-$f_6(Y_0,-Y_1|-X_0,-X_1;)$-and-add-pseudocounts\" data-toc-modified-id=\"Define-conditional-distributions-$f_3(Y_0,-Y_1|-X_0;-X_1)$,-$f_6(Y_0,-Y_1|-X_0,-X_1;)$-and-add-pseudocounts-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Define conditional distributions $f_3(Y_0, Y_1| X_0; X_1)$, $f_6(Y_0, Y_1| X_0, X_1;)$ and add pseudocounts</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-pseudocount-counter-dictionary\" data-toc-modified-id=\"Define-pseudocount-counter-dictionary-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Define pseudocount counter dictionary</a></span></li><li><span><a href=\"#Get-response-counts-(+-pseudocounts)\" data-toc-modified-id=\"Get-response-counts-(+-pseudocounts)-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Get response counts (+ pseudocounts)</a></span></li><li><span><a href=\"#Example-distribution\" data-toc-modified-id=\"Example-distribution-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Example distribution</a></span></li><li><span><a href=\"#Generate-both-lists-of-distributions\" data-toc-modified-id=\"Generate-both-lists-of-distributions-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span>Generate both lists of distributions</a></span></li></ul></li><li><span><a href=\"#Export/import-conditional-distributions-$f_3(Y_0,-Y_1|-X_0;-X_1)$,-$f_6(Y_0,-Y_1|-X_0,-X_1;)$\" data-toc-modified-id=\"Export/import-conditional-distributions-$f_3(Y_0,-Y_1|-X_0;-X_1)$,-$f_6(Y_0,-Y_1|-X_0,-X_1;)$-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Export/import conditional distributions $f_3(Y_0, Y_1| X_0; X_1)$, $f_6(Y_0, Y_1| X_0, X_1;)$</a></span><ul class=\"toc-item\"><li><span><a href=\"#Export-diphone-confusion-count-distributions-as-json-files\" data-toc-modified-id=\"Export-diphone-confusion-count-distributions-as-json-files-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Export diphone confusion count distributions as json files</a></span></li><li><span><a href=\"#...and-read-them-back-in\" data-toc-modified-id=\"...and-read-them-back-in-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>...and read them back in</a></span></li></ul></li><li><span><a href=\"#Define-and-export-conditional-distributions-$p_3(Y_0,-Y_1|-X_0;-X_1)$,-$p_6(Y_0,-Y_1|-X_0,-X_1;)$\" data-toc-modified-id=\"Define-and-export-conditional-distributions-$p_3(Y_0,-Y_1|-X_0;-X_1)$,-$p_6(Y_0,-Y_1|-X_0,-X_1;)$-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Define and export conditional distributions $p_3(Y_0, Y_1| X_0; X_1)$, $p_6(Y_0, Y_1| X_0, X_1;)$</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validate-and-export\" data-toc-modified-id=\"Validate-and-export-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Validate and export</a></span></li></ul></li><li><span><a href=\"#Define-and-export-conditional-distributions-$p_3(Y_1|X_0;-X_1)$,-$p_6(Y_0|X_0,-X_1;)$\" data-toc-modified-id=\"Define-and-export-conditional-distributions-$p_3(Y_1|X_0;-X_1)$,-$p_6(Y_0|X_0,-X_1;)$-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Define and export conditional distributions $p_3(Y_1|X_0; X_1)$, $p_6(Y_0|X_0, X_1;)$</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validate-and-export\" data-toc-modified-id=\"Validate-and-export-5.5.1\"><span class=\"toc-item-num\">5.5.1&nbsp;&nbsp;</span>Validate and export</a></span></li></ul></li><li><span><a href=\"#Produce-uniphone-channel-distribution-$p(Y|X)$\" data-toc-modified-id=\"Produce-uniphone-channel-distribution-$p(Y|X)$-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Produce uniphone channel distribution $p(Y|X)$</a></span><ul class=\"toc-item\"><li><span><a href=\"#Validate-and-export\" data-toc-modified-id=\"Validate-and-export-5.6.1\"><span class=\"toc-item-num\">5.6.1&nbsp;&nbsp;</span>Validate and export</a></span></li></ul></li><li><span><a href=\"#Produce-triphone-channel-distribution-$p_3(Y_1|X_0,-X_1;-X_2)$\" data-toc-modified-id=\"Produce-triphone-channel-distribution-$p_3(Y_1|X_0,-X_1;-X_2)$-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Produce triphone channel distribution $p_3(Y_1|X_0, X_1; X_2)$</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-relevant-n-phone-sequences\" data-toc-modified-id=\"Define-relevant-n-phone-sequences-5.7.1\"><span class=\"toc-item-num\">5.7.1&nbsp;&nbsp;</span>Define relevant n-phone sequences</a></span></li><li><span><a href=\"#Calculate-the-triphone-channel-distribution\" data-toc-modified-id=\"Calculate-the-triphone-channel-distribution-5.7.2\"><span class=\"toc-item-num\">5.7.2&nbsp;&nbsp;</span>Calculate the triphone channel distribution</a></span></li><li><span><a href=\"#Validate-and-export/import\" data-toc-modified-id=\"Validate-and-export/import-5.7.3\"><span class=\"toc-item-num\">5.7.3&nbsp;&nbsp;</span>Validate and export/import</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the ultimate goal of these notebooks is to process data for a word recognition model that can map from a segmental transcription of the incrementally produced prefix of a speaker's intended wordform to a listener's beliefs about what the speaker's actual intended wordform is. (See other notebooks - especially the collection documenting the model implementation -  for more details.) \n",
    "\n",
    "This requires a lexicon of transcribed wordforms, the ability to assign a prior probability to each wordform, and a model of coarticulation and noise/errors in the listening process. Where previous notebooks in this collection have each only transformed what is structurally the same dataset, this notebook transforms those structures into one of the two types of inputs to the word recognition model - a channel distribution describing what a listener thinks they *heard* or *perceived* given what segment(s) the speaker has produced so far of their intended wordform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, I am running Python 3.6.5, Jupyter 5.5.0, and otherwise Anaconda 5.2. **Various cells use joblib to parallelize data processing.** More specifically, this notebook assumes the current working directory contains\n",
    " - a copy of the dataset and annotations available from https://linguistics.arizona.edu/dpl/english_diphones (NOTE: Natasha Warner has just - as of early 2018 - changed the website, and links to the data are currently broken), processed by two previous notebooks. \n",
    "\n",
    "The first notebook (`Notebook 1a`) converted transcriptions to IPA and added annotation columns containing information about the complete stimulus of each trial. \n",
    "\n",
    "The second notebook (`Notebook 2a`) produced a new version of the output of the previous notebook for each of two lexicons of English (`Hammond's newdic` and `IPhOD`), where each version contained gating data whose segmental representations had been aligned with the segment inventory of one of the two lexicons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In slightly more detail, the *main* outputs of this notebook are \n",
    " - a JSON file containing a mapping from each segment in the stimuli of the (aligned) gating data to a probability distribution ('the uniphone channel distribution') over response segments $p(Y|X)$. This file ends with:\n",
    "   - `<WHICH> pYX.json`\n",
    " - a JSON file containing a mapping from each three segment sequence $x_{i-1}, x_i, x_{i+1} \\in \\Sigma \\cup \\{\\rtimes\\} \\cdot \\Sigma \\cdot \\Sigma \\cup \\{\\ltimes\\}$ to the 'triphone channel distribution' $p(Y_i|x_{i-1}, x_i, x_{i+1})$, where $Y_i = \\Sigma$ and $\\Sigma$ is the set of (aligned) stimuli segments. This file ends with:\n",
    "   - `<WHICH> pY1X0X1X2.json`\n",
    " - a JSON file containing a mapping from each two segment sequence $x_{i}, x_{i+1} \\in \\Sigma \\cdot \\Sigma$ to the 'preview channel distribution' $p(Y_{i+1}|x_{i}, x_{i+1})$, where $Y_i = \\Sigma$ and $\\Sigma$ is the set of (aligned) stimuli segments. This file ends with:\n",
    "   - `<WHICH> pY1X01.json`\n",
    "\n",
    "A more complete list of outputs (i.e. including secondary/intermediate/auxiliary outputs) includes:\n",
    " - csv files containing just the (possibly processed) gate3 and gate6 trials used in calculating all frequencies. These files end with:\n",
    "  - `<WHICH_NOCOUNT> gate3 trials.csv`\n",
    "  - `<WHICH_NOCOUNT> gate6 trials.csv`\n",
    " - JSON files containing frequency distributions over response diphones for each stimulus diphone at gates 3 and 6 - basically unnormalized versions of the listener's distributions $p(Y_0,Y_1|X_0, X_1 \\text{ are intended but only } X_0 \\text{ has been produced})$ and $p(Y_0,Y_1|X_0, X_1 \\text{ are intended and both have been produced})$; this is explicated further below. These two files end with:\n",
    "   - `<WHICH> f3_Y0Y1_X0X1.csv`\n",
    "   - `<WHICH> f6_Y0Y1_X0X1.csv`\n",
    " - JSON files containing probability distributions over response diphones for each stimulus diphone at gates 3 and 6. These two files end with:\n",
    "   - `<WHICH> p3Y01X01.csv`\n",
    "   - `<WHICH> p6Y01X01.csv`\n",
    " - JSON files containing probability distributions $p_3(Y_1|X_0;X_1)$ and $p_6(Y_0|X_0, X_1;)$. These two files end with:\n",
    "   - `<WHICH> p3Y1X01.csv`\n",
    "   - `<WHICH> p6Y0X01.csv`\n",
    " - three JSON files containing mappings representing the distributions $p(Y_0 = \\dot{y}|X_0 = \\dot{x} \\text{ has been produced})$ (i.e. marginalizing over following segments $X_1$ and weighting each phonotactically licit one equally),  $p(Y_1 = \\dot{y}|X_1 = \\dot{x}) \\text{ has been produced}$ (i.e. marginalizing over preceding segments $X_0$ and weighting each phonotactically licit one equally), and $p(Y = \\dot{y}|X = \\dot{x} \\text{ has been produced})$ (i.e. marginalizing over the other segment, weighting each licit one equally, and evenly weighting the possibility that $X$ was the first or the second segment in the diphone. These three files end with:\n",
    "   - `<WHICH> pYX.json`\n",
    "   - `<WHICH> p3YX.json`\n",
    "   - `<WHICH> p6YX.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, this notebook uses the following outputs from a previous processing notebook (`Processing Notebook 2a`), each containing lists of segment sequences relevant to defining sample spaces for channel distributions and whose size/contents are useful for other tasks (e.g. debugging, back of the envelope calculations):\n",
    "   - lists of stimulus and response segments ('uniphones') in the aligned data.\n",
    "   - lists of stimulus and response diphones in the aligned data.\n",
    "   - lists of triphones constructable and not constructable (i.e. in most cases phonotactically illicit) from the stimulus and response diphones.\n",
    "   - These files have the form:\n",
    "     - `<WHICH_nocount> stimuli diphone-based constructible triphones`\n",
    "     - `<WHICH_nocount> response diphone-based constructible triphones`\n",
    "     - `<WHICH_nocount> stimuli diphone-based illegal triphones`\n",
    "     - `<WHICH_nocount> response diphone-based illegal triphones`\n",
    "     - `<WHICH_nocount> response diphones.txt`\n",
    "     - `<WHICH_nocount> response uniphones.txt`\n",
    "     - `<WHICH_nocount> stimuli diphones.txt`\n",
    "     - `<WHICH_nocount> stimuli uniphones.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.441120Z",
     "start_time": "2019-02-20T17:42:19.212123Z"
    }
   },
   "outputs": [],
   "source": [
    "from boilerplate import *\n",
    "from probdist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.459485Z",
     "start_time": "2019-02-20T17:42:19.442613Z"
    }
   },
   "outputs": [],
   "source": [
    "#other stuff used in this notebook that is useful to define once, up here...\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.545141Z",
     "start_time": "2019-02-20T17:42:19.528909Z"
    }
   },
   "outputs": [],
   "source": [
    "# from math import log2, pow, isclose\n",
    "\n",
    "# def log(x):\n",
    "#     if x == 0.0:\n",
    "#         return 0.0\n",
    "#     return log2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.628044Z",
     "start_time": "2019-02-20T17:42:19.551148Z"
    }
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def getRandomKey(a_dict, printKey = False):\n",
    "#     randKey = random.choice(list(a_dict.keys()))\n",
    "#     if printKey:\n",
    "#         print('Random key: {0}'.format(randKey))\n",
    "#     return randKey\n",
    "\n",
    "# def testRandomKey(a_dict, printKey = True, printVal = True):\n",
    "#     randKey = getRandomKey(a_dict)\n",
    "#     if printKey:\n",
    "#         print('Random key: {0}'.format(randKey))\n",
    "#     if printVal:\n",
    "#         print('value ⟶ {0}'.format(a_dict[randKey]))\n",
    "#     return {'key': randKey, 'val': a_dict[randKey]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.711355Z",
     "start_time": "2019-02-20T17:42:19.632116Z"
    }
   },
   "outputs": [],
   "source": [
    "# my_epsilon = 1e-13\n",
    "\n",
    "# def norm(dist):\n",
    "#     return sum(dist.values())\n",
    "\n",
    "# def norms(dists):\n",
    "#     return map(norm, dists)\n",
    "\n",
    "# def isNormalized(dist, epsilon = None):\n",
    "#     if epsilon == None:\n",
    "#         epsilon = my_epsilon\n",
    "#     return abs(norm(dist) - 1) < my_epsilon\n",
    "\n",
    "# def areNormalized(dists, epsilon = None):\n",
    "#     if epsilon == None:\n",
    "#         epsilon = my_epsilon\n",
    "#     return all(map(lambda k: isNormalized(dists[k]), dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.822934Z",
     "start_time": "2019-02-20T17:42:19.718636Z"
    }
   },
   "outputs": [],
   "source": [
    "# import json, codecs\n",
    "\n",
    "# def exportProbDist(fn, dist):\n",
    "#     with codecs.open(fn, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(dist, f, ensure_ascii = False, indent = 4)\n",
    "        \n",
    "# def importProbDist(fn):\n",
    "#     with open(fn, encoding='utf-8') as data_file:\n",
    "#         dist_in = json.loads(data_file.read())\n",
    "#     return dist_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.911642Z",
     "start_time": "2019-02-20T17:42:19.830467Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tupleToDottedString(pair): \n",
    "#     return '.'.join(pair)\n",
    "\n",
    "# def dottedStringToTuple(s): \n",
    "#     return tuple(s.split('.'))\n",
    "\n",
    "# t2ds = tupleToDottedString\n",
    "# ds2t = dottedStringToTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:19.995006Z",
     "start_time": "2019-02-20T17:42:19.915759Z"
    }
   },
   "outputs": [],
   "source": [
    "# leftEdge = '⋊'\n",
    "# rightEdge = '⋉'\n",
    "# edgeSymbols = {leftEdge, rightEdge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.078069Z",
     "start_time": "2019-02-20T17:42:19.999425Z"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "\n",
    "# def union(Ss):\n",
    "#     return reduce(set.union, Ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.157197Z",
     "start_time": "2019-02-20T17:42:20.082554Z"
    }
   },
   "outputs": [],
   "source": [
    "# from itertools import takewhile, product\n",
    "\n",
    "# def dsToKfactors(k, ds):\n",
    "#     seq = ds2t(ds)\n",
    "#     l = len(seq)\n",
    "#     if k > l:\n",
    "#         return tuple()\n",
    "#     kFactor_start_indices = takewhile(lambda pair: pair[0] <= l-k, enumerate(seq))\n",
    "#     kFactors = tuple(seq[index[0]:index[0]+k] for index in kFactor_start_indices)\n",
    "#     return set(map(t2ds, kFactors))\n",
    "\n",
    "# def dsTo2factors(ds):\n",
    "#     return dsToKfactors(2, ds)\n",
    "# def dsTo3factors(ds):\n",
    "#     return dsToKfactors(3, ds)\n",
    "\n",
    "# def lexiconToKfactors(DSs, k):\n",
    "#     myDsToKfactors = lambda ds: dsToKfactors(k, ds)\n",
    "#     return union(map(set, map(myDsToKfactors, DSs)))\n",
    "\n",
    "# def lexiconTo2factors(DSs):\n",
    "#     return union(map(set, map(dsTo2factors, DSs)))\n",
    "# def lexiconTo3factors(DSs):\n",
    "#     return union(map(set, map(dsTo3factors, DSs)))\n",
    "\n",
    "\n",
    "# def compareKfactors(DSs_A, DSs_B, k):\n",
    "#     A = lexiconToKfactors(DSs_A, k)\n",
    "#     B = lexiconToKfactors(DSs_B, k)\n",
    "#     return {\"A == B\":A == B, \"A - B\": A - B, \"B - A\": B - A}\n",
    "\n",
    "# def sameKfactors(DSs_A, DSs_B, k):\n",
    "#     return compareKfactors(DSs_A, DSs_B, k)[\"A == B\"]\n",
    "\n",
    "# def hasIllicitKfactors(W, illicit_k_factors):\n",
    "#     if type(W) == str:      \n",
    "#         # gather the k-factors into an immutable data structure\n",
    "#         illicit_kfs = tuple(illicit_k_factors)\n",
    "#         # get the set of k-factor lengths (values of k) among the illicit_kfs\n",
    "#         illicit_factor_lengths = set([len(ds2t(kf)) for kf in illicit_kfs])\n",
    "#         # map each k to the set of k-factors of dotted string ds\n",
    "#         kFactorSets = {kf_l:dsToKfactors(kf_l, W) for kf_l in illicit_factor_lengths}\n",
    "#         illegal_kfactors_discovered = tuple(ikf for ikf in illicit_kfs if ikf in kFactorSets[len(ds2t(ikf))])\n",
    "#         if illegal_kfactors_discovered == tuple():\n",
    "#             return False\n",
    "#         return illegal_kfactors_discovered\n",
    "#     else:\n",
    "#         myFunc = lambda w: hasIllicitKfactors(w, illicit_k_factors)\n",
    "#         results = tuple(map(myFunc, W))\n",
    "#         if not any(results):\n",
    "#             return False\n",
    "#         return set(t2ds(each) for each in results if each != False)\n",
    "\n",
    "# def sigmaK(sigma, k):\n",
    "#     return product(sigma, repeat=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.274970Z",
     "start_time": "2019-02-20T17:42:20.161782Z"
    }
   },
   "outputs": [],
   "source": [
    "# def importSeqs(seq_fn):\n",
    "#     phoneSeqsAsStr = []\n",
    "#     with open(seq_fn, 'r') as the_file:\n",
    "#         for row in the_file:\n",
    "#             phoneSeqsAsStr.append(row.rstrip('\\r\\n'))\n",
    "#     return set(phoneSeqsAsStr)\n",
    "\n",
    "# def exportSeqs(seq_fn, seqs):\n",
    "#     with open(seq_fn, 'w') as the_file:\n",
    "#         for seq in seqs:\n",
    "#             the_file.write(seq + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.369561Z",
     "start_time": "2019-02-20T17:42:20.279497Z"
    }
   },
   "outputs": [],
   "source": [
    "#These are functions that facilitate dealing with segments annotated with stress information.\n",
    "\n",
    "def getStimSeg1(row):\n",
    "    seg = row['CorrAns1']\n",
    "    if which_stress == 'destressed':\n",
    "        return seg\n",
    "    elif which_stress == 'stressed':\n",
    "        s = row['seg1_stress']\n",
    "        if s == '2' or s == 2:\n",
    "            return seg\n",
    "        else:\n",
    "            return seg + str(s)\n",
    "    else:\n",
    "        assert which_stress in ['destressed', 'stressed'], '{0} is an invalid choice about stress representations'.format(which_stress)\n",
    "\n",
    "def getStimSeg2(row):\n",
    "    seg = row['CorrAns2']\n",
    "    if which_stress == 'destressed':\n",
    "        return seg\n",
    "    elif which_stress == 'stressed':\n",
    "        s = row['seg2_stress']\n",
    "        if s == '2' or s == 2:\n",
    "            return seg\n",
    "        else:\n",
    "            return seg + str(s)\n",
    "    else:\n",
    "        assert which_stress in ['destressed', 'stressed'], '{0} is an invalid choice about stress representations'.format(which_stress)\n",
    "        \n",
    "def removeConsStress(stringRep):\n",
    "    return ''.join([c for c in stringRep if c != \"2\"])\n",
    "\n",
    "def removeStress(stringRep):\n",
    "    return ''.join([c for c in stringRep if c != \"0\" and c != \"1\" and c != \"2\"])\n",
    "\n",
    "def replaceSyllableBoundaries(stringRep):\n",
    "    return stringRep.replace('-','.')\n",
    "\n",
    "def justSegments(stringRep):\n",
    "    return replaceSyllableBoundaries(removeStress(stringRep))\n",
    "\n",
    "def getDiphonesInAsStr(row):\n",
    "    if which_stress == 'destressed':\n",
    "        return row['diphoneInSeg']\n",
    "    elif which_stress == 'stressed': \n",
    "        #we remove consonant stress annotations because there are none in IPhOD (and probably none in Hammond's newdic, either)\n",
    "        assert removeStress(row['diphoneInWStress']) == row['diphoneInSeg'], '{0} and {1} have segmental mismatch'.format(row['diphoneIn'], row['diphoneInWStress'])\n",
    "        return removeConsStress(row['diphoneInWStress'])\n",
    "    else:\n",
    "        assert which_stress in ['destressed', 'stressed'], '{0} is an invalid choice about stress representations'.format(which_stress)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which gating data to process and what to produce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a set of (IPA transcribed and stimulus-annotated) trial data by leaving exactly one of the options below uncommented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.484424Z",
     "start_time": "2019-02-20T17:42:20.374397Z"
    }
   },
   "outputs": [],
   "source": [
    "# which_alignment = 'unaligned'\n",
    "which_alignment = 'Hammond-aligned'\n",
    "# which_alignment = 'IPhOD-aligned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose whether channel distributions should be over just IPA segments (i.e. with no reference to stress information) or whether stress information should be included in the channel distribution by leaving exactly one of the options below uncommented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.601003Z",
     "start_time": "2019-02-20T17:42:20.489082Z"
    }
   },
   "outputs": [],
   "source": [
    "which_stress = 'destressed'\n",
    "# which_stress = 'stressed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a smoothing pseudocount to add to all unobserved listener responses to each stimuli diphone: $\\{Y_0 Y_1|p(Y_0 Y_1 | X_0 X_1) = 0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.691050Z",
     "start_time": "2019-02-20T17:42:20.605418Z"
    }
   },
   "outputs": [],
   "source": [
    "# pseudocount = 0\n",
    "pseudocount = 0.001\n",
    "# pseudocount = 0.0011\n",
    "# pseudocount = 0.005\n",
    "# pseudocount = 0.01\n",
    "# pseudocount = 1\n",
    "\n",
    "which_pseudocount = 'pseudocount' + str(pseudocount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.790210Z",
     "start_time": "2019-02-20T17:42:20.695167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hammond-aligned_destressed_pseudocount0.001'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hammond-aligned_destressed'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which = '_'.join([which_alignment, which_stress, which_pseudocount])\n",
    "which\n",
    "\n",
    "whichNoCount = '_'.join([which_alignment, which_stress])\n",
    "whichNoCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.869175Z",
     "start_time": "2019-02-20T17:42:20.794153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/AD/emeinhar/c2-jn'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:20.948757Z",
     "start_time": "2019-02-20T17:42:20.873383Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:21.025864Z",
     "start_time": "2019-02-20T17:42:20.961059Z"
    }
   },
   "outputs": [],
   "source": [
    "def getDiphoneGatingTrials(filename, print_fields = True):\n",
    "    '''\n",
    "    Opens filename in the current working directory and returns the trials as a \n",
    "    list of dictionaries, plus the fieldnames in the order present in the file.\n",
    "    '''\n",
    "    diphone_fields = []\n",
    "    diphoneTrials = []\n",
    "    diphoneDataInFilename = filename\n",
    "    with open(diphoneDataInFilename, newline='') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "        diphone_fields = my_reader.fieldnames\n",
    "        if print_fields:\n",
    "            print(\"fieldnames: {0}\".format(diphone_fields))\n",
    "        for row in my_reader:\n",
    "            #print(row)\n",
    "            diphoneTrials.append(row)\n",
    "    return {'trials': diphoneTrials, 'fields':diphone_fields}\n",
    "\n",
    "def writeProcessedDataToCSV(theTrials, theFieldnames, filename):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, delimiter='\\t',fieldnames=theFieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(theTrials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:21.116246Z",
     "start_time": "2019-02-20T17:42:21.036867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hammond_aligned_trials.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unaligned_trials_filename = 'diphones-IPA-annotated-columns.csv'\n",
    "IPhOD_aligned_trials_filename = 'IPhOD_aligned_trials.csv'\n",
    "hammond_aligned_trials_filename = 'Hammond_aligned_trials.csv'\n",
    "\n",
    "my_filename = {\n",
    "    'unaligned':unaligned_trials_filename,\n",
    "    'IPhOD-aligned':IPhOD_aligned_trials_filename,\n",
    "    'Hammond-aligned':hammond_aligned_trials_filename\n",
    "}[which_alignment]\n",
    "my_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:23.342688Z",
     "start_time": "2019-02-20T17:42:21.120580Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fieldnames: ['Subject', 'Diph_num', 'Diph_name', 'Sylltype', 'SoundFile', 'Prec_context', 'gate', 'four_gate', 'seg1_stress', 'seg2_stress', 'CorrAns1', 'CorrAns2', 'Resp1', 'Resp2', 'Seg1Accur', 'Seg2Accur', 'Prec_context_binary', 'wrong_preccontext', 'replacedSeg1Data', 'replacedSeg2Data', 'diphoneInWStress', 'diphoneInSeg', 'diphoneOutSeg', 'stimulusWProsody', 'stimulusSeg', 'prefixWStress', 'prefixSeg', 'suffixWStress', 'suffixSeg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269280"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Subject', '1'),\n",
       "             ('Diph_num', '1'),\n",
       "             ('Diph_name', 'CC'),\n",
       "             ('Sylltype', 'CC'),\n",
       "             ('SoundFile', '0001_CC_CC-g1-beeped.wav'),\n",
       "             ('Prec_context', 'ɑ'),\n",
       "             ('gate', '1'),\n",
       "             ('four_gate', '0'),\n",
       "             ('seg1_stress', '2'),\n",
       "             ('seg2_stress', '2'),\n",
       "             ('CorrAns1', 'tʃ'),\n",
       "             ('CorrAns2', 'tʃ'),\n",
       "             ('Resp1', 'tʃ'),\n",
       "             ('Resp2', 't'),\n",
       "             ('Seg1Accur', '1'),\n",
       "             ('Seg2Accur', '0'),\n",
       "             ('Prec_context_binary', '1'),\n",
       "             ('wrong_preccontext', ' '),\n",
       "             ('replacedSeg1Data', ' '),\n",
       "             ('replacedSeg2Data', ' '),\n",
       "             ('diphoneInWStress', 'tʃ2.tʃ2'),\n",
       "             ('diphoneInSeg', 'tʃ.tʃ'),\n",
       "             ('diphoneOutSeg', 'tʃ.t'),\n",
       "             ('stimulusWProsody', 'ɑ1.tʃ2-tʃ2.ə0'),\n",
       "             ('stimulusSeg', 'ɑ.tʃ.tʃ.ə'),\n",
       "             ('prefixWStress', 'ɑ1.'),\n",
       "             ('prefixSeg', 'ɑ'),\n",
       "             ('suffixWStress', '.ə0'),\n",
       "             ('suffixSeg', 'ə')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file_data = getDiphoneGatingTrials(my_filename)\n",
    "rows = my_file_data['trials']\n",
    "the_fields = my_file_data['fields']\n",
    "\n",
    "len(rows)\n",
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:23.556064Z",
     "start_time": "2019-02-20T17:42:23.343720Z"
    }
   },
   "outputs": [],
   "source": [
    "stimuli_uniphones = importSeqs(whichNoCount + ' stimuli uniphones' + '.txt')\n",
    "response_uniphones = importSeqs(whichNoCount + ' response uniphones' + '.txt')\n",
    "stimuli_diphones = importSeqs(whichNoCount + ' stimuli diphones' + '.txt')\n",
    "response_diphones = importSeqs(whichNoCount + ' response diphones' + '.txt')\n",
    "constructableStimulusTriphones = importSeqs(whichNoCount + ' stimuli diphone-based constructible triphones' + '.txt')\n",
    "# illegalStimulusTriphones = phone_seqs['illegalStimulusTriphones']\n",
    "# illegalResponseTriphones = phone_seqs['illegalResponseTriphones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:23.655325Z",
     "start_time": "2019-02-20T17:42:23.557549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1421"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "42930"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stimuli_uniphones)\n",
    "len(response_uniphones)\n",
    "len(stimuli_diphones)\n",
    "len(response_diphones)\n",
    "len(constructableStimulusTriphones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create confusability counts and channel distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:23.724684Z",
     "start_time": "2019-02-20T17:42:23.656340Z"
    }
   },
   "outputs": [],
   "source": [
    "unfiltered_rows = rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal for now: export \n",
    " - **json files** (one set for gate 3, one set for gate 6), each containing **a list of dictionaries**:\n",
    "   - = a set of conditional frequency distributions $f_3(Y_0, Y_1 | X_0; X_1)$, $f_6(Y_0, Y_1 | X_0, X_1;)$ for each stimulus diphone $X_0, X_1$.\n",
    "   - = a set of diphone channel distributions $p_3(Y_0, Y_1 | X_0; X_1)$, $p_6(Y_0, Y_1 | X_0, X_1;)$ for each stimulus diphone $X_0, X_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining/exporting frequency distributions that (once normalized) correspond to:\n",
    " - $p(Y_0,Y_1|X_0, X_1 \\text{ are intended and only } X_0 \\text{ has been produced})$\n",
    " - $p(Y_0,Y_1|X_0, X_1 \\text{ are intended and both } X_0, X_1 \\text{ have been produced})$\n",
    "\n",
    "For conciseness and clarity, I will refer to these via\n",
    " - $p_3(Y_0,Y_1|X_0, X_1)$\n",
    " - $p_6(Y_0,Y_1|X_0, X_1)$\n",
    "\n",
    "or \n",
    " - $p(Y_0,Y_1|X_0;X_1)$\n",
    " - $p(Y_0,Y_1|X_0,X_1)$\n",
    "\n",
    "The '3'/'6' notation refers to properties of the set of measurements (laboratory measures from 'gate 3' vs. from 'gate 6') that I'm using to define the two distributions here (or distributions derivable from just one or the other), right now -- an extensional, instrumental (a  programmer might say *imperative*) definition that tells you as a reader and analyst how to construct the distributions I am referring to right now. (That could plausibly change, but other properties of this object could stay the same.)\n",
    "\n",
    "The ';' notation is intended to highlight the temporal ordering/distinction among the events being conditioned on (a relation -- viz. a temporal ordering -- between the set of 'completed' or 'past' events to its left and the set of 'anticipated' events to its right): when '$X_0, X_1 \\text{ are intended and only } X_0 \\text{ has been produced}$', the event referred to by $X_1$ (the 'complete' acoustic production of the second segment of the diphone $X_0,X_1$) is in a meaningful sense a 'future' event (';' indicates the temporal horizon) whose effects on the present are mediated through anticipatory cognition and coarticulation during the production of $X_0$, which is being conditioned on i.e. temporally 'finished'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the structure of the joint event space (diphone in vs. diphone out), these are the logically possible conditional distributions where conditioning reflects straightforward causal/temporal ordering:\n",
    " - $p(Y_0|;)$\n",
    " - $p(Y_1|;)$\n",
    " - $p(Y_0,Y_1|;)$\n",
    " - $p(Y_0|X_0;X_1)$\n",
    " - $p(Y_0,Y_1|X_0;X_1)$\n",
    " - $p(Y_1|X_0;X_1)$\n",
    " - $p(Y_0|X_0,X_1;)$\n",
    " - $p(Y_0,Y_1|X_0,X_1;)$\n",
    " - $p(Y_1|X_0,X_1;)$\n",
    "\n",
    "\n",
    "Among these, what we really want to define/export are frequency distributions that (once normalized) let us calculate:\n",
    " - $p(Y|X \\text{ has been produced}) = p(Y|\\dot{X};)$ = 'the uniphone channel distribution'\n",
    "  - ...defined via marginalization as \n",
    "\n",
    "$$ p(\\dot{y}|\\dot{x})  = \\sum_\\limits{i=0}^{i=1}  p(Y_{i} = \\dot{y}|X_{i} = \\dot{x})p(i|X_i = \\dot{x})$$\n",
    "\n",
    "$$ p(\\dot{y}|\\dot{x})  =  p(Y_{i=0} = \\dot{y}|X_{i=0} = \\dot{x})p(i=0|X_i = \\dot{x}) + p(Y_{i=1} = \\dot{y}| X_1 = \\dot{x})p(i=1|X_i = \\dot{x}) $$\n",
    "\n",
    "$$ = p(Y_{i=0} = \\dot{y}|X_{i=0} = \\dot{x})\\frac{1}{2} + p(Y_{i=1} = \\dot{y}| X_1 = \\dot{x})\\frac{1}{2}$$\n",
    "  $$ = \\frac{1}{2} \\sum_\\limits{X_1} [ p(Y_{i=0} = \\dot{y}, X_1|X_{i=0} = \\dot{x})] + \\frac{1}{2} \\sum_\\limits{X_0} [ p(Y_{i=1} = \\dot{y}, X_0| X_1 = \\dot{x}) ] $$\n",
    "\n",
    "  $$ = \\frac{1}{2} \\sum_\\limits{X_1} [ p(Y_0 = \\dot{y}|X_0 = \\dot{x}, X_1) p(X_1|X_0 = \\dot{x})] + \\frac{1}{2}  \\sum_\\limits{X_0} [ p(Y_1 = \\dot{y}|X_1 = \\dot{x}, X_0) p(X_0|X_1 = \\dot{x})]$$\n",
    "\n",
    "  - more explicitly:\n",
    "    $$p(\\dot{y}|\\dot{x}) = \\frac{1}{2} \\sum_\\limits{X_1} [ p(Y_0 = \\dot{y}|X_0 = \\dot{x}, X_1 \\text{ are intended & only } X_0 \\text{ has been produced}) p(X_1 \\text{ intended but not produced yet} |X_0 = \\dot{x} \\text{ intended & produced}) ] \\\\ + \\frac{1}{2} \\sum_\\limits{X_0} [ p(Y_1 = \\dot{y}|X_0, X_1 = \\dot{x} \\text{ intended & produced}) p(X_0 \\text{ intended & produced} |X_1 = \\dot{x}) ]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or \n",
    "\n",
    "\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2} \\sum_\\limits{X_1} \\sum_\\limits{Y_1}[ p_3(Y_0 = \\dot{y},Y_1|X_0 = \\dot{x}, X_1)  p(X_1|X_0 = \\dot{x})] + \\frac{1}{2} \\sum_\\limits{X_0} \\sum_\\limits{Y_0} p_6(Y_0,Y_1 = \\dot{y}|X_0, X_1 = \\dot{x})  p(X_0|X_1 = \\dot{x})]$$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2} \\sum_\\limits{X_1} \\sum_\\limits{Y_1}[ p(Y_0 = \\dot{y},Y_1|X_0 = \\dot{x}; X_1)  p(X_1|X_0 = \\dot{x})] + \\frac{1}{2} \\sum_\\limits{X_0} \\sum_\\limits{Y_0} [ p(Y_0,Y_1 = \\dot{y}|X_0, X_1 = \\dot{x})  p(X_0|X_1 = \\dot{x})]$$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2} \\sum_\\limits{X_1} [ p(Y_0 = \\dot{y}|X_0 = \\dot{x}; X_1)  p(X_1|X_0 = \\dot{x})] + \\frac{1}{2} \\sum_\\limits{X_0}  [ p(Y_1 = \\dot{y}|X_0, X_1 = \\dot{x})  p(X_0|X_1 = \\dot{x})]$$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2n} \\sum_\\limits{X_1} [ p(Y_0 = \\dot{y}|X_0 = \\dot{x}; X_1) ] + \\frac{1}{2m} \\sum_\\limits{X_0}  [ p(Y_1 = \\dot{y}|X_0, X_1 = \\dot{x}) ]$$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2} p(Y_0 = \\dot{y}|X_0 = \\dot{x};)  + \\frac{1}{2} p(Y_1 = \\dot{y}|X_1 = \\dot{x})$$\n",
    "\n",
    "\n",
    "where $n = |\\{ X_1|p(X_1|X_0 = \\dot{x}) > 0 \\}|$ and $m = |\\{ X_0|p(X_0|X_1 = \\dot{x}) > 0 \\}|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T23:23:49.909098Z",
     "start_time": "2018-03-23T23:23:49.894645Z"
    }
   },
   "source": [
    "...and a set of terms relevant to a triphone noise/coarticulation model:\n",
    "\n",
    "- $p(Y_i|X_{i-1},X_{i};X_{i+1})$ - what I'll refer to as a 'triphone channel distribution', whose calculation is derived and explained elsewhere \\FIXME insert reference.\n",
    " \n",
    "- $p(Y_{i+1} | X_i; X_{i+1} )$ - what I'll refer to as 'the preview term', whose calculation is derived and explained elsewhere \\FIXME insert reference.\n",
    " \n",
    "- $p(Y_{i-1} | X_{i-1}, X_i;)$ - what I'll refer to as 'the hindsight term', whose calculation is derived and explained elsewhere \\FIXME insert reference.\n",
    "\n",
    "- $p(Y_0^f | X_0^f;)$ - the channel distribution over the complete (expected) received/perceived signal given a complete produced wordform $X_0^f$.\n",
    "\n",
    "- $p(Y_0^f | X_0^i; X_{i+1})$ - the channel distribution over the complete (expected) received/perceived signal given a produced prefix $X_0^i$ and an upcoming segment $X_{i+1}$.\n",
    "\n",
    "- $p(Y_0^{i} | X_0^i; X_{i+1})$ - the matched-length channel distribution over $Y_0^{i}$ given a produced prefix $X_0^i$ and an upcoming segment $X_{i+1}$.\n",
    "\n",
    "- $p(Y_0^{i}; Y_{i+1} | X_0^i; X_{i+1})$ - the matched-length channel distribution over $Y_0^{i+1}$ given a produced prefix $X_0^i$ and an upcoming segment $X_{i+1}$.\n",
    "\n",
    "- $p(Y_0^j | X_0^i; X_{i+1})$ - the arbitrary-length channel distribution given a produced prefix $X_0^i$ and an upcoming segment $X_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the sample space and exporting gate 3 and gate 6 trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create non-trivial counts, some trials need to be considered *the same* as other trials -- I need to define equivalence classes and exclusion criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclusion criteria:** For now, I'm only interested in trials occurring at gates 3 or 6 (= all of the way through the first segment in the diphone and all of the way through the second segment in the diphone, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:23.841587Z",
     "start_time": "2019-02-20T17:42:23.728874Z"
    }
   },
   "outputs": [],
   "source": [
    "def include(row):\n",
    "    return row['gate'] == '3' or row['gate'] == '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:24.008031Z",
     "start_time": "2019-02-20T17:42:23.845726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# aligned trials, pre-filter: 269280\n",
      "# aligned trials, post-filter: 91520\n",
      "# trials filtered: 177760\n",
      "% trials filtered: 66.01307189542483\n"
     ]
    }
   ],
   "source": [
    "print('# aligned trials, pre-filter: {0}'.format(len(unfiltered_rows)))\n",
    "filtered_rows = [row for row in unfiltered_rows if include(row)]\n",
    "print('# aligned trials, post-filter: {0}'.format(len(filtered_rows)))\n",
    "print('# trials filtered: {0}'.format( len(unfiltered_rows) - len(filtered_rows) ))\n",
    "print('% trials filtered: {0}'.format( (len(unfiltered_rows) - len(filtered_rows)) / len(unfiltered_rows) * 100.0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:24.056748Z",
     "start_time": "2019-02-20T17:42:24.009010Z"
    }
   },
   "outputs": [],
   "source": [
    "rows_gate3 = [row for row in filtered_rows if row['gate'] == '3']\n",
    "rows_gate6 = [row for row in filtered_rows if row['gate'] == '6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export these trials for convenient analysis in R..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:24.131720Z",
     "start_time": "2019-02-20T17:42:24.057571Z"
    }
   },
   "outputs": [],
   "source": [
    "#assuming we are picking up from processing IPhOD\n",
    "fieldnames = ['Subject', 'Diph_num', 'Diph_name', 'Sylltype', 'SoundFile', 'Prec_context', 'gate', 'four_gate', \n",
    "              'seg1_stress', 'seg2_stress', 'CorrAns1', 'CorrAns2', 'Resp1', 'Resp2', 'Seg1Accur', 'Seg2Accur', \n",
    "              'Prec_context_binary', 'wrong_preccontext', 'replacedSeg1Data', 'replacedSeg2Data', \n",
    "              'diphoneInWStress', 'diphoneInSeg', 'diphoneOutSeg', 'stimulusWProsody', 'stimulusSeg', \n",
    "              'prefixWStress', 'prefixSeg', 'suffixWStress', 'suffixSeg']\n",
    "assert(len(the_fields) == len(fieldnames)) #I'm manually defining fieldnames here to ensure an ordering over columns.\n",
    "\n",
    "filename_out_stem3 = whichNoCount + ' gate3 trials'\n",
    "filename_out_stem6 = whichNoCount + ' gate6 trials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:24.910046Z",
     "start_time": "2019-02-20T17:42:24.133881Z"
    }
   },
   "outputs": [],
   "source": [
    "writeProcessedDataToCSV(rows_gate3, fieldnames, filename_out_stem3 + '.csv')\n",
    "writeProcessedDataToCSV(rows_gate6, fieldnames, filename_out_stem6 + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:24.913991Z",
     "start_time": "2019-02-20T17:42:24.911061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/AD/emeinhar/c2-jn'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.186325Z",
     "start_time": "2019-02-20T17:42:24.914832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hammond-aligned_destressed gate3 trials.csv'\r\n",
      "'Hammond-aligned_destressed gate6 trials.csv'\r\n"
     ]
    }
   ],
   "source": [
    "%ls *gate*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define conditional distributions $f_3(Y_0, Y_1| X_0; X_1)$, $f_6(Y_0, Y_1| X_0, X_1;)$ and add pseudocounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to directly define two conditional probability distributions that let us calculate channel distributions like the following:\n",
    "\n",
    "- $p(Y_0, Y_1|X_0,X_1 = dð \\text{ and only } X_0 = d \\text{ has been fully produced/perceived})$\n",
    "- $p(Y_0, Y_1|X_0, X_1 = dð \\text{ and both } X_0 = d \\text{ and } X_1 = ð \\text{ has been fully produced/perceived})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pseudocount counter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.219715Z",
     "start_time": "2019-02-20T17:42:25.191868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s.θ', 'h.ʌ', 'æ.dʒ', 'oʊ.ŋ', 'f.ð', 'dʒ.v', 'u.m', 'p.ð', 'oʊ.æ', 'g.z']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1421"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(response_diphones)[:10]\n",
    "len(response_diphones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.328803Z",
     "start_time": "2019-02-20T17:42:25.220929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1421"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1421"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudocounts = Counter(response_diphones) #everything defaults to a count of one\n",
    "pseudocounts['ð.v']\n",
    "len(pseudocounts)\n",
    "sum(pseudocounts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set all of the pseudocounts per the top-level notebook parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.429656Z",
     "start_time": "2019-02-20T17:42:25.333045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4209999999999543"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudocount\n",
    "for diph in response_diphones:\n",
    "    pseudocounts[diph] = pseudocount\n",
    "sum(pseudocounts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll adjust observed counts by adding the pseudocount counter to them, as in e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.571335Z",
     "start_time": "2019-02-20T17:42:25.434110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudocounts['ð.v']\n",
    "q = pseudocounts + Counter({'ð.v':1})\n",
    "q['ð.v']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response counts (+ pseudocounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.673424Z",
     "start_time": "2019-02-20T17:42:25.575706Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTrialsWhereStimulusDiphoneSegsAre(stim_diphoneAsStr, trials):\n",
    "    return [trial for trial in trials if getDiphonesInAsStr(trial) == stim_diphoneAsStr]\n",
    "\n",
    "# conditional distribution over responses...\n",
    "def getCondFreqDistOverDiphoneOutSegs(trialsWithSameDiphoneInSegs, pseudocounts = None):\n",
    "    trials = trialsWithSameDiphoneInSegs\n",
    "    assert(len(trials) > 0)\n",
    "    if len(trials) > 0:\n",
    "        stim_diphoneAsStr = getDiphonesInAsStr(trials[0])\n",
    "        assert all([getDiphonesInAsStr(trial) == stim_diphoneAsStr for trial in trials])\n",
    "    \n",
    "    getOutcome = lambda trial: trial['diphoneOutSeg']\n",
    "    outcomes = set(map(getOutcome, trials))\n",
    "    condFreqDist = {outcome:len([trial for trial in trials if getOutcome(trial) == outcome]) for outcome in outcomes}\n",
    "    if pseudocounts != None:\n",
    "        assert type(pseudocounts) == type(Counter()), 'pseudocounts must be a Counter object. Got {0}'.format(type(pseudocounts))\n",
    "        return Counter(condFreqDist) + pseudocounts\n",
    "    return Counter(condFreqDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example trial/stimulus diphone and its distribution over responses at gate 3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.786823Z",
     "start_time": "2019-02-20T17:42:25.677916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Subject', '5'),\n",
       "             ('Diph_num', '17'),\n",
       "             ('Diph_name', 'Db'),\n",
       "             ('Sylltype', 'CC'),\n",
       "             ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "             ('Prec_context', 'ɑ'),\n",
       "             ('gate', '3'),\n",
       "             ('four_gate', '0'),\n",
       "             ('seg1_stress', '2'),\n",
       "             ('seg2_stress', '2'),\n",
       "             ('CorrAns1', 'ð'),\n",
       "             ('CorrAns2', 'b'),\n",
       "             ('Resp1', 'v'),\n",
       "             ('Resp2', 'ð'),\n",
       "             ('Seg1Accur', '0'),\n",
       "             ('Seg2Accur', '0'),\n",
       "             ('Prec_context_binary', '1'),\n",
       "             ('wrong_preccontext', ' '),\n",
       "             ('replacedSeg1Data', ' '),\n",
       "             ('replacedSeg2Data', ' '),\n",
       "             ('diphoneInWStress', 'ð2.b2'),\n",
       "             ('diphoneInSeg', 'ð.b'),\n",
       "             ('diphoneOutSeg', 'v.ð'),\n",
       "             ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "             ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "             ('prefixWStress', 'ɑ1.'),\n",
       "             ('prefixSeg', 'ɑ'),\n",
       "             ('suffixWStress', '.ə0'),\n",
       "             ('suffixSeg', 'ə')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTrial = rows_gate3[324]\n",
    "myTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:25.916173Z",
     "start_time": "2019-02-20T17:42:25.790714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ð.b'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDiphoneInSeg = getDiphonesInAsStr(myTrial)\n",
    "myDiphoneInSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:26.020379Z",
     "start_time": "2019-02-20T17:42:25.920860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Subject', '1'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 't'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.t'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '2'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'ʌ'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.ʌ'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '3'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'v'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.v'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '4'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'ʌ'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.ʌ'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '5'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'ð'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.ð'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '7'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'ʌ'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.ʌ'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '10'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'ʌ'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.ʌ'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '11'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'θ'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.θ'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '12'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundFile', '0017_Db_CC-g3-beeped.wav'),\n",
       "              ('Prec_context', 'ɑ'),\n",
       "              ('gate', '3'),\n",
       "              ('four_gate', '0'),\n",
       "              ('seg1_stress', '2'),\n",
       "              ('seg2_stress', '2'),\n",
       "              ('CorrAns1', 'ð'),\n",
       "              ('CorrAns2', 'b'),\n",
       "              ('Resp1', 'v'),\n",
       "              ('Resp2', 'ʒ'),\n",
       "              ('Seg1Accur', '0'),\n",
       "              ('Seg2Accur', '0'),\n",
       "              ('Prec_context_binary', '1'),\n",
       "              ('wrong_preccontext', ' '),\n",
       "              ('replacedSeg1Data', ' '),\n",
       "              ('replacedSeg2Data', ' '),\n",
       "              ('diphoneInWStress', 'ð2.b2'),\n",
       "              ('diphoneInSeg', 'ð.b'),\n",
       "              ('diphoneOutSeg', 'v.ʒ'),\n",
       "              ('stimulusWProsody', 'ɑ1.ð2-b2.ə0'),\n",
       "              ('stimulusSeg', 'ɑ.ð.b.ə'),\n",
       "              ('prefixWStress', 'ɑ1.'),\n",
       "              ('prefixSeg', 'ɑ'),\n",
       "              ('suffixWStress', '.ə0'),\n",
       "              ('suffixSeg', 'ə')]),\n",
       " OrderedDict([('Subject', '15'),\n",
       "              ('Diph_num', '17'),\n",
       "              ('Diph_name', 'Db'),\n",
       "              ('Sylltype', 'CC'),\n",
       "              ('SoundF"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10935 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_response_trials = getTrialsWhereStimulusDiphoneSegsAre(myDiphoneInSeg, rows_gate3)\n",
    "len(my_response_trials)\n",
    "my_response_trials[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:26.098037Z",
     "start_time": "2019-02-20T17:42:26.021332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ð.h': 1,\n",
       "         'v.ð': 2,\n",
       "         'θ.d': 1,\n",
       "         'θ.b': 1,\n",
       "         'ð.ɚ': 1,\n",
       "         'v.ɛ': 1,\n",
       "         'v.ʌ': 5,\n",
       "         'v.ɪ': 1,\n",
       "         'v.θ': 1,\n",
       "         'v.t': 1,\n",
       "         'v.ʒ': 1,\n",
       "         'v.h': 1,\n",
       "         'ð.u': 1,\n",
       "         'v.v': 2})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_response_dist = getCondFreqDistOverDiphoneOutSegs(my_response_trials)\n",
    "my_response_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:26.190452Z",
     "start_time": "2019-02-20T17:42:26.102527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ð.h': 1.001,\n",
       "         'v.ð': 2.001,\n",
       "         'θ.d': 1.001,\n",
       "         'θ.b': 1.001,\n",
       "         'ð.ɚ': 1.001,\n",
       "         'v.ɛ': 1.001,\n",
       "         'v.ʌ': 5.001,\n",
       "         'v.ɪ': 1.001,\n",
       "         'v.θ': 1.001,\n",
       "         'v.t': 1.001,\n",
       "         'v.ʒ': 1.001,\n",
       "         'v.h': 1.001,\n",
       "         'ð.u': 1.001,\n",
       "         'v.v': 2.001,\n",
       "         's.θ': 0.001,\n",
       "         'h.ʌ': 0.001,\n",
       "         'æ.dʒ': 0.001,\n",
       "         'oʊ.ŋ': 0.001,\n",
       "         'f.ð': 0.001,\n",
       "         'dʒ.v': 0.001,\n",
       "         'u.m': 0.001,\n",
       "         'p.ð': 0.001,\n",
       "         'oʊ.æ': 0.001,\n",
       "         'g.z': 0.001,\n",
       "         'ʒ.tʃ': 0.001,\n",
       "         'b.r': 0.001,\n",
       "         'i.ɪ': 0.001,\n",
       "         'tʃ.eɪ': 0.001,\n",
       "         'ŋ.m': 0.001,\n",
       "         'aɪ.ɪ': 0.001,\n",
       "         'ð.w': 0.001,\n",
       "         'h.r': 0.001,\n",
       "         'ʊ.dʒ': 0.001,\n",
       "         'v.ɔɪ': 0.001,\n",
       "         'ʒ.u': 0.001,\n",
       "         'ʊ.tʃ': 0.001,\n",
       "         'z.m': 0.001,\n",
       "         'eɪ.æ': 0.001,\n",
       "         'j.ɛ': 0.001,\n",
       "         'ʒ.d': 0.001,\n",
       "         'p.k': 0.001,\n",
       "         'k.z': 0.001,\n",
       "         't.ʃ': 0.001,\n",
       "         's.t': 0.001,\n",
       "         'ʌ.ɚ': 0.001,\n",
       "         'ʌ.ʌ': 0.001,\n",
       "         'g.p': 0.001,\n",
       "         'i.l': 0.001,\n",
       "         'd.ɔɪ': 0.001,\n",
       "         'θ.l': 0.001,\n",
       "         'eɪ.b': 0.001,\n",
       "         'l.ɔɪ': 0.001,\n",
       "         'g.θ': 0.001,\n",
       "         'l.ʊ': 0.001,\n",
       "         'i.z': 0.001,\n",
       "         'θ.v': 0.001,\n",
       "         'ʃ.b': 0.001,\n",
       "         'dʒ.m': 0.001,\n",
       "         'ɛ.u': 0.001,\n",
       "         'r.z': 0.001,\n",
       "         'aʊ.g': 0.001,\n",
       "         'n.u': 0.001,\n",
       "         'j.aʊ': 0.001,\n",
       "         'b.w': 0.001,\n",
       "         'i.s': 0.001,\n",
       "         'f.ɛ': 0.001,\n",
       "         't.n': 0.001,\n",
       "         'b.s': 0.001,\n",
       "         'r.eɪ': 0.001,\n",
       "         'ɔɪ.r': 0.001,\n",
       "         'p.dʒ': 0.001,\n",
       "         'v.i': 0.001,\n",
       "         'm.s': 0.001,\n",
       "         'p.m': 0.001,\n",
       "         'ɚ.b': 0.001,\n",
       "         'k.ɑ': 0.001,\n",
       "         'w.n': 0.001,\n",
       "         'b.tʃ': 0.001,\n",
       "         'z.l': 0.001,\n",
       "         'ɛ.dʒ': 0.001,\n",
       "         'i.ʒ': 0.001,\n",
       "         'k.f': 0.001,\n",
       "         'tʃ.ŋ': 0.001,\n",
       "         'f.r': 0.001,\n",
       "         'k.v': 0.001,\n",
       "         'l.æ': 0.001,\n",
       "         'f.æ': 0.001,\n",
       "         'r.u': 0.001,\n",
       "         'i.p': 0.001,\n",
       "         'z.s': 0.001,\n",
       "         'ð.v': 0.001,\n",
       "         'ɑ.ɪ': 0.001,\n",
       "         'ɚ.r': 0.001,\n",
       "         'h.h': 0.001,\n",
       "         'ɔɪ.h': 0.001,\n",
       "         'dʒ.p': 0.001,\n",
       "         'ɛ.m': 0.001,\n",
       "         'ɪ.ð': 0.001,\n",
       "         'ʒ.eɪ': 0.001,\n",
       "         'aʊ.s': 0.001,\n",
       "         'ɛ.t': 0.001,\n",
       "         'h.j': 0.001,\n",
       "         'ɛ.ɚ': 0.001,\n",
       "         'l.tʃ': 0.001,\n",
       "         'æ.d': 0.001,\n",
       "         'w.s': 0.001,\n",
       "         'æ.l': 0.001,\n",
       "         'tʃ.i': 0.001,\n",
       "         'g.ʒ': 0.001,\n",
       "         'tʃ.θ': 0.001,\n",
       "         'p.g': 0.001,\n",
       "         'm.n': 0.001,\n",
       "         'ʌ.i': 0.001,\n",
       "         't.t': 0.001,\n",
       "         'ɑ.ɚ': 0.001,\n",
       "         'ʃ.aʊ': 0.001,\n",
       "         'ʃ.ʊ': 0.001,\n",
       "         'oʊ.d': 0.001,\n",
       "         'l.g': 0.001,\n",
       "         'ŋ.ʃ': 0.001,\n",
       "         'θ.ŋ': 0.001,\n",
       "         'oʊ.s': 0.001,\n",
       "         'ʒ.g': 0.001,\n",
       "         'ʊ.i': 0.001,\n",
       "         'u.ɚ': 0.001,\n",
       "         'l.b': 0.001,\n",
       "         'm.m': 0.001,\n",
       "         'b.ɔɪ': 0.001,\n",
       "         'i.ɛ': 0.001,\n",
       "         'ʌ.ʒ': 0.001,\n",
       "         'i.eɪ': 0.001,\n",
       "         'ʒ.ʊ': 0.001,\n",
       "         'ɪ.ʒ': 0.001,\n",
       "         'p.p': 0.001,\n",
       "         'ɔɪ.w': 0.001,\n",
       "         'k.w': 0.001,\n",
       "         'ɔɪ.u': 0.001,\n",
       "         'u.p': 0.001,\n",
       "         'aʊ.m': 0.001,\n",
       "         'f.θ': 0.001,\n",
       "         'ɔɪ.b': 0.001,\n",
       "         'r.r': 0.001,\n",
       "         's.g': 0.001,\n",
       "         'k.b': 0.001,\n",
       "         'm.d': 0.001,\n",
       "         'm.dʒ': 0.001,\n",
       "         'ɔɪ.j': 0.001,\n",
       "         'i.k': 0.001,\n",
       "         'ɑ.ɑ': 0.001,\n",
       "         'ɑ.b': 0.001,\n",
       "         'ɔɪ.ɚ': 0.001,\n",
       "         'ʌ.ʊ': 0.001,\n",
       "         'b.ð': 0.001,\n",
       "         'p.ŋ': 0.001,\n",
       "         'p.d': 0.001,\n",
       "         'θ.ʃ': 0.001,\n",
       "         'dʒ.aɪ': 0.001,\n",
       "         'aɪ.ŋ': 0.001,\n",
       "         't.ð': 0.001,\n",
       "         'ŋ.ɔɪ': 0.001,\n",
       "         'u.v': 0.001,\n",
       "         'v.r': 0.001,\n",
       "         'ʌ.f': 0.001,\n",
       "         'w.t': 0.001,\n",
       "         'l.f': 0.001,\n",
       "         'g.ɪ': 0.001,\n",
       "         'ɪ.v': 0.001,\n",
       "         'f.n': 0.001,\n",
       "         'u.tʃ': 0.001,\n",
       "         'j.v': 0.001,\n",
       "         'v.g': 0.001,\n",
       "         'ʒ.p': 0.001,\n",
       "         'k.oʊ': 0.001,\n",
       "         'θ.n': 0.001,\n",
       "         'w.θ': 0.001,\n",
       "         'j.ʊ': 0.001,\n",
       "         'r.ɔɪ': 0.001,\n",
       "         't.ɑ': 0.001,\n",
       "         'k.h': 0.001,\n",
       "         'l.ð': 0.001,\n",
       "         'ɔɪ.t': 0.001,\n",
       "         'θ.f': 0.001,\n",
       "         'dʒ.z': 0.001,\n",
       "         'z.æ': 0.001,\n",
       "         't.z': 0.001,\n",
       "         'w.d': 0.001,\n",
       "         'k.ʃ': 0.001,\n",
       "         'z.v': 0.001,\n",
       "         'aɪ.z': 0.001,\n",
       "         'g.k': 0.001,\n",
       "         'n.h': 0.001,\n",
       "         'ŋ.aɪ': 0.001,\n",
       "         'oʊ.r': 0.001,\n",
       "         'tʃ.dʒ': 0.001,\n",
       "         'z.b': 0.001,\n",
       "         'oʊ.k': 0.001,\n",
       "         'n.r': 0.001,\n",
       "         'l.ʌ': 0.001,\n",
       "         'i.g': 0.001,\n",
       "         'f.f': 0.001,\n",
       "         'w.i': 0.001,\n",
       "         'r.m': 0.001,\n",
       "         'z.oʊ': 0.001,\n",
       "         'u.z': 0.001,\n",
       "         'w.k': 0.001,\n",
       "         'j.s': 0.001,\n",
       "         'i.u': 0.001,\n",
       "         'b.ʃ': 0.001,\n",
       "         'n.eɪ': 0.001,\n",
       "         'ð.z': 0.001,\n",
       "         'dʒ.ʃ': 0.001,\n",
       "         'ɚ.oʊ': 0.001,\n",
       "         't.u': 0.001,\n",
       "         'ɑ.d': 0.001,\n",
       "         'oʊ.ɪ': 0.001,\n",
       "         'ʒ.æ': 0.001,\n",
       "         'ʌ.h': 0.001,\n",
       "         'v.p': 0.001,\n",
       "         'aʊ.k': 0.001,\n",
       "         'n.ɑ': 0.001,\n",
       "         'z.ʒ': 0.001,\n",
       "         'u.ð': 0.001,\n",
       "         'ŋ.w': 0.001,\n",
       "         'ɑ.h': 0.001,\n",
       "         'eɪ.t': 0.001,\n",
       "         'd.ɚ': 0.001,\n",
       "         'aʊ.d': 0.001,\n",
       "         'u.ɛ': 0.001,\n",
       "         'm.z': 0.001,\n",
       "         'g.s': 0.001,\n",
       "         'i.ɚ': 0.001,\n",
       "         'ɪ.p': 0.001,\n",
       "         'ŋ.d': 0.001,\n",
       "         'k.k': 0.001,\n",
       "         'n.z': 0.001,\n",
       "         'd.oʊ': 0.001,\n",
       "         's.ɪ': 0.001,\n",
       "         'ɔɪ.f': 0.001,\n",
       "         'ŋ.i': 0.001,\n",
       "         'i.ŋ': 0.001,\n",
       "         'ɛ.tʃ': 0.001,\n",
       "         'm.tʃ': 0.001,\n",
       "         's.ɚ': 0.001,\n",
       "         'ɑ.ʃ': 0.001,\n",
       "         'u.n': 0.001,\n",
       "         'v.w': 0.001,\n",
       "         'tʃ.oʊ': 0.001,\n",
       "         'ɚ.ð': 0.001,\n",
       "         'aɪ.oʊ': 0.001,\n",
       "         'b.u': 0.001,\n",
       "         'm.ʒ': 0.001,\n",
       "         'n.ɪ': 0.001,\n",
       "         'z.i': 0.001,\n",
       "         'b.n': 0.001,\n",
       "         'æ.ɚ': 0.001,\n",
       "         'ɪ.eɪ': 0.001,\n",
       "         'g.ɚ': 0.001,\n",
       "         'tʃ.aʊ': 0.001,\n",
       "         'ɛ.j': 0.001,\n",
       "         'g.ɑ': 0.001,\n",
       "         'r.k': 0.001,\n",
       "         'æ.ɑ': 0.001,\n",
       "         'θ.ɚ': 0.001,\n",
       "         'h.u': 0.001,\n",
       "         'aɪ.l': 0.001,\n",
       "         'oʊ.ð': 0.001,\n",
       "         'z.aʊ': 0.001,\n",
       "         'ʌ.z': 0.001,\n",
       "         't.ɚ': 0.001,\n",
       "         'f.ʊ': 0.001,\n",
       "         'aʊ.æ': 0.001,\n",
       "         'ð.ʌ': 0.001,\n",
       "         'aɪ.m': 0.001,\n",
       "         'oʊ.w': 0.001,\n",
       "         'g.ʃ': 0.001,\n",
       "         'b.g': 0.001,\n",
       "         'n.v': 0.001,\n",
       "         'b.eɪ': 0.001,\n",
       "         'w.g': 0.001,\n",
       "         'j.r': 0.001,\n",
       "         'ʃ.θ': 0.001,\n",
       "         'ʌ.v': 0.001,\n",
       "         'ɛ.eɪ': 0.001,\n",
       "         'ɪ.θ': 0.001,\n",
       "         's.ɑ': 0.001,\n",
       "         'h.ɔɪ': 0.001,\n",
       "         'ʌ.aʊ': 0.001,\n",
       "         'æ.w': 0.001,\n",
       "         't.ʌ': 0.001,\n",
       "         'ɚ.ɚ': 0.001,\n",
       "         'l.s': 0.001,\n",
       "         'θ.z': 0.001,\n",
       "         'aʊ.ɑ': 0.001,\n",
       "         'ɪ.ɪ': 0.001,\n",
       "         'ʌ.eɪ': 0.001,\n",
       "         's.v': 0.001,\n",
       "         'aɪ.d': 0.001,\n",
       "         'l.θ': 0.001,\n",
       "         'j.ɚ': 0.001,\n",
       "         'r.ɛ': 0.001,\n",
       "         'z.d': 0.001,\n",
       "         'ɚ.z': 0.001,\n",
       "         'ɔɪ.n': 0.001,\n",
       "         'p.ɪ': 0.001,\n",
       "         'i.n': 0.001,\n",
       "         'ʃ.ʌ': 0.001,\n",
       "         'r.ʊ': 0.001,\n",
       "         'tʃ.ʃ': 0.001,\n",
       "         'ɚ.l': 0.001,\n",
       "         'ɑ.k': 0.001,\n",
       "         'oʊ.eɪ': 0.001,\n",
       "         'l.v': 0.001,\n",
       "         'θ.h': 0.001,\n",
       "         'æ.n': 0.001,\n",
       "         'f.eɪ': 0.001,\n",
       "         'ŋ.k': 0.001,\n",
       "         'ð.ʒ': 0.001,\n",
       "         'eɪ.r': 0.001,\n",
       "         'k.i': 0.001,\n",
       "         'ŋ.eɪ': 0.001,\n",
       "         'g.dʒ': 0.001,\n",
       "         't.aʊ': 0.001,\n",
       "         'w.z': 0.001,\n",
       "         'z.dʒ': 0.001,\n",
       "         'oʊ.u': 0.001,\n",
       "         's.r': 0.001,\n",
       "         'g.g': 0.001,\n",
       "         'l.l': 0.001,\n",
       "         'θ.ʊ': 0.001,\n",
       "         'ŋ.aʊ': 0.001,\n",
       "         'f.d': 0.001,\n",
       "         'w.w': 0.001,\n",
       "         'aʊ.ŋ': 0.001,\n",
       "         'n.j': 0.001,\n",
       "         'ɑ.z': 0.001,\n",
       "         'h.n': 0.001,\n",
       "         's.n': 0.001,\n",
       "         'ʊ.r': 0.001,\n",
       "         'm.ŋ': 0.001,\n",
       "         'n.b': 0.001,\n",
       "         'f.ʃ': 0.001,\n",
       "         'ʃ.ʒ': 0.001,\n",
       "         'aʊ.aʊ': 0.001,\n",
       "         'p.oʊ': 0.001,\n",
       "         'ɪ.ɚ': 0.001,\n",
       "         'ʒ.ɚ': 0.001,\n",
       "         't.h': 0.001,\n",
       "         'aɪ.w': 0.001,\n",
       "         't.j': 0.001,\n",
       "         'ɪ.ʃ': 0.001,\n",
       "         'æ.ɪ': 0.001,\n",
       "         'ʒ.ɛ': 0.001,\n",
       "         'l.u': 0.001,\n",
       "         'm.h': 0.001,\n",
       "         'p.aʊ': 0.001,\n",
       "         'dʒ.aʊ': 0.001,\n",
       "         'oʊ.ɔɪ': 0.001,\n",
       "         'aʊ.f': 0.001,\n",
       "         'r.ʒ': 0.001,\n",
       "         's.k': 0.001,\n",
       "         'oʊ.aɪ': 0.001,\n",
       "         'aɪ.ʒ': 0.001,\n",
       "         'ʃ.ɪ': 0.001,\n",
       "         'ɑ.u': 0.001,\n",
       "         'ʊ.n': 0.001,\n",
       "         'ɚ.h': 0.001,\n",
       "         'k.d': 0.001,\n",
       "         'i.d': 0.001,\n",
       "         'n.aɪ': 0.001,\n",
       "         'aɪ.aɪ': 0.001,\n",
       "         'h.tʃ': 0.001,\n",
       "         'ʌ.g': 0.001,\n",
       "         'aɪ.tʃ': 0.001,\n",
       "         'ɑ.i': 0.001,\n",
       "         'eɪ.ɪ': 0.001,\n",
       "         'aʊ.h': 0.001,\n",
       "         'j.g': 0.001,\n",
       "         'ɪ.oʊ': 0.001,\n",
       "         'm.eɪ': 0.001,\n",
       "         'ʊ.ŋ': 0.001,\n",
       "         'ʌ.aɪ': 0.001,\n",
       "         'ʊ.g': 0.001,\n",
       "         'v.aʊ': 0.001,\n",
       "         'k.ð': 0.001,\n",
       "         'aʊ.v': 0.001,\n",
       "         'v.m': 0.001,\n",
       "         'ʊ.l': 0.001,\n",
       "         'm.oʊ': 0.001,\n",
       "         'aʊ.ʒ': 0.001,\n",
       "         'æ.θ': 0.001,\n",
       "         'p.ʒ': 0.001,\n",
       "         'z.f': 0.001,\n",
       "         'p.f': 0.001,\n",
       "         'ŋ.n': 0.001,\n",
       "         'ð.ʊ': 0.001,\n",
       "         'ɔɪ.z': 0.001,\n",
       "         'u.f': 0.001,\n",
       "         'w.ɛ': 0.001,\n",
       "         'ɪ.h': 0.001,\n",
       "         'h.ɑ': 0.001,\n",
       "         'aɪ.ʌ': 0.001,\n",
       "         'ʒ.ð': 0.001,\n",
       "         'oʊ.ʊ': 0.001,\n",
       "         'ð.r': 0.001,\n",
       "         's.p': 0.001,\n",
       "         'oʊ.v': 0.001,\n",
       "         'ʊ.s': 0.001,\n",
       "         'aɪ.i': 0.001,\n",
       "         'aʊ.ɛ': 0.001,\n",
       "         'p.u': 0.001,\n",
       "         'ð.oʊ': 0.001,\n",
       "         'k.n': 0.001,\n",
       "         'ɔɪ.tʃ': 0.001,\n",
       "         'l.h': 0.001,\n",
       "         'tʃ.u': 0.001,\n",
       "         'ʌ.ð': 0.001,\n",
       "         'ŋ.p': 0.001,\n",
       "         'oʊ.ɚ': 0.001,\n",
       "         'ɚ.ɑ': 0.001,\n",
       "         'g.d': 0.001,\n",
       "         't.θ': 0.001,\n",
       "         'ʌ.s': 0.001,\n",
       "         'f.ɚ': 0.001,\n",
       "         'v.tʃ': 0.001,\n",
       "         'i.ʌ': 0.001,\n",
       "         'r.aɪ': 0.001,\n",
       "         'ɔɪ.i': 0.001,\n",
       "         'ɚ.aɪ': 0.001,\n",
       "         '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 23387 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getCondFreqDistOverDiphoneOutSegs(my_response_trials, pseudocounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate both lists of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:26.273370Z",
     "start_time": "2019-02-20T17:42:26.191317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eɪ.ʌ', 's.θ', 'r.dʒ', 'v.d', 'ʃ.ɪ', 'z.j', 'ɑ.u', 'aɪ.ʒ', 'h.ʌ', 'æ.dʒ']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stimuli_diphones)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:26.353002Z",
     "start_time": "2019-02-20T17:42:26.278083Z"
    }
   },
   "outputs": [],
   "source": [
    "# #NB this takes ~22m on a macbook air and 4.5 min on kotoba.ucsd.edu with no paralellization\n",
    "# gate3_dists = {stim_diph:getCondFreqDistOverDiphoneOutSegs(getTrialsWhereStimulusDiphoneSegsAre(stim_diph, rows_gate3), pseudocounts) for stim_diph in stimuli_diphones}\n",
    "# gate6_dists = {stim_diph:getCondFreqDistOverDiphoneOutSegs(getTrialsWhereStimulusDiphoneSegsAre(stim_diph, rows_gate6), pseudocounts) for stim_diph in stimuli_diphones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:28.913246Z",
     "start_time": "2019-02-20T17:42:26.357692Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1292 out of 1292 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "# takes ~1m with joblib+loky\n",
    "# takes 2s with joblib+multiprocessing\n",
    "def foo3(stim_diph):\n",
    "    return (stim_diph, getCondFreqDistOverDiphoneOutSegs(getTrialsWhereStimulusDiphoneSegsAre(stim_diph, rows_gate3), pseudocounts))\n",
    "gate3_dists = dict(Parallel(n_jobs=-1, backend='multiprocessing',verbose=5)(delayed(foo3)(stim_diph) for stim_diph in stimuli_diphones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.321367Z",
     "start_time": "2019-02-20T17:42:28.915676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1292 out of 1292 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "# takes ~1m with joblib+loky\n",
    "# takes ~2s with joblib+multiprocessing\n",
    "def foo6(stim_diph):\n",
    "    return (stim_diph, getCondFreqDistOverDiphoneOutSegs(getTrialsWhereStimulusDiphoneSegsAre(stim_diph, rows_gate6), pseudocounts))\n",
    "gate6_dists = dict(Parallel(n_jobs=-1, backend='multiprocessing',verbose=5)(delayed(foo6)(stim_diph) for stim_diph in stimuli_diphones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now directly define two conditional probability distributions:\n",
    "\n",
    "- $p(Y_0, Y_1|X_0,X_1 = dð \\text{ and only } X_0 = d \\text{ has been fully produced/perceived})$ can be calculated by normalizing the counts given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.324334Z",
     "start_time": "2019-02-20T17:42:31.322420Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f3(y_01, x_01):\n",
    "#     return gate3_dists[x_01][y_01]\n",
    "    return gate3_dists[x_01].get(y_01, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.460276Z",
     "start_time": "2019-02-20T17:42:31.325156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random key: ð.k\n",
      "Counter({'v.h': 5.001, 'v.ɪ': 3.001, 'v.θ': 2.001, 'ð.h': 1.001, 'v.f': 1.001, 'v.n': 1.001, 'v.i': 1.001, 'θ.ɪ': 1.001, 'v.ɛ': 1.001, 'v.ʌ': 1.001, 'v.k': 1.001, 'ð.ʌ': 1.001, 'ð.g': 1.001, 's.θ': 0.001, 'h.ʌ': 0.001, 'æ.dʒ': 0.001, 'oʊ.ŋ': 0.001, 'f.ð': 0.001, 'dʒ.v': 0.001, 'u.m': 0.001, 'p.ð': 0.001, 'oʊ.æ': 0.001, 'g.z': 0.001, 'ʒ.tʃ': 0.001, 'b.r': 0.001, 'i.ɪ': 0.001, 'tʃ.eɪ': 0.001, 'ŋ.m': 0.001, 'aɪ.ɪ': 0.001, 'ð.w': 0.001, 'h.r': 0.001, 'ʊ.dʒ': 0.001, 'v.ɔɪ': 0.001, 'ʒ.u': 0.001, 'ʊ.tʃ': 0.001, 'z.m': 0.001, 'eɪ.æ': 0.001, 'j.ɛ': 0.001, 'ʒ.d': 0.001, 'p.k': 0.001, 'k.z': 0.001, 't.ʃ': 0.001, 's.t': 0.001, 'ʌ.ɚ': 0.001, 'ʌ.ʌ': 0.001, 'g.p': 0.001, 'i.l': 0.001, 'd.ɔɪ': 0.001, 'θ.l': 0.001, 'eɪ.b': 0.001, 'l.ɔɪ': 0.001, 'g.θ': 0.001, 'l.ʊ': 0.001, 'i.z': 0.001, 'θ.v': 0.001, 'ʃ.b': 0.001, 'dʒ.m': 0.001, 'ɛ.u': 0.001, 'r.z': 0.001, 'aʊ.g': 0.001, 'n.u': 0.001, 'j.aʊ': 0.001, 'b.w': 0.001, 'i.s': 0.001, 'f.ɛ': 0.001, 't.n': 0.001, 'b.s': 0.001, 'r.eɪ': 0.001, 'ɔɪ.r': 0.001, 'p.dʒ': 0.001, 'm.s': 0.001, 'p.m': 0.001, 'ɚ.b': 0.001, 'k.ɑ': 0.001, 'w.n': 0.001, 'b.tʃ': 0.001, 'z.l': 0.001, 'ɛ.dʒ': 0.001, 'i.ʒ': 0.001, 'v.v': 0.001, 'k.f': 0.001, 'tʃ.ŋ': 0.001, 'f.r': 0.001, 'k.v': 0.001, 'l.æ': 0.001, 'f.æ': 0.001, 'r.u': 0.001, 'i.p': 0.001, 'z.s': 0.001, 'ð.v': 0.001, 'ɑ.ɪ': 0.001, 'ɚ.r': 0.001, 'h.h': 0.001, 'ɔɪ.h': 0.001, 'dʒ.p': 0.001, 'ɛ.m': 0.001, 'ɪ.ð': 0.001, 'ʒ.eɪ': 0.001, 'aʊ.s': 0.001, 'ɛ.t': 0.001, 'h.j': 0.001, 'ɛ.ɚ': 0.001, 'l.tʃ': 0.001, 'æ.d': 0.001, 'w.s': 0.001, 'æ.l': 0.001, 'tʃ.i': 0.001, 'g.ʒ': 0.001, 'tʃ.θ': 0.001, 'p.g': 0.001, 'm.n': 0.001, 'ʌ.i': 0.001, 't.t': 0.001, 'ɑ.ɚ': 0.001, 'ʃ.aʊ': 0.001, 'ʃ.ʊ': 0.001, 'oʊ.d': 0.001, 'l.g': 0.001, 'ŋ.ʃ': 0.001, 'θ.ŋ': 0.001, 'oʊ.s': 0.001, 'ʒ.g': 0.001, 'ʊ.i': 0.001, 'u.ɚ': 0.001, 'l.b': 0.001, 'm.m': 0.001, 'b.ɔɪ': 0.001, 'i.ɛ': 0.001, 'ʌ.ʒ': 0.001, 'i.eɪ': 0.001, 'ʒ.ʊ': 0.001, 'ɪ.ʒ': 0.001, 'p.p': 0.001, 'ɔɪ.w': 0.001, 'k.w': 0.001, 'ɔɪ.u': 0.001, 'u.p': 0.001, 'aʊ.m': 0.001, 'f.θ': 0.001, 'ɔɪ.b': 0.001, 'r.r': 0.001, 's.g': 0.001, 'k.b': 0.001, 'm.d': 0.001, 'm.dʒ': 0.001, 'ɔɪ.j': 0.001, 'i.k': 0.001, 'ɑ.ɑ': 0.001, 'ɑ.b': 0.001, 'ɔɪ.ɚ': 0.001, 'ʌ.ʊ': 0.001, 'b.ð': 0.001, 'p.ŋ': 0.001, 'p.d': 0.001, 'θ.ʃ': 0.001, 'dʒ.aɪ': 0.001, 'aɪ.ŋ': 0.001, 't.ð': 0.001, 'ŋ.ɔɪ': 0.001, 'u.v': 0.001, 'v.r': 0.001, 'ʌ.f': 0.001, 'w.t': 0.001, 'l.f': 0.001, 'g.ɪ': 0.001, 'ɪ.v': 0.001, 'f.n': 0.001, 'u.tʃ': 0.001, 'j.v': 0.001, 'v.g': 0.001, 'ʒ.p': 0.001, 'k.oʊ': 0.001, 'θ.n': 0.001, 'w.θ': 0.001, 'j.ʊ': 0.001, 'r.ɔɪ': 0.001, 't.ɑ': 0.001, 'k.h': 0.001, 'l.ð': 0.001, 'ɔɪ.t': 0.001, 'θ.f': 0.001, 'dʒ.z': 0.001, 'z.æ': 0.001, 't.z': 0.001, 'w.d': 0.001, 'k.ʃ': 0.001, 'z.v': 0.001, 'aɪ.z': 0.001, 'g.k': 0.001, 'n.h': 0.001, 'ŋ.aɪ': 0.001, 'oʊ.r': 0.001, 'tʃ.dʒ': 0.001, 'z.b': 0.001, 'oʊ.k': 0.001, 'n.r': 0.001, 'l.ʌ': 0.001, 'i.g': 0.001, 'f.f': 0.001, 'w.i': 0.001, 'r.m': 0.001, 'z.oʊ': 0.001, 'u.z': 0.001, 'w.k': 0.001, 'j.s': 0.001, 'i.u': 0.001, 'b.ʃ': 0.001, 'n.eɪ': 0.001, 'ð.z': 0.001, 'dʒ.ʃ': 0.001, 'ɚ.oʊ': 0.001, 't.u': 0.001, 'ɑ.d': 0.001, 'oʊ.ɪ': 0.001, 'ʒ.æ': 0.001, 'ʌ.h': 0.001, 'v.p': 0.001, 'aʊ.k': 0.001, 'n.ɑ': 0.001, 'z.ʒ': 0.001, 'u.ð': 0.001, 'ŋ.w': 0.001, 'ɑ.h': 0.001, 'eɪ.t': 0.001, 'd.ɚ': 0.001, 'aʊ.d': 0.001, 'u.ɛ': 0.001, 'm.z': 0.001, 'g.s': 0.001, 'i.ɚ': 0.001, 'ɪ.p': 0.001, 'ŋ.d': 0.001, 'k.k': 0.001, 'n.z': 0.001, 'd.oʊ': 0.001, 's.ɪ': 0.001, 'ɔɪ.f': 0.001, 'ŋ.i': 0.001, 'i.ŋ': 0.001, 'ɛ.tʃ': 0.001, 'm.tʃ': 0.001, 's.ɚ': 0.001, 'ɑ.ʃ': 0.001, 'u.n': 0.001, 'v.w': 0.001, 'tʃ.oʊ': 0.001, 'ɚ.ð': 0.001, 'aɪ.oʊ': 0.001, 'b.u': 0.001, 'm.ʒ': 0.001, 'n.ɪ': 0.001, 'z.i': 0.001, 'b.n': 0.001, 'æ.ɚ': 0.001, 'ɪ.eɪ': 0.001, 'g.ɚ': 0.001, 'tʃ.aʊ': 0.001, 'ɛ.j': 0.001, 'g.ɑ': 0.001, 'r.k': 0.001, 'æ.ɑ': 0.001, 'θ.ɚ': 0.001, 'h.u': 0.001, 'aɪ.l': 0.001, 'oʊ.ð': 0.001, 'z.aʊ': 0.001, 'ʌ.z': 0.001, 't.ɚ': 0.001, 'f.ʊ': 0.001, 'aʊ.æ': 0.001, 'aɪ.m': 0.001, 'oʊ.w': 0.001, 'g.ʃ': 0.001, 'b.g': 0.001, 'n.v': 0.001, 'b.eɪ': 0.001, 'w.g': 0.001, 'j.r': 0.001, 'ʃ.θ': 0.001, 'ʌ.v': 0.001, 'ɛ.eɪ': 0.001, 'ɪ.θ': 0.001, 's.ɑ': 0.001, 'h.ɔɪ': 0.001, 'ʌ.aʊ': 0.001, 'æ.w': 0.001, 't.ʌ': 0.001, 'ɚ.ɚ': 0.001, 'l.s': 0.001, 'θ.z': 0.001, 'aʊ.ɑ': 0.001, 'ɪ.ɪ': 0.001, 'ʌ.eɪ': 0.001, 's.v': 0.001, 'aɪ.d': 0.001, 'l.θ': 0.001, 'j.ɚ': 0.001, 'r.ɛ': 0.001, 'z.d': 0.001, 'ɚ.z': 0.001, 'ɔɪ.n': 0.001, 'p.ɪ': 0.001, 'i.n': 0.001, 'ʃ.ʌ': 0.001, 'r.ʊ': 0.001, 'tʃ.ʃ': 0.001, 'ɚ.l': 0.001, 'ɑ.k': 0.001, 'oʊ.eɪ': 0.001, 'l.v': 0.001, 'θ.h': 0.001, 'æ.n': 0.001, 'f.eɪ': 0.001, 'ŋ.k': 0.001, 'ð.ʒ': 0.001, 'eɪ.r': 0.001, 'k.i': 0.001, 'ŋ.eɪ': 0.001, 'g.dʒ': 0.001, 't.aʊ': 0.001, 'w.z': 0.001, 'z.dʒ': 0.001, 'oʊ.u': 0.001, 's.r': 0.001, 'g.g': 0.001, 'l.l': 0.001, 'θ.ʊ': 0.001, 'ŋ.aʊ': 0.001, 'f.d': 0.001, 'w.w': 0.001, 'aʊ.ŋ': 0.001, 'n.j': 0.001, 'ɑ.z': 0.001, 'h.n': 0.001, 's.n': 0.001, 'ʊ.r': 0.001, 'm.ŋ': 0.001, 'n.b': 0.001, 'f.ʃ': 0.001, 'ʃ.ʒ': 0.001, 'aʊ.aʊ': 0.001, 'p.oʊ': 0.001, 'ɪ.ɚ': 0.001, 'ʒ.ɚ': 0.001, 't.h': 0.001, 'aɪ.w': 0.001, 't.j': 0.001, 'ɪ.ʃ': 0.001, 'æ.ɪ': 0.001, 'ʒ.ɛ': 0.001, 'l.u': 0.001, 'm.h': 0.001, 'p.aʊ': 0.001, 'dʒ.aʊ': 0.001, 'oʊ.ɔɪ': 0.001, 'aʊ.f': 0.001, 'r.ʒ': 0.001, 's.k': 0.001, 'oʊ.aɪ': 0.001, 'aɪ.ʒ': 0.001, 'ʃ.ɪ': 0.001, 'ɑ.u': 0.001, 'ʊ.n': 0.001, 'ɚ.h': 0.001, 'k.d': 0.001, 'i.d': 0.001, 'n.aɪ': 0.001, 'aɪ.aɪ': 0.001, 'h.tʃ': 0.001, 'ʌ.g': 0.001, 'aɪ.tʃ': 0.001, 'ɑ.i': 0.001, 'eɪ.ɪ': 0.001, 'aʊ.h': 0.001, 'j.g': 0.001, 'ɪ.oʊ': 0.001, 'm.eɪ': 0.001, 'ʊ.ŋ': 0.001, 'ʌ.aɪ': 0.001, 'ʊ.g': 0.001, 'v.aʊ': 0.001, 'k.ð': 0.001, 'aʊ.v': 0.001, 'v.m': 0.001, 'ʊ.l': 0.001, 'm.oʊ': 0.001, 'aʊ.ʒ': 0.001, 'æ.θ': 0.001, 'p.ʒ': 0.001, 'z.f': 0.001, 'p.f': 0.001, 'ŋ.n': 0.001, 'ð.ʊ': 0.001, 'ɔɪ.z': 0.001, 'u.f': 0.001, 'v.ʒ': 0.001, 'w.ɛ': 0.001, 'ɪ.h': 0.001, 'h.ɑ': 0.001, 'aɪ.ʌ': 0.001, 'ʒ.ð': 0.001, 'oʊ.ʊ': 0.001, 'ð.r': 0.001, 's.p': 0.001, 'oʊ.v': 0.001, 'ʊ.s': 0.001, 'aɪ.i': 0.001, 'aʊ.ɛ': 0.001, 'p.u': 0.001, 'ð.oʊ': 0.001, 'k.n': 0.001, 'ɔɪ.tʃ': 0.001, 'l.h': 0.001, 'tʃ.u': 0.001, 'ʌ.ð': 0.001, 'ŋ.p': 0.001, 'ð.ɚ': 0.001, 'oʊ.ɚ': 0.001, 'ɚ.ɑ': 0.001, 'g.d': 0.001, 't.θ': 0.001, 'ʌ.s': 0.001, 'f.ɚ': 0.001, 'v.tʃ': 0.001, 'i.ʌ': 0.001, 'r.aɪ': 0.001, 'ɔɪ.i': 0.001, 'ɚ.aɪ': 0.001, 'b.æ': 0.001, 'aʊ.ɪ': 0.001, 'z.ɛ': 0.001, 'z.h': 0.001, 'g.w': 0.001, 'oʊ.ʒ': 0.001, 'oʊ.l': 0.001, 'eɪ.h': 0.001, 'ʊ.oʊ': 0.001, 'i.æ': 0.001, 'eɪ.s': 0.001, 'tʃ.h': 0.001, 'ɚ.ʊ': 0.001, 'd.l': 0.001, 't.w': 0.001, 'v.ʃ': 0.001, 'ɪ.ʊ': 0.001, 'ɔɪ.θ': 0.001, 'r.oʊ': 0.001, 'oʊ.oʊ': 0.001, 's.oʊ': 0.001, 'u.u': 0.001, 'ɪ.ɛ': 0.001, 'f.ɔɪ': 0.001, 'ɪ.r': 0.001, 'd.eɪ': 0.001, 'æ.eɪ': 0.001, 'eɪ.j': 0.001, 'r.aʊ': 0.001, 'aɪ.dʒ': 0.001, 'oʊ.aʊ': 0.001, 'ɚ.j': 0.001, 'eɪ.f': 0.001, 'p.ɚ': 0.001, 'h.k': 0.001, 'ʃ.tʃ': 0.001, 'b.dʒ': 0.001, 'ɪ.aʊ': 0.001, 'ʒ.oʊ': 0.001, 's.b': 0.001, 'ɚ.tʃ': 0.001, 'i.r': 0.001, 'l.aʊ': 0.001, 'i.w': 0.001, 'i.t': 0.001, 'ŋ.ɪ': 0.001, 'ŋ.u': 0.001, 'h.aɪ': 0.001, 'p.ɛ': 0.001, 's.dʒ': 0.001, 'ɪ.ɔɪ': 0.001, 'n.ʒ': 0.001, 'z.k': 0.001, 'ʌ.p': 0.001, 'ʒ.w': 0.001, 'tʃ.ʊ': 0.001, 'aʊ.dʒ': 0.001, 'ʃ.t': 0.001, 'aʊ.t': 0.001, 'eɪ.w': 0.001, 'ʊ.ɑ': 0.001, 'p.ʃ': 0.001, 'ɔɪ.oʊ': 0.001, 'ɑ.eɪ': 0.001, 'dʒ.f': 0.001, 'ʃ.aɪ': 0.001, 'oʊ.θ': 0.001, 'j.ʌ': 0.001, 't.ʒ': 0.001, 'ʌ.tʃ': 0.001, 'f.aɪ': 0.001, 'w.u': 0.001, 'b.j': 0.001, 'ɑ.p': 0.001, 'oʊ.dʒ': 0.001, 'eɪ.ɔɪ': 0.001, 'j.k': 0.001, 'h.ŋ': 0.001, 's.ɛ': 0.001, 'm.f': 0.001, 'ŋ.l': 0.001, 'ɚ.i': 0.001, 'θ.r': 0.001, 'f.ɑ': 0.001, 'ɔɪ.p': 0.001, 'ɪ.f': 0.001, 'r.w': 0.001, 'v.j': 0.001, 'ʌ.θ': 0.001, 'ɑ.ʊ': 0.001, 'ʃ.r': 0.001, 'm.ɚ': 0.001, 'ʒ.h': 0.001, 'u.ʌ': 0.001, 'n.n': 0.001, 'eɪ.tʃ': 0.001, 'j.tʃ': 0.001, 'ɛ.b': 0.001, 'k.u': 0.001, 'ɔɪ.ŋ': 0.001, 's.tʃ': 0.001, 'tʃ.l': 0.001, 'ɚ.ɪ': 0.001, 'z.ɚ': 0.001, 'ð.eɪ': 0.001, 'v.dʒ': 0.001, 'θ.t': 0.001, 'p.w': 0.001, 'h.ð': 0.001, 'm.r': 0.001, 'w.tʃ': 0.001, 'u.ʊ': 0.001, 'd.aʊ': 0.001, 'aɪ.f': 0.001, 'z.n': 0.001, 'ʌ.ŋ': 0.001, 'd.tʃ': 0.001, 'p.aɪ': 0.001, 's.ʃ': 0.001, 'ʒ.t': 0.001, 'z.p': 0.001, 'f.s': 0.001, 'ʌ.t': 0.001, 'ɚ.w': 0.001, 'ð.n': 0.001, 'ɑ.s': 0.001, 'w.l': 0.001, 'n.w': 0.001, 's.aʊ': 0.001, 'p.ɔɪ': 0.001, 'dʒ.b': 0.001, 'æ.t': 0.001, 'aɪ.ɚ': 0.001, 'v.u': 0.001, 'ŋ.ʌ': 0.001, 'w.j': 0.001, 'l.oʊ': 0.001, 'j.b': 0.001, 'u.h': 0.001, 'k.eɪ': 0.001, 'ŋ.f': 0.001, 't.r': 0.001, 'ɑ.n': 0.001, 'm.j': 0.001, 't.ɪ': 0.001, 'ʃ.eɪ': 0.001, 'aʊ.l': 0.001, 'n.ʊ': 0.001, 'ɑ.dʒ': 0.001, 'u.ʒ': 0.001, 'ʒ.aɪ': 0.001, 'ɛ.ɑ': 0.001, 'l.p': 0.001, 'i.h': 0.001, 'l.ʃ': 0.001, 'ɛ.n': 0.001, 'h.ʃ': 0.001, 'f.b': 0.001, 'ʌ.ɛ': 0.001, 'v.s': 0.001, 'v.ɚ': 0.001, 'r.tʃ': 0.001, 'eɪ.ɑ': 0.001, 'ŋ.t': 0.001, 'ʊ.aʊ': 0.001, 'ɑ.aɪ': 0.001, 'ɛ.g': 0.001, 't.k': 0.001, 'ʊ.v': 0.001, 'ɛ.oʊ': 0.001, 'm.g': 0.001, 'p.n': 0.001, 'ð.u': 0.001, 'dʒ.h': 0.001, 't.l': 0.001, 'r.ɑ': 0.001, 'æ.h': 0.001, 'w.ʊ': 0.001, 'v.z': 0.001, 'n.oʊ': 0.001, 'oʊ.z': 0.001, 'ɛ.æ': 0.001, 'ɔɪ.ʃ': 0.001, 'ʃ.ɔɪ': 0.001, 'd.b': 0.001, 'oʊ.j': 0.001, 'ɑ.ʌ': 0.001, 'd.ʊ': 0.001, 'ɑ.v': 0.001, 'k.æ': 0.001, 'ɪ.ŋ': 0.001, 'z.tʃ': 0.001, 'k.j': 0.001, 'tʃ.ɚ': 0.001, 'r.ɪ': 0.001, 'aʊ.ʃ': 0.001, 'oʊ.tʃ': 0.001, 'ŋ.v': 0.001, 'tʃ.aɪ': 0.001, 'r.ʃ': 0.001, 'b.d': 0.001, 's.f': 0.001, 'u.s': 0.001, 'n.θ': 0.001, 's.eɪ': 0.001, 'u.ʃ': 0.001, 'r.ŋ': 0.001, 'd.ʌ': 0.001, 'ɚ.v': 0.001, 'θ.eɪ': 0.001, 'eɪ.ð': 0.001, 'g.m': 0.001, 'v.oʊ': 0.001, 'ɛ.d': 0.001, 'z.r': 0.001, 'ʃ.ʃ': 0.001, 'd.s': 0.001, 'ʒ.b': 0.001, 'b.l': 0.001, 'eɪ.d': 0.001, 'dʒ.æ': 0.001, 'i.aʊ': 0.001, 'ʒ.dʒ': 0.001, 'tʃ.tʃ': 0.001, 'eɪ.ŋ': 0.001, 'ʃ.p': 0.001, 'k.g': 0.001, 't.ŋ': 0.001, 'tʃ.m': 0.001, 'ʒ.aʊ': 0.001, 'ɪ.d': 0.001, 't.dʒ': 0.001, 'f.h': 0.001, 'ɪ.n': 0.001, 'ʒ.ɪ': 0.001, 'ŋ.ð': 0.001, 'f.m': 0.001, 'oʊ.i': 0.001, 'ɑ.t': 0.001, 'd.ɑ': 0.001, 'h.v': 0.001, 'f.l': 0.001, 'm.p': 0.001, 'ʊ.ɪ': 0.001, 'aɪ.k': 0.001, 'ɑ.æ': 0.001, 'd.k': 0.001, 'f.ɪ': 0.001, 'ɔɪ.ɪ': 0.001, 'i.i': 0.001, 'æ.i': 0.001, 'ʊ.u': 0.001, 'u.ɔɪ': 0.001, 'ð.ð': 0.001, 'ɑ.ʒ': 0.001, 'ʃ.h': 0.001, 'æ.b': 0.001, 'p.r': 0.001, 'm.æ': 0.001, 'ʃ.ɛ': 0.001, 'ɑ.θ': 0.001, 'eɪ.i': 0.001, 'tʃ.ɑ': 0.001, 'ɛ.ɪ': 0.001, 'v.ʊ': 0.001, 'r.g': 0.001, 'j."
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 20449 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testStimDiph = getRandomKey(gate3_dists, True)\n",
    "print(gate3_dists[testStimDiph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.552449Z",
     "start_time": "2019-02-20T17:42:31.465123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random key: r.p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRespDiph = getRandomKey(gate3_dists[testStimDiph], True)\n",
    "f3(testRespDiph, testStimDiph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and \n",
    "- $p(Y_0, Y_1|X_0, X_1 = dð \\text{ and both } X_0 = d \\text{ and } X_1 = ð \\text{ has been fully produced/perceived})$ can be calculated by normalizing the counts given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.626459Z",
     "start_time": "2019-02-20T17:42:31.556982Z"
    }
   },
   "outputs": [],
   "source": [
    "def f6(y_01, x_01):\n",
    "#     return gate6_dists[x_01][y_01]\n",
    "    return gate6_dists[x_01].get(y_01, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.706736Z",
     "start_time": "2019-02-20T17:42:31.631294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random key: b.ɑ\n",
      "Counter({'b.ɑ': 13.001, 'b.ɔɪ': 9.001, 'ɑ.h': 4.001, 'b.ʌ': 3.001, 'ʊ.d': 2.001, 'b.ʊ': 2.001, 'ɑ.t': 1.001, 'ɑ.k': 1.001, 'ʌ.ɪ': 1.001, 'b.i': 1.001, 'v.ʌ': 1.001, 'b.aɪ': 1.001, 'ɑ.θ': 1.001, 's.θ': 0.001, 'h.ʌ': 0.001, 'æ.dʒ': 0.001, 'oʊ.ŋ': 0.001, 'f.ð': 0.001, 'dʒ.v': 0.001, 'u.m': 0.001, 'p.ð': 0.001, 'oʊ.æ': 0.001, 'g.z': 0.001, 'ʒ.tʃ': 0.001, 'b.r': 0.001, 'i.ɪ': 0.001, 'tʃ.eɪ': 0.001, 'ŋ.m': 0.001, 'aɪ.ɪ': 0.001, 'ð.w': 0.001, 'h.r': 0.001, 'ʊ.dʒ': 0.001, 'v.ɔɪ': 0.001, 'ʒ.u': 0.001, 'ʊ.tʃ': 0.001, 'z.m': 0.001, 'eɪ.æ': 0.001, 'j.ɛ': 0.001, 'ʒ.d': 0.001, 'p.k': 0.001, 'k.z': 0.001, 't.ʃ': 0.001, 's.t': 0.001, 'ʌ.ɚ': 0.001, 'ʌ.ʌ': 0.001, 'g.p': 0.001, 'i.l': 0.001, 'd.ɔɪ': 0.001, 'θ.l': 0.001, 'eɪ.b': 0.001, 'l.ɔɪ': 0.001, 'g.θ': 0.001, 'l.ʊ': 0.001, 'i.z': 0.001, 'θ.v': 0.001, 'ʃ.b': 0.001, 'dʒ.m': 0.001, 'ɛ.u': 0.001, 'r.z': 0.001, 'aʊ.g': 0.001, 'n.u': 0.001, 'j.aʊ': 0.001, 'b.w': 0.001, 'i.s': 0.001, 'f.ɛ': 0.001, 't.n': 0.001, 'b.s': 0.001, 'r.eɪ': 0.001, 'ɔɪ.r': 0.001, 'p.dʒ': 0.001, 'v.i': 0.001, 'm.s': 0.001, 'p.m': 0.001, 'ɚ.b': 0.001, 'k.ɑ': 0.001, 'w.n': 0.001, 'b.tʃ': 0.001, 'z.l': 0.001, 'ɛ.dʒ': 0.001, 'i.ʒ': 0.001, 'v.v': 0.001, 'k.f': 0.001, 'tʃ.ŋ': 0.001, 'f.r': 0.001, 'k.v': 0.001, 'l.æ': 0.001, 'f.æ': 0.001, 'r.u': 0.001, 'i.p': 0.001, 'z.s': 0.001, 'ð.v': 0.001, 'ɑ.ɪ': 0.001, 'ɚ.r': 0.001, 'h.h': 0.001, 'ɔɪ.h': 0.001, 'dʒ.p': 0.001, 'ɛ.m': 0.001, 'ɪ.ð': 0.001, 'ʒ.eɪ': 0.001, 'aʊ.s': 0.001, 'ɛ.t': 0.001, 'h.j': 0.001, 'ɛ.ɚ': 0.001, 'l.tʃ': 0.001, 'æ.d': 0.001, 'w.s': 0.001, 'æ.l': 0.001, 'tʃ.i': 0.001, 'g.ʒ': 0.001, 'tʃ.θ': 0.001, 'p.g': 0.001, 'm.n': 0.001, 'ʌ.i': 0.001, 't.t': 0.001, 'ɑ.ɚ': 0.001, 'ʃ.aʊ': 0.001, 'ʃ.ʊ': 0.001, 'oʊ.d': 0.001, 'l.g': 0.001, 'ŋ.ʃ': 0.001, 'θ.ŋ': 0.001, 'oʊ.s': 0.001, 'ʒ.g': 0.001, 'ʊ.i': 0.001, 'u.ɚ': 0.001, 'l.b': 0.001, 'm.m': 0.001, 'i.ɛ': 0.001, 'ʌ.ʒ': 0.001, 'i.eɪ': 0.001, 'ʒ.ʊ': 0.001, 'ɪ.ʒ': 0.001, 'p.p': 0.001, 'ɔɪ.w': 0.001, 'k.w': 0.001, 'ɔɪ.u': 0.001, 'u.p': 0.001, 'aʊ.m': 0.001, 'f.θ': 0.001, 'ɔɪ.b': 0.001, 'r.r': 0.001, 's.g': 0.001, 'k.b': 0.001, 'm.d': 0.001, 'm.dʒ': 0.001, 'ɔɪ.j': 0.001, 'i.k': 0.001, 'ɑ.ɑ': 0.001, 'ɑ.b': 0.001, 'ɔɪ.ɚ': 0.001, 'ʌ.ʊ': 0.001, 'b.ð': 0.001, 'p.ŋ': 0.001, 'p.d': 0.001, 'θ.ʃ': 0.001, 'dʒ.aɪ': 0.001, 'aɪ.ŋ': 0.001, 't.ð': 0.001, 'ŋ.ɔɪ': 0.001, 'u.v': 0.001, 'v.r': 0.001, 'ʌ.f': 0.001, 'w.t': 0.001, 'l.f': 0.001, 'g.ɪ': 0.001, 'ɪ.v': 0.001, 'f.n': 0.001, 'u.tʃ': 0.001, 'j.v': 0.001, 'v.g': 0.001, 'ʒ.p': 0.001, 'k.oʊ': 0.001, 'θ.n': 0.001, 'w.θ': 0.001, 'j.ʊ': 0.001, 'r.ɔɪ': 0.001, 't.ɑ': 0.001, 'k.h': 0.001, 'l.ð': 0.001, 'ɔɪ.t': 0.001, 'θ.f': 0.001, 'dʒ.z': 0.001, 'z.æ': 0.001, 't.z': 0.001, 'w.d': 0.001, 'k.ʃ': 0.001, 'z.v': 0.001, 'aɪ.z': 0.001, 'g.k': 0.001, 'n.h': 0.001, 'ŋ.aɪ': 0.001, 'oʊ.r': 0.001, 'tʃ.dʒ': 0.001, 'z.b': 0.001, 'oʊ.k': 0.001, 'n.r': 0.001, 'l.ʌ': 0.001, 'i.g': 0.001, 'f.f': 0.001, 'w.i': 0.001, 'r.m': 0.001, 'z.oʊ': 0.001, 'u.z': 0.001, 'w.k': 0.001, 'j.s': 0.001, 'i.u': 0.001, 'b.ʃ': 0.001, 'n.eɪ': 0.001, 'ð.z': 0.001, 'dʒ.ʃ': 0.001, 'ɚ.oʊ': 0.001, 't.u': 0.001, 'ɑ.d': 0.001, 'oʊ.ɪ': 0.001, 'ʒ.æ': 0.001, 'ʌ.h': 0.001, 'v.p': 0.001, 'aʊ.k': 0.001, 'n.ɑ': 0.001, 'z.ʒ': 0.001, 'u.ð': 0.001, 'ŋ.w': 0.001, 'eɪ.t': 0.001, 'd.ɚ': 0.001, 'aʊ.d': 0.001, 'u.ɛ': 0.001, 'm.z': 0.001, 'g.s': 0.001, 'i.ɚ': 0.001, 'ɪ.p': 0.001, 'ŋ.d': 0.001, 'k.k': 0.001, 'n.z': 0.001, 'd.oʊ': 0.001, 's.ɪ': 0.001, 'ɔɪ.f': 0.001, 'ŋ.i': 0.001, 'i.ŋ': 0.001, 'ɛ.tʃ': 0.001, 'm.tʃ': 0.001, 's.ɚ': 0.001, 'ɑ.ʃ': 0.001, 'u.n': 0.001, 'v.w': 0.001, 'tʃ.oʊ': 0.001, 'ɚ.ð': 0.001, 'aɪ.oʊ': 0.001, 'b.u': 0.001, 'm.ʒ': 0.001, 'n.ɪ': 0.001, 'z.i': 0.001, 'b.n': 0.001, 'æ.ɚ': 0.001, 'ɪ.eɪ': 0.001, 'g.ɚ': 0.001, 'tʃ.aʊ': 0.001, 'ɛ.j': 0.001, 'g.ɑ': 0.001, 'r.k': 0.001, 'æ.ɑ': 0.001, 'θ.ɚ': 0.001, 'h.u': 0.001, 'aɪ.l': 0.001, 'oʊ.ð': 0.001, 'z.aʊ': 0.001, 'ʌ.z': 0.001, 't.ɚ': 0.001, 'f.ʊ': 0.001, 'aʊ.æ': 0.001, 'ð.ʌ': 0.001, 'aɪ.m': 0.001, 'oʊ.w': 0.001, 'g.ʃ': 0.001, 'b.g': 0.001, 'n.v': 0.001, 'b.eɪ': 0.001, 'w.g': 0.001, 'j.r': 0.001, 'ʃ.θ': 0.001, 'ʌ.v': 0.001, 'ɛ.eɪ': 0.001, 'ɪ.θ': 0.001, 's.ɑ': 0.001, 'h.ɔɪ': 0.001, 'ʌ.aʊ': 0.001, 'æ.w': 0.001, 't.ʌ': 0.001, 'ɚ.ɚ': 0.001, 'l.s': 0.001, 'θ.z': 0.001, 'aʊ.ɑ': 0.001, 'ɪ.ɪ': 0.001, 'ʌ.eɪ': 0.001, 's.v': 0.001, 'aɪ.d': 0.001, 'l.θ': 0.001, 'j.ɚ': 0.001, 'r.ɛ': 0.001, 'z.d': 0.001, 'ɚ.z': 0.001, 'ɔɪ.n': 0.001, 'p.ɪ': 0.001, 'i.n': 0.001, 'ʃ.ʌ': 0.001, 'r.ʊ': 0.001, 'tʃ.ʃ': 0.001, 'ɚ.l': 0.001, 'oʊ.eɪ': 0.001, 'l.v': 0.001, 'θ.h': 0.001, 'æ.n': 0.001, 'f.eɪ': 0.001, 'ŋ.k': 0.001, 'ð.ʒ': 0.001, 'eɪ.r': 0.001, 'k.i': 0.001, 'ŋ.eɪ': 0.001, 'g.dʒ': 0.001, 't.aʊ': 0.001, 'w.z': 0.001, 'z.dʒ': 0.001, 'oʊ.u': 0.001, 's.r': 0.001, 'g.g': 0.001, 'l.l': 0.001, 'θ.ʊ': 0.001, 'ŋ.aʊ': 0.001, 'f.d': 0.001, 'w.w': 0.001, 'aʊ.ŋ': 0.001, 'n.j': 0.001, 'ɑ.z': 0.001, 'h.n': 0.001, 's.n': 0.001, 'ʊ.r': 0.001, 'm.ŋ': 0.001, 'n.b': 0.001, 'f.ʃ': 0.001, 'ʃ.ʒ': 0.001, 'aʊ.aʊ': 0.001, 'p.oʊ': 0.001, 'ɪ.ɚ': 0.001, 'ʒ.ɚ': 0.001, 't.h': 0.001, 'aɪ.w': 0.001, 't.j': 0.001, 'ɪ.ʃ': 0.001, 'æ.ɪ': 0.001, 'ʒ.ɛ': 0.001, 'l.u': 0.001, 'm.h': 0.001, 'p.aʊ': 0.001, 'dʒ.aʊ': 0.001, 'oʊ.ɔɪ': 0.001, 'aʊ.f': 0.001, 'r.ʒ': 0.001, 's.k': 0.001, 'oʊ.aɪ': 0.001, 'aɪ.ʒ': 0.001, 'ʃ.ɪ': 0.001, 'ɑ.u': 0.001, 'ʊ.n': 0.001, 'ɚ.h': 0.001, 'k.d': 0.001, 'i.d': 0.001, 'n.aɪ': 0.001, 'aɪ.aɪ': 0.001, 'h.tʃ': 0.001, 'ʌ.g': 0.001, 'aɪ.tʃ': 0.001, 'ɑ.i': 0.001, 'eɪ.ɪ': 0.001, 'ð.h': 0.001, 'aʊ.h': 0.001, 'j.g': 0.001, 'ɪ.oʊ': 0.001, 'm.eɪ': 0.001, 'ʊ.ŋ': 0.001, 'ʌ.aɪ': 0.001, 'ʊ.g': 0.001, 'v.aʊ': 0.001, 'k.ð': 0.001, 'aʊ.v': 0.001, 'v.m': 0.001, 'ʊ.l': 0.001, 'm.oʊ': 0.001, 'aʊ.ʒ': 0.001, 'æ.θ': 0.001, 'p.ʒ': 0.001, 'z.f': 0.001, 'p.f': 0.001, 'ŋ.n': 0.001, 'ð.ʊ': 0.001, 'ɔɪ.z': 0.001, 'u.f': 0.001, 'v.ʒ': 0.001, 'w.ɛ': 0.001, 'ɪ.h': 0.001, 'h.ɑ': 0.001, 'aɪ.ʌ': 0.001, 'ʒ.ð': 0.001, 'oʊ.ʊ': 0.001, 'ð.r': 0.001, 's.p': 0.001, 'oʊ.v': 0.001, 'ʊ.s': 0.001, 'aɪ.i': 0.001, 'aʊ.ɛ': 0.001, 'p.u': 0.001, 'ð.oʊ': 0.001, 'k.n': 0.001, 'ɔɪ.tʃ': 0.001, 'l.h': 0.001, 'tʃ.u': 0.001, 'ʌ.ð': 0.001, 'ŋ.p': 0.001, 'ð.ɚ': 0.001, 'oʊ.ɚ': 0.001, 'ɚ.ɑ': 0.001, 'g.d': 0.001, 't.θ': 0.001, 'ʌ.s': 0.001, 'f.ɚ': 0.001, 'v.tʃ': 0.001, 'i.ʌ': 0.001, 'r.aɪ': 0.001, 'ɔɪ.i': 0.001, 'ɚ.aɪ': 0.001, 'b.æ': 0.001, 'aʊ.ɪ': 0.001, 'z.ɛ': 0.001, 'z.h': 0.001, 'g.w': 0.001, 'oʊ.ʒ': 0.001, 'oʊ.l': 0.001, 'eɪ.h': 0.001, 'ʊ.oʊ': 0.001, 'i.æ': 0.001, 'eɪ.s': 0.001, 'tʃ.h': 0.001, 'ɚ.ʊ': 0.001, 'd.l': 0.001, 't.w': 0.001, 'v.ʃ': 0.001, 'ɪ.ʊ': 0.001, 'ɔɪ.θ': 0.001, 'r.oʊ': 0.001, 'oʊ.oʊ': 0.001, 's.oʊ': 0.001, 'u.u': 0.001, 'ɪ.ɛ': 0.001, 'f.ɔɪ': 0.001, 'ɪ.r': 0.001, 'd.eɪ': 0.001, 'æ.eɪ': 0.001, 'eɪ.j': 0.001, 'r.aʊ': 0.001, 'aɪ.dʒ': 0.001, 'oʊ.aʊ': 0.001, 'ɚ.j': 0.001, 'eɪ.f': 0.001, 'p.ɚ': 0.001, 'h.k': 0.001, 'ʃ.tʃ': 0.001, 'b.dʒ': 0.001, 'ɪ.aʊ': 0.001, 'ʒ.oʊ': 0.001, 's.b': 0.001, 'ɚ.tʃ': 0.001, 'i.r': 0.001, 'l.aʊ': 0.001, 'i.w': 0.001, 'i.t': 0.001, 'ŋ.ɪ': 0.001, 'ŋ.u': 0.001, 'h.aɪ': 0.001, 'p.ɛ': 0.001, 's.dʒ': 0.001, 'ɪ.ɔɪ': 0.001, 'n.ʒ': 0.001, 'z.k': 0.001, 'ʌ.p': 0.001, 'ʒ.w': 0.001, 'tʃ.ʊ': 0.001, 'aʊ.dʒ': 0.001, 'ʃ.t': 0.001, 'aʊ.t': 0.001, 'eɪ.w': 0.001, 'ʊ.ɑ': 0.001, 'p.ʃ': 0.001, 'ɔɪ.oʊ': 0.001, 'ɑ.eɪ': 0.001, 'dʒ.f': 0.001, 'ʃ.aɪ': 0.001, 'oʊ.θ': 0.001, 'j.ʌ': 0.001, 't.ʒ': 0.001, 'ʌ.tʃ': 0.001, 'f.aɪ': 0.001, 'w.u': 0.001, 'b.j': 0.001, 'ɑ.p': 0.001, 'oʊ.dʒ': 0.001, 'eɪ.ɔɪ': 0.001, 'j.k': 0.001, 'h.ŋ': 0.001, 's.ɛ': 0.001, 'v.θ': 0.001, 'm.f': 0.001, 'ŋ.l': 0.001, 'ɚ.i': 0.001, 'θ.r': 0.001, 'f.ɑ': 0.001, 'θ.ɪ': 0.001, 'ɔɪ.p': 0.001, 'ɪ.f': 0.001, 'r.w': 0.001, 'v.j': 0.001, 'ʌ.θ': 0.001, 'ɑ.ʊ': 0.001, 'ʃ.r': 0.001, 'm.ɚ': 0.001, 'ʒ.h': 0.001, 'u.ʌ': 0.001, 'n.n': 0.001, 'eɪ.tʃ': 0.001, 'j.tʃ': 0.001, 'ɛ.b': 0.001, 'k.u': 0.001, 'ɔɪ.ŋ': 0.001, 's.tʃ': 0.001, 'tʃ.l': 0.001, 'ɚ.ɪ': 0.001, 'z.ɚ': 0.001, 'ð.eɪ': 0.001, 'v.dʒ': 0.001, 'θ.t': 0.001, 'p.w': 0.001, 'h.ð': 0.001, 'm.r': 0.001, 'w.tʃ': 0.001, 'u.ʊ': 0.001, 'd.aʊ': 0.001, 'aɪ.f': 0.001, 'z.n': 0.001, 'ʌ.ŋ': 0.001, 'd.tʃ': 0.001, 'p.aɪ': 0.001, 's.ʃ': 0.001, 'ʒ.t': 0.001, 'z.p': 0.001, 'f.s': 0.001, 'ʌ.t': 0.001, 'ɚ.w': 0.001, 'ð.n': 0.001, 'ɑ.s': 0.001, 'w.l': 0.001, 'n.w': 0.001, 's.aʊ': 0.001, 'p.ɔɪ': 0.001, 'dʒ.b': 0.001, 'æ.t': 0.001, 'aɪ.ɚ': 0.001, 'v.u': 0.001, 'ŋ.ʌ': 0.001, 'w.j': 0.001, 'l.oʊ': 0.001, 'j.b': 0.001, 'u.h': 0.001, 'k.eɪ': 0.001, 'ŋ.f': 0.001, 't.r': 0.001, 'ɑ.n': 0.001, 'm.j': 0.001, 't.ɪ': 0.001, 'ʃ.eɪ': 0.001, 'aʊ.l': 0.001, 'n.ʊ': 0.001, 'ɑ.dʒ': 0.001, 'u.ʒ': 0.001, 'ʒ.aɪ': 0.001, 'ɛ.ɑ': 0.001, 'l.p': 0.001, 'i.h': 0.001, 'l.ʃ': 0.001, 'ɛ.n': 0.001, 'h.ʃ': 0.001, 'f.b': 0.001, 'ʌ.ɛ': 0.001, 'v.s': 0.001, 'v.ɚ': 0.001, 'r.tʃ': 0.001, 'eɪ.ɑ': 0.001, 'ŋ.t': 0.001, 'ʊ.aʊ': 0.001, 'ɑ.aɪ': 0.001, 'ɛ.g': 0.001, 't.k': 0.001, 'ʊ.v': 0.001, 'ɛ.oʊ': 0.001, 'm.g': 0.001, 'p.n': 0.001, 'ð.u': 0.001, 'dʒ.h': 0.001, 't.l': 0.001, 'r.ɑ': 0.001, 'æ.h': 0.001, 'w.ʊ': 0.001, 'v.z': 0.001, 'n.oʊ': 0.001, 'oʊ.z': 0.001, 'ɛ.æ': 0.001, 'ɔɪ.ʃ': 0.001, 'ʃ.ɔɪ': 0.001, 'd.b': 0.001, 'oʊ.j': 0.001, 'ɑ.ʌ': 0.001, 'd.ʊ': 0.001, 'ɑ.v': 0.001, 'k.æ': 0.001, 'ɪ.ŋ': 0.001, 'z.tʃ': 0.001, 'k.j': 0.001, 'tʃ.ɚ': 0.001, 'r.ɪ': 0.001, 'aʊ.ʃ': 0.001, 'oʊ.tʃ': 0.001, 'ŋ.v': 0.001, 'tʃ.aɪ': 0.001, 'r.ʃ': 0.001, 'b.d': 0.001, 's.f': 0.001, 'u.s': 0.001, 'n.θ': 0.001, 's.eɪ': 0.001, 'u.ʃ': 0.001, 'r.ŋ': 0.001, 'd.ʌ': 0.001, 'ɚ.v': 0.001, 'θ.eɪ': 0.001, 'eɪ.ð': 0.001, 'g.m': 0.001, 'v.oʊ': 0.001, 'ɛ.d': 0.001, 'z.r': 0.001, 'ʃ.ʃ': 0.001, 'd.s': 0.001, 'ʒ.b': 0.001, 'b.l': 0.001, 'eɪ.d': 0.001, 'dʒ.æ': 0.001, 'i.aʊ': 0.001, 'ʒ.dʒ': 0.001, 'tʃ.tʃ': 0.001, 'eɪ.ŋ': 0.001, 'ʃ.p': 0.001, 'k.g': 0.001, 't.ŋ': 0.001, 'tʃ.m': 0.001, 'ʒ.aʊ': 0.001, 'ɪ.d': 0.001, 't.dʒ': 0.001, 'f.h': 0.001, 'ɪ.n': 0.001, 'ʒ.ɪ': 0.001, 'ŋ.ð': 0.001, 'f.m': 0.001, 'oʊ.i': 0.001, 'd.ɑ': 0.001, 'h.v': 0.001, 'f.l': 0.001, 'm.p': 0.001, 'ʊ.ɪ': 0.001, 'aɪ.k': 0.001, 'ɑ.æ': 0.001, 'd.k': 0.001, 'f.ɪ': 0.001, 'ɔɪ.ɪ': 0.001, 'i.i': 0.001, 'æ.i': 0.001, 'ʊ.u': 0.001, 'u.ɔɪ': 0.001, 'ð.ð': 0.001, 'ɑ.ʒ': 0.001, 'ʃ.h': 0.001, 'æ.b': 0.001, 'p.r': 0.001, 'm.æ': 0.001, 'ʃ.ɛ': 0.001, 'eɪ.i': 0.001, 'tʃ.ɑ': 0.001, 'ɛ.ɪ': 0.001, 'v.ʊ': 0.001, 'r.g': 0.001, '"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 20450 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testStimDiph = getRandomKey(gate6_dists, True)\n",
    "print(gate6_dists[testStimDiph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.789771Z",
     "start_time": "2019-02-20T17:42:31.711006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random key: w.n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRespDiph = getRandomKey(gate6_dists[testStimDiph], True)\n",
    "f6(testRespDiph, testStimDiph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export/import conditional distributions $f_3(Y_0, Y_1| X_0; X_1)$, $f_6(Y_0, Y_1| X_0, X_1;)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export diphone confusion count distributions as json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:31.911296Z",
     "start_time": "2019-02-20T17:42:31.794195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eɪ.ʌ'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'eɪ.ʌ': 17.001,\n",
       "         'eɪ.oʊ': 4.001,\n",
       "         'ɛ.ɑ': 1.001,\n",
       "         'eɪ.ʊ': 2.001,\n",
       "         'eɪ.ɑ': 13.001,\n",
       "         'aɪ.ʌ': 1.001,\n",
       "         'ʊ.n': 1.001,\n",
       "         'eɪ.n': 1.001,\n",
       "         's.θ': 0.001,\n",
       "         'h.ʌ': 0.001,\n",
       "         'æ.dʒ': 0.001,\n",
       "         'oʊ.ŋ': 0.001,\n",
       "         'f.ð': 0.001,\n",
       "         'dʒ.v': 0.001,\n",
       "         'u.m': 0.001,\n",
       "         'p.ð': 0.001,\n",
       "         'oʊ.æ': 0.001,\n",
       "         'g.z': 0.001,\n",
       "         'ʒ.tʃ': 0.001,\n",
       "         'b.r': 0.001,\n",
       "         'i.ɪ': 0.001,\n",
       "         'tʃ.eɪ': 0.001,\n",
       "         'ŋ.m': 0.001,\n",
       "         'aɪ.ɪ': 0.001,\n",
       "         'ð.w': 0.001,\n",
       "         'h.r': 0.001,\n",
       "         'ʊ.dʒ': 0.001,\n",
       "         'v.ɔɪ': 0.001,\n",
       "         'ʒ.u': 0.001,\n",
       "         'ʊ.tʃ': 0.001,\n",
       "         'z.m': 0.001,\n",
       "         'eɪ.æ': 0.001,\n",
       "         'j.ɛ': 0.001,\n",
       "         'ʒ.d': 0.001,\n",
       "         'p.k': 0.001,\n",
       "         'k.z': 0.001,\n",
       "         't.ʃ': 0.001,\n",
       "         's.t': 0.001,\n",
       "         'ʌ.ɚ': 0.001,\n",
       "         'ʌ.ʌ': 0.001,\n",
       "         'g.p': 0.001,\n",
       "         'i.l': 0.001,\n",
       "         'd.ɔɪ': 0.001,\n",
       "         'θ.l': 0.001,\n",
       "         'eɪ.b': 0.001,\n",
       "         'l.ɔɪ': 0.001,\n",
       "         'g.θ': 0.001,\n",
       "         'l.ʊ': 0.001,\n",
       "         'i.z': 0.001,\n",
       "         'θ.v': 0.001,\n",
       "         'ʃ.b': 0.001,\n",
       "         'dʒ.m': 0.001,\n",
       "         'ɛ.u': 0.001,\n",
       "         'r.z': 0.001,\n",
       "         'aʊ.g': 0.001,\n",
       "         'n.u': 0.001,\n",
       "         'j.aʊ': 0.001,\n",
       "         'b.w': 0.001,\n",
       "         'i.s': 0.001,\n",
       "         'f.ɛ': 0.001,\n",
       "         't.n': 0.001,\n",
       "         'b.s': 0.001,\n",
       "         'r.eɪ': 0.001,\n",
       "         'ɔɪ.r': 0.001,\n",
       "         'p.dʒ': 0.001,\n",
       "         'v.i': 0.001,\n",
       "         'm.s': 0.001,\n",
       "         'p.m': 0.001,\n",
       "         'ɚ.b': 0.001,\n",
       "         'k.ɑ': 0.001,\n",
       "         'w.n': 0.001,\n",
       "         'b.tʃ': 0.001,\n",
       "         'z.l': 0.001,\n",
       "         'ɛ.dʒ': 0.001,\n",
       "         'i.ʒ': 0.001,\n",
       "         'v.v': 0.001,\n",
       "         'k.f': 0.001,\n",
       "         'tʃ.ŋ': 0.001,\n",
       "         'f.r': 0.001,\n",
       "         'k.v': 0.001,\n",
       "         'l.æ': 0.001,\n",
       "         'f.æ': 0.001,\n",
       "         'r.u': 0.001,\n",
       "         'i.p': 0.001,\n",
       "         'z.s': 0.001,\n",
       "         'ð.v': 0.001,\n",
       "         'ɑ.ɪ': 0.001,\n",
       "         'ɚ.r': 0.001,\n",
       "         'h.h': 0.001,\n",
       "         'ɔɪ.h': 0.001,\n",
       "         'dʒ.p': 0.001,\n",
       "         'ɛ.m': 0.001,\n",
       "         'ɪ.ð': 0.001,\n",
       "         'ʒ.eɪ': 0.001,\n",
       "         'aʊ.s': 0.001,\n",
       "         'ɛ.t': 0.001,\n",
       "         'h.j': 0.001,\n",
       "         'ɛ.ɚ': 0.001,\n",
       "         'l.tʃ': 0.001,\n",
       "         'æ.d': 0.001,\n",
       "         'w.s': 0.001,\n",
       "         'æ.l': 0.001,\n",
       "         'tʃ.i': 0.001,\n",
       "         'g.ʒ': 0.001,\n",
       "         'tʃ.θ': 0.001,\n",
       "         'p.g': 0.001,\n",
       "         'm.n': 0.001,\n",
       "         'ʌ.i': 0.001,\n",
       "         't.t': 0.001,\n",
       "         'ɑ.ɚ': 0.001,\n",
       "         'ʃ.aʊ': 0.001,\n",
       "         'ʃ.ʊ': 0.001,\n",
       "         'oʊ.d': 0.001,\n",
       "         'l.g': 0.001,\n",
       "         'ŋ.ʃ': 0.001,\n",
       "         'θ.ŋ': 0.001,\n",
       "         'oʊ.s': 0.001,\n",
       "         'ʒ.g': 0.001,\n",
       "         'ʊ.i': 0.001,\n",
       "         'u.ɚ': 0.001,\n",
       "         'l.b': 0.001,\n",
       "         'm.m': 0.001,\n",
       "         'b.ɔɪ': 0.001,\n",
       "         'i.ɛ': 0.001,\n",
       "         'ʌ.ʒ': 0.001,\n",
       "         'i.eɪ': 0.001,\n",
       "         'ʒ.ʊ': 0.001,\n",
       "         'ɪ.ʒ': 0.001,\n",
       "         'p.p': 0.001,\n",
       "         'ɔɪ.w': 0.001,\n",
       "         'k.w': 0.001,\n",
       "         'ɔɪ.u': 0.001,\n",
       "         'u.p': 0.001,\n",
       "         'aʊ.m': 0.001,\n",
       "         'f.θ': 0.001,\n",
       "         'ɔɪ.b': 0.001,\n",
       "         'r.r': 0.001,\n",
       "         's.g': 0.001,\n",
       "         'k.b': 0.001,\n",
       "         'm.d': 0.001,\n",
       "         'm.dʒ': 0.001,\n",
       "         'ɔɪ.j': 0.001,\n",
       "         'i.k': 0.001,\n",
       "         'ɑ.ɑ': 0.001,\n",
       "         'ɑ.b': 0.001,\n",
       "         'ɔɪ.ɚ': 0.001,\n",
       "         'ʌ.ʊ': 0.001,\n",
       "         'b.ð': 0.001,\n",
       "         'p.ŋ': 0.001,\n",
       "         'p.d': 0.001,\n",
       "         'θ.ʃ': 0.001,\n",
       "         'dʒ.aɪ': 0.001,\n",
       "         'aɪ.ŋ': 0.001,\n",
       "         't.ð': 0.001,\n",
       "         'ŋ.ɔɪ': 0.001,\n",
       "         'u.v': 0.001,\n",
       "         'v.r': 0.001,\n",
       "         'ʌ.f': 0.001,\n",
       "         'w.t': 0.001,\n",
       "         'l.f': 0.001,\n",
       "         'g.ɪ': 0.001,\n",
       "         'ɪ.v': 0.001,\n",
       "         'f.n': 0.001,\n",
       "         'u.tʃ': 0.001,\n",
       "         'j.v': 0.001,\n",
       "         'v.g': 0.001,\n",
       "         'ʒ.p': 0.001,\n",
       "         'k.oʊ': 0.001,\n",
       "         'θ.n': 0.001,\n",
       "         'w.θ': 0.001,\n",
       "         'j.ʊ': 0.001,\n",
       "         'r.ɔɪ': 0.001,\n",
       "         't.ɑ': 0.001,\n",
       "         'k.h': 0.001,\n",
       "         'l.ð': 0.001,\n",
       "         'ɔɪ.t': 0.001,\n",
       "         'θ.f': 0.001,\n",
       "         'dʒ.z': 0.001,\n",
       "         'z.æ': 0.001,\n",
       "         't.z': 0.001,\n",
       "         'w.d': 0.001,\n",
       "         'k.ʃ': 0.001,\n",
       "         'z.v': 0.001,\n",
       "         'aɪ.z': 0.001,\n",
       "         'g.k': 0.001,\n",
       "         'n.h': 0.001,\n",
       "         'ŋ.aɪ': 0.001,\n",
       "         'oʊ.r': 0.001,\n",
       "         'tʃ.dʒ': 0.001,\n",
       "         'z.b': 0.001,\n",
       "         'oʊ.k': 0.001,\n",
       "         'n.r': 0.001,\n",
       "         'l.ʌ': 0.001,\n",
       "         'i.g': 0.001,\n",
       "         'f.f': 0.001,\n",
       "         'w.i': 0.001,\n",
       "         'r.m': 0.001,\n",
       "         'z.oʊ': 0.001,\n",
       "         'u.z': 0.001,\n",
       "         'w.k': 0.001,\n",
       "         'j.s': 0.001,\n",
       "         'i.u': 0.001,\n",
       "         'b.ʃ': 0.001,\n",
       "         'n.eɪ': 0.001,\n",
       "         'ð.z': 0.001,\n",
       "         'dʒ.ʃ': 0.001,\n",
       "         'ɚ.oʊ': 0.001,\n",
       "         't.u': 0.001,\n",
       "         'ɑ.d': 0.001,\n",
       "         'oʊ.ɪ': 0.001,\n",
       "         'ʒ.æ': 0.001,\n",
       "         'ʌ.h': 0.001,\n",
       "         'v.p': 0.001,\n",
       "         'aʊ.k': 0.001,\n",
       "         'n.ɑ': 0.001,\n",
       "         'z.ʒ': 0.001,\n",
       "         'u.ð': 0.001,\n",
       "         'ŋ.w': 0.001,\n",
       "         'ɑ.h': 0.001,\n",
       "         'eɪ.t': 0.001,\n",
       "         'd.ɚ': 0.001,\n",
       "         'aʊ.d': 0.001,\n",
       "         'u.ɛ': 0.001,\n",
       "         'm.z': 0.001,\n",
       "         'g.s': 0.001,\n",
       "         'i.ɚ': 0.001,\n",
       "         'ɪ.p': 0.001,\n",
       "         'ŋ.d': 0.001,\n",
       "         'k.k': 0.001,\n",
       "         'n.z': 0.001,\n",
       "         'd.oʊ': 0.001,\n",
       "         's.ɪ': 0.001,\n",
       "         'ɔɪ.f': 0.001,\n",
       "         'ŋ.i': 0.001,\n",
       "         'i.ŋ': 0.001,\n",
       "         'ɛ.tʃ': 0.001,\n",
       "         'm.tʃ': 0.001,\n",
       "         's.ɚ': 0.001,\n",
       "         'ɑ.ʃ': 0.001,\n",
       "         'u.n': 0.001,\n",
       "         'v.w': 0.001,\n",
       "         'tʃ.oʊ': 0.001,\n",
       "         'ɚ.ð': 0.001,\n",
       "         'aɪ.oʊ': 0.001,\n",
       "         'b.u': 0.001,\n",
       "         'm.ʒ': 0.001,\n",
       "         'n.ɪ': 0.001,\n",
       "         'z.i': 0.001,\n",
       "         'b.n': 0.001,\n",
       "         'æ.ɚ': 0.001,\n",
       "         'ɪ.eɪ': 0.001,\n",
       "         'g.ɚ': 0.001,\n",
       "         'tʃ.aʊ': 0.001,\n",
       "         'ɛ.j': 0.001,\n",
       "         'g.ɑ': 0.001,\n",
       "         'r.k': 0.001,\n",
       "         'æ.ɑ': 0.001,\n",
       "         'θ.ɚ': 0.001,\n",
       "         'h.u': 0.001,\n",
       "         'aɪ.l': 0.001,\n",
       "         'oʊ.ð': 0.001,\n",
       "         'z.aʊ': 0.001,\n",
       "         'ʌ.z': 0.001,\n",
       "         't.ɚ': 0.001,\n",
       "         'f.ʊ': 0.001,\n",
       "         'aʊ.æ': 0.001,\n",
       "         'ð.ʌ': 0.001,\n",
       "         'aɪ.m': 0.001,\n",
       "         'oʊ.w': 0.001,\n",
       "         'g.ʃ': 0.001,\n",
       "         'b.g': 0.001,\n",
       "         'n.v': 0.001,\n",
       "         'b.eɪ': 0.001,\n",
       "         'w.g': 0.001,\n",
       "         'j.r': 0.001,\n",
       "         'ʃ.θ': 0.001,\n",
       "         'ʌ.v': 0.001,\n",
       "         'ɛ.eɪ': 0.001,\n",
       "         'ɪ.θ': 0.001,\n",
       "         's.ɑ': 0.001,\n",
       "         'h.ɔɪ': 0.001,\n",
       "         'ʌ.aʊ': 0.001,\n",
       "         'æ.w': 0.001,\n",
       "         't.ʌ': 0.001,\n",
       "         'ɚ.ɚ': 0.001,\n",
       "         'l.s': 0.001,\n",
       "         'θ.z': 0.001,\n",
       "         'aʊ.ɑ': 0.001,\n",
       "         'ɪ.ɪ': 0.001,\n",
       "         'ʌ.eɪ': 0.001,\n",
       "         's.v': 0.001,\n",
       "         'aɪ.d': 0.001,\n",
       "         'l.θ': 0.001,\n",
       "         'j.ɚ': 0.001,\n",
       "         'r.ɛ': 0.001,\n",
       "         'z.d': 0.001,\n",
       "         'ɚ.z': 0.001,\n",
       "         'ɔɪ.n': 0.001,\n",
       "         'p.ɪ': 0.001,\n",
       "         'i.n': 0.001,\n",
       "         'ʃ.ʌ': 0.001,\n",
       "         'r.ʊ': 0.001,\n",
       "         'tʃ.ʃ': 0.001,\n",
       "         'ɚ.l': 0.001,\n",
       "         'ɑ.k': 0.001,\n",
       "         'oʊ.eɪ': 0.001,\n",
       "         'l.v': 0.001,\n",
       "         'θ.h': 0.001,\n",
       "         'æ.n': 0.001,\n",
       "         'f.eɪ': 0.001,\n",
       "         'ŋ.k': 0.001,\n",
       "         'ð.ʒ': 0.001,\n",
       "         'eɪ.r': 0.001,\n",
       "         'k.i': 0.001,\n",
       "         'ŋ.eɪ': 0.001,\n",
       "         'g.dʒ': 0.001,\n",
       "         't.aʊ': 0.001,\n",
       "         'w.z': 0.001,\n",
       "         'z.dʒ': 0.001,\n",
       "         'oʊ.u': 0.001,\n",
       "         's.r': 0.001,\n",
       "         'g.g': 0.001,\n",
       "         'l.l': 0.001,\n",
       "         'θ.ʊ': 0.001,\n",
       "         'ŋ.aʊ': 0.001,\n",
       "         'f.d': 0.001,\n",
       "         'w.w': 0.001,\n",
       "         'aʊ.ŋ': 0.001,\n",
       "         'n.j': 0.001,\n",
       "         'ɑ.z': 0.001,\n",
       "         'h.n': 0.001,\n",
       "         's.n': 0.001,\n",
       "         'ʊ.r': 0.001,\n",
       "         'm.ŋ': 0.001,\n",
       "         'n.b': 0.001,\n",
       "         'f.ʃ': 0.001,\n",
       "         'ʃ.ʒ': 0.001,\n",
       "         'aʊ.aʊ': 0.001,\n",
       "         'p.oʊ': 0.001,\n",
       "         'ɪ.ɚ': 0.001,\n",
       "         'ʒ.ɚ': 0.001,\n",
       "         't.h': 0.001,\n",
       "         'aɪ.w': 0.001,\n",
       "         't.j': 0.001,\n",
       "         'ɪ.ʃ': 0.001,\n",
       "         'æ.ɪ': 0.001,\n",
       "         'ʒ.ɛ': 0.001,\n",
       "         'l.u': 0.001,\n",
       "         'm.h': 0.001,\n",
       "         'p.aʊ': 0.001,\n",
       "         'dʒ.aʊ': 0.001,\n",
       "         'oʊ.ɔɪ': 0.001,\n",
       "         'aʊ.f': 0.001,\n",
       "         'r.ʒ': 0.001,\n",
       "         's.k': 0.001,\n",
       "         'oʊ.aɪ': 0.001,\n",
       "         'aɪ.ʒ': 0.001,\n",
       "         'ʃ.ɪ': 0.001,\n",
       "         'ɑ.u': 0.001,\n",
       "         'ɚ.h': 0.001,\n",
       "         'k.d': 0.001,\n",
       "         'i.d': 0.001,\n",
       "         'n.aɪ': 0.001,\n",
       "         'aɪ.aɪ': 0.001,\n",
       "         'h.tʃ': 0.001,\n",
       "         'ʌ.g': 0.001,\n",
       "         'aɪ.tʃ': 0.001,\n",
       "         'ɑ.i': 0.001,\n",
       "         'eɪ.ɪ': 0.001,\n",
       "         'ð.h': 0.001,\n",
       "         'aʊ.h': 0.001,\n",
       "         'j.g': 0.001,\n",
       "         'ɪ.oʊ': 0.001,\n",
       "         'm.eɪ': 0.001,\n",
       "         'ʊ.ŋ': 0.001,\n",
       "         'ʌ.aɪ': 0.001,\n",
       "         'ʊ.g': 0.001,\n",
       "         'v.aʊ': 0.001,\n",
       "         'k.ð': 0.001,\n",
       "         'aʊ.v': 0.001,\n",
       "         'v.m': 0.001,\n",
       "         'ʊ.l': 0.001,\n",
       "         'm.oʊ': 0.001,\n",
       "         'aʊ.ʒ': 0.001,\n",
       "         'æ.θ': 0.001,\n",
       "         'p.ʒ': 0.001,\n",
       "         'z.f': 0.001,\n",
       "         'p.f': 0.001,\n",
       "         'ŋ.n': 0.001,\n",
       "         'ð.ʊ': 0.001,\n",
       "         'ɔɪ.z': 0.001,\n",
       "         'u.f': 0.001,\n",
       "         'v.ʒ': 0.001,\n",
       "         'w.ɛ': 0.001,\n",
       "         'ɪ.h': 0.001,\n",
       "         'h.ɑ': 0.001,\n",
       "         'ʒ.ð': 0.001,\n",
       "         'oʊ.ʊ': 0.001,\n",
       "         'ð.r': 0.001,\n",
       "         's.p': 0.001,\n",
       "         'oʊ.v': 0.001,\n",
       "         'ʊ.s': 0.001,\n",
       "         'aɪ.i': 0.001,\n",
       "         'aʊ.ɛ': 0.001,\n",
       "         'p.u': 0.001,\n",
       "         'ð.oʊ': 0.001,\n",
       "         'k.n': 0.001,\n",
       "         'ɔɪ.tʃ': 0.001,\n",
       "         'l.h': 0.001,\n",
       "         'tʃ.u': 0.001,\n",
       "         'ʌ.ð': 0.001,\n",
       "         'ŋ.p': 0.001,\n",
       "         'ð.ɚ': 0.001,\n",
       "         'oʊ.ɚ': 0.001,\n",
       "         'ɚ.ɑ': 0.001,\n",
       "         'g.d': 0.001,\n",
       "         't.θ': 0.001,\n",
       "         'ʌ.s': 0.001,\n",
       "         'f.ɚ': 0.001,\n",
       "         'v.tʃ': 0.001,\n",
       "         'i.ʌ': 0.001,\n",
       "         'r.aɪ': 0.001,\n",
       "         'ɔɪ.i': 0.001,\n",
       "         'ɚ.aɪ': 0.001,\n",
       "         'b.æ': 0.001,\n",
       "         'aʊ.ɪ': 0.001,\n",
       "         'z.ɛ': 0.001,\n",
       "         'z.h': 0."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 23399 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(gate3_dists.keys())[0]\n",
    "gate3_dists[list(gate3_dists.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:42.772249Z",
     "start_time": "2019-02-20T17:42:31.912958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hammond-aligned_destressed_pseudocount0.001 f3_Y0Y1_X0X1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hammond-aligned_destressed_pseudocount0.001 f6_Y0Y1_X0X1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gate3_dist_fn_stem = which + ' gate-3 diphone channel distribution'\n",
    "# gate6_dist_fn_stem = which + ' gate-6 diphone channel distribution'\n",
    "gate3_dist_fn_stem = which + ' f3_Y0Y1_X0X1'\n",
    "gate6_dist_fn_stem = which + ' f6_Y0Y1_X0X1'\n",
    "gate3_dist_fn_stem\n",
    "gate6_dist_fn_stem\n",
    "\n",
    "with codecs.open(gate3_dist_fn_stem + '.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(gate3_dists, f, ensure_ascii = False, indent = 4)\n",
    "    \n",
    "with codecs.open(gate6_dist_fn_stem + '.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(gate6_dists, f, ensure_ascii=False, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...and read them back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:43.631239Z",
     "start_time": "2019-02-20T17:42:42.773335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hammond-aligned_destressed_pseudocount0.001 f3_Y0Y1_X0X1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Hammond-aligned_destressed_pseudocount0.001 f6_Y0Y1_X0X1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gate3_dist_fn_stem = which + ' gate-3 diphone channel distribution'\n",
    "# gate6_dist_fn_stem = which + ' gate-6 diphone channel distribution'\n",
    "gate3_dist_fn_stem = which + ' f3_Y0Y1_X0X1'\n",
    "gate6_dist_fn_stem = which + ' f6_Y0Y1_X0X1'\n",
    "gate3_dist_fn_stem\n",
    "gate6_dist_fn_stem\n",
    "\n",
    "with open(gate3_dist_fn_stem + '.json', encoding='utf-8') as data_file:\n",
    "   gate3_dists_in = json.loads(data_file.read())\n",
    "with open(gate6_dist_fn_stem + '.json', encoding='utf-8') as data_file:\n",
    "   gate6_dists_in = json.loads(data_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:43.644859Z",
     "start_time": "2019-02-20T17:42:43.632331Z"
    }
   },
   "outputs": [],
   "source": [
    "testRandomKey(gate3_dists_in, printKey = True, printVal = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:43.795900Z",
     "start_time": "2019-02-20T17:42:43.645933Z"
    }
   },
   "outputs": [],
   "source": [
    "gate3_dists = gate3_dists_in\n",
    "gate6_dists = gate6_dists_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and export conditional distributions $p_3(Y_0, Y_1| X_0; X_1)$, $p_6(Y_0, Y_1| X_0, X_1;)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:44.062276Z",
     "start_time": "2019-02-20T17:42:43.796884Z"
    }
   },
   "outputs": [],
   "source": [
    "gate3_dists = {k:Counter(gate3_dists[k]) for k in gate3_dists}\n",
    "gate6_dists = {k:Counter(gate6_dists[k]) for k in gate3_dists}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:42:44.100628Z",
     "start_time": "2019-02-20T17:42:44.065900Z"
    }
   },
   "outputs": [],
   "source": [
    "testStimDiph = getRandomKey(gate3_dists, True)\n",
    "testRespDiph = getRandomKey(gate3_dists[testStimDiph], True)\n",
    "\n",
    "f3(testRespDiph, testStimDiph)\n",
    "gate3_dists[testStimDiph][testRespDiph]\n",
    "\n",
    "assert f3(testRespDiph, testStimDiph) == gate3_dists[testStimDiph][testRespDiph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The distribution for calculating e.g. $p(Y_0, Y_1|X_0,X_1 = dð \\text{ and only } X_0 = d \\text{ has been fully produced/perceived})$ can be calculated by normalizing the counts given by $f_3(\\cdot|\\cdot)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:05.967810Z",
     "start_time": "2019-02-20T17:42:44.101721Z"
    }
   },
   "outputs": [],
   "source": [
    "def p3(y_01, x_01, norm_term = None, use_minus_log2 = False):\n",
    "    if norm_term == None:\n",
    "        norm_term = norm(gate3_dists[x_01])\n",
    "        if norm_term == 0:\n",
    "            norm_term = 1.0\n",
    "    if not use_minus_log2:\n",
    "        return f3(y_01, x_01) / norm_term\n",
    "    elif f3(y_01, x_01) == 0:\n",
    "        return 0.0 \n",
    "    else:\n",
    "        return -1 * log( f3(y_01, x_01) / norm_term)\n",
    "\n",
    "f3_dist = {x_01:{y_01:p3(y_01, x_01, norm_term = 1) for y_01 in response_diphones if p3(y_01, x_01) != 0.0} for x_01 in stimuli_diphones}\n",
    "# p3_dist = {x_01:{y_01:p3(y_01, x_01) for y_01 in response_diphones if p3(y_01, x_01) != 0.0} for x_01 in stimuli_diphones}\n",
    "p3_dist = {x_01:{y_01:p3(y_01, x_01) \n",
    "                 for y_01 in response_diphones} \n",
    "           for x_01 in stimuli_diphones}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The distribution for calculating e.g. $p(Y_0, Y_1|X_0, X_1 = dð \\text{ and both } X_0 = d \\text{ and } X_1 = ð \\text{ has been fully produced/perceived})$ can be calculated by normalizing the counts given by $f_6(\\cdot|\\cdot)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:27.934763Z",
     "start_time": "2019-02-20T17:43:05.968845Z"
    }
   },
   "outputs": [],
   "source": [
    "def p6(y_01, x_01, norm_term = None, use_minus_log2 = False):\n",
    "    if norm_term == None:\n",
    "        norm_term = norm(gate6_dists[x_01])\n",
    "        if norm_term == 0:\n",
    "            norm_term = 1.0\n",
    "    if not use_minus_log2:\n",
    "        return f6(y_01, x_01) / norm_term\n",
    "    elif f6(y_01, x_01) == 0:\n",
    "        return 0.0 \n",
    "    else:\n",
    "        return -1.0 * log( f6(y_01, x_01) / norm_term)\n",
    "\n",
    "f6_dist = {x_01:{y_01:p6(y_01, x_01, norm_term = 1) for y_01 in response_diphones if p6(y_01, x_01) != 0.0} for x_01 in stimuli_diphones}\n",
    "# p6_dist = {x_01:{y_01:p6(y_01, x_01) for y_01 in response_diphones if p6(y_01, x_01) != 0.0} for x_01 in stimuli_diphones}\n",
    "p6_dist = {x_01:{y_01:p6(y_01, x_01) \n",
    "                 for y_01 in response_diphones} \n",
    "           for x_01 in stimuli_diphones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:27.937634Z",
     "start_time": "2019-02-20T17:43:27.935828Z"
    }
   },
   "outputs": [],
   "source": [
    "p3Y01X01 = p3_dist\n",
    "p6Y01X01 = p6_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:28.114459Z",
     "start_time": "2019-02-20T17:43:27.938450Z"
    }
   },
   "outputs": [],
   "source": [
    "p3Y01X01['i.p']['i.p']\n",
    "sum(p3Y01X01['i.p'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:29.090815Z",
     "start_time": "2019-02-20T17:43:28.116119Z"
    }
   },
   "outputs": [],
   "source": [
    "if not areNormalized(p3_dist):\n",
    "    p3_dist = condProbDistAsDicts(condDistsAsProbDists(p3_dist))\n",
    "if not areNormalized(p6_dist):\n",
    "    p6_dist = condProbDistAsDicts(condDistsAsProbDists(p6_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:29.113450Z",
     "start_time": "2019-02-20T17:43:29.091887Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(p3_dist)\n",
    "assert areNormalized(p6_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:29.240972Z",
     "start_time": "2019-02-20T17:43:29.114453Z"
    }
   },
   "outputs": [],
   "source": [
    "p3_dist_fn = which + ' ' + 'p3Y01X01' + '.json'\n",
    "p6_dist_fn = which + ' ' + 'p6Y01X01' + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:41.989320Z",
     "start_time": "2019-02-20T17:43:29.245202Z"
    }
   },
   "outputs": [],
   "source": [
    "exportProbDist(p3_dist_fn, p3_dist)\n",
    "exportProbDist(p6_dist_fn, p6_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:43.488284Z",
     "start_time": "2019-02-20T17:43:41.990488Z"
    }
   },
   "outputs": [],
   "source": [
    "p3_dist_in = importProbDist(p3_dist_fn)\n",
    "p6_dist_in = importProbDist(p6_dist_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:43.603030Z",
     "start_time": "2019-02-20T17:43:43.489312Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(p3_dist_in)\n",
    "assert areNormalized(p6_dist_in)\n",
    "assert p3_dist_in == p3_dist\n",
    "assert p6_dist_in == p6_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and export conditional distributions $p_3(Y_1|X_0; X_1)$, $p_6(Y_0|X_0, X_1;)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:43:43.733872Z",
     "start_time": "2019-02-20T17:43:43.604001Z"
    }
   },
   "outputs": [],
   "source": [
    "def stimDiphonesWithFirstUniphone(x_0):\n",
    "    return set([diph for diph in stimuli_diphones if dottedStringToTuple(diph)[0] == x_0])\n",
    "    \n",
    "def stimDiphonesWithSecondUniphone(x_1):\n",
    "    return set([diph for diph in stimuli_diphones if dottedStringToTuple(diph)[1] == x_1])\n",
    "\n",
    "def respDiphonesWithFirstUniphone(y_0):\n",
    "    return set([diph for diph in response_diphones if dottedStringToTuple(diph)[0] == y_0])\n",
    "    \n",
    "def respDiphonesWithSecondUniphone(y_1):\n",
    "    return set([diph for diph in response_diphones if dottedStringToTuple(diph)[1] == y_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:06.140616Z",
     "start_time": "2019-02-20T17:43:43.738603Z"
    }
   },
   "outputs": [],
   "source": [
    "# p3Y1X01 = {x01:{y1:sum(p3Y01X01[x01][y01] for y01 in respDiphonesWithSecondUniphone(y1)) \n",
    "#                 for y1 in response_uniphones} \n",
    "#            for x01 in stimuli_diphones}\n",
    "\n",
    "# p3Y1X01 = dict()\n",
    "# for x01 in stimuli_diphones:\n",
    "#     dist = dict()\n",
    "#     for y1 in response_uniphones:\n",
    "#         s = 0\n",
    "#         for y01 in respDiphonesWithSecondUniphone(y1):\n",
    "#             cond_dist = p3Y01X01[x01]#[y01]\n",
    "#             cond_prob = cond_dist.get(y01, 0.0)\n",
    "#             s += cond_prob\n",
    "#         dist[y1] = s\n",
    "#     p3Y1X01[x01] = dist\n",
    "\n",
    "p3Y1X01 = {x01:{y1:sum(p3Y01X01[x01].get(y01, 0.0) for y01 in respDiphonesWithSecondUniphone(y1)) \n",
    "                for y1 in response_uniphones} \n",
    "           for x01 in stimuli_diphones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:28.157060Z",
     "start_time": "2019-02-20T17:44:06.141781Z"
    }
   },
   "outputs": [],
   "source": [
    "# p6Y0X01 = {x01:{y0:sum(p6Y01X01[x01][y01] for y01 in respDiphonesWithFirstUniphone(y0))\n",
    "#                 for y0 in response_uniphones}\n",
    "#            for x01 in stimuli_diphones}\n",
    "\n",
    "p6Y0X01 = {x01:{y0:sum(p6Y01X01[x01].get(y01, 0.0) for y01 in respDiphonesWithFirstUniphone(y0))\n",
    "                for y0 in response_uniphones}\n",
    "           for x01 in stimuli_diphones}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:28.161608Z",
     "start_time": "2019-02-20T17:44:28.158053Z"
    }
   },
   "outputs": [],
   "source": [
    "if not areNormalized(p3Y1X01):\n",
    "    p3Y1X01 = condProbDistAsDicts(condDistsAsProbDists(p3Y1X01))\n",
    "if not areNormalized(p6Y0X01):\n",
    "    p6Y0X01 = condProbDistAsDicts(condDistsAsProbDists(p6Y0X01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:28.334590Z",
     "start_time": "2019-02-20T17:44:28.162454Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(p3Y1X01)\n",
    "assert areNormalized(p6Y0X01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:28.416452Z",
     "start_time": "2019-02-20T17:44:28.335645Z"
    }
   },
   "outputs": [],
   "source": [
    "preview_dist_fn = which + ' ' + 'p3Y1X01' + '.json'\n",
    "postview_dist_fn = which + ' ' + 'p6Y0X01' + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:28.858577Z",
     "start_time": "2019-02-20T17:44:28.417379Z"
    }
   },
   "outputs": [],
   "source": [
    "exportProbDist(preview_dist_fn, p3Y1X01)\n",
    "exportProbDist(postview_dist_fn, p6Y0X01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:28.896978Z",
     "start_time": "2019-02-20T17:44:28.859474Z"
    }
   },
   "outputs": [],
   "source": [
    "preview_dist_in = importProbDist(preview_dist_fn)\n",
    "postview_dist_in = importProbDist(postview_dist_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:29.134158Z",
     "start_time": "2019-02-20T17:44:28.901840Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(preview_dist_in)\n",
    "assert areNormalized(postview_dist_in)\n",
    "assert preview_dist_in == p3Y1X01\n",
    "assert postview_dist_in == p6Y0X01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Produce uniphone channel distribution $p(Y|X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to define \n",
    "\n",
    "$$= p(\\dot{y}|\\dot{x}) = p(Y_0 = \\dot{y}|X_0 = \\dot{x};)p(i=0|X_{i} = \\dot{x}) + p(Y_1 = \\dot{y}|X_1 = \\dot{x})p(i=1|X_{i} = \\dot{x}) $$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2n} \\sum_\\limits{X_1,Y_1} [ p(Y_0 = \\dot{y}, Y_1|X_0 = \\dot{x}; X_1) ] + \\frac{1}{2m} \\sum_\\limits{X_0, Y_0}  [ p(Y_0, Y_1 = \\dot{y}|X_0, X_1 = \\dot{x};) ]$$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2n} \\sum_\\limits{X_1} [ p(Y_0 = \\dot{y}|X_0 = \\dot{x}; X_1) ] + \\frac{1}{2m} \\sum_\\limits{X_0}  [ p(Y_1 = \\dot{y}|X_0, X_1 = \\dot{x}) ]$$\n",
    "$$= p(\\dot{y}|\\dot{x}) = \\frac{1}{2} p(Y_0 = \\dot{y}|X_0 = \\dot{x};)  + \\frac{1}{2} p(Y_1 = \\dot{y}|X_1 = \\dot{x})$$\n",
    "\n",
    "where \n",
    " - $\\frac{1}{2} = p(i=0|X_{i} = \\dot{x}) = p(i=1|X_{i} = \\dot{x})$, by assumption (we want to capture the effect of phonetics/acoustics controlling for top-down expectations) and by design/interpretation of the diphone gating experiment...\n",
    " - $n = |\\{ X_1|p(X_1|X_0 = \\dot{x}) > 0 \\}| = |\\{ X_1|p(\\dot{x}.X_1) > 0 \\}| = |\\{X_1| X_0.X_1 \\text{is a diphone with non-zero gate 3 responses} \\}|$ and $\\frac{1}{n}$ represents the assumption (because we want to capture inference against acoustics absent informative top-down expectations) that each segment that is permitted by phonotactics to follow $\\dot{x}$ has equal probability of appearing as the second segmentwhen $\\dot{x}$ is the first segment of the diphone.\n",
    " - $m = |\\{ X_0|p(X_0|X_1 = \\dot{x}) > 0 \\}| = |\\{ X_1|p(X_0.\\dot{x}) > 0 \\}| = |\\{X_0| X_0.X_1 \\text{is a diphone with non-zero gate 6 responses} \\}|$ and $\\frac{1}{m}$ represents the assumption (because we want to capture inference against acoustics absent informative top-down expectations) that each segment that is permitted by phonotactics to precede $\\dot{x}$ has equal probability of appearing as the first segmentwhen $\\dot{x}$ is the second segment of the diphone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, when we have negative log probabilities...\n",
    "\n",
    "$$= -log_2 p(\\dot{y}|\\dot{x}) = \\frac{1}{2n} \\sum_\\limits{X_1,Y_1} [ 2^{--log_2 p(Y_0 = \\dot{y}, Y_1|X_0 = \\dot{x}; X_1)} ] + \\frac{1}{2m} \\sum_\\limits{X_0, Y_0}  [ 2^{--log_2 p(Y_0, Y_1 = \\dot{y}|X_0, X_1 = \\dot{x};)} ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit derivations (taken from the top of $\\S 5$) for the code below:\n",
    "\n",
    "Recall that\n",
    "\n",
    "$p(Y_{i=0} = \\dot{y}|X_{i=0} = \\dot{x};)$\n",
    "$ = \\sum_\\limits{X_1} p(Y_{i=0} = \\dot{y}, X_1|X_{i=0} = \\dot{x};)$\n",
    "$ = \\sum_\\limits{X_1} p(Y_0 = \\dot{y}|X_0 = \\dot{x}; X_1) p(X_1|X_0 = \\dot{x};)$\n",
    "$ = \\sum_\\limits{X_1, Y_1} p(Y_0 = \\dot{y},Y_1|X_0 = \\dot{x}; X_1)  p(X_1|X_0 = \\dot{x};) $\n",
    "$ = \\sum_\\limits{X_1, Y_1} p(Y_0 = \\dot{y},Y_1|X_0 = \\dot{x}; X_1)  \\frac{1}{n} $\n",
    "$ = \\frac{1}{n} \\sum_\\limits{X_1, Y_1} p(Y_0 = \\dot{y},Y_1|X_0 = \\dot{x}; X_1)$\n",
    "\n",
    "...and\n",
    "\n",
    "$p(Y_{i=1} = \\dot{y}|X_{i=1} = \\dot{x};)$\n",
    "$ = \\sum_\\limits{X_0} p(Y_{i=1} = \\dot{y}, X_0|X_{i=1} = \\dot{x};)$\n",
    "$ = \\sum_\\limits{X_0} p(Y_1 = \\dot{y}|X_0, X_1 = \\dot{x};) p(X_0|X_1 = \\dot{x};)$\n",
    "$ = \\sum_\\limits{X_0, Y_0} p(Y_0, Y_1 = \\dot{y}|X_0, X_1 = \\dot{x};)  p(X_0|X_1 = \\dot{x};) $\n",
    "$ = \\sum_\\limits{X_0, Y_0} p(Y_0, Y_1 = \\dot{y}|X_0, X_1 = \\dot{x};)  \\frac{1}{m} $\n",
    "$ = \\frac{1}{m} \\sum_\\limits{X_0, Y_0} p(Y_0, Y_1 = \\dot{y}|X_0, X_1 = \\dot{x};)$\n",
    "\n",
    "where $n = |\\{ X_1|p(X_1|X_0 = \\dot{x}) > 0 \\}|$ and $m = |\\{ X_0|p(X_0|X_1 = \\dot{x}) > 0 \\}|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:29.208334Z",
     "start_time": "2019-02-20T17:44:29.139624Z"
    }
   },
   "outputs": [],
   "source": [
    "def inv(negLogProb):\n",
    "    return pow(2, -1.0 * negLogProb)\n",
    "\n",
    "#   p_uniphone_0(y_1, x_1)\n",
    "#   p(Y_0 = y|X_0 = x)\n",
    "#   p(Y_0 = \\dot{y}|X_0 = \\dot{x})\n",
    "def p_uniphone_0(y_0, x_0, use_minus_log2 = None):\n",
    "    if use_minus_log2 == None:\n",
    "        use_minus_log2 = False\n",
    "    elif use_minus_log2 == True:\n",
    "        print('ERROR: existing negative log probability calculation has at least one bug and is disabled. Reverting to False.')\n",
    "        use_minus_log2 = False\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    stimDiph_startingWithX = stimDiphonesWithFirstUniphone(x_0)\n",
    "    n = len(stimDiph_startingWithX)\n",
    "    respDiph_startingWithY = respDiphonesWithFirstUniphone(y_0)\n",
    "\n",
    "    secondPhonePairs = list(product(stimDiph_startingWithX, respDiph_startingWithY))\n",
    "    sum_result = sum([p3(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in secondPhonePairs])\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    result = (1.0 / n) * sum_result\n",
    "    if (result < 0.0 or result > 1.0):\n",
    "        terms = [p3(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in secondPhonePairs]\n",
    "        print('Error: {0} should be >= 0.0 and <= 1.0'.format(result))\n",
    "        print('{0} = sum of terms, where terms = '.format(result))\n",
    "        print(terms)\n",
    "    assert(result >= 0.0 and result <= 1.0)\n",
    "    return result\n",
    "\n",
    "#   p_uniphone_1(y_1, x_1)\n",
    "#   p(Y_1 = y|X_1 = x)\n",
    "#   p(Y_1 = \\dot{y}|X_1 = \\dot{x})\n",
    "def p_uniphone_1(y_1, x_1, use_minus_log2 = None):\n",
    "    if use_minus_log2 == None:\n",
    "        use_minus_log2 = False\n",
    "    elif use_minus_log2 == True:\n",
    "        print('ERROR: existing negative log probability calculation has at least one bug and is disabled. Reverting to False.')\n",
    "        use_minus_log2 = False\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    stimDiph_endingWithX = stimDiphonesWithSecondUniphone(x_1)\n",
    "    m = len(stimDiph_endingWithX)\n",
    "    respDiph_endingWithY = respDiphonesWithSecondUniphone(y_1)\n",
    "\n",
    "    firstPhonePairs = list(product(stimDiph_endingWithX, respDiph_endingWithY))\n",
    "    sum_terms = [p6(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in firstPhonePairs]\n",
    "    sum_result = sum(sum_terms)\n",
    "    if m == 0:\n",
    "        return 0.0\n",
    "    result = (1.0 / m) *  sum_result\n",
    "    if (result < 0.0 or result > 1.0):\n",
    "        terms = [p6(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in firstPhonePairs]\n",
    "        print('Error: {0} should be >= 0.0 and <= 1.0'.format(result))\n",
    "        print('{0} = sum of terms, where terms = '.format(result))\n",
    "        print(terms)\n",
    "    assert(result >= 0.0 and result <= 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:29.336261Z",
     "start_time": "2019-02-20T17:44:29.212899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p.l'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'k.t'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.6683161383685136e-05"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.668316138368512e-05"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testStimDiph\n",
    "testRespDiph\n",
    "f3(testRespDiph, testStimDiph)\n",
    "f6(testRespDiph, testStimDiph)\n",
    "p3(testRespDiph, testStimDiph)\n",
    "p6(testRespDiph, testStimDiph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that (taken from the top of $\\S$ 5.5)\n",
    "$$p(\\dot{y}|\\dot{x}) = \\frac{1}{2} p(Y_0 = \\dot{y}|X_0 = \\dot{x};)  + \\frac{1}{2} p(Y_1 = \\dot{y}|X_1 = \\dot{x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:29.410876Z",
     "start_time": "2019-02-20T17:44:29.341367Z"
    }
   },
   "outputs": [],
   "source": [
    "# def p_uniphone(y, x):\n",
    "def p_uniphone(y, x, use_minus_log2 = None):\n",
    "    if use_minus_log2 == None:\n",
    "        use_minus_log2 = False\n",
    "    \n",
    "#     stimDiph_startingWithX = stimDiphonesWithFirstUniphone(x)\n",
    "#     n = len(stimDiph_startingWithX)\n",
    "#     respDiph_startingWithY = respDiphonesWithFirstUniphone(y)\n",
    "\n",
    "#     secondPhonePairs = list(product(stimDiph_startingWithX, respDiph_startingWithY))\n",
    "#     firstTerm = 0.5 * (1/n) * sum([p3(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in secondPhonePairs])\n",
    "    firstTerm = 0.5 * p_uniphone_0(y, x, use_minus_log2 = False)\n",
    "    \n",
    "    #commented out code immediately below attempted to permit calculations using negative log probabilities \n",
    "    # and then checked it for correctness; I couldn't get it to work properly and couldn't figure out\n",
    "    # what I was doing wrong...\n",
    "#     firstTerm = -10\n",
    "#     if not use_minus_log2:\n",
    "#         firstTerm = 0.5 * (1/n) * sum([p3(y_01,x_01, use_minus_log2 = use_minus_log2) for (x_01,y_01) in secondPhonePairs])\n",
    "#     else:\n",
    "#         subterms = [inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)) for (x_01,y_01) in secondPhonePairs]\n",
    "#         if not all([inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)) == p3(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in secondPhonePairs]):\n",
    "##             print([(x_01,y_01) for (x_01,y_01) in secondPhonePairs if inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)) != p3(y_01,x_01, use_minus_log2 = False)])\n",
    "#             badTerms = [(x_01,y_01) for (x_01,y_01) in secondPhonePairs if inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)) != p3(y_01,x_01, use_minus_log2 = False)]\n",
    "#             print('{0}/{1} subterms are bad.'.format(len(badTerms), len(secondPhonePairs)))\n",
    "#             veryBadTerms = [(x_01,y_01) for (x_01,y_01) in secondPhonePairs if not isclose(inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)), p3(y_01,x_01, use_minus_log2 = False))]\n",
    "#             print('{0}/{1} subterms are very bad.'.format(len(veryBadTerms), len(secondPhonePairs)))\n",
    "#         assert(all([inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)) == p3(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in secondPhonePairs]))\n",
    "#         firstTerm = 0.5 * (1/n) * sum([inv(p3(y_01,x_01, use_minus_log2 = use_minus_log2)) for (x_01,y_01) in secondPhonePairs])\n",
    "    \n",
    "    \n",
    "#     stimDiph_endingWithX = stimDiphonesWithSecondUniphone(x)\n",
    "#     m = len(stimDiph_endingWithX)\n",
    "#     respDiph_endingWithY = respDiphonesWithSecondUniphone(y)\n",
    "\n",
    "#     firstPhonePairs = list(product(stimDiph_endingWithX, respDiph_endingWithY))\n",
    "#     secondTerm = 0.5 * (1/m) * sum([p6(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in firstPhonePairs])\n",
    "    secondTerm = 0.5 * p_uniphone_1(y, x, use_minus_log2 = False)\n",
    "    \n",
    "    #commented out code immediately below attempted to permit calculations using negative log probabilities similar to code above...\n",
    "#     secondTerm = -100\n",
    "#     if not use_minus_log2:\n",
    "#         secondTerm = 0.5 * (1/m) * sum([p6(y_01,x_01, use_minus_log2 = use_minus_log2) for (x_01,y_01) in firstPhonePairs])\n",
    "#     else:\n",
    "#         assert(all([pow(2, -1.0 * p6(y_01,x_01, use_minus_log2 = use_minus_log2)) == p6(y_01,x_01, use_minus_log2 = False) for (x_01,y_01) in firstPhonePairs]))\n",
    "#         secondTerm = 0.5 * (1/m) * sum([pow(2, -1.0 * p6(y_01,x_01, use_minus_log2 = use_minus_log2)) for (x_01,y_01) in firstPhonePairs])\n",
    "\n",
    "    result = firstTerm + secondTerm\n",
    "    if use_minus_log2:\n",
    "        return -1.0 * log(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:44:29.600770Z",
     "start_time": "2019-02-20T17:44:29.415365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.030421667566304718"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.030421667566304718"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.030421667566304718"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testStimUniph = dottedStringToTuple(testStimDiph)[0]\n",
    "testRespUniph = dottedStringToTuple(testRespDiph)[0]\n",
    "testStimUniph\n",
    "testRespUniph\n",
    "p_uniphone(testRespUniph, testStimUniph)\n",
    "p_uniphone(testRespUniph, testStimUniph)\n",
    "p_uniphone(testRespUniph, testStimUniph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the uniphone channel distribution $p(Y|X)$ as a dictionary for export, as well as two of the distributions used to define it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.271219Z",
     "start_time": "2019-02-20T17:44:29.601859Z"
    }
   },
   "outputs": [],
   "source": [
    "# uniphone_dist = {x:{y:p_uniphone(y,x) \n",
    "#                     for y in response_uniphones if p_uniphone(y,x) != 0.0} \n",
    "#                  for x in stimuli_uniphones}\n",
    "# gate3_uniphone_dist = {x:{y:p_uniphone_0(y,x) \n",
    "#                           for y in response_uniphones if p_uniphone_0(y,x) != 0.0} \n",
    "#                        for x in stimuli_uniphones}\n",
    "# gate6_uniphone_dist = {x:{y:p_uniphone_1(y,x) \n",
    "#                           for y in response_uniphones if p_uniphone_1(y,x) != 0.0} \n",
    "#                        for x in stimuli_uniphones}\n",
    "\n",
    "uniphone_dist = {x:{y:p_uniphone(y,x) \n",
    "                    for y in response_uniphones} \n",
    "                 for x in stimuli_uniphones}\n",
    "gate3_uniphone_dist = {x:{y:p_uniphone_0(y,x) \n",
    "                          for y in response_uniphones} \n",
    "                       for x in stimuli_uniphones}\n",
    "gate6_uniphone_dist = {x:{y:p_uniphone_1(y,x) \n",
    "                          for y in response_uniphones} \n",
    "                       for x in stimuli_uniphones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.278497Z",
     "start_time": "2019-02-20T17:45:17.272358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'f': 0.005573707755813633,\n",
       " 't': 0.004918081308173249,\n",
       " 'ɚ': 0.001788614165603161,\n",
       " 'v': 0.004347998013392948,\n",
       " 'n': 0.0017904521682995753,\n",
       " 'ɛ': 0.0050323383754999115,\n",
       " 'θ': 0.004348212217073981,\n",
       " 'm': 0.0024030804927538223,\n",
       " 'æ': 0.0014727897570385065,\n",
       " 'eɪ': 0.0027695442399186506,\n",
       " 'z': 0.001434032131853283,\n",
       " 'aɪ': 0.0014727897570385065,\n",
       " 'r': 0.0018081000800362922,\n",
       " 'u': 0.0017904521682995753,\n",
       " 'd': 0.0017888283692841954,\n",
       " 'tʃ': 0.0021211669984786204,\n",
       " 'k': 0.030421667566304718,\n",
       " 'p': 0.8317021439284464,\n",
       " 'w': 0.0020821951696123877,\n",
       " 'h': 0.018982712335955748,\n",
       " 's': 0.002101681084045518,\n",
       " 'j': 0.001277930612707197,\n",
       " 'aʊ': 0.002087041880508057,\n",
       " 'b': 0.007208885046631457,\n",
       " 'l': 0.0053837765879596,\n",
       " 'ɑ': 0.0027400146147668917,\n",
       " 'ʒ': 0.001434032131853283,\n",
       " 'ʃ': 0.002677389786010914,\n",
       " 'ɔɪ': 0.0014727897570385065,\n",
       " 'i': 0.0018081000800362905,\n",
       " 'ʊ': 0.0014727897570385065,\n",
       " 'ɪ': 0.004054417009383773,\n",
       " 'g': 0.002456477321476406,\n",
       " 'ŋ': 0.0019284498909576792,\n",
       " 'ð': 0.0014147604211011914,\n",
       " 'oʊ': 0.002461072814295087,\n",
       " 'ʌ': 0.02790834654274351,\n",
       " 'dʒ': 0.002063137662541329}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'f': 0.004534290984451905,\n",
       " 't': 0.007030271307196374,\n",
       " 'ɚ': 0.001441957668051742,\n",
       " 'v': 0.0026704619149909873,\n",
       " 'n': 0.0021162543194401433,\n",
       " 'ɛ': 0.0021162543194401294,\n",
       " 'θ': 0.0027094337438572586,\n",
       " 'm': 0.00270943374385726,\n",
       " 'æ': 0.0014809294969180054,\n",
       " 'eɪ': 0.0014809294969180054,\n",
       " 'z': 0.001441957668051742,\n",
       " 'aɪ': 0.0014809294969180054,\n",
       " 'r': 0.0014809294969180054,\n",
       " 'u': 0.0021162543194401433,\n",
       " 'd': 0.0014809294969180054,\n",
       " 'tʃ': 0.0014809294969180054,\n",
       " 'k': 0.05803744382345935,\n",
       " 'p': 0.7830574905727075,\n",
       " 'w': 0.0014029858391854796,\n",
       " 'h': 0.031895403751005726,\n",
       " 's': 0.001441957668051742,\n",
       " 'j': 0.0010912112082553866,\n",
       " 'aʊ': 0.002709433743857107,\n",
       " 'b': 0.008258775554135312,\n",
       " 'l': 0.003937937990796175,\n",
       " 'ɑ': 0.003344758566379201,\n",
       " 'ʒ': 0.001441957668051742,\n",
       " 'ʃ': 0.002670461914990986,\n",
       " 'ɔɪ': 0.0014809294969180054,\n",
       " 'i': 0.0014809294969180054,\n",
       " 'ʊ': 0.0014809294969180054,\n",
       " 'ɪ': 0.002709433743857246,\n",
       " 'g': 0.0014809294969180054,\n",
       " 'ŋ': 0.0014809294969180054,\n",
       " 'ð': 0.001441957668051742,\n",
       " 'oʊ': 0.002116254319440067,\n",
       " 'ʌ': 0.04782378384481652,\n",
       " 'dʒ': 0.001441957668051742}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'f': 0.0066131245271753595,\n",
       " 't': 0.0028058913091501244,\n",
       " 'ɚ': 0.0021352706631545797,\n",
       " 'v': 0.006025534111794908,\n",
       " 'n': 0.0014646500171590076,\n",
       " 'ɛ': 0.007948422431559693,\n",
       " 'θ': 0.005986990690290704,\n",
       " 'm': 0.002096727241650385,\n",
       " 'æ': 0.0014646500171590076,\n",
       " 'eɪ': 0.0040581589829192955,\n",
       " 'z': 0.0014261065956548242,\n",
       " 'aɪ': 0.0014646500171590076,\n",
       " 'r': 0.0021352706631545793,\n",
       " 'u': 0.0014646500171590076,\n",
       " 'd': 0.002096727241650385,\n",
       " 'tʃ': 0.002761404500039235,\n",
       " 'k': 0.002805891309150085,\n",
       " 'p': 0.8803467972841855,\n",
       " 'w': 0.0027614045000392954,\n",
       " 'h': 0.006070020920905771,\n",
       " 's': 0.002761404500039294,\n",
       " 'j': 0.0014646500171590076,\n",
       " 'aʊ': 0.0014646500171590076,\n",
       " 'b': 0.006158994539127602,\n",
       " 'l': 0.006829615185123025,\n",
       " 'ɑ': 0.0021352706631545828,\n",
       " 'ʒ': 0.0014261065956548242,\n",
       " 'ʃ': 0.0026843176570308415,\n",
       " 'ɔɪ': 0.0014646500171590076,\n",
       " 'i': 0.002135270663154576,\n",
       " 'ʊ': 0.0014646500171590076,\n",
       " 'ɪ': 0.0053994002749103,\n",
       " 'g': 0.003432025146034807,\n",
       " 'ŋ': 0.002375970284997353,\n",
       " 'ð': 0.001387563174150641,\n",
       " 'oʊ': 0.0028058913091501066,\n",
       " 'ʌ': 0.007992909240670507,\n",
       " 'dʒ': 0.0026843176570309165}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testStimUniph\n",
    "uniphone_dist[testStimUniph]\n",
    "gate3_uniphone_dist[testStimUniph]\n",
    "gate6_uniphone_dist[testStimUniph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.425265Z",
     "start_time": "2019-02-20T17:45:17.279325Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(uniphone_dist)\n",
    "assert areNormalized(gate3_uniphone_dist)\n",
    "assert areNormalized(gate6_uniphone_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.510503Z",
     "start_time": "2019-02-20T17:45:17.429743Z"
    }
   },
   "outputs": [],
   "source": [
    "uniphone_fn = which + ' pYX' + '.json'\n",
    "uniphone_gate3_fn = which + ' p3YX' + '.json'\n",
    "uniphone_gate6_fn = which + ' p6YX' + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.662696Z",
     "start_time": "2019-02-20T17:45:17.515023Z"
    }
   },
   "outputs": [],
   "source": [
    "exportProbDist(uniphone_fn, uniphone_dist)\n",
    "exportProbDist(uniphone_gate3_fn, gate3_uniphone_dist)\n",
    "exportProbDist(uniphone_gate6_fn, gate6_uniphone_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.778505Z",
     "start_time": "2019-02-20T17:45:17.664019Z"
    }
   },
   "outputs": [],
   "source": [
    "uniphone_dist_in = importProbDist(uniphone_fn)\n",
    "gate3_uniphone_dist_in = importProbDist(uniphone_gate3_fn)\n",
    "gate6_uniphone_dist_in = importProbDist(uniphone_gate6_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.875634Z",
     "start_time": "2019-02-20T17:45:17.783131Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(uniphone_dist_in)\n",
    "assert areNormalized(gate3_uniphone_dist_in)\n",
    "assert areNormalized(gate6_uniphone_dist_in)\n",
    "\n",
    "assert uniphone_dist_in == uniphone_dist\n",
    "assert gate3_uniphone_dist_in == gate3_uniphone_dist\n",
    "assert gate6_uniphone_dist_in == gate6_uniphone_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce triphone channel distribution $p_3(Y_1|X_0, X_1; X_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to define $p(y_i|x_{i-1}, x_i; x_{i+1})$ for all combinations of \n",
    " - $x_i \\in \\Sigma$\n",
    " - $y_i \\in \\Gamma$\n",
    " - $x_{i-1} \\in \\Sigma \\cup \\{\\rtimes\\}$\n",
    " - $x_{i+1} \\in \\Sigma \\cup \\{\\ltimes\\}$\n",
    "\n",
    "where \n",
    " - $\\Sigma$ is the set of (aligned) stimuli segments and $\\Gamma$ is the set of (aligned) response segments.\n",
    " - the interpretation of $p(y_i|x_{i-1}, x_i; x_{i+1})$ is the channel distribution over the $i$th segment in a sequence given that $x_{i-1}$ preceded it and $x_{i+1}$ hasn't been produced yet, but will be.\n",
    " \n",
    "We approximate $p(y_i|x_{i-1}, x_i; x_{i+1})$ as proportional to $p_6(y_i|x_{i-1}, x_i;) \\cdot p_3(y_i|x_i; x_{i+1})$:\n",
    "$$p(y_i|x_{i-1}, x_i; x_{i+1}) \\propto p_6(y_i|x_{i-1}, x_i;) \\cdot p_3(y_i|x_i; x_{i+1})$$\n",
    "$$p(y_i|x_{i-1}, x_i; x_{i+1}) = \\frac{p_6(y_i|x_{i-1}, x_i;) \\cdot p_3(y_i|x_i; x_{i+1})}{\\sum\\limits_{y'_i} p_6(y'_i|x_{i-1},x_i;) \\cdot p_3(y'_i|x_i; x_{i+1})}$$\n",
    "\n",
    "where \n",
    " - $p(y_i|\\rtimes, x_i; \\ltimes) = p(y|x)$, the uniphone channel distribution\n",
    " - $p(y_i|\\rtimes, x_i; x_{i+1} \\neq \\ltimes) = p_3(y_i|x_i; x_{i+1})$\n",
    " - $p(y_i| x_i \\neq \\rtimes, x_i; \\ltimes) = p_6(y_i|x_{i-1}, x_i;)$\n",
    " - $p_3(y_i|x_i; x_{i+1}) = \\sum\\limits_{y_{i+1}} p_3(y_i, y_{i+1}|x_i; x_{i+1})$, where $x_i, x_{i+1} \\in \\Sigma$ and $y_i, y_{i+1} \\in \\Gamma$ (i.e. $\\rtimes$ and $\\ltimes$ are excluded).\n",
    " - $p_6(y_i|x_{i-1}, x_i;) = \\sum\\limits_{y_{i-1}} p_6(y_{i-1}, y_i|x_{i-1}, x_i;)$, where $x_{i-1}, x_i \\in \\Sigma$ and $y_{i-1}, y_i \\in \\Gamma$ (i.e. $\\rtimes$ and $\\ltimes$ are excluded)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define relevant n-phone sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_triphs` represents the set of $x_{i-1}, x_i, x_{i+1}$ above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:17.972312Z",
     "start_time": "2019-02-20T17:45:17.876521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42930"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_triphs = set(list(constructableStimulusTriphones)[:])\n",
    "len(X_triphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to ensure it includes triphones involving word edge symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.097774Z",
     "start_time": "2019-02-20T17:45:17.975609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋉'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftEdge\n",
    "rightEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.196518Z",
     "start_time": "2019-02-20T17:45:18.098695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[each for each in X_triphs if leftEdge in each]\n",
    "[each for each in X_triphs if rightEdge in each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.281645Z",
     "start_time": "2019-02-20T17:45:18.197428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.p.l'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.'.join([leftEdge, testStimDiph])\n",
    "addLeftEdge = lambda s: '.'.join([leftEdge, s])\n",
    "addRightEdge = lambda s: '.'.join([s, rightEdge])\n",
    "sandwich = lambda s: addRightEdge(addLeftEdge(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.375760Z",
     "start_time": "2019-02-20T17:45:18.285876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_edge_triphs = set(map(addLeftEdge, stimuli_diphones))\n",
    "len(left_edge_triphs)\n",
    "right_edge_triphs = set(map(addRightEdge, stimuli_diphones))\n",
    "len(right_edge_triphs)\n",
    "sandwich_triphs = set(map(sandwich, stimuli_uniphones))\n",
    "len(sandwich_triphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.443440Z",
     "start_time": "2019-02-20T17:45:18.380206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45553"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_triphs.update(left_edge_triphs, right_edge_triphs, sandwich_triphs)\n",
    "len(X_triphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're working with gating data that is aligned with a lexicon (and destressed, for now), we can throw out stimuli triphones that are not present in the lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.514348Z",
     "start_time": "2019-02-20T17:45:18.444893Z"
    }
   },
   "outputs": [],
   "source": [
    "# slim_triphones = True\n",
    "\n",
    "# if slim_triphones and (which_alignment == 'Hammond-aligned' or which_alignment == 'IPhOD-aligned') and which_stress == 'destressed' and pseudocount >= 0:\n",
    "#     hammond_destressed_triphones_fn = 'Hammond_newdic_IPA_aligned_destressedTriphones.txt'\n",
    "#     iphod_destressed_triphones_fn = 'IPhOD2_Words_IPA_prob_caughtCotMerged_schwa_destressedTriphones.txt'\n",
    "    \n",
    "#     h_triphs = []\n",
    "#     with open(hammond_destressed_triphones_fn, 'r') as the_file:\n",
    "#         for row in the_file:\n",
    "#             h_triphs.append(row.rstrip('\\r\\n'))\n",
    "    \n",
    "#     i_triphs = []\n",
    "#     with open(iphod_destressed_triphones_fn, 'r') as the_file:\n",
    "#         for row in the_file:\n",
    "#             i_triphs.append(row.rstrip('\\r\\n'))\n",
    "\n",
    "#     print(len(X_triphs))\n",
    "#     if which_alignment == 'Hammond-aligned':\n",
    "#         X_triphs = set([triph for triph in X_triphs if leftEdge in triph or rightEdge in triph or triph in h_triphs])\n",
    "#     if which_alignment == 'IPhOD-aligned':\n",
    "#         X_triphs = set([triph for triph in X_triphs if leftEdge in triph or rightEdge in triph or triph in i_triphs])\n",
    "#     print(len(X_triphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Ys` represents the set of allowable $y_i$ above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.595130Z",
     "start_time": "2019-02-20T17:45:18.515576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ys = response_uniphones\n",
    "len(Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the triphone channel distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p3_y0` computes $p_3(y_i|x_i; x_{i+1})$ and `p6_y1` computes $p_6(y_i|x_{i-1}, x_i;)$, each via marginalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:45:18.678647Z",
     "start_time": "2019-02-20T17:45:18.599519Z"
    }
   },
   "outputs": [],
   "source": [
    "def p3_y0(y0, x01):\n",
    "    assert y0 in Ys, '{0} not a valid response segment'.format(y0)\n",
    "    assert x01 in stimuli_diphones, '{0} not a valid stimulus diphone'.format(x01)\n",
    "    \n",
    "    y01s = respDiphonesWithFirstUniphone(y0)\n",
    "    sumTerms = [p3(y01, x01) for y01 in y01s]\n",
    "    sum_result = sum(sumTerms)\n",
    "    return sum_result\n",
    "\n",
    "def p6_y1(y1, x01):\n",
    "    assert y1 in Ys, '{0} not a valid response segment'.format(y1)\n",
    "    assert x01 in stimuli_diphones, '{0} not a valid stimulus diphone'.format(x01)\n",
    "    \n",
    "    y01s = respDiphonesWithSecondUniphone(y1)\n",
    "    sumTerms = [p6(y01, x01) for y01 in y01s]\n",
    "    sum_result = sum(sumTerms)\n",
    "    return sum_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:02.108038Z",
     "start_time": "2019-02-20T17:45:18.683087Z"
    }
   },
   "outputs": [],
   "source": [
    "# ~45s altogether [kotoba/python3]\n",
    "\n",
    "p3Y0X01 = {x01:{y0:sum(p3Y01X01[x01].get(y01, 0.0) for y01 in respDiphonesWithFirstUniphone(y0)) \n",
    "                for y0 in response_uniphones} \n",
    "           for x01 in stimuli_diphones}\n",
    "\n",
    "p6Y1X01 = {x01:{y1:sum(p6Y01X01[x01].get(y01, 0.0) for y01 in respDiphonesWithSecondUniphone(y1))\n",
    "                for y1 in response_uniphones}\n",
    "           for x01 in stimuli_diphones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:02.112590Z",
     "start_time": "2019-02-20T17:46:02.109011Z"
    }
   },
   "outputs": [],
   "source": [
    "if not areNormalized(p3Y0X01):\n",
    "    p3Y0X01 = condProbDistAsDicts(condDistsAsProbDists(p3Y0X01))\n",
    "if not areNormalized(p6Y1X01):\n",
    "    p6Y1X01 = condProbDistAsDicts(condDistsAsProbDists(p6Y1X01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:02.284924Z",
     "start_time": "2019-02-20T17:46:02.113405Z"
    }
   },
   "outputs": [],
   "source": [
    "assert areNormalized(p3Y0X01)\n",
    "assert areNormalized(p6Y1X01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:02.382967Z",
     "start_time": "2019-02-20T17:46:02.285906Z"
    }
   },
   "outputs": [],
   "source": [
    "f_dist_fn = which + ' ' + 'p3Y0X01' + '.json'\n",
    "b_dist_fn = which + ' ' + 'p6Y1X01' + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:02.791538Z",
     "start_time": "2019-02-20T17:46:02.383871Z"
    }
   },
   "outputs": [],
   "source": [
    "exportProbDist(f_dist_fn, p3Y0X01)\n",
    "exportProbDist(b_dist_fn, p6Y1X01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`triph_channel` computes $p(y_i|x_{i-1}, x_i; x_{i+1})$ as defined above, and `annihilation` checks for whether exactly one of $\\{p(y_i|x_{i-1}, x_i;), p(y_i|x_i;x_{i+1})\\}$ is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:02.794566Z",
     "start_time": "2019-02-20T17:46:02.792651Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import localtime, strftime\n",
    "def stamp():\n",
    "    return strftime('%H:%M:%S', localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:46:03.173319Z",
     "start_time": "2019-02-20T17:46:02.795521Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "geometric_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:16.594502Z",
     "start_time": "2019-02-20T17:46:03.177948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1464 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2436 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3624 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5028 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done 6648 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8484 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10536 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 27384 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 30948 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 34728 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 38724 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 42936 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 45553 out of 45553 | elapsed:  6.2min finished\n"
     ]
    }
   ],
   "source": [
    "def triph_channel_unnormalized(y1, x012):\n",
    "    assert y1 in Ys, '{0} not a valid output segment'.format(y1)\n",
    "    assert x012 in X_triphs, '{0} not a valid input triphone'.format(x012)\n",
    "    \n",
    "    Xs = dottedStringToTuple(x012)\n",
    "    x0, x1, x2 = Xs[0], Xs[1], Xs[2]\n",
    "    x01 = tupleToDottedString((x0, x1))\n",
    "    x12 = tupleToDottedString((x1, x2))\n",
    "    if x0 == leftEdge and x2 == rightEdge:\n",
    "        return uniphone_dist[x1].get(y1, 0.0)\n",
    "    elif x0 == leftEdge:\n",
    "        assert x12 in stimuli_diphones, '{0} not a valid stimulus diphone'.format(x12)\n",
    "        return p3_y0(y1, x12)\n",
    "    elif x2 == rightEdge:\n",
    "        assert x01 in stimuli_diphones, '{0} not a valid stimulus diphone'.format(x01)\n",
    "        return p6_y1(y1, x01)\n",
    "    else:\n",
    "#         y_terms = [(p6_y1(y, x01), p3_y0(y, x12)) for y in Ys]\n",
    "        prod = lambda pair: pair[0]*pair[1]\n",
    "#         products = list(map(prod, y_terms))\n",
    "#         normalization_term = sum(products) #denominator        \n",
    "#         assert normalization_term != 0.0 , \"Normalization term probably shouldn't = 0.\\ny1 = {1}, x012 = {2}\\nTerms:\\n{0}\".format(y_terms, y1, x012)\n",
    "        \n",
    "        key_term = (p6_y1(y1, x01), p3_y0(y1, x12)) #numerator\n",
    "        \n",
    "#         return prod(key_term) / normalization_term\n",
    "        if geometric_mean:\n",
    "            return sqrt(prod(key_term))\n",
    "        else:\n",
    "            return prod(key_term)\n",
    "\n",
    "# if pseudocount != 0:\n",
    "#     triph_dist_unnormalized = {x012:{y1:triph_channel_unnormalized(y1, x012) for y1 in Ys if triph_channel_unnormalized(y1, x012) != 0.0} for x012 in X_triphs}\n",
    "\n",
    "# print('Triphone channel dist calculation started @ {0}'.format(stamp()))\n",
    "\n",
    "# triph_dist_unnormalized = dict()\n",
    "# if pseudocount != 0:\n",
    "#     num_X_triphs = len(X_triphs)\n",
    "#     benchmarkPercentages = [1,2,3,5,10,20,30,40,50,60,70,80,90,95,96,97,98,99,100]\n",
    "#     benchmarkIndices = [round(each/100.0 * num_X_triphs) for each in benchmarkPercentages]\n",
    "#     for i, x012 in enumerate(X_triphs):\n",
    "#         if i in benchmarkIndices:\n",
    "#             print('{0} | {0}/{1} = {2} | {3} | {4}'.format(i, num_X_triphs, i/num_X_triphs, x012, stamp()))\n",
    "\n",
    "#         triph_dist_unnormalized[x012] = {y1:triph_channel_unnormalized(y1, x012) for y1 in Ys if triph_channel_unnormalized(y1, x012) != 0.0}\n",
    "\n",
    "\n",
    "if pseudocount != 0:\n",
    "    def foo(x012):\n",
    "        return (x012, bar(x012))\n",
    "    def bar(x012):\n",
    "        return {y1:triph_channel_unnormalized(y1, x012) for y1 in Ys}\n",
    "#         return dict(  Parallel(n_jobs=4)(delayed(baz)(y1, x012) for y1 in Ys) )\n",
    "#     def baz(y1, x012):\n",
    "#         return (y1, triph_channel_unnormalized(y1, x012))\n",
    "    triph_dist_unnormalized = dict( Parallel(n_jobs=-1, backend='multiprocessing', verbose=5)( delayed(foo)(x012) for x012 in X_triphs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:17.394640Z",
     "start_time": "2019-02-20T17:52:16.596258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 45553 out of 45553 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "def triph_channel_norm(x012):\n",
    "    assert x012 in X_triphs, '{0} not a valid input triphone'.format(x012)\n",
    "    Xs = dottedStringToTuple(x012)\n",
    "    x0, x1, x2 = Xs[0], Xs[1], Xs[2]\n",
    "    x01 = tupleToDottedString((x0, x1))\n",
    "    x12 = tupleToDottedString((x1, x2))\n",
    "    if x0 == leftEdge or x2 == rightEdge:\n",
    "        return 1.0\n",
    "\n",
    "#     y_terms = [(p6_y1(y, x01), p3_y0(y, x12)) for y in Ys]\n",
    "#     prod = lambda pair: pair[0]*pair[1]\n",
    "#     products = list(map(prod, y_terms))\n",
    "    products = [triph_dist_unnormalized[x012][y] for y in Ys]\n",
    "    normalization_term = sum(products) #denominator\n",
    "    assert normalization_term != 0.0 , \"Normalization term probably shouldn't = 0.\\nx012 = {1}\\nTerms:\\n{0}\".format(y_terms, x012)\n",
    "    return normalization_term\n",
    "\n",
    "# Compute norms *once* for each stimulus triphone\n",
    "triph_dist_norms = dict()\n",
    "if pseudocount != 0:\n",
    "#     triph_dist_norms = {x012:triph_channel_norm(x012) for x012 in X_triphs}\n",
    "\n",
    "#     num_X_triphs = len(X_triphs)\n",
    "#     benchmarkPercentages = [1,2,3,5,10,20,30,40,50,60,70,80,90,95,96,97,98,99,100]\n",
    "#     benchmarkIndices = [round(each/100.0 * num_X_triphs) for each in benchmarkPercentages]\n",
    "#     for i, x012 in enumerate(X_triphs):\n",
    "#         if i in benchmarkIndices:\n",
    "#             print('{0} | {0}/{1} = {2} | {3} | {4}'.format(i, num_X_triphs, i/num_X_triphs, x012, stamp()))\n",
    "\n",
    "#         triph_dist_norms[x012] = triph_channel_norm(x012)\n",
    "\n",
    "    def foo(x012):\n",
    "        return (x012, triph_channel_norm(x012))\n",
    "    \n",
    "    triph_dist_norms = dict(Parallel(n_jobs=-1, backend='multiprocessing', verbose=5)(delayed(foo)(x012) for x012 in X_triphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:17.801894Z",
     "start_time": "2019-02-20T17:52:17.395778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 | 456/45553 = 0.010010317651965842 | aʊ.ʒ.p | 09:52:17\n",
      "911 | 911/45553 = 0.01999868285294053 | t.d.f | 09:52:17\n",
      "1367 | 1367/45553 = 0.03000900050490637 | dʒ.aʊ.v | 09:52:17\n",
      "2278 | 2278/45553 = 0.0500076833578469 | ɑ.b.ə | 09:52:17\n",
      "4555 | 4555/45553 = 0.09999341426470265 | m.ʃ.u | 09:52:17\n",
      "9111 | 9111/45553 = 0.20000878098039646 | ɛ.tʃ.ʃ | 09:52:17\n",
      "13666 | 13666/45553 = 0.30000219524509913 | ⋊.f.z | 09:52:17\n",
      "18221 | 18221/45553 = 0.3999956095098018 | aʊ.oʊ.ʒ | 09:52:17\n",
      "22776 | 22776/45553 = 0.49998902377450444 | ɔɪ.g.aɪ | 09:52:17\n",
      "27332 | 27332/45553 = 0.6000043904901983 | æ.tʃ.aɪ | 09:52:17\n",
      "31887 | 31887/45553 = 0.6999978047549009 | ⋊.i.l | 09:52:17\n",
      "36442 | 36442/45553 = 0.7999912190196036 | ɚ.oʊ.ɪ | 09:52:17\n",
      "40998 | 40998/45553 = 0.9000065857352973 | l.tʃ.ɔɪ | 09:52:17\n",
      "43275 | 43275/45553 = 0.9499923166421531 | f.n.ɛ | 09:52:17\n",
      "43731 | 43731/45553 = 0.9600026342941189 | aɪ.g.ʒ | 09:52:17\n",
      "44186 | 44186/45553 = 0.9699909994950936 | ɛ.s.g | 09:52:17\n",
      "44642 | 44642/45553 = 0.9800013171470595 | ð.ə.s | 09:52:17\n",
      "45097 | 45097/45553 = 0.9899896823480342 | oʊ.z.ʃ | 09:52:17\n"
     ]
    }
   ],
   "source": [
    "triph_dist = dict()\n",
    "if pseudocount != 0:\n",
    "#     triph_dist = {x012:{y1:triph_dist_unnormalized(y1, x012)/triph_dist_norms(x012) for y1 in Ys if triph_channel_unnormalized(y1, x012) != 0.0} for x012 in X_triphs}\n",
    "    num_X_triphs = len(X_triphs)\n",
    "    benchmarkPercentages = [1,2,3,5,10,20,30,40,50,60,70,80,90,95,96,97,98,99,100]\n",
    "    benchmarkIndices = [round(each/100.0 * num_X_triphs) for each in benchmarkPercentages]\n",
    "    for i, x012 in enumerate(X_triphs):\n",
    "        if i in benchmarkIndices:\n",
    "            print('{0} | {0}/{1} = {2} | {3} | {4}'.format(i, num_X_triphs, i/num_X_triphs, x012, stamp()))\n",
    "\n",
    "        triph_dist[x012] = {y1:triph_dist_unnormalized[x012][y1]/triph_dist_norms[x012] for y1 in Ys if triph_dist_unnormalized[x012][y1] != 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and export/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:17.833714Z",
     "start_time": "2019-02-20T17:52:17.803226Z"
    }
   },
   "outputs": [],
   "source": [
    "if pseudocount != 0:\n",
    "    if not areNormalized(triph_dist):\n",
    "        triph_dist = condProbDistAsDicts(condDistsAsProbDists(triph_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:17.998341Z",
     "start_time": "2019-02-20T17:52:17.834685Z"
    }
   },
   "outputs": [],
   "source": [
    "if pseudocount != 0:\n",
    "    assert areNormalized(triph_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:18.042697Z",
     "start_time": "2019-02-20T17:52:17.999444Z"
    }
   },
   "outputs": [],
   "source": [
    "triphone_fn = which + ' pY1X0X1X2' + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:23.868085Z",
     "start_time": "2019-02-20T17:52:18.043639Z"
    }
   },
   "outputs": [],
   "source": [
    "if pseudocount != 0:\n",
    "    exportProbDist(triphone_fn, triph_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:24.042459Z",
     "start_time": "2019-02-20T17:52:23.869140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hammond-aligned_destressed_pseudocount0.0011 pY1X0X1X2.json'\r\n",
      "'Hammond-aligned_destressed_pseudocount0.001 pY1X0X1X2.json'\r\n",
      "'Hammond-aligned_destressed_pseudocount0.005 pY1X0X1X2.json'\r\n",
      "'Hammond-aligned_destressed_pseudocount0.01 pY1X0X1X2.json'\r\n"
     ]
    }
   ],
   "source": [
    "%ls *pY1X0X1X2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:24.923108Z",
     "start_time": "2019-02-20T17:52:24.047709Z"
    }
   },
   "outputs": [],
   "source": [
    "if pseudocount != 0:\n",
    "    triph_dist_in = importProbDist(triphone_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T17:52:24.985908Z",
     "start_time": "2019-02-20T17:52:24.924046Z"
    }
   },
   "outputs": [],
   "source": [
    "if pseudocount != 0:\n",
    "    assert areNormalized(triph_dist_in)\n",
    "    assert triph_dist_in == triph_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "459px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
