{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T09:25:29.181008Z",
     "start_time": "2019-05-20T09:25:29.177298Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview-and-requirements\" data-toc-modified-id=\"Overview-and-requirements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview and requirements</a></span><ul class=\"toc-item\"><li><span><a href=\"#Usage\" data-toc-modified-id=\"Usage-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Usage</a></span><ul class=\"toc-item\"><li><span><a href=\"#Papermill---command-line\" data-toc-modified-id=\"Papermill---command-line-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Papermill - command line</a></span></li><li><span><a href=\"#Old-School\" data-toc-modified-id=\"Old-School-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Old School</a></span></li></ul></li></ul></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Filter-the-lexicon\" data-toc-modified-id=\"Filter-the-lexicon-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Filter the lexicon</a></span></li><li><span><a href=\"#Export-the-lexicon\" data-toc-modified-id=\"Export-the-lexicon-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Export the lexicon</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to take \n",
    " - a transcribed lexicon relation `.tsv`\n",
    " - a triphone channel distribution `.json` file \n",
    " \n",
    "and produce \n",
    " - a new version of the transcribed lexicon relation that only contains entries that can be aligned with the triphone channel distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papermill - command line\n",
    "\n",
    "This notebook is intended to be used with the [`papermill`](https://papermill.readthedocs.io/en/latest/) package.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```\n",
    "papermill \"Filter transcription lexicon by channel model.ipynb\" \"Filter LTR_Buckeye against channel model.ipynb\" -p l \"LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_w_GD_AmE-diphones.tsv\" -p c \"CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/pY1X0X1X2.json\" -p o \"LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered.tsv\"\n",
    "```\n",
    "will \n",
    " - create a new notebook `Filter LTR_Buckeye against channel model.ipynb`\n",
    "\n",
    "...and output `LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have or want to use this notebook as intended, edit the filenames/paths in the cell below with the top comment `# parameters`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:49:33.527650Z",
     "start_time": "2019-05-20T10:49:33.524562Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import getcwd, chdir, listdir, path, mkdir, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:22:03.433232Z",
     "start_time": "2019-05-20T10:22:03.430162Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# l = ''\n",
    "l = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_w_GD_AmE-diphones.tsv'\n",
    " \n",
    "# c = ''\n",
    "c = 'CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/pY1X0X1X2.json'\n",
    "\n",
    "# o = ''\n",
    "o = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:49:18.340866Z",
     "start_time": "2019-05-20T10:49:16.587149Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T11:13:36.152629Z",
     "start_time": "2019-05-20T11:13:35.083373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('Orthographic_Wordform', 'i'), ('Transcription', 'aɪ')]),\n",
       " OrderedDict([('Orthographic_Wordform', 'uh'), ('Transcription', 'ʌ')]),\n",
       " OrderedDict([('Orthographic_Wordform', 'grew'), ('Transcription', 'g.ɹ.u')]),\n",
       " OrderedDict([('Orthographic_Wordform', 'up'), ('Transcription', 'ʌ.p')]),\n",
       " OrderedDict([('Orthographic_Wordform', 'in'), ('Transcription', 'ɪ.n')])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_rows_in = []\n",
    "\n",
    "with open(l) as csvfile:\n",
    "    my_reader = csv.DictReader(csvfile, delimiter='\\t', quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "    for row in my_reader:\n",
    "        #print(row)\n",
    "        lexicon_rows_in.append(row)\n",
    "lexicon_rows_in[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:56:04.946574Z",
     "start_time": "2019-05-20T10:56:04.943936Z"
    }
   },
   "outputs": [],
   "source": [
    "from probdist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:56:06.697658Z",
     "start_time": "2019-05-20T10:56:05.602375Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_model = importProbDist(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T10:56:35.963797Z",
     "start_time": "2019-05-20T10:56:35.948387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46860"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(channel_model)\n",
    "stimuli_triphones = set(channel_model.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T16:33:28.583223Z",
     "start_time": "2019-05-20T16:33:28.577423Z"
    }
   },
   "outputs": [],
   "source": [
    "def padInputSequenceWithBoundaries(inputSeq):\n",
    "    temp = list(dottedStringToTuple(inputSeq))\n",
    "    temp = tuple([leftEdge] + temp + [rightEdge])\n",
    "    return tupleToDottedString(temp)\n",
    "\n",
    "def trimBoundariesFromSequence(seq):\n",
    "    temp = list(dottedStringToTuple(seq))\n",
    "    if temp[0] == leftEdge:\n",
    "        temp = temp[1:]\n",
    "    if temp[-1] == rightEdge:\n",
    "        temp = temp[:-1]\n",
    "    return tupleToDottedString(tuple(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T16:33:45.109088Z",
     "start_time": "2019-05-20T16:33:45.105570Z"
    }
   },
   "outputs": [],
   "source": [
    "def rowToTriphones(row):\n",
    "    three_factors = dsTo3factors(padInputSequenceWithBoundaries(row['Transcription']))\n",
    "    return three_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T16:33:46.745046Z",
     "start_time": "2019-05-20T16:33:46.740218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'⋊.aɪ.⋉'},\n",
       " {'⋊.ʌ.⋉'},\n",
       " {'g.ɹ.u', 'ɹ.u.⋉', '⋊.g.ɹ'},\n",
       " {'ʌ.p.⋉', '⋊.ʌ.p'},\n",
       " {'ɪ.n.⋉', '⋊.ɪ.n'},\n",
       " {'ɪ.z.⋉', '⋊.ɪ.z'},\n",
       " {'ð.ɪ.s', 'ɪ.s.⋉', '⋊.ð.ɪ'},\n",
       " {'ɪ.z.⋉', '⋊.ɪ.z'},\n",
       " {'ð.ɪ.s', 'ɪ.s.⋉', '⋊.ð.ɪ'},\n",
       " {'b.ɪ.k', 'k.ʌ.z', 'ɪ.k.ʌ', 'ʌ.z.⋉', '⋊.b.ɪ'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(rowToTriphones, lexicon_rows_in[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T11:25:47.191114Z",
     "start_time": "2019-05-20T11:25:47.187384Z"
    }
   },
   "outputs": [],
   "source": [
    "def modelableEntry(row):\n",
    "    three_factors = rowToTriphones(row)\n",
    "    return all([factor in stimuli_triphones for factor in three_factors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T16:35:50.100649Z",
     "start_time": "2019-05-20T16:35:48.715027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Lexicon in| = 216062\n",
      "|Lexicon out| = 205173|\n",
      "|words| removed = 10889\n",
      "% words removed = 5.039757106756395\n"
     ]
    }
   ],
   "source": [
    "lexicon_out = list(filter(modelableEntry,\n",
    "                          lexicon_rows_in))\n",
    "\n",
    "print('|Lexicon in| = {0}'.format(len(lexicon_rows_in)))\n",
    "print('|Lexicon out| = {0}|'.format(len(lexicon_out)))\n",
    "print('|words| removed = {0}'.format(len(lexicon_rows_in) - len(lexicon_out)))\n",
    "print('% words removed = {0}'.format((len(lexicon_rows_in) - len(lexicon_out)) / len(lexicon_rows_in) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(o, 'w', newline='\\n') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=['Orthographic_Wordform', 'Transcription'], delimiter='\\t', quoting=csv.QUOTE_NONE, quotechar='@')\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(lexicon_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
