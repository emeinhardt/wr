{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:43:56.473620Z",
     "start_time": "2018-03-31T23:43:56.462566Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation/Problem-Statement\" data-toc-modified-id=\"Motivation/Problem-Statement-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation/Problem Statement</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-requirements\" data-toc-modified-id=\"Code-requirements-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Code requirements</a></span></li><li><span><a href=\"#Exposition-/-other-notebooks\" data-toc-modified-id=\"Exposition-/-other-notebooks-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exposition / other notebooks</a></span></li></ul></li><li><span><a href=\"#Boilerplate-code-for-representing-and-manipulating-probability-distributions\" data-toc-modified-id=\"Boilerplate-code-for-representing-and-manipulating-probability-distributions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Boilerplate code for representing and manipulating probability distributions</a></span></li><li><span><a href=\"#Boilerplate-code-for-generating-model-code-given-model-inputs\" data-toc-modified-id=\"Boilerplate-code-for-generating-model-code-given-model-inputs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Boilerplate code for generating model code given model inputs</a></span></li><li><span><a href=\"#Getting-data\" data-toc-modified-id=\"Getting-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Getting data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Converting-data-to-the-required-probability-distributions\" data-toc-modified-id=\"Converting-data-to-the-required-probability-distributions-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Converting data to the required probability distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Explorations-/-asides-/-sanity-checks\" data-toc-modified-id=\"Explorations-/-asides-/-sanity-checks-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Explorations / asides / sanity checks</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Testing</a></span></li></ul></li></ul></li><li><span><a href=\"#Generating-a-model\" data-toc-modified-id=\"Generating-a-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Generating a model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Testing-the-model\" data-toc-modified-id=\"Testing-the-model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Testing the model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation/Problem Statement\n",
    "\n",
    "The goal of this collection of notebooks ('Model Notebook k', $k \\in \\{0, 1, 2, 3\\}$) is to document/develop code for calculations related to an isolated word recognition task where:\n",
    "\n",
    " - A *lexicon* $\\mathcal{L}$ is a set of **wordforms**  $w$, where a **wordform** is a finite sequence $s_0, s_1, s_2 ... s_f$ of segments, and $s_0^i$ denotes the prefix of some wordform $w \\in \\mathcal{L}$ such that $f = |w| - 1$ and such that $w$ begins with segments $s_0, s_1, ..., s_i$, where $0 \\leq i \\leq f$.\n",
    " - In a single episode of the task, a **speaker** samples a wordform $w = s_0^f$ from $\\mathcal{L} \\sim p(s_0^f)$.\n",
    " - The speaker incrementally produces their intended wordform (one segment at a time, for our purposes) and the **listener** incrementally perceives $\\sigma_0^i \\sim p(\\sigma_0^i | s_0^i)$.\n",
    " - The listener considers what they have perceived so far $\\sigma_0^i$ and reasons about what the most likely actual intended wordform of the speaker is $\\sim p(\\hat{s_0^f}|\\sigma_0^i) \\propto p(\\sigma_0^i|s_0^f) p(s_0^f) = p(\\sigma_0^i|s_0^i) p(s_0^i)$.\n",
    "\n",
    "\n",
    "In particular, we want, for each possible intended wordform $s_0^f \\in \\mathcal{L}$, for each possible prefix $s_0^i$ of $s_0^f$, the listener's expected distribution over the speaker's intended wordform given the actual prefix produced so far $s_0^i$, where the expectation is taken with respect to possible perceived sequences $\\sigma_0^i$: \n",
    "\n",
    "$$p(\\hat{s_0^f}|s_0^i) = \\sum_\\limits{\\sigma_0^i} p(s_0^f|\\sigma_0^i)p(\\sigma_0^i|s_0^i) \\propto \\sum_\\limits{\\sigma_0^i} p(\\sigma_0^i|\\hat{s_0^f})p(\\hat{s_0^f})p(\\sigma_0^i|s_0^i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code requirements\n",
    "\n",
    "The code for calculating \n",
    "$$p(\\hat{s_0^f}|s_0^i) = \\sum_\\limits{\\sigma_0^i} p(s_0^f|\\sigma_0^i)p(\\sigma_0^i|s_0^i) \\propto \\sum_\\limits{\\sigma_0^i} p(\\sigma_0^i|\\hat{s_0^f})p(\\hat{s_0^f})p(\\sigma_0^i|s_0^i)$$\n",
    "needs to take only two basic inputs:\n",
    "\n",
    " - a prior distribution over the lexicon $p(s_0^f) = p(\\hat{s_0^f})$.\n",
    " - an incrementally defined channel distribution $p(\\sigma_0^i|s_0^i) = p(\\sigma_0^i|\\hat{s_0^i})$, defined (for now) in terms of a uniphone channel distribution $p(\\sigma_i|s_i)$, where the distribution over what segment the listener perceives as the $i$th one depends (by assumption) *only* on the actual $i$th segment $s_i$ the speaker produced (if they've actually produced it at the time we're asking about).\n",
    "\n",
    "from which it needs to generate all relevant code and representations of probability distributions or means of estimating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposition / other notebooks\n",
    "\n",
    "*Notebook 0* introduces the model being developed and implemented, the organization of other notebooks in the collection, and introduces the adapted form of Peter Norvig's code for conveniently representing and manipulating probability distributions that I make use of in other notebooks.\n",
    "\n",
    "*Notebook 1* introduces the final model implementation and the derivations underlying its implementation and does so using randomly generated but highly constrained binary lexicons with a simple noise model. It is intended to introduce the model implementation/derivation in a context where the behavior and purpose (and basic correctness) of code is discernable by going through the notebook and the generated example.\n",
    "\n",
    "*Notebook 2* is more for testing purposes. It contains multiple implementations of the model. One is defined entirely in terms of the abstractions Peter Norvig provides -- abstractions that cannot scale but which were easy to use and whose correctness I have high confidence in. The second implementation is the one presented in notebooks 1 and 3. \n",
    "\n",
    "*This notebook*, *Notebook 3* is a demonstration notebook where real data is loaded and basic queries are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate code for representing and manipulating probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:19.791735Z",
     "start_time": "2018-03-31T23:44:19.443517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#from \n",
    "#    http://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb\n",
    "#    http://nbviewer.jupyter.org/url/norvig.com/ipython/ProbabilityParadox.ipynb\n",
    "#with slight modification.\n",
    "\n",
    "from fractions import Fraction\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def P(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "    \n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...};\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...};\n",
    "    in both cases only with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}\n",
    "\n",
    "# class ProbDist(dict):\n",
    "class ProbDist(Counter):\n",
    "    \"A Probability Distribution; an {outcome: probability} mapping where probabilities sum to 1.\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        total = sum(self.values())\n",
    "        if isinstance(total, int): \n",
    "            total = Fraction(total, 1)\n",
    "        for key in self: # Make probabilities sum to 1.\n",
    "            self[key] = self[key] / total\n",
    "            \n",
    "    def __and__(self, predicate): # Call this method by writing `probdist & predicate`\n",
    "        \"A new ProbDist, restricted to the outcomes of this ProbDist for which the predicate is true.\"\n",
    "        return ProbDist({e:self[e] for e in self if predicate(e)})\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for k in self:\n",
    "            if isinstance(self[k], Fraction):\n",
    "                s+=\"{0}: {2}/{3} = {1}\\n\".format(transcriptionReprHack(k), float(self[k]), self[k].numerator, self[k].denominator)\n",
    "            else:\n",
    "                s+=\"{0}: {1}\\n\".format(transcriptionReprHack(k), float(self[k]))\n",
    "        return s\n",
    "\n",
    "dottedStringToTuple = lambda ds: tuple(ds.split('.'))\n",
    "tupleToDottedString = lambda t: '.'.join(t)\n",
    "\n",
    "def transcriptionReprHack(k):\n",
    "    if type(k) == type(tuple()):\n",
    "        if all(map(lambda el: type(el) == type(''), k)):\n",
    "            return tupleToDottedString(k)\n",
    "    return k.__repr__()    \n",
    "\n",
    "def Uniform(outcomes): return ProbDist({e: 1 for e in outcomes})\n",
    "\n",
    "def joint(A, B):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {(a, b): P(a) * P(b)}\"\"\"\n",
    "    return ProbDist({(a,b): A[a] * B[b]\n",
    "                    for a in A\n",
    "                    for b in B})\n",
    "\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "def union(iterable):\n",
    "    return reduce(set.union, iterable)\n",
    "\n",
    "def joint2(iter_of_dists):\n",
    "    #ProbDist({(a,b): A[a] * B[b] for a in A for b in B})\n",
    "    #ProbDist({ab: A[ab[0]] * B[ab[1]] for ab in product(A,B)})\n",
    "    return ProbDist({each : prod(dist[each[i]] for i,dist in enumerate(iter_of_dists)) for each in list(product(*iter_of_dists))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:20.344627Z",
     "start_time": "2018-03-31T23:44:20.101292Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bookkeeping - don't worry about this function...\n",
    "def getBoundaryVal(dist, i):\n",
    "    #p = {a:1/2, b:1/2} -> 2 items -> 2-1=1 boundaries where \n",
    "    #                   the boundary separating 'a' (item 0) from 'b' (item 1) is at 0+p(a)\n",
    "    #q = {0:1/3, 1:1/3, 2:1/6, 3:1/6} -> 4 items -> 4-1=3 boundaries where \n",
    "    #                   the boundary separating 0 from 1   is at 0 + q(0) = 1/3,\n",
    "    #                   the boundary separating 1 from 2   is at 0 + q(0) + q(1) = 2/3,\n",
    "    #                   the boundary separating 2 from 3   is at 0 + q(0) + q(1) + q(2) = 5/6,\n",
    "    #                ...the boundary separating i from i+1 is at \\sum_{j=0}^{j=i} q(j)\n",
    "    outcomes = list(dist.keys())\n",
    "    if i >= len(outcomes) - 1:\n",
    "        raise Exception(\"Boundary i = {0} out of bounds / does not exist for distribution {1} with {2} outcomes.\".format(i, dist, len(outcomes)))\n",
    "    if i == 0:\n",
    "        return dist[outcomes[0]]\n",
    "    return dist[outcomes[i]] + getBoundaryVal(dist, i-1)\n",
    "\n",
    "#bookkeeping - don't worry about this function...\n",
    "def getSampleOutcomeIndex(randReal, boundariesLeft, currIndex):\n",
    "#     print(\"boundariesLeft: {0}\".format(boundariesLeft))\n",
    "#     print(\"currIndex: {0}\".format(currIndex))\n",
    "    if boundariesLeft == [] or randReal <= boundariesLeft[0]:\n",
    "        return currIndex\n",
    "    return getSampleOutcomeIndex(randReal, boundariesLeft[1:], currIndex + 1)\n",
    "\n",
    "\n",
    "def sampleFrom(dist, num_samples = None):\n",
    "    \"\"\"\n",
    "    Given a distribution (either an {outcome: probability} mapping where the \n",
    "    probabilities sum to 1 or an implicit definition of a distribution via a thunk), \n",
    "    this returns a single sample from the distribution, unless num_samples is specified, \n",
    "    in which case a generator with num_samples samples is returned.\n",
    "    \"\"\"\n",
    "    if num_samples == None:\n",
    "        if callable(dist):\n",
    "            return dist()\n",
    "        elif isinstance(dist, ProbDist):\n",
    "            outcomes = list(dist.keys())\n",
    "        #     print(\"outcomes: {0}\".format(outcomes))\n",
    "\n",
    "            boundaries = [getBoundaryVal(dist, i) for i in range(len(outcomes)-1)]\n",
    "        #     print(\"boundaries: {0}\".format(boundaries))\n",
    "\n",
    "            randVal = random.random() #random real from unit interval\n",
    "        #     print(\"randval: {0}\".format(randVal))\n",
    "\n",
    "            sampledOutcomeIndex = getSampleOutcomeIndex(randVal, boundaries, 0)\n",
    "        #     print(\"sampledOutcomeIndex: {0}\".format(sampledOutcomeIndex))\n",
    "            if not (sampledOutcomeIndex >= 0 and sampledOutcomeIndex < len(outcomes)):\n",
    "                print('sampledOutcomeIndex: {0}'.format(sampledOutcomeIndex))\n",
    "                print('len(outcomes): {0}'.format(len(outcomes)))\n",
    "                if len(outcomes) == 0:\n",
    "                    print('len(outcomes) == 0! dist:')\n",
    "                    print(type(dist))\n",
    "                    print(dist)\n",
    "            assert(sampledOutcomeIndex >= 0 and sampledOutcomeIndex < len(outcomes))\n",
    "\n",
    "            sampledOutcome = outcomes[sampledOutcomeIndex]\n",
    "        #     print(\"sampledOutcome: {0}\".format(sampledOutcome))\n",
    "            return sampledOutcome\n",
    "    else:\n",
    "        if callable(dist):\n",
    "            return (dist() for each in range(num_samples))\n",
    "        elif isinstance(dist, ProbDist):\n",
    "            return (sampleFrom(dist, num_samples = None) for each in range(num_samples))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def frequencies(samples):\n",
    "    return Counter(samples)\n",
    "\n",
    "def makeSampler(dist):\n",
    "    \"\"\"\n",
    "    Given a ProbDist, returns a thunk that when called, returns one sample from dist.\n",
    "    \"\"\"\n",
    "    return lambda: sampleFrom(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:21.173564Z",
     "start_time": "2018-03-31T23:44:21.168308Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftEdge = '‚ãä'\n",
    "rightEdge = '‚ãâ'\n",
    "edgeSymbols = set([leftEdge, rightEdge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate code for generating model code given model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:23.400520Z",
     "start_time": "2018-03-31T23:44:22.966690Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating functions and values derived from p(X_0^f)...\n",
    "\n",
    "import itertools\n",
    "\n",
    "def getPrefixes(s):\n",
    "    return set(s[0:i] for i in range(1, len(s)+1))\n",
    "\n",
    "def getHasPrefix(prefix):\n",
    "    l = len(prefix)\n",
    "    hasAsPrefix = lambda full_input_seq: full_input_seq[0:l] == prefix\n",
    "    return hasAsPrefix\n",
    "  \n",
    "def getHasSuffix(suffix):\n",
    "    l = len(suffix)\n",
    "    hasAsSuffix = lambda full_input_seq: full_input_seq[-len(suffix):] == suffix\n",
    "    return hasAsSuffix\n",
    "\n",
    "def padInputSequenceWithBoundaries(inputSeq):\n",
    "    temp = list(inputSeq)\n",
    "    temp = tuple([leftEdge] + temp + [rightEdge])\n",
    "    return temp\n",
    "\n",
    "def trimBoundariesFromSequence(seq):\n",
    "    temp = list(seq)\n",
    "    if temp[0] == leftEdge:\n",
    "        temp = temp[1:]\n",
    "    if temp[-1] == rightEdge:\n",
    "        temp = temp[:-1]\n",
    "    return tuple(temp)\n",
    "\n",
    "def generateInputModel(inputDist, pad_with_boundaries = None):\n",
    "    if pad_with_boundaries == None:\n",
    "        pad_with_boundaries = False\n",
    "    model = {} #FIXME consider changing to a namedtuple/frozendict (possibly just before returning a value)\n",
    "    \n",
    "    if pad_with_boundaries:\n",
    "        old_map = list(inputDist.items())\n",
    "        old_inputs = list(map(lambda p: p[0], old_map))\n",
    "#         old_inputs = list(inputDist.keys())\n",
    "        old_values = [v for k,v in old_map]\n",
    "        new_inputs = list(map(padInputSequenceWithBoundaries, old_inputs))\n",
    "        assert(list(map(trimBoundariesFromSequence, new_inputs)) == old_inputs)\n",
    "        assert(list(zip(old_inputs, old_values)) == old_map)\n",
    "        new_map = dict(list(zip(new_inputs, old_values)))\n",
    "        inputDist = new_map\n",
    "    \n",
    "    model['inputDist'] = inputDist\n",
    "    model['p(X_0^f)'] = inputDist\n",
    "    \n",
    "    inputs = list(inputDist.keys())\n",
    "    model['inputs'] = inputs\n",
    "    \n",
    "    \n",
    "    inputAlphabet = set(itertools.chain.from_iterable([set(k) for k in inputs ]))\n",
    "#   print(inputAlphabet)\n",
    "#     if pad_with_boundaries and (leftEdge not in inputAlphabet):\n",
    "#         inputAlphabet += [leftEdge]\n",
    "#     if pad_with_boundaries and (rightEdge not in inputAlphabet):\n",
    "#         inputAlphabet += [rightEdge]\n",
    "    model['inputAlphabet'] = inputAlphabet\n",
    "    \n",
    "\n",
    "    prefixes = map(getPrefixes, inputs)\n",
    "    prefixes = set(itertools.chain.from_iterable(prefixes))\n",
    "#   print(\"<= 10 prefixes of lexicon:\")\n",
    "#   print(list(prefixes)[0:11])\n",
    "    model['prefixes'] = prefixes\n",
    "  \n",
    "    \n",
    "    # convenient calculation of p(x_0^i) as pmf, not as 'dist'\n",
    "    def prefixProb(input_prefix):\n",
    "        hasAsPrefix = getHasPrefix(input_prefix)\n",
    "        return P(hasAsPrefix, inputDist)\n",
    "    model['prefixProb'] = prefixProb\n",
    "    model['p(x_0^i)'] = prefixProb\n",
    "    \n",
    "    \n",
    "    # definition of p(X_0^f | x_0^i) as dist\n",
    "    def inputDist_givenPrefix(prefix):\n",
    "        hasPrefix = getHasPrefix(prefix)\n",
    "        return inputDist & hasPrefix\n",
    "    model['inputDist_givenPrefix'] = inputDist_givenPrefix\n",
    "    model['p(X_0^f | x_0^i)'] = inputDist_givenPrefix\n",
    "    \n",
    "    \n",
    "    # definition of p(x_{i+1}^f | x_0^i) as pmf, not as 'dist'\n",
    "    def suffixProb(input_suffix, input_prefix):\n",
    "        #p(X_0^f | x_0^i)\n",
    "        d = inputDist_givenPrefix(input_prefix)\n",
    "        isExactlyEqualTo = lambda s: s == tuple(list(input_prefix) + list(input_suffix))\n",
    "        return P(isExactlyEqualTo, d)\n",
    "    model['suffixProb'] = suffixProb\n",
    "    model['p(x_{i+1}^f | x_0^i)'] = suffixProb\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:29.151702Z",
     "start_time": "2018-03-31T23:44:28.803386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating functions and values derived from p(Y_i|x_i)...\n",
    "\n",
    "\n",
    "def generateChannelModel(channelOutput_i_dist, inputModel, pad_with_boundaries = None):\n",
    "    if pad_with_boundaries == None:\n",
    "        pad_with_boundaries = False\n",
    "    \n",
    "    model = {} #FIXME consider changing to a namedtuple/frozendict (possibly just before returning a value)\n",
    "    \n",
    "    model['channelOutput_i_dist'] = channelOutput_i_dist\n",
    "    model['p(Y_i|x_i)'] = channelOutput_i_dist\n",
    "    \n",
    "    \n",
    "    # definition of p(Y_i) as a dist\n",
    "    sourceInputAlphabet = inputModel['inputAlphabet']\n",
    "    \n",
    "    \n",
    "    getKeys = lambda d: set(d.keys()) #assumes they're hashable\n",
    "#     getVals = lambda d: set(d.values()) #assumes they're hashable\n",
    "    channelInputAlphabet = getKeys(channelOutput_i_dist)\n",
    "    \n",
    "    getOutputSymbols = lambda cond_channel_dist: getKeys(cond_channel_dist)\n",
    "    outputSymbolsByInput = map(lambda eachInputSymbol: getOutputSymbols(channelOutput_i_dist[eachInputSymbol]), channelOutput_i_dist)\n",
    "    channelOutputAlphabet = reduce(set.union, outputSymbolsByInput)\n",
    "    \n",
    "    totalAlphabet = reduce(set.union, [channelOutputAlphabet, channelInputAlphabet, sourceInputAlphabet])\n",
    "    \n",
    "    \n",
    "#     channelOutput_i_marginal_dist = ProbDist({y: sum(channelOutput_i_dist(x)[y] for x in inputAlphabet) for y in inputAlphabet})\n",
    "    channelOutput_i_marginal_dist = ProbDist({y: sum(channelOutput_i_dist[x].get(y, 0.0) for x in channelInputAlphabet) for y in channelOutputAlphabet})\n",
    "    model['channelOutput_i_marginal_dist'] = channelOutput_i_marginal_dist\n",
    "    model['p(Y_i)'] = channelOutput_i_marginal_dist\n",
    "    \n",
    "    \n",
    "    # definition of p(y_0^j|x_0^i) as a pmf but not as a 'dist', assuming uniphone noise/channel model\n",
    "    prefixes = inputModel['prefixes']\n",
    "    def channelOutput_prefix_prob(inputPrefix, outputPrefix):\n",
    "        if len(outputPrefix) == len(inputPrefix):\n",
    "        #         |y_0^j|    ==      |x_0^i|\n",
    "#             slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist(x_i))\n",
    "            slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist[x_i])\n",
    "            return prod(slice_prob(y, x) for y,x in zip(outputPrefix, inputPrefix))\n",
    "        elif len(outputPrefix) < len(inputPrefix): #truncate excess part of inputPrefix\n",
    "                  #|y_0^j|     <      |x_0^i|\n",
    "            return channelOutput_prefix_prob(inputPrefix[:len(outputPrefix)], outputPrefix)\n",
    "        else:\n",
    "                  #|y_0^j|     >      |x_0^i|\n",
    "            hasInputPrefixAsPrefix = getHasPrefix(inputPrefix)\n",
    "            my_prefixes = (pref for pref in prefixes if len(pref) == len(outputPrefix) and hasInputPrefixAsPrefix(pref))\n",
    "            #         p(y_0^j|x_0^j)                                 p(x_0^j)          1   / p(x_0^i)\n",
    "            terms = ((channelOutput_prefix_prob(pref, outputPrefix), inputModel['prefixProb'](pref), 0.0 if inputModel['prefixProb'](inputPrefix) == 0.0 else 1.0 / inputModel['prefixProb'](inputPrefix) ) for pref in my_prefixes)\n",
    "            return sum(map(prod, terms))\n",
    "    model['p(y_0^j|x_0^i)'] = channelOutput_prefix_prob\n",
    "    model['channelOutput_prefix_prob'] = channelOutput_prefix_prob\n",
    "\n",
    "\n",
    "    # definition of sampler from p(Y_0^i|x_0^i), assuming uniphone noise/channel model\n",
    "    def channelOutput_prefix_sampler(inputPrefix):\n",
    "#         return tuple([sampleFrom(channelOutput_i_dist(x_i)) for x_i in inputPrefix])\n",
    "        return tuple([sampleFrom(channelOutput_i_dist[x_i]) for x_i in inputPrefix])\n",
    "    model['sample from p(Y_0^i|x_0^i)'] = channelOutput_prefix_sampler\n",
    "    model['channelOutput_prefix_sampler'] = channelOutput_prefix_sampler\n",
    "\n",
    "    \n",
    "    # calculation of p(y_0^i) as a pmf but not as a 'dist'\n",
    "    #   marginalizes over all prefixes of input sequences with length matching y_0^i \n",
    "    def channelOutput_prefix_marginal_prob(outputPrefix):\n",
    "\n",
    "        l = len(outputPrefix)\n",
    "        my_prefixes = (prefix for prefix in prefixes if len(prefix) == l)\n",
    "\n",
    "        #\\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i)\n",
    "        terms = ((inputModel['prefixProb'](input_prefix), channelOutput_prefix_prob(input_prefix, outputPrefix)) for input_prefix in my_prefixes)\n",
    "        probs = map(prod, terms)\n",
    "    #     probs = (prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes)\n",
    "    #     probs = [prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes] #only for testing; use generator exp otherwise\n",
    "    #     print('terms of \\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i):')\n",
    "    #     print(probs)\n",
    "        return sum(probs)\n",
    "    model['p(y_0^i)'] = channelOutput_prefix_marginal_prob\n",
    "    model['channelOutput_prefix_marginal_prob'] = channelOutput_prefix_marginal_prob\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:40.507601Z",
     "start_time": "2018-03-31T23:44:40.332836Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "#Hoeffding's inequality w.r.t. mc estimate p-hat(x-hat_0^j|x_0^i):\n",
    "# Let  X = p-hat(x-hat_0^j|x_0^i)\n",
    "#      ùõç = p(x-hat_0^j|x_0^i)\n",
    "#      n = the number of samples that go into calculating X\n",
    "# then\n",
    "#      p(|X - ùõç| > ùõÜ) ‚â§ exp(2nùõÜ¬≤)\n",
    "#\n",
    "#  E.g. for n = 1000, ùõÜ = 0.01\n",
    "#      p(|X - ùõç| > ùõÜ) ‚â§ ‚âà0.82\n",
    "#\n",
    "#       for n = 1000, ùõÜ = 0.03\n",
    "#     p(|X - ùõç| > ùõÜ) ‚â§ ‚âà0.165\n",
    "#\n",
    "#       for n = 1000, ùõÜ = 0.05\n",
    "#     p(|X - ùõç| > ùõÜ) ‚â§ ‚âà0.0068\n",
    "#\n",
    "#       for n = 1000, ùõÜ = 0.1\n",
    "#     p(|X - ùõç| > ùõÜ) ‚â§ ‚âà2.06*10^-9\n",
    "def hoeffdingProb(epsilon, num_samples):\n",
    "    upperBound = exp(-2.0 * num_samples * epsilon * epsilon)\n",
    "    return upperBound\n",
    "\n",
    "def generateTotalModel(inputDist, channelOutput_i_dist, pad_with_boundaries = None):\n",
    "    if pad_with_boundaries == None:\n",
    "        pad_with_boundaries = False\n",
    "    \n",
    "    inputModel = generateInputModel(inputDist, pad_with_boundaries = pad_with_boundaries)\n",
    "    channelModel = generateChannelModel(channelOutput_i_dist, inputModel, pad_with_boundaries = pad_with_boundaries)\n",
    "    model = {**inputModel, **channelModel} #FIXME consider changing to a namedtuple/frozendict (possibly just before returning a value)\n",
    "\n",
    "    # receiver/listener model\n",
    "    #  = mc estimate of p(x-hat_0^j|x_0^i) as pmf, not as 'dist', assuming uniphone error probs\n",
    "    #                         x_0^i             x-hat_0^j\n",
    "    def est_channelInput_prob(true_inputPrefix, poss_inputPrefix, num_samples = None):\n",
    "        if num_samples == None:\n",
    "            num_samples = 1000\n",
    "\n",
    "    #     print('true x_0^i: {0}'.format(true_inputPrefix))\n",
    "    #     print('x-hat_0^j: {0}'.format(poss_inputPrefix))\n",
    "    #     print('num samples: {0}'.format(num_samples))\n",
    "\n",
    "        lenTruePrefix = len(true_inputPrefix) #|x_0^i|\n",
    "        lenPossPrefix = len(poss_inputPrefix) #|x-hat_0^j|\n",
    "\n",
    "        #if |x-hat_0^j|  < |x_0^i|, then calculate \\sum_\\limits{x-hat_0^i | x-hat_0^j is a prefix} p(x-hat_0^i|x_0^i)\n",
    "        if lenPossPrefix < lenTruePrefix:\n",
    "            hasPossPrefixAsPrefix = getHasPrefix(poss_inputPrefix)\n",
    "            my_prefixes = (pref for pref in model['prefixes'] if len(pref) == lenTruePrefix and hasPossPrefixAsPrefix(pref))\n",
    "            probs = (est_channelInput_prob(true_inputPrefix, pref) for pref in my_prefixes)\n",
    "            return sum(probs)\n",
    "\n",
    "        #if |x-hat_0^j| ‚â• |x_0^i|, then proceed 'normally'...\n",
    "\n",
    "        #samples from p(Y_0^i|x_0^i)\n",
    "        samples = sampleFrom(lambda: model['channelOutput_prefix_sampler'](true_inputPrefix), num_samples)\n",
    "    #     samples = list(sampleFrom(lambda: channelOutput_prefix_sampler(true_inputPrefix), num_samples)) # only for debugging - otherwise use generator exp\n",
    "    #     print('samples from p(Y_0^i|x_0^i):')\n",
    "    #     print(samples)\n",
    "    #     likelihoods = [channelOutput_prefix_prob(poss_inputPrefix, outputPrefix) for outputPrefix in samples]\n",
    "    #     print('likelihoods p(y_0^i|x-hat_0^i):')\n",
    "    #     print(likelihoods)\n",
    "    #     priorOfOutputs = [channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples]\n",
    "    #     print('priorOfOutputs p(y_0^i):')\n",
    "    #     print(priorOfOutputs)\n",
    "\n",
    "        #p(x-hat_0^j)\n",
    "        poss_inputPrefix_prob = model['prefixProb'](poss_inputPrefix)\n",
    "    #     print('p(x-hat_0^j) = {0}'.format( poss_inputPrefix_prob ))\n",
    "\n",
    "        #terms in \\sum_{samples y_0^i from p(Y_0^i|x_0^i)} p(y_0^i|x-hat_0^i) * p(x-hat_0^j) / p(y_0^i)\n",
    "#         terms = (model['channelOutput_prefix_prob'](poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / model['channelOutput_prefix_marginal_prob'](outputPrefix) for outputPrefix in samples)\n",
    "        terms = ((model['channelOutput_prefix_prob'](poss_inputPrefix, outputPrefix), 0.0 if model['channelOutput_prefix_marginal_prob'](outputPrefix) == 0.0 else poss_inputPrefix_prob / model['channelOutput_prefix_marginal_prob'](outputPrefix) ) for outputPrefix in samples)\n",
    "    #     for outputPrefix in samples:\n",
    "    #       print('y_0^i: {0}'.format(outputPrefix))\n",
    "    #       print('term: {0} * {1} / {2}'.format(channelOutput_prefix_prob(poss_inputPrefix, outputPrefix), poss_inputPrefix_prob, channelOutput_prefix_marginal_prob(outputPrefix)))\n",
    "    #     terms = [channelOutput_prefix_prob(poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / channelOutput_prefix_marginal_prob(outputPrefix) for outputPrefix in samples] #use only for debugging, otherwise use generator exp\n",
    "    #     print('terms in sum:')\n",
    "    #     print(terms)\n",
    "#         est = sum(terms) / num_samples\n",
    "        est = sum(map(prod,terms)) / num_samples\n",
    "\n",
    "        return est\n",
    "    model['p-hat(x-hat_0^j|x_0^i)'] = est_channelInput_prob\n",
    "    model['est_channelInput_prob'] = est_channelInput_prob\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:41.569801Z",
     "start_time": "2018-03-31T23:44:41.545410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ericmeinhardt/Google Drive/Ideas/HH/recoverability/c2-jn'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:42.892452Z",
     "start_time": "2018-03-31T23:44:42.719558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPhOD-aligned gate-3 diphone channel distribution.json\r\n",
      "IPhOD-aligned gate-6 diphone channel distribution.json\r\n",
      "IPhOD-aligned gate3 uniphone channel distribution.json\r\n",
      "IPhOD-aligned gate6 uniphone channel distribution.json\r\n",
      "IPhOD-aligned response diphones.txt\r\n",
      "IPhOD-aligned stimuli diphones.txt\r\n",
      "IPhOD-aligned stimuli uniphones.txt\r\n",
      "IPhOD-aligned trials just-gate3.csv\r\n",
      "IPhOD-aligned trials just-gate6.csv\r\n",
      "IPhOD-aligned uniphone channel distribution.json\r\n",
      "IPhOD2_Words_IPA_prob_caughtCotMerged_schwa_phonWordToProb.json\r\n",
      "IPhOD_aligned_trials.csv\r\n",
      "IPhOD_noStress_lowercase_IPA_ALLDUPES.json\r\n",
      "IPhOD_noStress_lowercase_IPA_noDupes_consolidated_UTFesc.json\r\n",
      "IPhOD_noStress_lowercase_IPA_noDupes_consolidated_noUTFesc.json\r\n",
      "IPhOD_processed.json\r\n",
      "IPhOD_processed_UTFesc.json\r\n",
      "IPhOD_processed_noUTFesc.json\r\n",
      "IPhODv2.0_REALS.zip\r\n",
      "illegal triphones from IPhOD-aligned response diphones.txt\r\n",
      "illegal triphones from IPhOD-aligned stimuli diphones.txt\r\n",
      "triphones from IPhOD-aligned response diphones.txt\r\n",
      "triphones from IPhOD-aligned stimuli diphones.txt\r\n",
      "\r\n",
      "IPhODv2.0_REALS:\r\n",
      "2009_Dec01_Release_Readme.txt\r\n",
      "CMU_pronunciation_key.pdf\r\n",
      "IPhOD2_Words.txt\r\n",
      "IPhOD2_Words_IPA.csv\r\n",
      "IPhOD2_Words_IPA_prob.csv\r\n",
      "IPhOD2_Words_IPA_prob_caughtCotMerged.csv\r\n",
      "IPhOD2_Words_IPA_prob_caughtCotMerged_schwa.csv\r\n",
      "IPhOD2_Words_IPA_prob_caughtCotMerged_schwa_phonWordToNlprob.json\r\n",
      "IPhOD2_Words_IPA_prob_caughtCotMerged_schwa_phonWordToProb.json\r\n",
      "gpl.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls *IPhOD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T22:49:59.783850Z",
     "start_time": "2018-03-31T22:49:59.652098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hammond's mysterious newdic.txt\r\n",
      "Hammond-aligned gate-3 diphone channel distribution.json\r\n",
      "Hammond-aligned gate-6 diphone channel distribution.json\r\n",
      "Hammond-aligned gate3 uniphone channel distribution.json\r\n",
      "Hammond-aligned gate6 uniphone channel distribution.json\r\n",
      "Hammond-aligned response diphones.txt\r\n",
      "Hammond-aligned stimuli diphones.txt\r\n",
      "Hammond-aligned stimuli uniphones.txt\r\n",
      "Hammond-aligned trials just-gate3.csv\r\n",
      "Hammond-aligned trials just-gate6.csv\r\n",
      "Hammond-aligned uniphone channel distribution.json\r\n",
      "Hammond_aligned_trials.csv\r\n",
      "Hammond_newdic_IPA.csv\r\n",
      "Hammond_newdic_IPA_aligned.csv\r\n",
      "Hammond_newdic_IPA_aligned_phonWordToNlprob.json\r\n",
      "Hammond_newdic_IPA_aligned_phonWordToProb.json\r\n"
     ]
    }
   ],
   "source": [
    "%ls Hammond*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:45.151621Z",
     "start_time": "2018-03-31T23:44:45.139328Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniphone_dist_fn_IPhOD = 'IPhOD-aligned uniphone channel distribution.json'\n",
    "uniphone_dist_fn_hammond = 'Hammond-aligned uniphone channel distribution.json'\n",
    "uniphone_dist_fn = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:45.774019Z",
     "start_time": "2018-03-31T23:44:45.766063Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexicon_dist_fn_IPhOD = 'IPhOD2_Words_IPA_prob_caughtCotMerged_schwa_phonWordToProb.json'\n",
    "lexicon_dist_fn_hammond = 'Hammond_newdic_IPA_aligned_phonWordToProb.json'\n",
    "lexicon_dist_fn = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:12.045780Z",
     "start_time": "2018-03-31T23:45:12.040120Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which = 'IPhOD'\n",
    "# which = 'hammond'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:20.050556Z",
     "start_time": "2018-03-31T23:45:20.043008Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if which == 'IPhOD':\n",
    "    uniphone_dist_fn = uniphone_dist_fn_IPhOD\n",
    "    lexicon_dist_fn = lexicon_dist_fn_IPhOD\n",
    "else:\n",
    "    uniphone_dist_fn = uniphone_dist_fn_hammond\n",
    "    lexicon_dist_fn = lexicon_dist_fn_hammond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:44:57.050570Z",
     "start_time": "2018-03-31T23:44:57.045764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:29.403319Z",
     "start_time": "2018-03-31T23:45:29.395140Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(uniphone_dist_fn, encoding='utf-8') as data_file:\n",
    "   uniphone_dist_in = json.loads(data_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:31.840945Z",
     "start_time": "2018-03-31T23:45:31.826731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'a ä': 0.0006578947368421052,\n",
       " 'b': 0.006048976608187134,\n",
       " 'd': 0.00034722222222222224,\n",
       " 'd í': 0.0006944444444444445,\n",
       " 'e…™': 0.001388888888888889,\n",
       " 'f': 0.004422514619883041,\n",
       " 'g': 0.0010416666666666669,\n",
       " 'h': 0.01822002923976608,\n",
       " 'i': 0.00034722222222222224,\n",
       " 'k': 0.030957602339181284,\n",
       " 'l': 0.004093567251461988,\n",
       " 'm': 0.0010051169590643274,\n",
       " 'n': 0.0003289473684210526,\n",
       " 'o ä': 0.0010233918128654971,\n",
       " 'p': 0.8784173976608189,\n",
       " 'r': 0.00034722222222222224,\n",
       " 's': 0.0006944444444444445,\n",
       " 't': 0.003654970760233918,\n",
       " 't É': 0.0006944444444444445,\n",
       " 'u': 0.0003289473684210526,\n",
       " 'v': 0.0030884502923976607,\n",
       " 'w': 0.0006944444444444445,\n",
       " '≈ã': 0.0006944444444444445,\n",
       " '…ë': 0.0013340643274853802,\n",
       " '…ö': 0.00034722222222222224,\n",
       " '…õ': 0.003801169590643275,\n",
       " '…™': 0.002741228070175439,\n",
       " ' É': 0.0013523391812865497,\n",
       " ' å': 0.02814327485380117,\n",
       " 'Œ∏': 0.0030884502923976603}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_k = list(uniphone_dist_in.keys())[0]\n",
    "test_k\n",
    "uniphone_dist_in[test_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:45.546930Z",
     "start_time": "2018-03-31T23:45:45.540537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniphone_dist = uniphone_dist_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:48.057077Z",
     "start_time": "2018-03-31T23:45:48.050222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ericmeinhardt/Google Drive/Ideas/HH/recoverability/c2-jn/IPhODv2.0_REALS\n"
     ]
    }
   ],
   "source": [
    "# %cd ..\n",
    "%cd IPhODv2.0_REALS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:48.927651Z",
     "start_time": "2018-03-31T23:45:48.835396Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(lexicon_dist_fn, encoding='utf-8') as data_file:\n",
    "   lexicon_in = json.loads(data_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:50.344300Z",
     "start_time": "2018-03-31T23:45:50.337347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ericmeinhardt/Google Drive/Ideas/HH/recoverability/c2-jn\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:52.729180Z",
     "start_time": "2018-03-31T23:45:52.711342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ãä. É. ä.r.…ô.t.i.‚ãâ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4555929067625541e-07"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_k = list(lexicon_in.keys())[0]\n",
    "test_k\n",
    "lexicon_in[test_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:53.411253Z",
     "start_time": "2018-03-31T23:45:53.218464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('‚ãä', ' É', ' ä', 'r', '…ô', 't', 'i', '‚ãâ')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4555929067625541e-07"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = {dottedStringToTuple(k):lexicon_in[k] for k in lexicon_in}\n",
    "dottedStringToTuple(test_k)\n",
    "lexicon[dottedStringToTuple(test_k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data to the required probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:56.439738Z",
     "start_time": "2018-03-31T23:45:56.333287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('‚ãä',\n",
       "  'd',\n",
       "  'j',\n",
       "  'u',\n",
       "  'p',\n",
       "  'l',\n",
       "  '…ô',\n",
       "  'k',\n",
       "  'e…™',\n",
       "  't',\n",
       "  '…™',\n",
       "  'd',\n",
       "  '‚ãâ'): 4.262807798377089e-07,\n",
       " ('‚ãä',\n",
       "  'f',\n",
       "  '…ë',\n",
       "  'r',\n",
       "  't',\n",
       "  '…ô',\n",
       "  'f',\n",
       "  '…ô',\n",
       "  'k',\n",
       "  'e…™',\n",
       "  ' É',\n",
       "  '…ô',\n",
       "  'n',\n",
       "  '‚ãâ'): 1.0397092191163634e-07,\n",
       " ('‚ãä', 'h', '…ë', '≈ã', 'k', '…™', '≈ã', '‚ãâ'): 3.1607160261137446e-06,\n",
       " ('‚ãä', 'k', '√¶', 'b', 'n', '…ô', 't', '‚ãâ'): 4.330388897619654e-06,\n",
       " ('‚ãä',\n",
       "  'm',\n",
       "  '…ô',\n",
       "  't',\n",
       "  '…™',\n",
       "  'r',\n",
       "  'i',\n",
       "  '…ô',\n",
       "  'l',\n",
       "  'a…™',\n",
       "  'z',\n",
       "  '…™',\n",
       "  'z',\n",
       "  '‚ãâ'): 6.23825531469818e-08,\n",
       " ('‚ãä', 'r', '√¶', 'd', 'm', '…ô', 'n', '‚ãâ'): 2.079418438232727e-08,\n",
       " ('‚ãä',\n",
       "  's',\n",
       "  '…õ',\n",
       "  'k',\n",
       "  '…ô',\n",
       "  'n',\n",
       "  'd',\n",
       "  '…õ',\n",
       "  'r',\n",
       "  'i',\n",
       "  '‚ãâ'): 4.262807798377089e-06,\n",
       " ('‚ãä',\n",
       "  's',\n",
       "  ' å',\n",
       "  'f',\n",
       "  '…ô',\n",
       "  'k',\n",
       "  'e…™',\n",
       "  ' É',\n",
       "  '…ô',\n",
       "  'n',\n",
       "  '‚ãâ'): 7.797819143372725e-07,\n",
       " ('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i', '‚ãâ'): 5.302517017493452e-07,\n",
       " ('‚ãä', '…ô', 'n', 't', '√¶', '≈ã', 'l', '…™', '≈ã', '‚ãâ'): 1.0397092191163634e-07}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p(X_0^f)\n",
    "inputDist = ProbDist(lexicon)\n",
    "\n",
    "phonWords = set(inputDist.keys())\n",
    "someWords = list(phonWords)[:10]\n",
    "{w:inputDist[w] for w in someWords}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorations / asides / sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - How many words in the lexicon have probability 0? (The answer should be that zero words do.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:58.842733Z",
     "start_time": "2018-03-31T23:45:58.786365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroWords = {k for k in phonWords if inputDist[k] == 0}\n",
    "len(zeroWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - How many words are there of each length (in phonemes, i.e. not counting word edge symbols.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getLength(word):\n",
    "    '''\n",
    "    Returns the length of the word in a lexicon distribution, not including edgesymbols.\n",
    "    '''\n",
    "    return len(word) - 2\n",
    "\n",
    "len(('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i', '‚ãâ'))\n",
    "getLength(('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i', '‚ãâ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myWords = list(inputDist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = list(map(getLength, myWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.7828168794767985"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "mean(lengths)\n",
    "median(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 28])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(6, 9137),\n",
       " (5, 8185),\n",
       " (7, 8153),\n",
       " (8, 6641),\n",
       " (4, 5556),\n",
       " (9, 4605),\n",
       " (10, 2940),\n",
       " (3, 2310),\n",
       " (11, 1783),\n",
       " (12, 1027),\n",
       " (13, 464),\n",
       " (2, 291),\n",
       " (14, 166),\n",
       " (15, 65),\n",
       " (16, 29),\n",
       " (1, 13),\n",
       " (17, 8),\n",
       " (18, 1),\n",
       " (20, 1),\n",
       " (28, 1)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthCounter = Counter(lengths)\n",
    "lengthCounter.keys()\n",
    "lengthCounter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50337"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "51376"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths_with_more_than_1000_words = {k for k in lengthCounter.keys() if lengthCounter[k] > 1000}\n",
    "len(lengths_with_more_than_1000_words)\n",
    "min(lengths_with_more_than_1000_words)\n",
    "max(lengths_with_more_than_1000_words)\n",
    "all(l >= min(lengths_with_more_than_1000_words) and l <= max(lengths_with_more_than_1000_words) for l in lengths_with_more_than_1000_words)\n",
    "sum(lengthCounter[k] for k in lengths_with_more_than_1000_words)\n",
    "sum(lengthCounter[k] for k in lengthCounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 98% of the pronounciations in IPhOD are 3-12 phonemes long.\n",
    " - Just about 50% of the pronounciations in IPhOD are either 5, 6, or 7 phonemes long.\n",
    " - About 16% of the pronounciations in IPhOD are 4 phonemes long or shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIXME plotnine plot of length of word type vs. count of word types with that length..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lengths = list(range(min(lengths) + 2, max(lengths) + 2 + 1))\n",
    "len(word_lengths)\n",
    "words_by_length = {l:[w for w in myWords if len(w) == l] for l in word_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('‚ãä',\n",
       "  'd',\n",
       "  'i',\n",
       "  '…™',\n",
       "  'n',\n",
       "  's',\n",
       "  't',\n",
       "  '…™',\n",
       "  't',\n",
       "  'u',\n",
       "  ' É',\n",
       "  '…ô',\n",
       "  'n',\n",
       "  '…ô',\n",
       "  'l',\n",
       "  '…ô',\n",
       "  'z',\n",
       "  'e…™',\n",
       "  ' É',\n",
       "  '…ô',\n",
       "  'n',\n",
       "  '‚ãâ')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_by_length[22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - How many unique prefixes of each length are there (not counting edge symbols, again)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51376"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "162198"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_prefixes = list(map(getPrefixes, myWords))\n",
    "my_prefixes = set(itertools.chain.from_iterable(my_prefixes))\n",
    "len(myWords)\n",
    "len(my_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPrefixLength(prefix):\n",
    "    if prefix[0] == leftEdge:\n",
    "        adjustment = -1\n",
    "    if prefix[-1] == rightEdge:\n",
    "        adjustment = -2\n",
    "    return len(prefix) + adjustment\n",
    "len(('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i', '‚ãâ'))\n",
    "getPrefixLength(('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i', '‚ãâ'))\n",
    "len(('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i'))\n",
    "getPrefixLength(('‚ãä', '√¶', 'b', '…ô', 'l', 'o ä', 'n', 'i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.562713473655656"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixLengths = list(map(getPrefixLength, my_prefixes))\n",
    "mean(prefixLengths)\n",
    "median(prefixLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(6, 29673),\n",
       " (5, 29127),\n",
       " (7, 25047),\n",
       " (4, 20596),\n",
       " (8, 19251),\n",
       " (9, 13023),\n",
       " (10, 8076),\n",
       " (3, 7368),\n",
       " (11, 4726),\n",
       " (12, 2546),\n",
       " (13, 1120),\n",
       " (2, 913),\n",
       " (14, 411),\n",
       " (15, 164),\n",
       " (16, 68),\n",
       " (1, 51),\n",
       " (17, 19),\n",
       " (18, 4),\n",
       " (20, 3),\n",
       " (19, 2),\n",
       " (28, 2),\n",
       " (0, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "162198"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_lengthCounter = Counter(prefixLengths)\n",
    "prefix_lengthCounter.keys()\n",
    "prefix_lengthCounter.most_common()\n",
    "sum(prefix_lengthCounter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ‚âà94% of all unique prefixes in IPhOD are 3-10 phonemes long.\n",
    " - ‚âà84% of all unqiue prefixes in IPhOD are 4-9 phonemes long.\n",
    " - ‚âà52% of all unique prefixes in IPhOD are 5-7 phonemes long.\n",
    " - ‚âà18% of all unique prefixes (= prefix types) in IPhOD are 1-4 phonemes long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('‚ãä',\n",
       "  '√¶',\n",
       "  'n',\n",
       "  't',\n",
       "  'a…™',\n",
       "  'd',\n",
       "  '…™',\n",
       "  's',\n",
       "  '…ô',\n",
       "  's',\n",
       "  't',\n",
       "  '√¶',\n",
       "  'b',\n",
       "  'l',\n",
       "  '…™',\n",
       "  ' É',\n",
       "  'm',\n",
       "  '…ô',\n",
       "  'n',\n",
       "  't',\n",
       "  '…õ',\n",
       "  'r',\n",
       "  'i',\n",
       "  '…ô')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_lengths = list(range(min(prefixLengths), max(lengths) + 2 + 1))\n",
    "len(prefix_lengths)\n",
    "prefixes_by_length = {l:[p for p in my_prefixes if len(p) == l] for l in prefix_lengths}\n",
    "prefixes_by_length[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - How many neighbors does each unique full word and each unique prefix have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_shared_indices(wordA, wordB):\n",
    "    '''\n",
    "    Given two sequences, this function returns the number of indices where wordA and wordB have the same values. \n",
    "    '''\n",
    "    #NB if one word is longer than the other, zip truncates the extra values in the longer word - which is just fine.\n",
    "    equalVals = [pairedVals[0] == pairedVals[1] for pairedVals in zip(wordA, wordB)]\n",
    "    return sum(equalVals)\n",
    "\n",
    "def hammingDistance(wordA, wordB):\n",
    "    '''\n",
    "    Returns the Hamming distance between two sequences, where the Hamming distance between two words of unequal length is stipulated as undefined, which is to say 'None'.\n",
    "    '''\n",
    "    if len(wordA) != len(wordB):\n",
    "        return None\n",
    "    differentIndices = len(wordA) - num_shared_indices(wordA, wordB)\n",
    "    return differentIndices\n",
    "\n",
    "def isNeighbor(targetWord, possibleNeighbor, distanceThreshold = 1):\n",
    "    distance = hammingDistance(targetWord, possibleNeighbor)\n",
    "    if distance == None:\n",
    "        return False\n",
    "    return distance <= distanceThreshold\n",
    "\n",
    "def getNeighbors(targetWord, words, distanceThreshold = 1):\n",
    "#     sameLengthWords = [w for w in words if len(w) == len(targetWord)]\n",
    "#     return [w for w in sameLengthWords if isNeighbor(targetWord, w, distanceThreshold) and targetWord != w]\n",
    "    return [w for w in words if isNeighbor(targetWord, w, distanceThreshold) and targetWord != w]\n",
    "\n",
    "def numNeighbors(targetWord, words, distanceThreshold = 1):\n",
    "    return len(getNeighbors(targetWord, words, distanceThreshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3258330738087825"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 21456),\n",
       " (1, 10445),\n",
       " (2, 4535),\n",
       " (3, 2540),\n",
       " (4, 1718),\n",
       " (5, 1344),\n",
       " (6, 1156),\n",
       " (7, 918),\n",
       " (8, 784),\n",
       " (9, 696),\n",
       " (10, 631),\n",
       " (11, 524),\n",
       " (12, 508),\n",
       " (13, 380),\n",
       " (15, 344),\n",
       " (14, 337),\n",
       " (16, 312),\n",
       " (17, 273),\n",
       " (18, 257),\n",
       " (19, 223),\n",
       " (20, 187),\n",
       " (21, 180),\n",
       " (22, 170),\n",
       " (24, 153),\n",
       " (23, 148),\n",
       " (25, 137),\n",
       " (27, 129),\n",
       " (28, 128),\n",
       " (26, 124),\n",
       " (29, 119),\n",
       " (32, 101),\n",
       " (30, 97),\n",
       " (31, 76),\n",
       " (33, 66),\n",
       " (34, 36),\n",
       " (35, 35),\n",
       " (37, 29),\n",
       " (36, 26),\n",
       " (38, 21),\n",
       " (39, 16),\n",
       " (40, 6),\n",
       " (41, 6),\n",
       " (43, 4),\n",
       " (42, 1)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "51376"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullWord_neighborCounts = [numNeighbors(w, words_by_length[len(w)]) for w in myWords]\n",
    "mean(fullWord_neighborCounts)\n",
    "median(fullWord_neighborCounts)\n",
    "fullWord_neighborCounter = Counter(fullWord_neighborCounts)\n",
    "fullWord_neighborCounter.keys()\n",
    "fullWord_neighborCounter.most_common()\n",
    "sum(fullWord_neighborCounter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.020542793375998"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(0, 45698),\n",
       " (1, 33872),\n",
       " (2, 18003),\n",
       " (3, 11104),\n",
       " (4, 7668),\n",
       " (5, 5686),\n",
       " (6, 4440),\n",
       " (7, 3531),\n",
       " (8, 2943),\n",
       " (9, 2542),\n",
       " (10, 2269),\n",
       " (11, 2006),\n",
       " (12, 1924),\n",
       " (13, 1685),\n",
       " (14, 1502),\n",
       " (15, 1344),\n",
       " (16, 1218),\n",
       " (17, 1093),\n",
       " (18, 1002),\n",
       " (19, 1001),\n",
       " (20, 862),\n",
       " (22, 813),\n",
       " (21, 800),\n",
       " (23, 733),\n",
       " (24, 657),\n",
       " (26, 607),\n",
       " (25, 587),\n",
       " (27, 554),\n",
       " (28, 491),\n",
       " (31, 447),\n",
       " (29, 433),\n",
       " (30, 409),\n",
       " (33, 383),\n",
       " (32, 372),\n",
       " (35, 346),\n",
       " (37, 324),\n",
       " (34, 307),\n",
       " (36, 291),\n",
       " (38, 284),\n",
       " (40, 259),\n",
       " (41, 251),\n",
       " (39, 238),\n",
       " (42, 207),\n",
       " (43, 192),\n",
       " (44, 181),\n",
       " (45, 134),\n",
       " (46, 127),\n",
       " (47, 117),\n",
       " (48, 63),\n",
       " (49, 49),\n",
       " (50, 39),\n",
       " (51, 32),\n",
       " (52, 30),\n",
       " (53, 11),\n",
       " (55, 11),\n",
       " (56, 8),\n",
       " (54, 7),\n",
       " (57, 4),\n",
       " (59, 3),\n",
       " (60, 2),\n",
       " (58, 1),\n",
       " (61, 1)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "162198"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_neighborCounts = [numNeighbors(p, prefixes_by_length[len(p)]) for p in my_prefixes]\n",
    "mean(prefix_neighborCounts)\n",
    "median(prefix_neighborCounts)\n",
    "prefix_neighborCounter = Counter(prefix_neighborCounts)\n",
    "prefix_neighborCounter.keys()\n",
    "prefix_neighborCounter.most_common()\n",
    "sum(prefix_neighborCounter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's trim the lexicon down to 10 words for the sake of inspectability throughout testing in this section/immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:45:59.677838Z",
     "start_time": "2018-03-31T23:45:59.666372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbDist({('‚ãä',\n",
       "           'b',\n",
       "           'o ä',\n",
       "           'l',\n",
       "           ' É',\n",
       "           '…ô',\n",
       "           'v',\n",
       "           '…™',\n",
       "           'k',\n",
       "           's',\n",
       "           '‚ãâ'): 0.006997455470737914,\n",
       "          ('‚ãä', 'k', 'o ä', 'k', 'o ä', '‚ãâ'): 0.31075063613231546,\n",
       "          ('‚ãä',\n",
       "           'k',\n",
       "           '…ë',\n",
       "           'r',\n",
       "           'b',\n",
       "           'j',\n",
       "           '…ö',\n",
       "           'i',\n",
       "           ' É',\n",
       "           '…ô',\n",
       "           'n',\n",
       "           '‚ãâ'): 0.0006361323155216284,\n",
       "          ('‚ãä',\n",
       "           'k',\n",
       "           '…ô',\n",
       "           'm',\n",
       "           'p',\n",
       "           'r',\n",
       "           '…õ',\n",
       "           's',\n",
       "           't',\n",
       "           '‚ãâ'): 0.028625954198473278,\n",
       "          ('‚ãä',\n",
       "           'n',\n",
       "           '√¶',\n",
       "           'n',\n",
       "           'o ä',\n",
       "           's',\n",
       "           '…õ',\n",
       "           'k',\n",
       "           '…ô',\n",
       "           'n',\n",
       "           'd',\n",
       "           '‚ãâ'): 0.004452926208651399,\n",
       "          ('‚ãä', 'p', 'r', '…ë', 's', '…õ', 's', 't', '‚ãâ'): 0.07983460559796436,\n",
       "          ('‚ãä', 's', 'k', 'i', 'm', 'z', '‚ãâ'): 0.05597964376590331,\n",
       "          ('‚ãä', 's', '…™', '≈ã', '…ö', '‚ãâ'): 0.4990458015267174,\n",
       "          ('‚ãä',\n",
       "           '…™',\n",
       "           'n',\n",
       "           '…ë',\n",
       "           'k',\n",
       "           'j',\n",
       "           '…ô',\n",
       "           'l',\n",
       "           'e…™',\n",
       "           't',\n",
       "           '‚ãâ'): 0.011132315521628498,\n",
       "          ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ'): 0.0025445292620865138})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's trim the lexicon down to 10 words for the sake of inspectability\n",
    "lexicon_actual = inputDist\n",
    "inputDist = ProbDist({w:inputDist[w] for w in someWords})\n",
    "inputDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:01.886518Z",
     "start_time": "2018-03-31T23:46:01.863549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ãä.s.k.i.m.z.‚ãâ: 0.05597964376590331\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 0.0025445292620865138\n",
      "‚ãä.s.…™.≈ã.…ö.‚ãâ: 0.4990458015267174\n",
      "‚ãä.k.…ë.r.b.j.…ö.i. É.…ô.n.‚ãâ: 0.0006361323155216284\n",
      "‚ãä.p.r.…ë.s.…õ.s.t.‚ãâ: 0.07983460559796436\n",
      "‚ãä.b.o ä.l. É.…ô.v.…™.k.s.‚ãâ: 0.006997455470737914\n",
      "‚ãä.k.…ô.m.p.r.…õ.s.t.‚ãâ: 0.028625954198473278\n",
      "‚ãä.n.√¶.n.o ä.s.…õ.k.…ô.n.d.‚ãâ: 0.004452926208651399\n",
      "‚ãä.k.o ä.k.o ä.‚ãâ: 0.31075063613231546\n",
      "‚ãä.…™.n.…ë.k.j.…ô.l.e…™.t.‚ãâ: 0.011132315521628498\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('‚ãä', 's', 'k', 'i', 'm', 'z', '‚ãâ')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.05597964376590331"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputDist)\n",
    "q = list(inputDist.keys())[0]\n",
    "q\n",
    "type(q)\n",
    "inputDist[q]\n",
    "type(inputDist[q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:02.607107Z",
     "start_time": "2018-03-31T23:46:02.568616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a…™'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ProbDist({'a…™': 0.8234302484302483,\n",
       "          'a ä': 0.0033783783783783825,\n",
       "          'b': 0.0012643325143325162,\n",
       "          'd': 0.0013513513513513532,\n",
       "          'e…™': 0.11726214851214868,\n",
       "          'f': 0.00037878787878787933,\n",
       "          'g': 0.00037878787878787933,\n",
       "          'h': 0.0016635954135954156,\n",
       "          'i': 0.001515151515151517,\n",
       "          'j': 0.0020833333333333363,\n",
       "          'n': 0.00037878787878787933,\n",
       "          'o ä': 0.0003378378378378383,\n",
       "          'r': 0.0029484029484029527,\n",
       "          't': 0.0007575757575757587,\n",
       "          'u': 0.00018939393939393966,\n",
       "          '√¶': 0.005023205023205031,\n",
       "          '√∞': 0.0003378378378378383,\n",
       "          '≈ã': 0.00037878787878787933,\n",
       "          '…ë': 0.02136568386568389,\n",
       "          '…î…™': 0.0043355855855855925,\n",
       "          '…ö': 0.0005272317772317779,\n",
       "          '…õ': 0.0026566339066339106,\n",
       "          '…™': 0.0025081900081900116,\n",
       "          ' å': 0.00445331695331696,\n",
       "          ' í': 0.0003378378378378383,\n",
       "          'Œ∏': 0.0007575757575757587})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_k = list(uniphone_dist_in.keys())[0]\n",
    "test_k\n",
    "\n",
    "uniphone_dist_in.update({rightEdge:{rightEdge: 1.0}})\n",
    "uniphone_dist_in.update({leftEdge:{leftEdge: 1.0}})\n",
    "\n",
    "#P(Y_i|X_i) as a dict mapping to ProbDists\n",
    "channelOutput_i_dist = {phone:ProbDist(uniphone_dist[phone]) for phone in uniphone_dist}\n",
    "channelOutput_i_dist[test_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:04.105589Z",
     "start_time": "2018-03-31T23:46:04.094647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Y_i|X_i = p):\n",
      "'d': 0.000347222222222222\n",
      "'p': 0.8784173976608184\n",
      "'t É': 0.000694444444444444\n",
      "'n': 0.0003289473684210524\n",
      "'Œ∏': 0.003088450292397658\n",
      "'u': 0.0003289473684210524\n",
      "' É': 0.0013523391812865489\n",
      "'l': 0.004093567251461985\n",
      "'b': 0.006048976608187129\n",
      "'m': 0.0010051169590643268\n",
      "'h': 0.01822002923976607\n",
      "'r': 0.000347222222222222\n",
      "'≈ã': 0.000694444444444444\n",
      "'o ä': 0.0010233918128654965\n",
      "'k': 0.030957602339181264\n",
      "'s': 0.000694444444444444\n",
      "'t': 0.0036549707602339153\n",
      "'v': 0.0030884502923976586\n",
      "' å': 0.028143274853801154\n",
      "'f': 0.004422514619883039\n",
      "'a ä': 0.0006578947368421048\n",
      "'…ö': 0.000347222222222222\n",
      "'w': 0.000694444444444444\n",
      "'i': 0.000347222222222222\n",
      "'e…™': 0.001388888888888888\n",
      "'g': 0.0010416666666666662\n",
      "'d í': 0.000694444444444444\n",
      "'…ë': 0.0013340643274853793\n",
      "'…õ': 0.003801169590643272\n",
      "'…™': 0.002741228070175437\n",
      "\n",
      "p(Y_i|X_i = b):\n",
      "'d': 0.0264285714285714\n",
      "'p': 0.15612781954887195\n",
      "'t É': 0.001428571428571427\n",
      "'n': 0.005357142857142851\n",
      "'Œ∏': 0.007142857142857135\n",
      "'z': 0.00035714285714285676\n",
      "'l': 0.004943609022556385\n",
      "'j': 0.0007142857142857135\n",
      "'m': 0.012857142857142845\n",
      "'…™': 0.015046992481202993\n",
      "'≈ã': 0.002142857142857141\n",
      "'t': 0.002142857142857141\n",
      "'√¶': 0.0019736842105263137\n",
      "' ä': 0.0027725563909774408\n",
      "' å': 0.03374999999999997\n",
      "'…ö': 0.0013439849624060135\n",
      "'i': 0.002142857142857141\n",
      "'g': 0.02351503759398494\n",
      "'v': 0.023214285714285694\n",
      "'…õ': 0.003486842105263154\n",
      "' í': 0.0010432330827067659\n",
      "'u': 0.002499999999999997\n",
      "'w': 0.006071428571428565\n",
      "'√∞': 0.0035150375939849584\n",
      "'h': 0.00848684210526315\n",
      "'r': 0.0030451127819548836\n",
      "'o ä': 0.000686090225563909\n",
      "'k': 0.002471804511278193\n",
      "'…ë': 0.004802631578947364\n",
      "'f': 0.002744360902255636\n",
      "'a ä': 0.00035714285714285676\n",
      "'b': 0.6370300751879702\n",
      "'e…™': 0.00035714285714285676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('p(Y_i|X_i = p):')\n",
    "print(channelOutput_i_dist['p'])\n",
    "print('p(Y_i|X_i = b):')\n",
    "print(channelOutput_i_dist['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!** A peculiarity of the diphone gating trial data is that while […ô] is indeed a segment recognized in the original dataset, they didn't ask participants to differentiate it from [ å] -- indeed, North American/non-British linguists typically consider these to be stress variants of each other rather than distinct phonemes in (at least) N. American English.  One result of this is that there are exactly zero trials in which participants identified […ô] as […ô]. *In terms of the code below, this means that $p(Y = […ô]|X = […ô]) = 0$.* \n",
    "\n",
    "This matters because, in the code below, I often examine conditional distributions -- e.g. $p(y_0^j|x_0^i)$ or $p(\\hat{x}_0^j|x_0^i)$ where one of the two strings/events in question is a prefix of the other -- sometimes identical. The fact that $p(Y = […ô]|X = […ô]) = 0$ means that $p(y_0^j = s|x_0^i = s) = 0$ if […ô] is in the produced prefix $s$. *Don't be spooked by seeing zero probabilities like this - it's not evidence that something, somewhere is wrong.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:05.166565Z",
     "start_time": "2018-03-31T23:46:05.154677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbDist({'a…™': 0.025272556390977443,\n",
       "          'a ä': 0.005557644110275688,\n",
       "          'b': 0.006278195488721804,\n",
       "          'd': 0.002086466165413534,\n",
       "          'e…™': 0.1606766917293233,\n",
       "          'f': 0.002261904761904762,\n",
       "          'g': 0.0014285714285714286,\n",
       "          'h': 0.003593358395989975,\n",
       "          'i': 0.005357142857142857,\n",
       "          'j': 0.0008959899749373433,\n",
       "          'n': 0.0010150375939849624,\n",
       "          'o ä': 0.044251253132832055,\n",
       "          'p': 0.0006578947368421052,\n",
       "          'r': 0.0026879699248120296,\n",
       "          's': 0.0002380952380952381,\n",
       "          't': 0.0013721804511278195,\n",
       "          'u': 0.002086466165413534,\n",
       "          'w': 0.0003289473684210526,\n",
       "          '√¶': 0.0019392230576441103,\n",
       "          '…ë': 0.05714598997493732,\n",
       "          '…î…™': 0.030375939849624056,\n",
       "          '…ö': 0.04531954887218044,\n",
       "          '…õ': 0.10053884711779446,\n",
       "          '…™': 0.08782581453634083,\n",
       "          ' ä': 0.044047619047619044,\n",
       "          ' å': 0.36676065162907273})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelOutput_i_dist['…ô']\n",
    "'…ô' in channelOutput_i_dist['…ô']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:07.378631Z",
     "start_time": "2018-03-31T23:46:07.225009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DERIVED VALUES/FUNCTIONS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'channelOutput_i_dist': {'a…™': ProbDist({'a…™': 0.8234302484302483,\n",
       "            'a ä': 0.0033783783783783825,\n",
       "            'b': 0.0012643325143325162,\n",
       "            'd': 0.0013513513513513532,\n",
       "            'e…™': 0.11726214851214868,\n",
       "            'f': 0.00037878787878787933,\n",
       "            'g': 0.00037878787878787933,\n",
       "            'h': 0.0016635954135954156,\n",
       "            'i': 0.001515151515151517,\n",
       "            'j': 0.0020833333333333363,\n",
       "            'n': 0.00037878787878787933,\n",
       "            'o ä': 0.0003378378378378383,\n",
       "            'r': 0.0029484029484029527,\n",
       "            't': 0.0007575757575757587,\n",
       "            'u': 0.00018939393939393966,\n",
       "            '√¶': 0.005023205023205031,\n",
       "            '√∞': 0.0003378378378378383,\n",
       "            '≈ã': 0.00037878787878787933,\n",
       "            '…ë': 0.02136568386568389,\n",
       "            '…î…™': 0.0043355855855855925,\n",
       "            '…ö': 0.0005272317772317779,\n",
       "            '…õ': 0.0026566339066339106,\n",
       "            '…™': 0.0025081900081900116,\n",
       "            ' å': 0.00445331695331696,\n",
       "            ' í': 0.0003378378378378383,\n",
       "            'Œ∏': 0.0007575757575757587}),\n",
       "  'a ä': ProbDist({'a…™': 0.002116454689984105,\n",
       "            'a ä': 0.8571641494435609,\n",
       "            'b': 0.0010135135135135153,\n",
       "            'd': 0.0007054848966613682,\n",
       "            'd í': 0.00110294117647059,\n",
       "            'e…™': 0.0006127450980392167,\n",
       "            'f': 0.00036764705882352995,\n",
       "            'g': 0.000551470588235295,\n",
       "            'h': 0.0010433227344992066,\n",
       "            'i': 0.0010731319554848982,\n",
       "            'j': 0.000551470588235295,\n",
       "            'l': 0.002053524112347645,\n",
       "            'm': 0.00036764705882352995,\n",
       "            'n': 0.0007352941176470599,\n",
       "            'o ä': 0.025635930047694783,\n",
       "            'r': 0.0015798887122416558,\n",
       "            's': 0.00036764705882352995,\n",
       "            't': 0.0018498277689454187,\n",
       "            't É': 0.00036764705882352995,\n",
       "            'u': 0.002038619501854799,\n",
       "            'v': 0.00036764705882352995,\n",
       "            'w': 0.000551470588235295,\n",
       "            '√¶': 0.013364467408585075,\n",
       "            '≈ã': 0.00110294117647059,\n",
       "            '…ë': 0.038925874403815626,\n",
       "            '…î…™': 0.005975092739798632,\n",
       "            '…ö': 0.0034479332273449964,\n",
       "            '…õ': 0.011979994700582957,\n",
       "            '…™': 0.0005365659777424491,\n",
       "            ' É': 0.00036764705882352995,\n",
       "            ' ä': 0.00110294117647059,\n",
       "            ' å': 0.020243773184949687,\n",
       "            ' í': 0.00036764705882352995,\n",
       "            'Œ∏': 0.00036764705882352995}),\n",
       "  'b': ProbDist({'a ä': 0.00035714285714285676,\n",
       "            'b': 0.6370300751879702,\n",
       "            'd': 0.0264285714285714,\n",
       "            'e…™': 0.00035714285714285676,\n",
       "            'f': 0.002744360902255636,\n",
       "            'g': 0.02351503759398494,\n",
       "            'h': 0.00848684210526315,\n",
       "            'i': 0.002142857142857141,\n",
       "            'j': 0.0007142857142857135,\n",
       "            'k': 0.002471804511278193,\n",
       "            'l': 0.004943609022556385,\n",
       "            'm': 0.012857142857142845,\n",
       "            'n': 0.005357142857142851,\n",
       "            'o ä': 0.000686090225563909,\n",
       "            'p': 0.15612781954887195,\n",
       "            'r': 0.0030451127819548836,\n",
       "            't': 0.002142857142857141,\n",
       "            't É': 0.001428571428571427,\n",
       "            'u': 0.002499999999999997,\n",
       "            'v': 0.023214285714285694,\n",
       "            'w': 0.006071428571428565,\n",
       "            'z': 0.00035714285714285676,\n",
       "            '√¶': 0.0019736842105263137,\n",
       "            '√∞': 0.0035150375939849584,\n",
       "            '≈ã': 0.002142857142857141,\n",
       "            '…ë': 0.004802631578947364,\n",
       "            '…ö': 0.0013439849624060135,\n",
       "            '…õ': 0.003486842105263154,\n",
       "            '…™': 0.015046992481202993,\n",
       "            ' ä': 0.0027725563909774408,\n",
       "            ' å': 0.03374999999999997,\n",
       "            ' í': 0.0010432330827067659,\n",
       "            'Œ∏': 0.007142857142857135}),\n",
       "  'd': ProbDist({'a…™': 0.000714285714285714,\n",
       "            'a ä': 0.001015037593984962,\n",
       "            'b': 0.005902255639097741,\n",
       "            'd': 0.6806484962406019,\n",
       "            'd í': 0.0027443609022556378,\n",
       "            'e…™': 0.001071428571428571,\n",
       "            'f': 0.001973684210526315,\n",
       "            'g': 0.012387218045112777,\n",
       "            'h': 0.005601503759398494,\n",
       "            'i': 0.001428571428571428,\n",
       "            'k': 0.013703007518796986,\n",
       "            'm': 0.002086466165413533,\n",
       "            'n': 0.004971804511278193,\n",
       "            'p': 0.00620300751879699,\n",
       "            'r': 0.01738721804511278,\n",
       "            's': 0.00032894736842105246,\n",
       "            't': 0.18222744360902243,\n",
       "            't É': 0.002030075187969924,\n",
       "            'u': 0.0013721804511278189,\n",
       "            'v': 0.003101503759398495,\n",
       "            'w': 0.0006578947368421049,\n",
       "            '√¶': 0.00032894736842105246,\n",
       "            '√∞': 0.004887218045112779,\n",
       "            '≈ã': 0.001428571428571428,\n",
       "            '…ë': 0.005733082706766914,\n",
       "            '…ö': 0.00032894736842105246,\n",
       "            '…õ': 0.004501879699248118,\n",
       "            '…™': 0.005930451127819546,\n",
       "            ' ä': 0.001428571428571428,\n",
       "            ' å': 0.019859022556390972,\n",
       "            ' í': 0.000714285714285714,\n",
       "            'Œ∏': 0.007302631578947364}),\n",
       "  'd í': ProbDist({'b': 0.0024574303405572743,\n",
       "            'd': 0.11546052631578935,\n",
       "            'd í': 0.5620162538699691,\n",
       "            'e…™': 0.001760835913312693,\n",
       "            'g': 0.024613003095975226,\n",
       "            'h': 0.0007352941176470585,\n",
       "            'i': 0.00036764705882352924,\n",
       "            'l': 0.0007352941176470585,\n",
       "            'n': 0.0007352941176470585,\n",
       "            'o ä': 0.001470588235294117,\n",
       "            'r': 0.0007352941176470585,\n",
       "            't': 0.016950464396284823,\n",
       "            't É': 0.23407507739938088,\n",
       "            'u': 0.0014318885448916404,\n",
       "            'w': 0.0007352941176470585,\n",
       "            '√∞': 0.005979102167182659,\n",
       "            '≈ã': 0.0007352941176470585,\n",
       "            '…ë': 0.00036764705882352924,\n",
       "            '…õ': 0.001470588235294117,\n",
       "            '…™': 0.009152476780185754,\n",
       "            ' É': 0.003889318885448915,\n",
       "            ' ä': 0.0007352941176470585,\n",
       "            ' å': 0.0052825077399380775,\n",
       "            ' í': 0.005901702786377706,\n",
       "            'Œ∏': 0.002205882352941176}),\n",
       "  'e…™': ProbDist({'a…™': 0.012286036036036046,\n",
       "            'a ä': 0.00033783783783783813,\n",
       "            'b': 0.005912162162162167,\n",
       "            'd': 0.0008204633204633211,\n",
       "            'd í': 0.0010714285714285723,\n",
       "            'e…™': 0.9221492921492919,\n",
       "            'f': 0.0003571428571428574,\n",
       "            'h': 0.0021541184041184063,\n",
       "            'i': 0.006618404118404125,\n",
       "            'j': 0.0017760617760617773,\n",
       "            'k': 0.0003571428571428574,\n",
       "            'n': 0.0003571428571428574,\n",
       "            'o ä': 0.00033783783783783813,\n",
       "            'p': 0.00033783783783783813,\n",
       "            'r': 0.0003571428571428574,\n",
       "            's': 0.00033783783783783813,\n",
       "            't': 0.002461389961389963,\n",
       "            'u': 0.0007319819819819826,\n",
       "            'v': 0.0002252252252252254,\n",
       "            '√¶': 0.004200450450450454,\n",
       "            '√∞': 0.0005823680823680828,\n",
       "            '…ë': 0.004000965250965255,\n",
       "            '…î…™': 0.0008638996138996147,\n",
       "            '…ö': 0.0002252252252252254,\n",
       "            '…õ': 0.019842342342342358,\n",
       "            '…™': 0.01096042471042472,\n",
       "            ' ä': 0.00033783783783783813}),\n",
       "  'f': ProbDist({'a…™': 0.0003472222222222222,\n",
       "            'd í': 0.0006944444444444444,\n",
       "            'e…™': 0.0003472222222222222,\n",
       "            'f': 0.7521016081871346,\n",
       "            'g': 0.0006944444444444444,\n",
       "            'h': 0.007163742690058477,\n",
       "            'i': 0.001023391812865497,\n",
       "            'k': 0.0006944444444444444,\n",
       "            'l': 0.0006944444444444444,\n",
       "            'n': 0.0013523391812865495,\n",
       "            'o ä': 0.0013888888888888887,\n",
       "            'p': 0.0036184210526315776,\n",
       "            'r': 0.0009868421052631577,\n",
       "            's': 0.0044773391812865495,\n",
       "            't': 0.004093567251461988,\n",
       "            't É': 0.0006944444444444444,\n",
       "            'u': 0.0003472222222222222,\n",
       "            'v': 0.014236111111111109,\n",
       "            'w': 0.002704678362573099,\n",
       "            '√∞': 0.004842836257309941,\n",
       "            '…ë': 0.0006578947368421051,\n",
       "            '…õ': 0.001023391812865497,\n",
       "            '…™': 0.0034539473684210517,\n",
       "            ' É': 0.0003472222222222222,\n",
       "            ' ä': 0.0006944444444444444,\n",
       "            ' å': 0.019389619883040932,\n",
       "            'Œ∏': 0.17192982456140346}),\n",
       "  'g': ProbDist({'b': 0.00859133126934984,\n",
       "            'd': 0.00965557275541795,\n",
       "            'd í': 0.002941176470588233,\n",
       "            'e…™': 0.0018382352941176457,\n",
       "            'f': 0.0019736842105263146,\n",
       "            'g': 0.5911184210526316,\n",
       "            'h': 0.010603715170278631,\n",
       "            'i': 0.002089783281733745,\n",
       "            'j': 0.006249999999999996,\n",
       "            'k': 0.2359133126934983,\n",
       "            'l': 0.0026702786377708963,\n",
       "            'm': 0.0010642414860681107,\n",
       "            'n': 0.002708978328173373,\n",
       "            'o ä': 0.0011029411764705878,\n",
       "            'p': 0.009616873065015477,\n",
       "            'r': 0.001644736842105262,\n",
       "            't': 0.024535603715170266,\n",
       "            't É': 0.0021284829721362215,\n",
       "            'u': 0.0017608359133126927,\n",
       "            'v': 0.0003289473684210524,\n",
       "            'w': 0.0033668730650154776,\n",
       "            '√¶': 0.0006578947368421048,\n",
       "            '√∞': 0.0007352941176470583,\n",
       "            '≈ã': 0.007198142414860676,\n",
       "            '…ë': 0.0033668730650154776,\n",
       "            '…ö': 0.0006578947368421048,\n",
       "            '…õ': 0.0007352941176470583,\n",
       "            '…™': 0.009113777089783276,\n",
       "            ' ä': 0.002941176470588233,\n",
       "            ' å': 0.04496904024767799,\n",
       "            ' í': 0.0036764705882352915,\n",
       "            'Œ∏': 0.0040441176470588204}),\n",
       "  'h': ProbDist({'a…™': 0.0007352941176470586,\n",
       "            'a ä': 0.0018939393939393936,\n",
       "            'b': 0.0022727272727272726,\n",
       "            'd': 0.001515151515151515,\n",
       "            'd í': 0.003787878787878787,\n",
       "            'e…™': 0.008311051693404634,\n",
       "            'f': 0.0034090909090909085,\n",
       "            'g': 0.0007575757575757575,\n",
       "            'h': 0.762945632798574,\n",
       "            'i': 0.0029411764705882344,\n",
       "            'j': 0.0007575757575757575,\n",
       "            'k': 0.00374331550802139,\n",
       "            'l': 0.0022727272727272726,\n",
       "            'm': 0.0003"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 101552 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('DERIVED VALUES/FUNCTIONS:')\n",
    "\n",
    "total_model = generateTotalModel(inputDist, channelOutput_i_dist, pad_with_boundaries = False)\n",
    "total_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we do with this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:09.205276Z",
     "start_time": "2018-03-31T23:46:09.196403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channelOutput_i_dist',\n",
       " 'channelOutput_i_marginal_dist',\n",
       " 'channelOutput_prefix_marginal_prob',\n",
       " 'channelOutput_prefix_prob',\n",
       " 'channelOutput_prefix_sampler',\n",
       " 'est_channelInput_prob',\n",
       " 'inputAlphabet',\n",
       " 'inputDist',\n",
       " 'inputDist_givenPrefix',\n",
       " 'inputs',\n",
       " 'p(X_0^f | x_0^i)',\n",
       " 'p(X_0^f)',\n",
       " 'p(Y_i)',\n",
       " 'p(Y_i|x_i)',\n",
       " 'p(x_0^i)',\n",
       " 'p(x_{i+1}^f | x_0^i)',\n",
       " 'p(y_0^i)',\n",
       " 'p(y_0^i|x_0^i)',\n",
       " 'p-hat(x-hat_0^j|x_0^i)',\n",
       " 'prefixProb',\n",
       " 'prefixes',\n",
       " 'sample from p(Y_0^i|x_0^i)',\n",
       " 'suffixProb']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(total_model.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:10.276094Z",
     "start_time": "2018-03-31T23:46:10.266313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channelOutput_i_dist': dict,\n",
       " 'channelOutput_i_marginal_dist': __main__.ProbDist,\n",
       " 'channelOutput_prefix_marginal_prob': function,\n",
       " 'channelOutput_prefix_prob': function,\n",
       " 'channelOutput_prefix_sampler': function,\n",
       " 'est_channelInput_prob': function,\n",
       " 'inputAlphabet': set,\n",
       " 'inputDist': __main__.ProbDist,\n",
       " 'inputDist_givenPrefix': function,\n",
       " 'inputs': list,\n",
       " 'p(X_0^f | x_0^i)': function,\n",
       " 'p(X_0^f)': __main__.ProbDist,\n",
       " 'p(Y_i)': __main__.ProbDist,\n",
       " 'p(Y_i|x_i)': dict,\n",
       " 'p(x_0^i)': function,\n",
       " 'p(x_{i+1}^f | x_0^i)': function,\n",
       " 'p(y_0^i)': function,\n",
       " 'p(y_0^i|x_0^i)': function,\n",
       " 'p-hat(x-hat_0^j|x_0^i)': function,\n",
       " 'prefixProb': function,\n",
       " 'prefixes': set,\n",
       " 'sample from p(Y_0^i|x_0^i)': function,\n",
       " 'suffixProb': function}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:type(total_model[k]) for k in total_model.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:11.910325Z",
     "start_time": "2018-03-31T23:46:11.869368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_input: ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')\n",
      "prefix_a: ('‚ãä', 'Œ∏')\n",
      "prefix_b: ('‚ãä', 'Œ∏', 'r')\n",
      "prefix_c: ('‚ãä', 'Œ∏', 'r', ' å')\n",
      "prefix_d: ('‚ãä', 'Œ∏', 'r', ' å', 's')\n",
      "suffix_a: ('s', 's', '‚ãâ')\n",
      "suffix_b: ('s', '‚ãâ')\n",
      "suffix_c: ('s', '‚ãâ')\n"
     ]
    }
   ],
   "source": [
    "# print('TEST INPUTS:')\n",
    "an_input = total_model['inputs'][1]\n",
    "prefix_a = an_input[0:2]\n",
    "prefix_b = an_input[0:3]\n",
    "prefix_c = an_input[0:4]\n",
    "prefix_d = an_input[:-2]\n",
    "suffix_a = an_input[-3:]\n",
    "suffix_b = tuple([an_input[-2],'‚ãâ'])\n",
    "suffix_c = an_input[-2:]\n",
    "\n",
    "print(\"{0}: {1}\".format('an_input', an_input))\n",
    "print(\"{0}: {1}\".format('prefix_a', prefix_a))\n",
    "print(\"{0}: {1}\".format('prefix_b', prefix_b))\n",
    "print(\"{0}: {1}\".format('prefix_c', prefix_c))\n",
    "print(\"{0}: {1}\".format('prefix_d', prefix_d))\n",
    "print(\"{0}: {1}\".format('suffix_a', suffix_a))\n",
    "print(\"{0}: {1}\".format('suffix_b', suffix_b))\n",
    "print(\"{0}: {1}\".format('suffix_c', suffix_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two cells below show properties of the input distribution $p(X_0^f)$ and calculations derived from it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:22.813598Z",
     "start_time": "2018-03-31T23:46:22.775741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some inputs:\n",
      "[('‚ãä', 's', 'k', 'i', 'm', 'z', '‚ãâ'), ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ'), ('‚ãä', 's', '…™', '≈ã', '…ö', '‚ãâ'), ('‚ãä', 'k', '…ë', 'r', 'b', 'j', '…ö', 'i', ' É', '…ô', 'n', '‚ãâ'), ('‚ãä', 'p', 'r', '…ë', 's', '…õ', 's', 't', '‚ãâ'), ('‚ãä', 'b', 'o ä', 'l', ' É', '…ô', 'v', '…™', 'k', 's', '‚ãâ'), ('‚ãä', 'k', '…ô', 'm', 'p', 'r', '…õ', 's', 't', '‚ãâ'), ('‚ãä', 'n', '√¶', 'n', 'o ä', 's', '…õ', 'k', '…ô', 'n', 'd', '‚ãâ'), ('‚ãä', 'k', 'o ä', 'k', 'o ä', '‚ãâ'), ('‚ãä', '…™', 'n', '…ë', 'k', 'j', '…ô', 'l', 'e…™', 't', '‚ãâ')]\n",
      "preview of p(X_0^f):\n",
      "{('‚ãä', 's', 'k', 'i', 'm', 'z', '‚ãâ'): 0.05597964376590331, ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ'): 0.0025445292620865138, ('‚ãä', 's', '…™', '≈ã', '…ö', '‚ãâ'): 0.4990458015267174, ('‚ãä', 'k', '…ë', 'r', 'b', 'j', '…ö', 'i', ' É', '…ô', 'n', '‚ãâ'): 0.0006361323155216284, ('‚ãä', 'p', 'r', '…ë', 's', '…õ', 's', 't', '‚ãâ'): 0.07983460559796436, ('‚ãä', 'b', 'o ä', 'l', ' É', '…ô', 'v', '…™', 'k', 's', '‚ãâ'): 0.006997455470737914, ('‚ãä', 'k', '…ô', 'm', 'p', 'r', '…õ', 's', 't', '‚ãâ'): 0.028625954198473278, ('‚ãä', 'n', '√¶', 'n', 'o ä', 's', '…õ', 'k', '…ô', 'n', 'd', '‚ãâ'): 0.004452926208651399, ('‚ãä', 'k', 'o ä', 'k', 'o ä', '‚ãâ'): 0.31075063613231546, ('‚ãä', '…™', 'n', '…ë', 'k', 'j', '…ô', 'l', 'e…™', 't', '‚ãâ'): 0.011132315521628498}\n",
      "input alphabet:\n",
      "{'‚ãâ', 'd', 'p', 'n', 'Œ∏', 'z', 'l', 'j', '≈ã', 'm', '…™', 't', '√¶', ' å', '…ö', 'i', '…ë', '…õ', 'v', ' É', '…ô', 'b', 'r', 'o ä', 'k', 's', '‚ãä', 'e…™'}\n",
      "input alphabet - edge symbols:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'b',\n",
       " 'd',\n",
       " 'e…™',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o ä',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'v',\n",
       " 'z',\n",
       " '√¶',\n",
       " '≈ã',\n",
       " '…ë',\n",
       " '…ô',\n",
       " '…ö',\n",
       " '…õ',\n",
       " '…™',\n",
       " ' É',\n",
       " ' å',\n",
       " 'Œ∏'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<= 10 prefixes of lexicon:\n",
      "[('‚ãä', 's', 'k', 'i', 'm', 'z', '‚ãâ'), ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ'), ('‚ãä', 's', '…™', '≈ã', '…ö', '‚ãâ'), ('‚ãä', 'b', 'o ä', 'l', ' É', '…ô', 'v', '…™'), ('‚ãä', 's', '…™', '≈ã', '…ö'), ('‚ãä', 'n'), ('‚ãä', 'k', '…ë', 'r', 'b', 'j', '…ö', 'i', ' É', '…ô', 'n', '‚ãâ'), ('‚ãä', 'p', 'r', '…ë', 's', '…õ', 's', 't', '‚ãâ'), ('‚ãä', 'p', 'r'), ('‚ãä', 'b', 'o ä', 'l'), ('‚ãä', 'b', 'o ä', 'l', ' É', '…ô', 'v', '…™', 'k', 's', '‚ãâ')]\n"
     ]
    }
   ],
   "source": [
    "someInputs = total_model['inputs'][:10]\n",
    "print('some inputs:')\n",
    "print(someInputs)\n",
    "print('preview of p(X_0^f):')\n",
    "print({k:total_model['p(X_0^f)'][k] for k in someInputs})\n",
    "assert(all([k in total_model['p(X_0^f)'] for k in someInputs]))\n",
    "\n",
    "print('input alphabet:')\n",
    "print(total_model['inputAlphabet'])\n",
    "print('input alphabet - edge symbols:')\n",
    "total_model['inputAlphabet'] - edgeSymbols\n",
    "\n",
    "print(\"<= 10 prefixes of lexicon:\")\n",
    "print(list(total_model['prefixes'])[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...like \n",
    " - the probability the speaker's intended wordform has a particular prefix $p(x_0^i)$.\n",
    " - the distribution over full wordforms given a specific prefix $p(X_0^f|x_0^i)$.\n",
    " - the probability of a particular suffix given a particular prefix $p(x_{i+1}^f|x_0^i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:24.571683Z",
     "start_time": "2018-03-31T23:46:24.476838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "‚ãä.s.k.i.m.z.‚ãâ: 0.05597964376590331\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 0.0025445292620865138\n",
      "‚ãä.s.…™.≈ã.…ö.‚ãâ: 0.4990458015267174\n",
      "‚ãä.k.…ë.r.b.j.…ö.i. É.…ô.n.‚ãâ: 0.0006361323155216284\n",
      "‚ãä.p.r.…ë.s.…õ.s.t.‚ãâ: 0.07983460559796436\n",
      "‚ãä.b.o ä.l. É.…ô.v.…™.k.s.‚ãâ: 0.006997455470737914\n",
      "‚ãä.k.…ô.m.p.r.…õ.s.t.‚ãâ: 0.028625954198473278\n",
      "‚ãä.n.√¶.n.o ä.s.…õ.k.…ô.n.d.‚ãâ: 0.004452926208651399\n",
      "‚ãä.k.o ä.k.o ä.‚ãâ: 0.31075063613231546\n",
      "‚ãä.…™.n.…ë.k.j.…ô.l.e…™.t.‚ãâ: 0.011132315521628498\n",
      "\n",
      "TEST PREFIX: ('‚ãä', 'Œ∏')\n",
      "p(x_0^i = ('‚ãä', 'Œ∏')) = 0.0025445292620865138\n",
      "p(X_0^f| x_0^i = ('‚ãä', 'Œ∏')):\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 1.0\n",
      "\n",
      "TEST PREFIX: ('‚ãä', 'Œ∏', 'r')\n",
      "p(x_0^i = ('‚ãä', 'Œ∏', 'r')) = 0.0025445292620865138\n",
      "p(X_0^f| x_0^i = ('‚ãä', 'Œ∏', 'r')):\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 1.0\n",
      "\n",
      "TEST PREFIX: ('‚ãä', 'Œ∏', 'r', ' å')\n",
      "p(x_0^i = ('‚ãä', 'Œ∏', 'r', ' å')) = 0.0025445292620865138\n",
      "p(X_0^f| x_0^i = ('‚ãä', 'Œ∏', 'r', ' å')):\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 1.0\n",
      "\n",
      "TEST PREFIX: ('‚ãä', 'Œ∏', 'r', ' å')\n",
      "TEST SUFFIX: ('s', 's', '‚ãâ')\n",
      "Let j = i+1:\n",
      " p(x_j^f = ('s', 's', '‚ãâ')|x_0^i = ('‚ãä', 'Œ∏', 'r', ' å')) = 1.0\n",
      "TEST PREFIX: ('‚ãä', 'Œ∏', 'r', ' å', 's')\n",
      "TEST SUFFIX: ('s', '‚ãâ')\n",
      "Let j = i+1:\n",
      " p(x_j^f = ('s', '‚ãâ')|x_0^i = ('‚ãä', 'Œ∏', 'r', ' å', 's')) = 1.0\n"
     ]
    }
   ],
   "source": [
    "print('p(X_0^f):')\n",
    "# print('...')\n",
    "print(inputDist)\n",
    "test_prefix = prefix_a\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "# print(\"{0} in dist:{1}\".format(test_prefix, test_prefix in total_model['prefixProb']))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, total_model['prefixProb'](test_prefix)))\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(total_model['inputDist_givenPrefix'](test_prefix))\n",
    "test_prefix = prefix_b\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, total_model['prefixProb'](test_prefix)))\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(total_model['inputDist_givenPrefix'](test_prefix))\n",
    "test_prefix = prefix_c\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('p(x_0^i = {0}) = {1}'.format(test_prefix, total_model['prefixProb'](test_prefix)))\n",
    "print('p(X_0^f| x_0^i = {0}):'.format(test_prefix))\n",
    "print(total_model['inputDist_givenPrefix'](test_prefix))\n",
    "\n",
    "test_suffix = suffix_a\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('TEST SUFFIX: {0}'.format(test_suffix))\n",
    "print('Let j = i+1:')\n",
    "print(' p(x_j^f = {0}|x_0^i = {1}) = {2}'.format(test_suffix, test_prefix, total_model['suffixProb'](test_suffix, test_prefix)))\n",
    "test_prefix = prefix_d\n",
    "test_suffix = suffix_c\n",
    "print(\"TEST PREFIX: {0}\".format(test_prefix))\n",
    "print('TEST SUFFIX: {0}'.format(test_suffix))\n",
    "print('Let j = i+1:')\n",
    "print(' p(x_j^f = {0}|x_0^i = {1}) = {2}'.format(test_suffix, test_prefix, total_model['suffixProb'](test_suffix, test_prefix)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the channel distribution over (two examples of) a single segment $p(Y|X = x)$ and the marginal distribution $p(Y)$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:25.719101Z",
     "start_time": "2018-03-31T23:46:25.696790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Y_i|X_i = n):\n",
      "'a…™': 0.0003289473684210526\n",
      "'d': 0.0006944444444444445\n",
      "'p': 0.0006944444444444445\n",
      "'t É': 0.0020833333333333337\n",
      "' í': 0.0006944444444444445\n",
      "'n': 0.8828947368421052\n",
      "'Œ∏': 0.0006944444444444445\n",
      "'u': 0.001736111111111111\n",
      "'z': 0.00034722222222222224\n",
      "'l': 0.003435672514619883\n",
      "'b': 0.0006578947368421052\n",
      "'√∞': 0.0006944444444444445\n",
      "'…ë': 0.003983918128654971\n",
      "'≈ã': 0.019060672514619886\n",
      "'h': 0.004093567251461989\n",
      "'…™': 0.008607456140350878\n",
      "'m': 0.02388523391812866\n",
      "'o ä': 0.00034722222222222224\n",
      "'k': 0.0006944444444444445\n",
      "'√¶': 0.0006944444444444445\n",
      "'j': 0.0010233918128654971\n",
      "' ä': 0.002722953216374269\n",
      "' å': 0.025292397660818724\n",
      "'…ö': 0.0010416666666666669\n",
      "'w': 0.007346491228070177\n",
      "'i': 0.0006944444444444445\n",
      "'g': 0.0020833333333333337\n",
      "'d í': 0.001388888888888889\n",
      "'v': 0.001388888888888889\n",
      "'…õ': 0.0006944444444444445\n",
      "\n",
      "p(Y_i|X_i = o ä):\n",
      "'a…™': 0.0003378378378378383\n",
      "'p': 0.00036764705882352984\n",
      "' í': 0.00036764705882352984\n",
      "'n': 0.0009191176470588246\n",
      "'Œ∏': 0.00036764705882352984\n",
      "'u': 0.009994369369369382\n",
      "'l': 0.0036764705882352984\n",
      "'b': 0.0022257551669316407\n",
      "'√∞': 0.00036764705882352984\n",
      "'m': 0.00036764705882352984\n",
      "'h': 0.00036764705882352984\n",
      "'r': 0.0009042130365659788\n",
      "'o ä': 0.852550344462109\n",
      "'k': 0.0007352941176470597\n",
      "'…î…™': 0.02265169581346055\n",
      "'t': 0.0018382352941176492\n",
      "'…™': 0.0011029411764705897\n",
      "' å': 0.02595223900370962\n",
      "'a ä': 0.052389705882352984\n",
      "'…ö': 0.010159976152623224\n",
      "'w': 0.000536565977742449\n",
      "' ä': 0.008677795442501334\n",
      "'e…™': 0.0005216613672496032\n",
      "'g': 0.00036764705882352984\n",
      "'…ë': 0.000536565977742449\n",
      "'…õ': 0.001715686274509806\n",
      "\n",
      "p(Y_i):\n",
      "'‚ãâ': 0.02439024390243903\n",
      "'d': 0.02538809224763328\n",
      "'p': 0.028890118803680868\n",
      "'t É': 0.028880786981696435\n",
      "'n': 0.024598273702872563\n",
      "'Œ∏': 0.02693656411588989\n",
      "'z': 0.023239876785794922\n",
      "'l': 0.024064798028873204\n",
      "'j': 0.018651074285518383\n",
      "'≈ã': 0.022521445686844388\n",
      "'…™': 0.021805729551926598\n",
      "'m': 0.022320025205211577\n",
      "'…î…™': 0.025773698108884264\n",
      "'t': 0.025421552140268883\n",
      "'√¶': 0.013845653637737786\n",
      "' ä': 0.010413149659775063\n",
      "' å': 0.05511173240413619\n",
      "'…ö': 0.027143278062194808\n",
      "'i': 0.0272691088827528\n",
      "'g': 0.01710842044165127\n",
      "'d í': 0.018991820609385084\n",
      "'v': 0.03348209362024438\n",
      "'…õ': 0.027526404705259584\n",
      "'a…™': 0.02694954729104761\n",
      "' í': 0.018219901536612418\n",
      "' É': 0.022373436854510553\n",
      "'u': 0.02677998977586433\n",
      "'w': 0.020658327698519482\n",
      "'√∞': 0.007454425783170211\n",
      "'h': 0.022724847033381748\n",
      "'r': 0.024968706689229705\n",
      "'o ä': 0.028088191120730504\n",
      "'k': 0.030359294982302755\n",
      "'s': 0.02369489708181848\n",
      "'…ë': 0.035551200317502495\n",
      "'f': 0.025929518092214256\n",
      "'‚ãä': 0.02439024390243903\n",
      "'a ä': 0.025073484350774958\n",
      "'b': 0.018683206749752084\n",
      "'e…™': 0.044326839169458315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_phone_a = list(total_model['inputAlphabet'])[3]\n",
    "test_phone_b = list(total_model['inputAlphabet'])[23]\n",
    "\n",
    "print('p(Y_i|X_i = {0}):'.format(test_phone_a))\n",
    "# print(channelOutput_i_dist(0))\n",
    "print(channelOutput_i_dist[test_phone_a])\n",
    "print('p(Y_i|X_i = {0}):'.format(test_phone_b))\n",
    "# print(channelOutput_i_dist(1))\n",
    "print(channelOutput_i_dist[test_phone_b])\n",
    "\n",
    "print(\"p(Y_i):\")\n",
    "print(total_model['channelOutput_i_marginal_dist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are example calculations related to the following channel distribution over prefixes:\n",
    " - $p(y_0^i|x_0^i)$\n",
    " - $p(y_0^j|x_0^i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:26.677146Z",
     "start_time": "2018-03-31T23:46:26.600585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "‚ãä.s.k.i.m.z.‚ãâ: 0.05597964376590331\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 0.0025445292620865138\n",
      "‚ãä.s.…™.≈ã.…ö.‚ãâ: 0.4990458015267174\n",
      "‚ãä.k.…ë.r.b.j.…ö.i. É.…ô.n.‚ãâ: 0.0006361323155216284\n",
      "‚ãä.p.r.…ë.s.…õ.s.t.‚ãâ: 0.07983460559796436\n",
      "‚ãä.b.o ä.l. É.…ô.v.…™.k.s.‚ãâ: 0.006997455470737914\n",
      "‚ãä.k.…ô.m.p.r.…õ.s.t.‚ãâ: 0.028625954198473278\n",
      "‚ãä.n.√¶.n.o ä.s.…õ.k.…ô.n.d.‚ãâ: 0.004452926208651399\n",
      "‚ãä.k.o ä.k.o ä.‚ãâ: 0.31075063613231546\n",
      "‚ãä.…™.n.…ë.k.j.…ô.l.e…™.t.‚ãâ: 0.011132315521628498\n",
      "\n",
      "TEST INPUT full: ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')\n",
      "TEST OUTPUT full: ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')\n",
      "p(y_0^i = ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')| x_0^i = ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')) = 0.33122571061530065\n",
      " \n",
      "TEST INPUT prefix: ('‚ãä', 'Œ∏')\n",
      "TEST OUTPUT prefix: ('‚ãä', 'Œ∏')\n",
      "p(y_0^i = ('‚ãä', 'Œ∏')| x_0^i = ('‚ãä', 'Œ∏')) = 0.6907205882352944\n",
      " \n",
      "TEST INPUT prefix: ('‚ãä', 'Œ∏')\n",
      "TEST OUTPUT prefix: ('‚ãä', 'Œ∏', 'r')\n",
      "p(y_0^j = ('‚ãä', 'Œ∏', 'r')| x_0^i = ('‚ãä', 'Œ∏')) = 0.5782879288175375\n",
      " \n",
      "TEST INPUT prefix: ('‚ãä', 'Œ∏', 'r')\n",
      "TEST OUTPUT prefix: ('‚ãä', 'Œ∏')\n",
      "p(y_0^j = ('‚ãä', 'Œ∏')| x_0^i = ('‚ãä', 'Œ∏', 'r')) = 0.6907205882352944\n"
     ]
    }
   ],
   "source": [
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "  \n",
    "test_input_full = an_input\n",
    "test_output_full = an_input\n",
    "print(\"TEST INPUT full: {0}\".format(test_input_full))\n",
    "print(\"TEST OUTPUT full: {0}\".format(test_output_full))\n",
    "print('p(y_0^i = {0}| x_0^i = {1}) = {2}'.format(test_output_full, test_input_full, total_model['channelOutput_prefix_prob'](test_input_full, test_output_full)))\n",
    "# print('len({0}) = {1}'.format(trimBoundariesFromSequence(test_input_full), len(trimBoundariesFromSequence(test_input_full))))\n",
    "# print('p(no_error) = {0}'.format(channelOutput_i_dist[]))\n",
    "# print('{2}^(len({0})) = {1}'.format(trimBoundariesFromSequence(test_input_full), pNoError_i ** len(trimBoundariesFromSequence(test_input_full)), pNoError_i))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = prefix_a\n",
    "test_output_slice = prefix_a\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^i = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, total_model['channelOutput_prefix_prob'](test_input_slice, test_output_slice)))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = prefix_a\n",
    "test_output_slice = prefix_b\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, total_model['channelOutput_prefix_prob'](test_input_slice, test_output_slice)))\n",
    "\n",
    "print(' ')\n",
    "test_input_slice = prefix_b\n",
    "test_output_slice = prefix_a\n",
    "print(\"TEST INPUT prefix: {0}\".format(test_input_slice))\n",
    "print(\"TEST OUTPUT prefix: {0}\".format(test_output_slice))\n",
    "print('p(y_0^j = {0}| x_0^i = {1}) = {2}'.format(test_output_slice, test_input_slice, total_model['channelOutput_prefix_prob'](test_input_slice, test_output_slice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are samples from $p(Y_0^i|x_0^i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:34.274791Z",
     "start_time": "2018-03-31T23:46:27.577378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST INPUT full: ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')\n",
      "est. p(Y_0^i = ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')|x_0^i = ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')) based on 1,000 samples:\n",
      "333/1000\n",
      "Examples of output samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['‚ãä.Œ∏.r. å.s.s.‚ãâ',\n",
       " '‚ãä.Œ∏.r. å.s.s.‚ãâ',\n",
       " '‚ãä.Œ∏.r.…ë.i.s.‚ãâ',\n",
       " '‚ãä.p.r. å.s.…î…™.‚ãâ',\n",
       " '‚ãä.Œ∏.r. å.s.s.‚ãâ',\n",
       " '‚ãä.Œ∏.r. ä.s.s.‚ãâ',\n",
       " '‚ãä.Œ∏.r. ä.s.s.‚ãâ',\n",
       " '‚ãä.f.r.…ö.s.s.‚ãâ',\n",
       " '‚ãä.Œ∏.r.…ë.s.s.‚ãâ',\n",
       " '‚ãä. å.r. å.s.s.‚ãâ']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_full = an_input\n",
    "print(\"TEST INPUT full: {0}\".format(test_input_full))\n",
    "outputSamples = list(sampleFrom(lambda : total_model['channelOutput_prefix_sampler'](test_input_full), 1000))\n",
    "outputSamplesDS = list(map(tupleToDottedString, outputSamples))\n",
    "outputSamplesDS_dist = ProbDist(Counter(outputSamplesDS))\n",
    "print('est. p(Y_0^i = {0}|x_0^i = {0}) based on 1,000 samples:'.format(an_input))\n",
    "print(outputSamplesDS_dist[tupleToDottedString(test_input_full)])\n",
    "print('Examples of output samples:')\n",
    "outputSamplesDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:34.304431Z",
     "start_time": "2018-03-31T23:46:34.279831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST INPUT prefix: ('‚ãä', 'Œ∏', 'r')\n",
      "10 samples from p(Y_0^i|x_0^i = ('‚ãä', 'Œ∏', 'r')): [('‚ãä', 'f', '√¶'), ('‚ãä', 'Œ∏', 'r'), ('‚ãä', 'Œ∏', 'r'), ('‚ãä', 'Œ∏', 'r'), ('‚ãä', 'd í', 'r'), ('‚ãä', '√∞', 'r'), ('‚ãä', '…õ', 'r'), ('‚ãä', 'Œ∏', 'r'), ('‚ãä', 'Œ∏', '…ö'), ('‚ãä', 'Œ∏', 'r')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST INPUT prefix: {0}\".format(prefix_b))\n",
    "print('10 samples from p(Y_0^i|x_0^i = {0}): {1}'.format(prefix_b, list(sampleFrom(lambda : total_model['channelOutput_prefix_sampler'](prefix_b), 10)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example calculation of $p(y_0^i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:34.320604Z",
     "start_time": "2018-03-31T23:46:34.308134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST OUTPUT prefix = ('‚ãä', 'Œ∏', 'r')\n",
      "p(y_0^i = ('‚ãä', 'Œ∏', 'r')) = 0.0016787690901115722\n"
     ]
    }
   ],
   "source": [
    "print('TEST OUTPUT prefix = {0}'.format(prefix_b))\n",
    "print('p(y_0^i = {0}) = {1}'.format(prefix_b, total_model['channelOutput_prefix_marginal_prob'](prefix_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below are example calculations of $p(\\hat{x}_0^j| x_0^i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:46:58.358658Z",
     "start_time": "2018-03-31T23:46:34.335768Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X_0^f):\n",
      "‚ãä.s.k.i.m.z.‚ãâ: 0.05597964376590331\n",
      "‚ãä.Œ∏.r. å.s.s.‚ãâ: 0.0025445292620865138\n",
      "‚ãä.s.…™.≈ã.…ö.‚ãâ: 0.4990458015267174\n",
      "‚ãä.k.…ë.r.b.j.…ö.i. É.…ô.n.‚ãâ: 0.0006361323155216284\n",
      "‚ãä.p.r.…ë.s.…õ.s.t.‚ãâ: 0.07983460559796436\n",
      "‚ãä.b.o ä.l. É.…ô.v.…™.k.s.‚ãâ: 0.006997455470737914\n",
      "‚ãä.k.…ô.m.p.r.…õ.s.t.‚ãâ: 0.028625954198473278\n",
      "‚ãä.n.√¶.n.o ä.s.…õ.k.…ô.n.d.‚ãâ: 0.004452926208651399\n",
      "‚ãä.k.o ä.k.o ä.‚ãâ: 0.31075063613231546\n",
      "‚ãä.…™.n.…ë.k.j.…ô.l.e…™.t.‚ãâ: 0.011132315521628498\n",
      "\n",
      "est p(x-hat_0^j = ('‚ãä', 1)| x_0^i = ('‚ãä', 'Œ∏', 'r')) = 0\n",
      " \n",
      "est p(x-hat_0^j = ('‚ãä', 'Œ∏', 'r')| x_0^i = ('‚ãä', 'Œ∏', 'r')) = 0.7132299796807328\n",
      " \n",
      "est p(x-hat_0^j = ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')| x_0^i = ('‚ãä', 'Œ∏', 'r')) = 0.7215248357105462\n",
      " \n",
      "est p(x-hat_0^j = ('‚ãä', 'Œ∏', 'r')| x_0^i = ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')) = 0.9999763433531295\n",
      " \n",
      " \n",
      "est p(x-hat_0^j = ('‚ãä', 'Œ∏')| x_0^i = ('‚ãä', 'Œ∏')) = 0.720068487711772\n",
      " \n",
      "est p(x-hat_0^j = ('‚ãä', 'Œ∏')| x_0^i = ('‚ãä', 'Œ∏', 'r')) = 0.7201675102912667\n",
      " \n",
      "est p(x-hat_0^j = ('‚ãä', 'Œ∏', 'r')| x_0^i = ('‚ãä', 'Œ∏')) = 0.7181326246871341\n"
     ]
    }
   ],
   "source": [
    "print(\"p(X_0^f):\")\n",
    "print(inputDist)\n",
    "\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(('‚ãä', 1), prefix_b, total_model['est_channelInput_prob'](prefix_b, ('‚ãä', 1))))\n",
    "print(' ')\n",
    "\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_b, prefix_b, total_model['est_channelInput_prob'](prefix_b, prefix_b)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(an_input, prefix_b, total_model['est_channelInput_prob'](prefix_b, an_input)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_b, an_input, total_model['est_channelInput_prob'](an_input, prefix_b)))\n",
    "\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_a, prefix_a, total_model['est_channelInput_prob'](prefix_b, prefix_b)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_a, prefix_b, total_model['est_channelInput_prob'](prefix_b, prefix_b)))\n",
    "print(' ')\n",
    "print('est p(x-hat_0^j = {0}| x_0^i = {1}) = {2}'.format(prefix_b, prefix_a, total_model['est_channelInput_prob'](prefix_b, prefix_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to calculate the query $p(\\hat{X}_0^i = s|X_0^i = s)$, over random prefixes from our tiny ten word lexicon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:50:18.061801Z",
     "start_time": "2018-03-31T23:50:18.031725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST INPUT full: ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prefixes of increasing length:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('‚ãä',),\n",
       " ('‚ãä', 'Œ∏'),\n",
       " ('‚ãä', 'Œ∏', 'r'),\n",
       " ('‚ãä', 'Œ∏', 'r', ' å'),\n",
       " ('‚ãä', 'Œ∏', 'r', ' å', 's'),\n",
       " ('‚ãä', 'Œ∏', 'r', ' å', 's', 's'),\n",
       " ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_full = an_input\n",
    "print(\"TEST INPUT full: {0}\".format(test_input_full))\n",
    "testPrefixes = sorted(list(getPrefixes(an_input)), key = lambda prefix: len(prefix))\n",
    "len(testPrefixes)\n",
    "print('Test prefixes of increasing length:')\n",
    "testPrefixes\n",
    "# testPrefixes - {tuple(['‚ãä'])}\n",
    "# testPrefixes = testPrefixes- {tuple(['‚ãä'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:48:11.406019Z",
     "start_time": "2018-03-31T23:47:23.601753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('‚ãä',): 0.15563607215881348,\n",
       " ('‚ãä', 'Œ∏'): 1.1722090244293213,\n",
       " ('‚ãä', 'Œ∏', 'r'): 2.2120699882507324,\n",
       " ('‚ãä', 'Œ∏', 'r', ' å'): 2.6993730068206787,\n",
       " ('‚ãä', 'Œ∏', 'r', ' å', 's'): 3.2806639671325684,\n",
       " ('‚ãä', 'Œ∏', 'r', ' å', 's', 's'): 3.9217159748077393,\n",
       " ('‚ãä', 'Œ∏', 'r', ' å', 's', 's', '‚ãâ'): 3.872938871383667}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between successive queries (of increasing prefix lengths):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0165729522705078,\n",
       " 1.0398609638214111,\n",
       " 0.4873030185699463,\n",
       " 0.5812909603118896,\n",
       " 0.6410520076751709,\n",
       " -0.048777103424072266]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean difference:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6195504665374756"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time/segment:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15563607215881348,\n",
       " 0.5861045122146606,\n",
       " 0.7373566627502441,\n",
       " 0.6748432517051697,\n",
       " 0.6561327934265136,\n",
       " 0.6536193291346232,\n",
       " 0.5532769816262382]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean time/segment:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5738528004308947"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import statistics\n",
    "\n",
    "def timeCall(thunk):\n",
    "    timeStart = time.time()\n",
    "    result = thunk()\n",
    "    timeEnd = time.time()\n",
    "    timePassed = timeEnd - timeStart\n",
    "    return timePassed\n",
    "\n",
    "\n",
    "times = dict()\n",
    "for eachPrefix in testPrefixes:\n",
    "#     print(eachPrefix)\n",
    "#     results[eachPrefix] = total_model['est_channelInput_prob'](eachPrefix, eachPrefix)\n",
    "    times[eachPrefix] = timeCall(lambda: total_model['est_channelInput_prob'](eachPrefix, eachPrefix))\n",
    "#     print('{0}: {1}'.format(eachPrefix, times[eachPrefix]))\n",
    "print('times:')\n",
    "times\n",
    "timeValues = [times[eachPrefix] for eachPrefix in testPrefixes]\n",
    "\n",
    "print('difference between successive queries (of increasing prefix lengths):')\n",
    "diffs = [trial_next_time - trial_time for trial_time, trial_next_time in zip(timeValues, timeValues[1:])]\n",
    "diffs\n",
    "print('mean difference:')\n",
    "statistics.mean(diffs)\n",
    "\n",
    "print('time/segment:')\n",
    "timePerSegment = [times[eachPrefix] / (1.0 * len(eachPrefix)) for eachPrefix in testPrefixes]\n",
    "timePerSegment\n",
    "print('mean time/segment:')\n",
    "statistics.mean(timePerSegment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to calculate $p(\\hat{X}_0^f = s|X_0^f = s)$ as the size of the lexicon grows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T23:52:24.354533Z",
     "start_time": "2018-03-31T23:52:23.580370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "51376"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['channelOutput_i_dist',\n",
       " 'channelOutput_i_marginal_dist',\n",
       " 'channelOutput_prefix_marginal_prob',\n",
       " 'channelOutput_prefix_prob',\n",
       " 'channelOutput_prefix_sampler',\n",
       " 'est_channelInput_prob',\n",
       " 'inputAlphabet',\n",
       " 'inputDist',\n",
       " 'inputDist_givenPrefix',\n",
       " 'inputs',\n",
       " 'p(X_0^f | x_0^i)',\n",
       " 'p(X_0^f)',\n",
       " 'p(Y_i)',\n",
       " 'p(Y_i|x_i)',\n",
       " 'p(x_0^i)',\n",
       " 'p(x_{i+1}^f | x_0^i)',\n",
       " 'p(y_0^i)',\n",
       " 'p(y_0^i|x_0^i)',\n",
       " 'p-hat(x-hat_0^j|x_0^i)',\n",
       " 'prefixProb',\n",
       " 'prefixes',\n",
       " 'sample from p(Y_0^i|x_0^i)',\n",
       " 'suffixProb']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first we want to restore the input distribution to the full one we imported...\n",
    "\n",
    "len(inputDist) #current input distribution\n",
    "len(lexicon_actual) #reference to the originally imported lexicon\n",
    "inputDist = lexicon_actual\n",
    "new_total_model = generateTotalModel(inputDist, channelOutput_i_dist, pad_with_boundaries = False)\n",
    "# new_total_model\n",
    "sorted(new_total_model.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across $m$ $n$-word sublexicons of the actual lexicon, what is the average time to make $k$ random queries of $p(\\hat{X}_0^f = s|X_0^f = s)$ and where $s$ is chosen from a uniform distribution over words in the lexicon? Let's start with $m=3$ and $k=10$ and let $n$ vary over $\\{10, 100, 1000, 10000, 20000, 40000\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-01T00:58:37.729966Z",
     "start_time": "2018-04-01T00:09:38.634258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken (s) for 10 queries: 42.809144020080566\n",
      "Time taken (s) for 10 queries: 54.05713701248169\n",
      "Time taken (s) for 10 queries: 62.51040315628052\n",
      "Mean time (over 3 sublexicons) to make 10 queries over a 10-word sublexicon: 53.12556139628092\n",
      "Time taken (s) for 10 queries: 103.55769801139832\n",
      "Time taken (s) for 10 queries: 99.49169898033142\n",
      "Time taken (s) for 10 queries: 101.20855593681335\n",
      "Mean time (over 3 sublexicons) to make 10 queries over a 100-word sublexicon: 101.4193176428477\n",
      "Time taken (s) for 10 queries: 442.6917288303375\n",
      "Time taken (s) for 10 queries: 557.3850648403168\n",
      "Time taken (s) for 10 queries: 492.1795291900635\n",
      "Mean time (over 3 sublexicons) to make 10 queries over a 1000-word sublexicon: 497.41877428690594\n",
      "Time taken (s) for 10 queries: 64854.661350011826\n",
      "Time taken (s) for 10 queries: 4353.231388092041\n",
      "Time taken (s) for 10 queries: 5082.366680145264\n",
      "Mean time (over 3 sublexicons) to make 10 queries over a 10000-word sublexicon: 24763.419806083042\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     }\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollectTimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_k\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_ns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     }\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollectTimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_k\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_ns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36mcollectTimes\u001b[0;34m(m, n, k)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mrandom_sublexicons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetLexiconSampleOfSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenMatchingModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_sublexicons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mmean_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean time (over {0} sublexicons) to make {1} queries over a {2}-word sublexicon: {3}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mrandom_sublexicons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetLexiconSampleOfSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenMatchingModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_sublexicons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mmean_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean time (over {0} sublexicons) to make {1} queries over a {2}-word sublexicon: {3}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36mgetTime\u001b[0;34m(model, a_k_val)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtimeStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmakeQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmakeRandomQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmakeQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtimeEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtimeTaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeEnd\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimeStart\u001b[0m \u001b[0;31m#seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtimeStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmakeQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmakeRandomQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmakeQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtimeEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtimeTaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeEnd\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimeStart\u001b[0m \u001b[0;31m#seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_k_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtimeStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmakeQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmakeRandomQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmakeQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_k_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtimeEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-0a0708517d8e>\u001b[0m in \u001b[0;36mmakeRandomQuery\u001b[0;34m(a_total_model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# print('Starting query for {0}'.format(ds))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtimeStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_total_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p-hat(x-hat_0^j|x_0^i)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtimeEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtimeTaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeEnd\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimeStart\u001b[0m \u001b[0;31m#seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3b605e82bde3>\u001b[0m in \u001b[0;36mest_channelInput_prob\u001b[0;34m(true_inputPrefix, poss_inputPrefix, num_samples)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m#     print(terms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#         est = sum(terms) / num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3b605e82bde3>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#terms in \\sum_{samples y_0^i from p(Y_0^i|x_0^i)} p(y_0^i|x-hat_0^i) * p(x-hat_0^j) / p(y_0^i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#         terms = (model['channelOutput_prefix_prob'](poss_inputPrefix, outputPrefix)  * poss_inputPrefix_prob / model['channelOutput_prefix_marginal_prob'](outputPrefix) for outputPrefix in samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channelOutput_prefix_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposs_inputPrefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channelOutput_prefix_marginal_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mposs_inputPrefix_prob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channelOutput_prefix_marginal_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutputPrefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;31m#     for outputPrefix in samples:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m#       print('y_0^i: {0}'.format(outputPrefix))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5c2b3bf9e7b3>\u001b[0m in \u001b[0;36mchannelOutput_prefix_marginal_prob\u001b[0;34m(outputPrefix)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m#     print('terms of \\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i):')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#     print(probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p(y_0^i)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannelOutput_prefix_marginal_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channelOutput_prefix_marginal_prob'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannelOutput_prefix_marginal_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5c2b3bf9e7b3>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#\\sum_{X_0^i} p(x_0^i) * p(y_0^i|x_0^i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prefixProb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannelOutput_prefix_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_prefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_prefixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m#     probs = (prefixProb(input_prefix) * channelOutput_prefix_prob(input_prefix, outputPrefix) for input_prefix in my_prefixes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5c2b3bf9e7b3>\u001b[0m in \u001b[0;36mchannelOutput_prefix_prob\u001b[0;34m(inputPrefix, outputPrefix)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#             slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist(x_i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mslice_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannelOutput_i_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#truncate excess part of inputPrefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                   \u001b[0;31m#|y_0^j|     <      |x_0^i|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ef97d726618d>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5c2b3bf9e7b3>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#             slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist(x_i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mslice_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannelOutput_i_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#truncate excess part of inputPrefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                   \u001b[0;31m#|y_0^j|     <      |x_0^i|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5c2b3bf9e7b3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(y_i, x_i)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#         |y_0^j|    ==      |x_0^i|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#             slice_prob = lambda y_i, x_i: P({y_i}, channelOutput_i_dist(x_i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mslice_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannelOutput_i_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPrefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputPrefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#truncate excess part of inputPrefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ef97d726618d>\u001b[0m in \u001b[0;36mP\u001b[0;34m(event, space)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuch_that\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbDist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspace\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ef97d726618d>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuch_that\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbDist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspace\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_m = 3\n",
    "my_k = 10\n",
    "my_ns = [10, 100, 1000, 10000, 20000, 40000]\n",
    "\n",
    "def getLexiconSampleOfSize(full_lexicon, n):\n",
    "    some_entries = random.sample(phonWords, n) #sample n words without replacement from the lexicon\n",
    "    newLexicon = ProbDist({w:full_lexicon[w] for w in some_entries})\n",
    "    return newLexicon\n",
    "\n",
    "def genMatchingModel(random_sublexicon):\n",
    "    model = generateTotalModel(random_sublexicon, channelOutput_i_dist, pad_with_boundaries = False)\n",
    "    return model\n",
    "\n",
    "def makeRandomQuery(a_total_model):\n",
    "    random_word = random.choice(a_total_model['inputs'])\n",
    "    ds = tupleToDottedString(random_word)\n",
    "    # print('Starting query for {0}'.format(ds))\n",
    "    timeStart = time.time()\n",
    "    query_result = a_total_model['p-hat(x-hat_0^j|x_0^i)'](random_word, random_word)\n",
    "    timeEnd = time.time()\n",
    "    timeTaken = timeEnd - timeStart #seconds\n",
    "    # print('Finished query. Time taken (s): {0}'.format(timeTaken))\n",
    "    return (random_word, query_result, timeTaken)\n",
    "\n",
    "def getTime(model, a_k_val):\n",
    "    timeStart = time.time()\n",
    "    makeQuery = lambda: makeRandomQuery(model)\n",
    "    queries = [makeQuery() for each in range(a_k_val)]\n",
    "    timeEnd = time.time()\n",
    "    timeTaken = timeEnd - timeStart #seconds\n",
    "    print('Time taken (s) for {0} queries: {1}'.format(a_k_val, timeTaken))\n",
    "    return timeTaken\n",
    "\n",
    "def collectTimes(m, n, k):\n",
    "    parameters = {'m':m, 'n':n, 'k':k}\n",
    "    random_sublexicons = list(getLexiconSampleOfSize(inputDist, n) for each in range(m))\n",
    "    models = list(map(genMatchingModel, random_sublexicons))\n",
    "    times = list(map(lambda model: getTime(model, k), models))\n",
    "    mean_time = statistics.mean(times)\n",
    "    print('Mean time (over {0} sublexicons) to make {1} queries over a {2}-word sublexicon: {3}'.format(m, k, n, mean_time))\n",
    "    return {\n",
    "        'parameters':parameters, \n",
    "        'sublexicons':random_sublexicons, \n",
    "        'models':models, \n",
    "        'times':times, \n",
    "        'mean time':mean_time\n",
    "    }\n",
    "\n",
    "observations = [collectTimes(my_m, each_n, my_k) for each_n in my_ns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Jupyter is buggy and slow; when corresponding code is run *outside* of a notebook, the mean time to make 10 queries is somewhere between 45-65 seconds no matter how large the (sub)lexicons in question are.)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "188px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
