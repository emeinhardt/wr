{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:37.769334Z",
     "start_time": "2019-08-11T05:05:37.764280Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook author:** emeinhardt@ucsd.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Requirements</a></span></li><li><span><a href=\"#Usage\" data-toc-modified-id=\"Usage-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Usage</a></span></li><li><span><a href=\"#Watermark\" data-toc-modified-id=\"Watermark-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Watermark</a></span></li></ul></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Imports-/-load-data\" data-toc-modified-id=\"Imports-/-load-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Imports / load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load/extract-sanity-checking-data\" data-toc-modified-id=\"Load/extract-sanity-checking-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Load/extract sanity-checking data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Segmental-lexicon,-prefixes,-inventory,-and-triphones\" data-toc-modified-id=\"Segmental-lexicon,-prefixes,-inventory,-and-triphones-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Segmental lexicon, prefixes, inventory, and triphones</a></span></li><li><span><a href=\"#Triphone-channel-distribution-and-channel-alphabet\" data-toc-modified-id=\"Triphone-channel-distribution-and-channel-alphabet-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Triphone channel distribution and channel alphabet</a></span></li><li><span><a href=\"#Preview-and-postview-distributions-and-alphabets\" data-toc-modified-id=\"Preview-and-postview-distributions-and-alphabets-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Preview and postview distributions and alphabets</a></span></li><li><span><a href=\"#Corpus-contexts\" data-toc-modified-id=\"Corpus-contexts-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Corpus contexts</a></span></li><li><span><a href=\"#Conversion-to-one-hot-vectors-/-sequences-thereof\" data-toc-modified-id=\"Conversion-to-one-hot-vectors-/-sequences-thereof-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>Conversion to one-hot vectors / sequences thereof</a></span></li></ul></li><li><span><a href=\"#Load-segmental-sequence-channel-matrices-$p(Y_0^k|X_0^k)$-and-$p(Y_0^f|X_0^f)$\" data-toc-modified-id=\"Load-segmental-sequence-channel-matrices-$p(Y_0^k|X_0^k)$-and-$p(Y_0^f|X_0^f)$-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Load segmental sequence channel matrices $p(Y_0^k|X_0^k)$ and $p(Y_0^f|X_0^f)$</a></span></li><li><span><a href=\"#Load-contextual-distribution-on-segmental-wordforms-$p(W|C)$\" data-toc-modified-id=\"Load-contextual-distribution-on-segmental-wordforms-$p(W|C)$-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Load contextual distribution on segmental wordforms $p(W|C)$</a></span></li><li><span><a href=\"#Load-lexicon-metadata\" data-toc-modified-id=\"Load-lexicon-metadata-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Load lexicon metadata</a></span></li></ul></li><li><span><a href=\"#Slow,-but-sanity-checking-calculations\" data-toc-modified-id=\"Slow,-but-sanity-checking-calculations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Slow, but sanity-checking calculations</a></span><ul class=\"toc-item\"><li><span><a href=\"#$p(C_0^i-|-X_0^i;-X_{i+1})$\" data-toc-modified-id=\"$p(C_0^i-|-X_0^i;-X_{i+1})$-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>$p(C_0^i | X_0^i; X_{i+1})$</a></span></li><li><span><a href=\"#$p(Y_0^i|X_0^k)$\" data-toc-modified-id=\"$p(Y_0^i|X_0^k)$-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>$p(Y_0^i|X_0^k)$</a></span></li><li><span><a href=\"#$p(X_0^f|C)$\" data-toc-modified-id=\"$p(X_0^f|C)$-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>$p(X_0^f|C)$</a></span></li><li><span><a href=\"#$p(Y_0^i-|-c)$\" data-toc-modified-id=\"$p(Y_0^i-|-c)$-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>$p(Y_0^i | c)$</a></span></li><li><span><a href=\"#$p(Y_0^i|x_0^k)$-sampler\" data-toc-modified-id=\"$p(Y_0^i|x_0^k)$-sampler-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>$p(Y_0^i|x_0^k)$ sampler</a></span></li><li><span><a href=\"#$p(\\widehat{X_0^f}|Y_0^{i},-C)$\" data-toc-modified-id=\"$p(\\widehat{X_0^f}|Y_0^{i},-C)$-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>$p(\\widehat{X_0^f}|Y_0^{i}, C)$</a></span></li><li><span><a href=\"#$\\widehat{p}(\\widehat{X_0^f}|X_0^i;X_{i+1},-C)$\" data-toc-modified-id=\"$\\widehat{p}(\\widehat{X_0^f}|X_0^i;X_{i+1},-C)$-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>$\\widehat{p}(\\widehat{X_0^f}|X_0^i;X_{i+1}, C)$</a></span></li></ul></li><li><span><a href=\"#Definition-of-core-calculation\" data-toc-modified-id=\"Definition-of-core-calculation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Definition of core calculation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Channel-sampler\" data-toc-modified-id=\"Channel-sampler-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Channel sampler</a></span></li><li><span><a href=\"#Sample-parallel-posterior-estimator\" data-toc-modified-id=\"Sample-parallel-posterior-estimator-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Sample-parallel posterior estimator</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Testing</a></span></li><li><span><a href=\"#Parallelization-over-samples-and-contexts\" data-toc-modified-id=\"Parallelization-over-samples-and-contexts-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Parallelization over samples and contexts</a></span></li><li><span><a href=\"#Exact/full-wordform-length-variant-functions\" data-toc-modified-id=\"Exact/full-wordform-length-variant-functions-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Exact/full wordform-length variant functions</a></span></li><li><span><a href=\"#Calculation-volume-organization-for-Case-1\" data-toc-modified-id=\"Calculation-volume-organization-for-Case-1-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Calculation volume organization for Case 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Slices:-Calculate-results-for-groups-of-reconstructed-wordforms-by-(input-prefix,-context)\" data-toc-modified-id=\"Slices:-Calculate-results-for-groups-of-reconstructed-wordforms-by-(input-prefix,-context)-5.6.1\"><span class=\"toc-item-num\">5.6.1&nbsp;&nbsp;</span>Slices: Calculate results for groups of reconstructed wordforms by (input prefix, context)</a></span></li><li><span><a href=\"#Blocks:-Calculate-results-for-groups-of-input-prefixes-by-context\" data-toc-modified-id=\"Blocks:-Calculate-results-for-groups-of-input-prefixes-by-context-5.6.2\"><span class=\"toc-item-num\">5.6.2&nbsp;&nbsp;</span>Blocks: Calculate results for groups of input prefixes by context</a></span></li></ul></li><li><span><a href=\"#Calculation-volume-organization-2\" data-toc-modified-id=\"Calculation-volume-organization-2-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Calculation volume organization 2</a></span></li><li><span><a href=\"#Calculation-volume-organization-3\" data-toc-modified-id=\"Calculation-volume-organization-3-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Calculation volume organization 3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Slices:-Calculate-$\\{p(\\widehat{W}-=-w^*-|-W-=-w^*,-C-=-c)\\}$-for-all-$W$-and-for-a-single-given-$c$\" data-toc-modified-id=\"Slices:-Calculate-$\\{p(\\widehat{W}-=-w^*-|-W-=-w^*,-C-=-c)\\}$-for-all-$W$-and-for-a-single-given-$c$-5.8.1\"><span class=\"toc-item-num\">5.8.1&nbsp;&nbsp;</span>Slices: Calculate $\\{p(\\widehat{W} = w^* | W = w^*, C = c)\\}$ for all $W$ and for a single given $c$</a></span></li><li><span><a href=\"#Slices:-Calculate-$\\{p(\\widehat{W}-=-w^*-|-W-=-w^*,-C-=-c)\\}$-for-all-$c$\" data-toc-modified-id=\"Slices:-Calculate-$\\{p(\\widehat{W}-=-w^*-|-W-=-w^*,-C-=-c)\\}$-for-all-$c$-5.8.2\"><span class=\"toc-item-num\">5.8.2&nbsp;&nbsp;</span>Slices: Calculate $\\{p(\\widehat{W} = w^* | W = w^*, C = c)\\}$ for all $c$</a></span></li></ul></li></ul></li><li><span><a href=\"#Calculate-distribution\" data-toc-modified-id=\"Calculate-distribution-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Calculate distribution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-calculations-necessary-under-different-calculation-criteria\" data-toc-modified-id=\"Number-of-calculations-necessary-under-different-calculation-criteria-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Number of calculations necessary under different calculation criteria</a></span></li><li><span><a href=\"#Determine-dimensions-and-cells-to-be-calculated-vs.-ignored\" data-toc-modified-id=\"Determine-dimensions-and-cells-to-be-calculated-vs.-ignored-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Determine dimensions and cells to be calculated vs. ignored</a></span><ul class=\"toc-item\"><li><span><a href=\"#Option:-Only-calculate-full-source-wordforms-rather-than-all-source-prefixes?\" data-toc-modified-id=\"Option:-Only-calculate-full-source-wordforms-rather-than-all-source-prefixes?-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Option: Only calculate full source wordforms rather than all source prefixes?</a></span></li><li><span><a href=\"#Suboption:-Given-$\\neg-r$-and-a-full-source-wordform-$w^*$,-only-calculate-posterior-probability-$p(\\widehat{W}-=-w^*-|-W-=-w^*,-C-=-c)$,-$\\forall-w^*$?\" data-toc-modified-id=\"Suboption:-Given-$\\neg-r$-and-a-full-source-wordform-$w^*$,-only-calculate-posterior-probability-$p(\\widehat{W}-=-w^*-|-W-=-w^*,-C-=-c)$,-$\\forall-w^*$?-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Suboption: Given $\\neg r$ and a full source wordform $w^*$, only calculate posterior probability $p(\\widehat{W} = w^* | W = w^*, C = c)$, $\\forall w^*$?</a></span></li><li><span><a href=\"#Suboption:-Restrict-calculations-only-to-(source-sequence,-reconstruction-sequence)-pairs-within-edit-distance-$k$?\" data-toc-modified-id=\"Suboption:-Restrict-calculations-only-to-(source-sequence,-reconstruction-sequence)-pairs-within-edit-distance-$k$?-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Suboption: Restrict calculations only to (source sequence, reconstruction sequence) pairs within edit distance $k$?</a></span></li><li><span><a href=\"#Altogether...\" data-toc-modified-id=\"Altogether...-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Altogether...</a></span></li></ul></li><li><span><a href=\"#Case-1:-$r-\\land-(0-<-k-\\leq-4)$\" data-toc-modified-id=\"Case-1:-$r-\\land-(0-<-k-\\leq-4)$-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Case 1: $r \\land (0 &lt; k \\leq 4)$</a></span></li><li><span><a href=\"#Case-2:-$\\neg-r-\\land-(0-<-k-\\leq-4)-\\land-\\neg-e$\" data-toc-modified-id=\"Case-2:-$\\neg-r-\\land-(0-<-k-\\leq-4)-\\land-\\neg-e$-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Case 2: $\\neg r \\land (0 &lt; k \\leq 4) \\land \\neg e$</a></span></li><li><span><a href=\"#Case-3:-$\\neg-r-\\land-e$\" data-toc-modified-id=\"Case-3:-$\\neg-r-\\land-e$-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Case 3: $\\neg r \\land e$</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a choice of parameters $\\epsilon$ and $n$, and given\n",
    " - wordform channel matrices $p(Y_0^f|X_0^f)$\n",
    " - a contextual distribution on segmental wordforms $p(X_0^f|C)$\n",
    " - segmental lexicon metadata pre-calculating $k$-cousins/$k$-spheres up to $k=4$\n",
    " \n",
    "Calculate\n",
    "\n",
    "$$\\hat{p}(\\hat{X}_0^f = x_0^{'f}|X_0^f = x_0^{*f}, c) = \\frac{1}{n} \\sum\\limits_{y_0^f \\in S} p(\\hat{X}_0^f = x_0^{'f}|y_0^f, c)$$\n",
    " where \n",
    "  - edit distance $d(x_0^{'f}, x_0^{*f}) \\leq 4$\n",
    "  - $S = $ a set of $n$ samples from $p(Y_0^f|x_0^{*f})$. In practice an $n \\approx 50$ seems to result in estimates that are within $10^{-6}$ of the true estimate. \n",
    "  - $p(\\hat{X}_0^f = x_0^{'f}|Y_0^f = y_0^f, c) = \\frac{p(y_0^f|x_0^{'f})p(x_0^{'f}|c)}{p(y_0^f | c)}$\n",
    "  - $p(y_0^f| c) = \\sum\\limits_{v', x_0^{''f}} p(y_0^f|x_0^{''f})p(x_0^{''f}|v')p(v'|c) = \\sum\\limits_{x_0^{''f}} p(y_0^f|x_0^{''f})p(x_0^{''f}|c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:38.317402Z",
     "start_time": "2019-08-11T05:05:37.796929Z"
    }
   },
   "outputs": [],
   "source": [
    "import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:38.320586Z",
     "start_time": "2019-08-11T05:05:38.318485Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:38.657344Z",
     "start_time": "2019-08-11T05:05:38.321585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2019-08-10T22:05:38-07:00\n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.7.0\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-51-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n",
      "host name  : kotoba\n",
      "Git hash   : 9d300bff690d71c35cc28349b42bba9e7e61a15d\n"
     ]
    }
   ],
   "source": [
    "%watermark -ihmuvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:38.877305Z",
     "start_time": "2019-08-11T05:05:38.663948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              12\r\n",
      "On-line CPU(s) list: 0-11\r\n",
      "Thread(s) per core:  2\r\n",
      "Core(s) per socket:  6\r\n",
      "Socket(s):           1\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               158\r\n",
      "Model name:          Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\r\n",
      "Stepping:            10\r\n",
      "CPU MHz:             800.368\r\n",
      "CPU max MHz:         4600.0000\r\n",
      "CPU min MHz:         800.0000\r\n",
      "BogoMIPS:            6384.00\r\n",
      "Virtualization:      VT-x\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            256K\r\n",
      "L3 cache:            12288K\r\n",
      "NUMA node0 CPU(s):   0-11\r\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:38.992163Z",
     "start_time": "2019-08-11T05:05:38.882741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        3.4G         27G        8.2M        430M         27G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:39.123577Z",
     "start_time": "2019-08-11T05:05:38.997619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:        410.104\r\n",
      "srcversion:     3B812B02678A6B43A294F17\r\n"
     ]
    }
   ],
   "source": [
    "!modinfo nvidia | grep version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:39.155276Z",
     "start_time": "2019-08-11T05:05:39.129081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/AD/emeinhar/wr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:39.262872Z",
     "start_time": "2019-08-11T05:05:39.159637Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import getcwd, chdir, listdir, path, mkdir, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:40.667541Z",
     "start_time": "2019-08-11T05:05:39.268770Z"
    }
   },
   "outputs": [],
   "source": [
    "from boilerplate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:40.679090Z",
     "start_time": "2019-08-11T05:05:40.671884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/AD/emeinhar/wr'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_dir = getcwd(); repo_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:40.827990Z",
     "start_time": "2019-08-11T05:05:40.681930Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "#p(Y_0^k|X_0^k) - from step 4e\n",
    "c = ''\n",
    "# c = 'CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/LTR_Buckeye_aligned_CM_filtered_LM_filtered_CMs_by_length_by_prefix_index.pickle'\n",
    "c = 'CM_AmE_destressed_aligned_w_LTR_newdic_destressed_pseudocount0.01/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_CMs_by_length_by_wordform_index.pickle'\n",
    "\n",
    "#p(Y_0^f|X_0^f) - from step 4e\n",
    "f = ''\n",
    "f = 'CM_AmE_destressed_aligned_w_LTR_newdic_destressed_pseudocount0.01/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_exact_CMs_by_length_by_wordform_index.pickle'\n",
    "\n",
    "#p(X_0^f|C) - from step 4c\n",
    "w = ''\n",
    "# w = 'LD_Fisher_vocab_in_Buckeye_contexts/LTR_Buckeye_aligned_CM_filtered_LM_filtered_in_buckeye_contexts.pW_C.npy'\n",
    "w = 'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_C.npy'\n",
    "\n",
    "# LTR metadata directory - contains pre-computed k-cousin/k-sphere information\n",
    "m = ''\n",
    "# m = 'LTR_Buckeye_aligned_w_GD_AmE_destressed'\n",
    "m = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed'\n",
    "\n",
    "# output filepath prefix for pW_WC\n",
    "o = ''\n",
    "# o = 'LD_Fisher_vocab_in_Buckeye_contexts/LTR_Buckeye_aligned_CM_filtered_LM_filtered_in_buckeye_contexts.pW_WC'\n",
    "# o = 'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC'\n",
    "o = 'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts'\n",
    "\n",
    "# for sanity checking...\n",
    "\n",
    "# the sorted prefixes of W here correspond to the W dimension of file 'w'\n",
    "p = ''\n",
    "# p = 'LTR_Buckeye_aligned_w_GD_AmE_destressed/LTR_Buckeye_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "p = 'LTR_newdic_destressed_aligned_w_GD_AmE_destressed/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered.pW_V.json'\n",
    "\n",
    "# the sorted conditioning triphones and outcome response uniphones correspond to\n",
    "# the dimensions of file 'c'\n",
    "t = ''\n",
    "# t = 'CM_AmE_destressed_aligned_w_LTR_Buckeye_pseudocount0.01/LTR_Buckeye_aligned_CM_filtered_LM_filtered_pY1X0X1X2.json'\n",
    "t = 'CM_AmE_destressed_aligned_w_LTR_newdic_destressed_pseudocount0.01/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_p3Y1X012.json'\n",
    "\n",
    "# the sorted projected contexts here correspond to the C dimension of file 'w'\n",
    "s = ''\n",
    "# s = 'LD_Fisher_vocab_in_Buckeye_contexts/LM_filtered_buckeye_contexts.txt'\n",
    "s = 'LD_Fisher_vocab_in_swbd2003_contexts/LM_filtered_swbd2003_contexts.txt'\n",
    "\n",
    "\n",
    "# if True, then run notebook 'benchmark' cells\n",
    "x = ''\n",
    "\n",
    "# if True, then don't recalculate anything that's been calcualted already...\n",
    "d = ''\n",
    "d = 'True'\n",
    "# d = 'False'\n",
    "\n",
    "# calculation parameters\n",
    "\n",
    "#samples per (reconstructed target wordform, source prefix, context) triple\n",
    "n = ''\n",
    "n = '50'\n",
    "\n",
    "#maximum edit distance for reconstructed target, source prefix 'cousins' to calculate\n",
    "k = ''\n",
    "k = '2'\n",
    "\n",
    "#batch size - currently only interpretable/used for case 3 (see below)\n",
    "# if using a GPU with around 8GB of memory, use a batch size < 300\n",
    "# if using a CPU and parallelizing, use a larger batch size (500-750).\n",
    "# In either case, using all available memory will *not* in general\n",
    "# maximize performance.\n",
    "b = ''\n",
    "b = '250'\n",
    "\n",
    "#parallelize batches over processes?\n",
    "l = ''\n",
    "l = 'True'\n",
    "\n",
    "#use GPU? (overrides parallelize option)\n",
    "g = ''\n",
    "g = 'True'\n",
    "\n",
    "#if 'False', only calculate p(\\hat{W}|W = w, c), i.e. don't calculate p(\\hat{W}|P = p, c)\n",
    "r = ''\n",
    "r = 'False' \n",
    "\n",
    "#if r='False' and e='True', only calculate p(\\hat{W} = w*| W = w*, c) ∀w ∈ W\n",
    "e = ''\n",
    "e = 'True' \n",
    "\n",
    "#the (optional) beginning and end of the block of complete wordforms this notebook should calculate\n",
    "wStart = ''\n",
    "wEnd = ''\n",
    "# wStart = '0'\n",
    "# wEnd = '2'\n",
    "\n",
    "#the (optional) beginning and end of the block of contexts this notebook should calculate\n",
    "# cStart = ''\n",
    "# cEnd = ''\n",
    "# cStart = '0'\n",
    "# cEnd = '10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.113044Z",
     "start_time": "2019-08-11T05:05:40.829190Z"
    }
   },
   "outputs": [],
   "source": [
    "file_params = (c, f, w, m, p, t, s)\n",
    "for fp in file_params:\n",
    "    if not path.exists(fp):\n",
    "        print(f\"Parameter path does not exist: {fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.133039Z",
     "start_time": "2019-08-11T05:05:41.117849Z"
    }
   },
   "outputs": [],
   "source": [
    "if x == '' or x == 'False' or x == False:\n",
    "    benchmark = False\n",
    "elif x == 'True' or x == True:\n",
    "    benchmark = True\n",
    "else:\n",
    "    raise Exception(f\"x arg must be one of {'', 'True', 'False'}, got {x} instead, with type ={type(x)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.222819Z",
     "start_time": "2019-08-11T05:05:41.138073Z"
    }
   },
   "outputs": [],
   "source": [
    "if d == '' or d == 'True' or d == True:\n",
    "    d = True\n",
    "elif d == 'False' or d == False:\n",
    "    d = False\n",
    "else:\n",
    "    raise Exception(f\"d arg must be one of {'', 'True', 'False'}, got {d} instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.298987Z",
     "start_time": "2019-08-11T05:05:41.226594Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = path.dirname(o)\n",
    "if not path.exists(output_dir):\n",
    "    print('Making output path {0}'.format(output_dir))\n",
    "    makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.379907Z",
     "start_time": "2019-08-11T05:05:41.303808Z"
    }
   },
   "outputs": [],
   "source": [
    "if n == '':\n",
    "    n = 50\n",
    "else:\n",
    "    n = int(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.457028Z",
     "start_time": "2019-08-11T05:05:41.384874Z"
    }
   },
   "outputs": [],
   "source": [
    "if k == '':\n",
    "    k = 2\n",
    "else:\n",
    "    k = int(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.532622Z",
     "start_time": "2019-08-11T05:05:41.461596Z"
    }
   },
   "outputs": [],
   "source": [
    "if b == '':\n",
    "    b = None\n",
    "else:\n",
    "    b = int(b)\n",
    "    \n",
    "assert 0 < b, f\"Batch size argument b = {b} must be greater than 0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.613395Z",
     "start_time": "2019-08-11T05:05:41.537301Z"
    }
   },
   "outputs": [],
   "source": [
    "if l == '' or l == 'True' or l == True:\n",
    "    l = True\n",
    "elif l == 'False' or l == False:\n",
    "    l = False\n",
    "else:\n",
    "    raise Exception(f\"l must be one of {'', 'True', 'False'}, got {l} instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.707345Z",
     "start_time": "2019-08-11T05:05:41.617989Z"
    }
   },
   "outputs": [],
   "source": [
    "if g == '' or g == 'True' or g == True:\n",
    "    g = True\n",
    "elif g == 'False' or g == False:\n",
    "    g = False\n",
    "else:\n",
    "    raise Exception(f\"g must be one of {'', 'True', 'False'}, got {g} instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.824150Z",
     "start_time": "2019-08-11T05:05:41.711854Z"
    }
   },
   "outputs": [],
   "source": [
    "if r == '' or r == 'False' or r == False:\n",
    "    r = False\n",
    "#     raise Exception('Assuming only full wordforms have been produced is not supported currently.')\n",
    "elif r == 'True' or r == True:\n",
    "    r = True\n",
    "else:\n",
    "    raise Exception(f\"r must be one of {'','True','False'}, got '{r}' instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:41.905436Z",
     "start_time": "2019-08-11T05:05:41.828779Z"
    }
   },
   "outputs": [],
   "source": [
    "if not r and (e == '' or e == 'True' or e == True):\n",
    "    e = True\n",
    "#     raise Exception('Only calculating the posterior probability of the actual (correct) full intended wordform is not supported currently.')\n",
    "elif r and (e == '' or e == 'True' or e == True):\n",
    "    raise Exception(\"e can only be True if r is False\")\n",
    "elif e == 'False' or e == False:\n",
    "    e = False\n",
    "else:\n",
    "    raise Exception(f\"e must be one of {'','True','False'}, got '{e}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:42.040247Z",
     "start_time": "2019-08-11T05:05:41.921379Z"
    }
   },
   "outputs": [],
   "source": [
    "if b is not None:\n",
    "    if r:\n",
    "        raise Exception(f'batch size b = {b} only currently interpretable and supported when r is False and e is True.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:42.129490Z",
     "start_time": "2019-08-11T05:05:42.048805Z"
    }
   },
   "outputs": [],
   "source": [
    "# postview_fp = path.join(path.dirname(t), \"p6Y0X01.json\"); postview_fp\n",
    "\n",
    "# preview_fp = path.join(path.dirname(t), \"p3Y1X01.json\"); preview_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:42.215340Z",
     "start_time": "2019-08-11T05:05:42.135231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No wEnd provided. Will be set to 1 less than the length of the number of contexts in the metadata.\n"
     ]
    }
   ],
   "source": [
    "# cStart = int(cStart)\n",
    "# cEnd = int(cEnd)\n",
    "\n",
    "# assert cStart <= cEnd, f\"First context id of block to calculate be <= the context id of the end of the block, got {cStart} and {cEnd} instead.\"\n",
    "\n",
    "if wStart == '':\n",
    "    wStart = 0\n",
    "else:\n",
    "    wStart = int(wStart)\n",
    "if wEnd == '':\n",
    "    wEnd = None\n",
    "    print('No wEnd provided. Will be set to 1 less than the length of the number of contexts in the metadata.')\n",
    "else:\n",
    "    wEnd = int(wEnd)\n",
    "\n",
    "if wEnd is not None:\n",
    "    assert wStart <= wEnd, f\"First word id of block to calculate must be <= the word id of the end of the block, got {wStart} and {wEnd} instead.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:42.304944Z",
     "start_time": "2019-08-11T05:05:42.221605Z"
    }
   },
   "outputs": [],
   "source": [
    "consolidation_enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports / load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:42.396537Z",
     "start_time": "2019-08-11T05:05:42.310384Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:50.731637Z",
     "start_time": "2019-08-11T05:05:42.397712Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy\n",
    "import torch\n",
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.157261Z",
     "start_time": "2019-08-11T05:05:50.736869Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiledb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.216094Z",
     "start_time": "2019-08-11T05:05:51.162121Z"
    }
   },
   "outputs": [],
   "source": [
    "from probdist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.428722Z",
     "start_time": "2019-08-11T05:05:51.220595Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_gui, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.432752Z",
     "start_time": "2019-08-11T05:05:51.429870Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "J = -1\n",
    "# J = 16\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def par(gen_expr):\n",
    "    return Parallel(n_jobs=J, backend=BACKEND, verbose=V, prefer=PREFER)(gen_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.554934Z",
     "start_time": "2019-08-11T05:05:51.433711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Disabling 'parallelize' flag...\n",
      "GeForce GTX 1080\n",
      "Total Memory: 8513.978368\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    if g and l:\n",
    "        print(\"Disabling 'parallelize' flag...\")\n",
    "        l = False\n",
    "    \n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    total_mem_MB = torch.cuda.get_device_properties(device).total_memory / 1e6\n",
    "    print('Total Memory: {0}'.format(total_mem_MB) )\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(torch.cuda.get_device_name(1))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(1)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_cached(1)/1024**3,1), 'GB')\n",
    "elif g:\n",
    "    print(\"g set to 'True', but torch cannot find a GPU. Setting g to 'False'.\")\n",
    "    g = False\n",
    "else:\n",
    "    pass\n",
    "#     raise Exception(f\"g set to 'True' but torch cannot find a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.682673Z",
     "start_time": "2019-08-11T05:05:51.559966Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "my_device = cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:51.780117Z",
     "start_time": "2019-08-11T05:05:51.687794Z"
    }
   },
   "outputs": [],
   "source": [
    "cuda_ft = torch.cuda.FloatTensor\n",
    "cuda_dt = torch.cuda.DoubleTensor\n",
    "\n",
    "ft = torch.FloatTensor\n",
    "dt = torch.DoubleTensor\n",
    "\n",
    "my_ft = ft\n",
    "my_dt = dt\n",
    "\n",
    "my_type = my_ft\n",
    "# my_type = my_dt\n",
    "\n",
    "torch.set_default_tensor_type(my_type)\n",
    "\n",
    "my_tt = torch.float32\n",
    "# my_tt = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/extract sanity-checking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to make queries, spot checks, and sanity checks. That means we want to be able to reference\n",
    " 1. the set of strings constituting segmental wordforms and prefixes\n",
    " 2. the source and channel alphabets\n",
    " 3. the channel distribution's conditioning triphones ∩ the triphones in the lexicon = the triphones in the lexicon\n",
    " 4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmental wordforms were necessary for \n",
    " - the lexicon metadata calculation (step 4b)\n",
    " - the contextual distribution on segmental wordforms (step 4c)\n",
    " - the definition of the segmental sequence channel matrices (step 4d)\n",
    " \n",
    "What does each use as input? (Pass that to this notebook.)\n",
    "\n",
    "Each notebook uses ...pW_V.json (or something slightly downstream of that)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmental lexicon, prefixes, inventory, and triphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:52.035695Z",
     "start_time": "2019-08-11T05:05:51.786302Z"
    }
   },
   "outputs": [],
   "source": [
    "pW_V = condDistsAsProbDists(importProbDist(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract \n",
    " - `orthographic vocabulary`\n",
    " - `segmental vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:52.703019Z",
     "start_time": "2019-08-11T05:05:52.036847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9411"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vs = set(pW_V.keys())\n",
    "Ws = union(mapValues(lambda dist: set(conditions(dist)), \n",
    "                     pW_V).values())\n",
    "len(Vs)\n",
    "len(Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:52.888716Z",
     "start_time": "2019-08-11T05:05:52.703967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{4: 5,\n",
       " 5: 173,\n",
       " 6: 1266,\n",
       " 7: 1790,\n",
       " 8: 1646,\n",
       " 9: 1328,\n",
       " 10: 1052,\n",
       " 11: 828,\n",
       " 12: 508,\n",
       " 13: 329,\n",
       " 14: 150,\n",
       " 15: 66,\n",
       " 16: 24,\n",
       " 17: 6,\n",
       " 19: 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengthsInclEdges = set(len(ds2t(w)) for w in Ws)\n",
    "wordlengthsInclEdges\n",
    "numWordsOfExactlyLength = {l:len(wordformsOfLength(l, Ws, True)) for l in wordlengthsInclEdges}\n",
    "numWordsOfExactlyLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:52.913277Z",
     "start_time": "2019-08-11T05:05:52.889697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordLengthRange = sorted(list(range(min(wordlengthsInclEdges),\n",
    "                                    max(wordlengthsInclEdges)+1)))\n",
    "wordLengthRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:53.068297Z",
     "start_time": "2019-08-11T05:05:52.914228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengthsNotIncludingEdges = {each-2 for each in wordlengthsInclEdges}\n",
    "wordlengthsNotIncludingEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:05:53.244562Z",
     "start_time": "2019-08-11T05:05:53.071881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 9172,\n",
       " 5: 9167,\n",
       " 6: 8994,\n",
       " 7: 7728,\n",
       " 8: 5938,\n",
       " 9: 4292,\n",
       " 10: 2964,\n",
       " 11: 1912,\n",
       " 12: 1084,\n",
       " 13: 576,\n",
       " 14: 247,\n",
       " 15: 97,\n",
       " 16: 31,\n",
       " 17: 7,\n",
       " 19: 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthFreqs = {l:len(wordformsAtLeastLlong(l, Ws, True)) for l in wordlengthsInclEdges}\n",
    "lengthFreqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mappings between `segmental wordforms` and `segmental prefixes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:00.128163Z",
     "start_time": "2019-08-11T05:05:53.245529Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9172/9172 [00:06<00:00, 1343.26it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79727"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_relation = set(union({(w,p) for p in getPrefixes(w)} for w in tqdm(Ws)))\n",
    "len(prefix_relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract \n",
    " - `segmental prefixes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:00.144270Z",
     "start_time": "2019-08-11T05:06:00.129277Z"
    }
   },
   "outputs": [],
   "source": [
    "Ps = set(map(lambda pair: pair[1],\n",
    "             prefix_relation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \n",
    " - `sorted` versions of the `segmental vocabulary` and `segmental prefixes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:00.305962Z",
     "start_time": "2019-08-11T05:06:00.145257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "42231"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_t = tuple(sorted(list(Ws)))\n",
    "Ps_t = tuple(sorted(list(Ps)))\n",
    "num_wordforms = len(Ws_t)\n",
    "num_prefixes = len(Ps_t)\n",
    "\n",
    "num_wordforms\n",
    "num_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:00.468675Z",
     "start_time": "2019-08-11T05:06:00.307227Z"
    }
   },
   "outputs": [],
   "source": [
    "wordformsByLength_t = {l:tuple(sorted([w for w in wordformsOfLength(l, Ws, True)]))\n",
    "                       for l in wordlengthsInclEdges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:00.478260Z",
     "start_time": "2019-08-11T05:06:00.469994Z"
    }
   },
   "outputs": [],
   "source": [
    "Ws_l_t = wordformsByLength_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mappings between `orthographic wordforms` and `segmental wordforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:05.604516Z",
     "start_time": "2019-08-11T05:06:00.479648Z"
    }
   },
   "outputs": [],
   "source": [
    "v_to_Ws = mapValues(lambda dist: set(conditions(dist)),\n",
    "                    pW_V)\n",
    "V_W_relation = {(v,w) \n",
    "                for v in v_to_Ws \n",
    "                for w in v_to_Ws[v]}\n",
    "w_to_Vs = {w:{v for v in Vs if (v,w) in V_W_relation}\n",
    "           for w in Ws}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:05.609733Z",
     "start_time": "2019-08-11T05:06:05.605791Z"
    }
   },
   "outputs": [],
   "source": [
    "if not benchmark: \n",
    "    del pW_V\n",
    "    del Vs\n",
    "    del v_to_Ws\n",
    "    del V_W_relation\n",
    "    del w_to_Vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract\n",
    " - `segmental inventory`\n",
    " - `triphones` in the `segmental lexicon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:05.772150Z",
     "start_time": "2019-08-11T05:06:05.611177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'aɪ',\n",
       " 'aʊ',\n",
       " 'b',\n",
       " 'd',\n",
       " 'dʒ',\n",
       " 'eɪ',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'oʊ',\n",
       " 'p',\n",
       " 's',\n",
       " 't',\n",
       " 'tʃ',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'z',\n",
       " 'æ',\n",
       " 'ð',\n",
       " 'ŋ',\n",
       " 'ɑ',\n",
       " 'ɔɪ',\n",
       " 'ə',\n",
       " 'ɚ',\n",
       " 'ɛ',\n",
       " 'ɪ',\n",
       " 'ɹ',\n",
       " 'ʃ',\n",
       " 'ʊ',\n",
       " 'ʌ',\n",
       " 'ʒ',\n",
       " 'θ',\n",
       " '⋉',\n",
       " '⋊'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_alphabet = lexiconToInventory(Ws)\n",
    "Xs = source_alphabet\n",
    "len(Xs)\n",
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:05.847412Z",
     "start_time": "2019-08-11T05:06:05.773416Z"
    }
   },
   "outputs": [],
   "source": [
    "Xs_t = tuple(sorted(Xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:06.728021Z",
     "start_time": "2019-08-11T05:06:05.851747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7412"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['p.ʌ.k',\n",
       " '⋊.s.p',\n",
       " 'dʒ.u.v',\n",
       " 'ʒ.m.ɪ',\n",
       " 'i.tʃ.ɚ',\n",
       " 'k.s.⋉',\n",
       " 'ɪ.n.v',\n",
       " 'b.ʊ.ʃ',\n",
       " 'ɑ.ŋ.z',\n",
       " 'w.oʊ.l']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_triphones = lexiconTo3factors(Ws)\n",
    "len(lexicon_triphones)\n",
    "list(lexicon_triphones)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:06.732677Z",
     "start_time": "2019-08-11T05:06:06.729115Z"
    }
   },
   "outputs": [],
   "source": [
    "X012s = lexicon_triphones\n",
    "X012s_t = tuple(sorted(list(X012s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:06.850200Z",
     "start_time": "2019-08-11T05:06:06.733575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triphs_with_LE = {triph for triph in lexicon_triphones if leftEdge in triph}\n",
    "len(triphs_with_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:06.935371Z",
     "start_time": "2019-08-11T05:06:06.853092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triphs_with_RE = {triph for triph in lexicon_triphones if rightEdge in triph}\n",
    "len(triphs_with_RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.170317Z",
     "start_time": "2019-08-11T05:06:06.939820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['z.u', 'ʊ.t', 'ɹ.ʊ', 'ɚ.ʃ', 'n.u', 'ə.t', 'v.ɹ', 'θ.æ', 'æ.l', 'i.d']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_diphones = lexiconTo2factors(Ws)\n",
    "len(lexicon_diphones)\n",
    "list(lexicon_diphones)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.173344Z",
     "start_time": "2019-08-11T05:06:07.171298Z"
    }
   },
   "outputs": [],
   "source": [
    "X01s = lexicon_diphones\n",
    "X01s_t = tuple(sorted(list(X01s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.267178Z",
     "start_time": "2019-08-11T05:06:07.174306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X01s_with_LE = {diph for diph in X01s if leftEdge in diph}\n",
    "len(X01s_with_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.352716Z",
     "start_time": "2019-08-11T05:06:07.271314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X01s_with_RE = {diph for diph in X01s if rightEdge in diph}\n",
    "len(X01s_with_RE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triphone channel distribution and channel alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.796538Z",
     "start_time": "2019-08-11T05:06:07.357435Z"
    }
   },
   "outputs": [],
   "source": [
    "p3Y1X012 = condDistsAsProbDists(importProbDist(t))\n",
    "\n",
    "assert uniformOutcomes(p3Y1X012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.801708Z",
     "start_time": "2019-08-11T05:06:07.797639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7412"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_triphones = conditions(p3Y1X012)\n",
    "len(channel_triphones)\n",
    "\n",
    "assert all(triph in channel_triphones for triph in lexicon_triphones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:07.939672Z",
     "start_time": "2019-08-11T05:06:07.802621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{triph for triph in lexicon_triphones if triph not in channel_triphones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.040244Z",
     "start_time": "2019-08-11T05:06:07.943909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'aɪ',\n",
       " 'aʊ',\n",
       " 'b',\n",
       " 'd',\n",
       " 'dʒ',\n",
       " 'eɪ',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'oʊ',\n",
       " 'p',\n",
       " 's',\n",
       " 't',\n",
       " 'tʃ',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'z',\n",
       " 'æ',\n",
       " 'ð',\n",
       " 'ŋ',\n",
       " 'ɑ',\n",
       " 'ɔɪ',\n",
       " 'ɚ',\n",
       " 'ɛ',\n",
       " 'ɪ',\n",
       " 'ɹ',\n",
       " 'ʃ',\n",
       " 'ʊ',\n",
       " 'ʌ',\n",
       " 'ʒ',\n",
       " 'θ',\n",
       " '⋉'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_alphabet = outcomes(p3Y1X012)\n",
    "len(channel_alphabet)\n",
    "channel_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.124355Z",
     "start_time": "2019-08-11T05:06:08.044818Z"
    }
   },
   "outputs": [],
   "source": [
    "Y1s = channel_alphabet\n",
    "Y1s_t = tuple(sorted(Y1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.211734Z",
     "start_time": "2019-08-11T05:06:08.129151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ə', '⋊'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_lexicon_inventory_but_not_in_channel_inventory = source_alphabet - channel_alphabet\n",
    "in_lexicon_inventory_but_not_in_channel_inventory\n",
    "\n",
    "assert in_lexicon_inventory_but_not_in_channel_inventory == {leftEdge, rightEdge} or in_lexicon_inventory_but_not_in_channel_inventory == {'ə', leftEdge, rightEdge} or in_lexicon_inventory_but_not_in_channel_inventory == {'ə', leftEdge}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview and postview distributions and alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.298807Z",
     "start_time": "2019-08-11T05:06:08.216240Z"
    }
   },
   "outputs": [],
   "source": [
    "# preview_fp\n",
    "# postview_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.390825Z",
     "start_time": "2019-08-11T05:06:08.303746Z"
    }
   },
   "outputs": [],
   "source": [
    "# p3Y1X01 = condDistsAsProbDists(importProbDist(preview_fp))\n",
    "\n",
    "# p6Y0X01 = condDistsAsProbDists(importProbDist(postview_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.481563Z",
     "start_time": "2019-08-11T05:06:08.395440Z"
    }
   },
   "outputs": [],
   "source": [
    "# assert uniformOutcomes(p3Y1X01)\n",
    "\n",
    "# assert uniformOutcomes(p6Y0X01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.565315Z",
     "start_time": "2019-08-11T05:06:08.491890Z"
    }
   },
   "outputs": [],
   "source": [
    "# preview_outcomes = outcomes(p3Y1X01)\n",
    "\n",
    "# postview_outcomes = outcomes(p6Y0X01)\n",
    "\n",
    "# assert preview_outcomes == Y1s\n",
    "\n",
    "# assert postview_outcomes == Y1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.648811Z",
     "start_time": "2019-08-11T05:06:08.576823Z"
    }
   },
   "outputs": [],
   "source": [
    "# preview_channel_diphones = conditions(p3Y1X01)\n",
    "# len(preview_channel_diphones)\n",
    "\n",
    "# # missing_preview_conditions = {diph for diph in lexicon_diphones if (diph not in preview_channel_diphones) and (leftEdge not in diph)}\n",
    "# # missing_preview_conditions\n",
    "\n",
    "# # p3Y1X01 = condProbDistAsDicts(p3Y1X01)\n",
    "\n",
    "# # #add 𝚺⋉ to preview conditions\n",
    "# # # for each 𝛔⋉ ∈ 𝚺⋉, ensure p(Y_1 = ⋉|𝛔⋉) = 1.0\n",
    "# # for c in missing_preview_conditions:\n",
    "# #     p3Y1X01[c] = {o:1.0 if ds2t(o)[1] == rightEdge else 0.0 for o in Y1s}\n",
    "\n",
    "# # # add ⋉ to preview outcomes\n",
    "# # for c in preview_channel_diphones\n",
    "    \n",
    "# # p3Y1X01 = condDistsAsProbDists(p3Y1X01)\n",
    "\n",
    "# assert all(diph in preview_channel_diphones for diph in lexicon_diphones if not (leftEdge in diph or rightEdge in diph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.732201Z",
     "start_time": "2019-08-11T05:06:08.653403Z"
    }
   },
   "outputs": [],
   "source": [
    "# postview_channel_diphones = conditions(p6Y0X01)\n",
    "# len(postview_channel_diphones)\n",
    "\n",
    "# assert all(diph in postview_channel_diphones for diph in lexicon_diphones if not (leftEdge in diph or rightEdge in diph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.861235Z",
     "start_time": "2019-08-11T05:06:08.736804Z"
    }
   },
   "outputs": [],
   "source": [
    "# p3Y1X01 = condProbDistAsDicts(p3Y1X01)\n",
    "# p6Y0X01 = condProbDistAsDicts(p6Y0X01)\n",
    "\n",
    "# p3Y1X01 = {c:p3Y1X01[c] for c in lexicon_diphones if not (leftEdge in c or rightEdge in c)}\n",
    "# p6Y0X01 = {c:p6Y0X01[c] for c in lexicon_diphones if not (leftEdge in c or rightEdge in c)}\n",
    "\n",
    "# assert areNormalized(p3Y1X01)\n",
    "# assert areNormalized(p6Y0X01)\n",
    "# assert uniformOutcomes(p3Y1X01)\n",
    "# assert uniformOutcomes(p6Y0X01)\n",
    "\n",
    "# p3Y1X01 = condDistsAsProbDists(p3Y1X01)\n",
    "# p6Y0X01 = condDistsAsProbDists(p6Y0X01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:08.949130Z",
     "start_time": "2019-08-11T05:06:08.865786Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(conditions(p3Y1X01))\n",
    "# len(conditions(p6Y0X01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.032145Z",
     "start_time": "2019-08-11T05:06:08.954086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y012s = set(map(t2ds, sigmaK(set.union(Y1s, edgeSymbols), 3)))\n",
    "# len(set.union(Y1s, edgeSymbols))\n",
    "# len(Y012s)\n",
    "# Y012s_t = tuple(sorted(list(Y012s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.166377Z",
     "start_time": "2019-08-11T05:06:09.036976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('<rem> and doctor',\n",
       " '<rem> and electric',\n",
       " '<rem> and especially',\n",
       " '<rem> and even',\n",
       " '<rem> and for',\n",
       " '<rem> and he')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = importSeqs(s, list)\n",
    "len(Cs)\n",
    "\n",
    "Cs_t = tuple(sorted(Cs))\n",
    "Cs_t[123:129]\n",
    "\n",
    "assert tuple(Cs) == Cs_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.267193Z",
     "start_time": "2019-08-11T05:06:09.167680Z"
    }
   },
   "outputs": [],
   "source": [
    "if not benchmark:\n",
    "    del Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.359315Z",
     "start_time": "2019-08-11T05:06:09.272891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wEnd not provided; setting wEnd to 1 less than the number of segmental wordforms in the metadata = 9172\n"
     ]
    }
   ],
   "source": [
    "if wEnd is None:\n",
    "    print(f'wEnd not provided; setting wEnd to 1 less than the number of segmental wordforms in the metadata = {len(Ws_t)}')\n",
    "    wEnd = len(Ws_t) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.447473Z",
     "start_time": "2019-08-11T05:06:09.365408Z"
    }
   },
   "outputs": [],
   "source": [
    "if wEnd > len(Ws_t):\n",
    "    raise Exception(f'wEnd = {wEnd} must be less than the number of segmental wordforms ({len(Ws_t)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.531491Z",
     "start_time": "2019-08-11T05:06:09.449645Z"
    }
   },
   "outputs": [],
   "source": [
    "if wEnd < wStart:\n",
    "    raise Exception(f\"wStart must be <= wEnd, got {wStart} and {wEnd} instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to one-hot vectors / sequences thereof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.615697Z",
     "start_time": "2019-08-11T05:06:09.535403Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct what you need to convert to/from one-hot representations\n",
    "\n",
    "# look at segment sequence channel matrix notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.733300Z",
     "start_time": "2019-08-11T05:06:09.620582Z"
    }
   },
   "outputs": [],
   "source": [
    "Xmap = seqsToIndexMap(Xs)\n",
    "XOHmap = seqsToOneHotMap(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.868250Z",
     "start_time": "2019-08-11T05:06:09.737885Z"
    }
   },
   "outputs": [],
   "source": [
    "X012map = seqsToIndexMap(X012s)\n",
    "# X012OHs = seqMapToOneHots(X012map)\n",
    "X012OHmap = seqsToOneHotMap(X012s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:09.946996Z",
     "start_time": "2019-08-11T05:06:09.869265Z"
    }
   },
   "outputs": [],
   "source": [
    "Y1map = seqsToIndexMap(Y1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.073178Z",
     "start_time": "2019-08-11T05:06:09.948171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  9,  6, 12])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('t.i.f', 'i.f.l')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3756, 1449])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2, 7412)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7412,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dsToUniphoneIndices(ds, uniphoneToIndexMap):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    return np.array([uniphoneToIndexMap[uniphone] for uniphone in uniphoneSeq])\n",
    "\n",
    "def dsToUniphoneOHs(ds, uniphoneToOHmap):\n",
    "    uniphoneSeq = ds2t(ds)\n",
    "    return np.array([uniphoneToOHmap[uniphone] for uniphone in uniphoneSeq])\n",
    "\n",
    "def dsToTriphoneSeq(ds):\n",
    "    return dsToKfactorSequence(3, ds)\n",
    "\n",
    "def dsToTriphoneIndices(ds, triphoneToIndexMap):\n",
    "    triphoneSeq = dsToTriphoneSeq(ds)\n",
    "    return np.array([triphoneToIndexMap[triphone] for triphone in triphoneSeq])\n",
    "\n",
    "def dsToTriphoneOHs(ds, triphoneToOHmap):\n",
    "    triphoneSeq = dsToTriphoneSeq(ds)\n",
    "    return np.array([triphoneToOHmap[triphone] for triphone in triphoneSeq])\n",
    "\n",
    "dsToUniphoneIndices('t.i.f.l', Xmap)\n",
    "dsToUniphoneOHs('t.i.f.l', XOHmap)\n",
    "dsToTriphoneSeq('t.i.f.l')\n",
    "dsToTriphoneIndices('t.i.f.l', X012map)\n",
    "dsToTriphoneOHs('t.i.f.l', X012OHmap)\n",
    "dsToTriphoneOHs('t.i.f.l', X012OHmap).shape\n",
    "dsToTriphoneOHs('t.i.f.l', X012OHmap)[0].shape\n",
    "dsToTriphoneOHs('t.i.f.l', X012OHmap)[0][5528]\n",
    "dsToTriphoneOHs('t.i.f.l', X012OHmap)[1][5352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.289990Z",
     "start_time": "2019-08-11T05:06:10.074178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.t.u.p'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.t.u.p'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'t.u.p'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 39)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 39)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y1s_RE = outcomes(p3Y1X01)\n",
    "# len(Y1s_RE)\n",
    "# Y1s_RE_list = sorted(list(Y1s_RE))\n",
    "\n",
    "# print(Y1s_RE - Y1s)\n",
    "\n",
    "# Y1REmap = seqsToIndexMap(Y1s_RE)\n",
    "\n",
    "# Y1REOHs = seqMapToOneHots(Y1REmap)\n",
    "# Y1REOHmap = seqsToOneHotMap(Y1s_RE)\n",
    "Y1OHmap = seqsToOneHotMap(Y1s)\n",
    "# OHY1REmap = oneHotToSeqMap(Y1s_RE)\n",
    "OHY1map = oneHotToSeqMap(Y1s)\n",
    "\n",
    "def ymap(y):\n",
    "#     return Y1REmap[y]\n",
    "    return Y1map[y]\n",
    "\n",
    "def y0kMap(y0k):\n",
    "    return np.array(list(map(ymap, ds2t(y0k)[1:])))\n",
    "\n",
    "def channelSeqOHs2ds(y0k_OHs, addLeftEdge = False):\n",
    "    if not addLeftEdge:\n",
    "#         return t2ds(tuple( map(OHY1REmap, tuple(y0k_OHs) ) ))\n",
    "        return t2ds(tuple( map(OHY1map, tuple(y0k_OHs) ) ))\n",
    "#     return leftEdge + '.' + t2ds(tuple( map(OHY1REmap, tuple(y0k_OHs) ) ))\n",
    "    return leftEdge + '.' + t2ds(tuple( map(OHY1map, tuple(y0k_OHs) ) ))\n",
    "\n",
    "def channelSeqds2OHs(y0k):\n",
    "    y0k_t = ds2t(y0k)\n",
    "    if leftEdge == y0k_t[0]:\n",
    "        y1k_t = y0k_t[1:]\n",
    "    y1k_t = y0k_t[1:]\n",
    "#     return np.array([Y1REOHmap[ yj ] for yj in y1k_t]) #shape should be (_, 39)\n",
    "    return np.array([Y1OHmap[ yj ] for yj in y1k_t]) #shape should be (_, 38)\n",
    "\n",
    "def y0kOHmap(y0k):\n",
    "##     y0k_t = ds2t(y0k)\n",
    "## #     y0k_indices = y0kMap(y0k) #np.array(list(map(lambda y1: Y1map[y1], y0k_t[1:])))\n",
    "##     y1k = t2ds(y0k_t[1:])\n",
    "##     y0k_OHs = dsToUniphoneOHs(y1k, Y1REOHmap)\n",
    "#     return dsToUniphoneOHs(t2ds(ds2t(y0k)[1:]), Y1REOHmap)\n",
    "    y0k_t = ds2t(y0k) #let l = len(y0k_t)\n",
    "    if y0k_t[0] == leftEdge:\n",
    "        y1k_t = y0k_t[1:]\n",
    "#         return np.array([Y1REOHmap[ yj ] for yj in y1k_t]) #shape should be (l-1, 39)\n",
    "        return np.array([Y1OHmap[ yj ] for yj in y1k_t]) #shape should be (l-1, 38)\n",
    "#     return np.array([Y1REOHmap[ yj ] for yj in y0k_t]) #shape should be (l, 39)\n",
    "    return np.array([Y1OHmap[ yj ] for yj in y0k_t]) #shape should be (l, 38)\n",
    "\n",
    "\n",
    "# list(Y1s_RE)[0]\n",
    "list(Y1s)[0]\n",
    "# OHY1REmap( Y1REOHmap[ list(Y1s_RE)[0] ] )\n",
    "OHY1map( Y1OHmap[ list(Y1s)[0] ] )\n",
    "\n",
    "channelSeqds2OHs(leftEdge + '.'+ 't.u.p')\n",
    "\n",
    "channelSeqOHs2ds( channelSeqds2OHs(leftEdge + '.'+ 't.u.p') , True)\n",
    "\n",
    "channelSeqOHs2ds(y0kOHmap(leftEdge + '.' + 't.u.p'), True)\n",
    "channelSeqOHs2ds(y0kOHmap('t.u.p'))\n",
    "len(ds2t(leftEdge + '.' + 't.u.p'))\n",
    "len(ds2t('t.u.p'))\n",
    "y0kOHmap('t.u.p').shape\n",
    "y0kOHmap(leftEdge + '.' + 't.u.p').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.489939Z",
     "start_time": "2019-08-11T05:06:10.291017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 7412)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3Y1X012_np = condDistFamilyToNP(p3Y1X012)\n",
    "p3Y1X012_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.530393Z",
     "start_time": "2019-08-11T05:06:10.491079Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.632881Z",
     "start_time": "2019-08-11T05:06:10.531369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.s.ɛ.n.s.⋉.⋉'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.l.ɛ.t.d'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_wordform = choice(list(Ws_t))\n",
    "random_source_wordform\n",
    "\n",
    "random_source_prefix = choice(list(Ps_t))\n",
    "random_source_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.746185Z",
     "start_time": "2019-08-11T05:06:10.635656Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomPrefix(l, alphabet=Xs):\n",
    "    return randomString(alphabet, l, hasLeftEdge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.836444Z",
     "start_time": "2019-08-11T05:06:10.751280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ŋ.oʊ.ʊ.b.æ.h'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_channel_prefix2 = randomPrefix(len(ds2t(random_source_wordform))-1, alphabet=Y1s)\n",
    "random_channel_prefix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:10.935357Z",
     "start_time": "2019-08-11T05:06:10.840680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.b.ɹ.u.h.ɑ.h.ɑ.⋉.⋉'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.m.ɪ.s.k.ɪ'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.p.ʊ.f.t.d'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_source_prefix = getRandomKey(pX0i)\n",
    "random_source_prefix = choice(list(Ps_t))\n",
    "random_channel_prefix = randomPrefix(len(ds2t(random_source_prefix))-1, alphabet=Y1s)\n",
    "while ds2t(random_source_prefix)[-1] == rightEdge or len(ds2t(random_source_prefix)) > len(ds2t(random_source_wordform)) or len(ds2t(random_channel_prefix)) + 1 > len(ds2t(random_source_wordform)):\n",
    "#     random_source_prefix = getRandomKey(pX0i)\n",
    "    random_source_prefix = choice(list(Ps_t))\n",
    "    random_source_wordform = choice(list(Ws_t))\n",
    "    random_channel_prefix = randomPrefix(len(ds2t(random_source_prefix))-1, alphabet=Y1s)\n",
    "# while len(ds2t(random_source_prefix)) > len(ds2t(random_source_wordform)):\n",
    "# #     random_source_prefix = getRandomKey(pX0i)\n",
    "#     random_source_prefix = choice(list(Ps))\n",
    "# # random_channel_prefix = randomPrefix(len(ds2t(random_source_prefix))-1, alphabet=Y1s)\n",
    "# while len(ds2t(random_channel_prefix)) + 1 > len(ds2t(random_source_wordform)):\n",
    "#     random_channel_prefix = randomPrefix(len(ds2t(random_source_prefix))-1, alphabet=Y1s)\n",
    "\n",
    "random_source_wordform\n",
    "random_source_prefix\n",
    "random_channel_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:11.059907Z",
     "start_time": "2019-08-11T05:06:10.939949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(random_channel_prefix))\n",
    "len(ds2t(random_source_prefix))\n",
    "len(ds2t(random_source_wordform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:11.145962Z",
     "start_time": "2019-08-11T05:06:11.064552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.m.ɪ', 'm.ɪ.s', 'ɪ.s.k', 's.k.ɪ')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.m.ɪ.s.k.ɪ'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sourcePrefixToTriphones(x0k):\n",
    "    xp_t = ds2t(x0k) #\"x prefix\"\n",
    "    \n",
    "#     xi = xp_t[-2] #just-completed segment\n",
    "#     xk = xp_t[-1] #upcoming segment that we only get coarticulatory information about\n",
    "    \n",
    "#     xik_ds = t2ds((xi, xk))\n",
    "#     preview_dist = p3Y1X01[xik_ds]\n",
    "    \n",
    "    x012s = dsToKfactorSequence(3, t2ds(xp_t))\n",
    "    return x012s\n",
    "\n",
    "random_triphoneSeq = sourcePrefixToTriphones(random_source_prefix)\n",
    "random_triphoneSeq\n",
    "threeFactorSequenceToDS(random_triphoneSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:11.233260Z",
     "start_time": "2019-08-11T05:06:11.150664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7120, 2523, 6010, 3450)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sourcePrefixToTriphoneIndices(x0k):\n",
    "    triphoneSequence = sourcePrefixToTriphones(x0k)\n",
    "    return tuple(map(lambda x012: X012map[x012], triphoneSequence))\n",
    "\n",
    "sourcePrefixToTriphoneIndices(random_source_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load segmental sequence channel matrices $p(Y_0^k|X_0^k)$ and $p(Y_0^f|X_0^f)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index $i$ of `pY0k_X0ks` is a tensor of shape $|W| \\times |Y_1| \\times (i-2)$: for each wordform $w$ in $W$, there is a length $i-2$ stack of vectors giving the channel distribution for the length $i$ prefix (including the left word edge symbol and the upcoming segment) of $w$. (The stack is of length $i-2$ because there are $i-2$ triphones associated with a length $i$ source prefix.) Where necessary and appropriate (viz. when the wordform's length is incongruent w.r.t. the channel string), a wordform's channel matrix has been padded with columns of 0s to reflect the fact that the relevant source prefix could never have given rise to a channel string of that length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pY0f_X0fs` is an analogous tensor with a similar shape, but intended for use in contexts where only wordforms whose length exactly matches the length of a channel string is worth considering as a cause of the channel string. Accordingly, its first dimension is $|W_{i+2}|$, where $W_{i+2}$ is the set of all wordforms exactly of length $i+2$ (including the left word edge and the upcoming symbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:13.898578Z",
     "start_time": "2019-08-11T05:06:11.237701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks = pickle.load(open(c, 'rb'))\n",
    "len(pY0k_X0ks)\n",
    "pY0k_X0ks[10].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:13.902211Z",
     "start_time": "2019-08-11T05:06:13.899720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9172, 39, 8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.136409Z",
     "start_time": "2019-08-11T05:06:13.903215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0f_X0fs = pickle.load(open(f, 'rb'))\n",
    "len(pY0f_X0fs)\n",
    "pY0f_X0fs[10].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.297659Z",
     "start_time": "2019-08-11T05:06:14.138841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005723328,\n",
       " 0.008584992,\n",
       " 0.011446656,\n",
       " 0.01430832,\n",
       " 0.017169984,\n",
       " 0.020031648,\n",
       " 0.022893312,\n",
       " 0.025754976,\n",
       " 0.02861664,\n",
       " 0.031478304,\n",
       " 0.034339968,\n",
       " 0.037201632,\n",
       " 0.040063296,\n",
       " 0.04292496,\n",
       " 0.045786624,\n",
       " 0.048648288]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.434972928"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.12e-06,\n",
       " 0.000161928,\n",
       " 0.001579968,\n",
       " 0.0027924,\n",
       " 0.003081312,\n",
       " 0.002900352,\n",
       " 0.002625792,\n",
       " 0.002325024,\n",
       " 0.00158496,\n",
       " 0.001129128,\n",
       " 0.0005616,\n",
       " 0.000267696,\n",
       " 0.000104832,\n",
       " 2.808e-05,\n",
       " 0.0,\n",
       " 5.304e-06]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.019151496"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda stack: stack.nbytes / 1e9 if stack is not None else None,\n",
    "         pY0k_X0ks))\n",
    "sum(list(map(lambda stack: stack.nbytes / 1e9 if stack is not None else None,\n",
    "         pY0k_X0ks)))\n",
    "list(map(lambda stack: stack.nbytes / 1e9 if stack is not None else None,\n",
    "         pY0f_X0fs))\n",
    "sum(list(map(lambda stack: stack.nbytes / 1e9 if stack is not None else None,\n",
    "         pY0f_X0fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.389649Z",
     "start_time": "2019-08-11T05:06:14.302407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks[0].dtype\n",
    "pY0f_X0fs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.469129Z",
     "start_time": "2019-08-11T05:06:14.394025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{4: 9172,\n",
       " 5: 9167,\n",
       " 6: 8994,\n",
       " 7: 7728,\n",
       " 8: 5938,\n",
       " 9: 4292,\n",
       " 10: 2964,\n",
       " 11: 1912,\n",
       " 12: 1084,\n",
       " 13: 576,\n",
       " 14: 247,\n",
       " 15: 97,\n",
       " 16: 31,\n",
       " 17: 7,\n",
       " 19: 1}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengthsNotIncludingEdges\n",
    "wordlengthsInclEdges\n",
    "lengthFreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.589565Z",
     "start_time": "2019-08-11T05:06:14.470189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "len(Y1s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.713591Z",
     "start_time": "2019-08-11T05:06:14.594304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9172, 39, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5, 39, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks[0].shape\n",
    "pY0k_X0ks[1].shape\n",
    "pY0k_X0ks[2].shape\n",
    "pY0k_X0ks[3].shape\n",
    "pY0k_X0ks[4].shape\n",
    "\n",
    "pY0f_X0fs[0].shape\n",
    "pY0f_X0fs[1].shape\n",
    "pY0f_X0fs[2].shape\n",
    "pY0f_X0fs[3].shape\n",
    "pY0f_X0fs[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.764693Z",
     "start_time": "2019-08-11T05:06:14.718072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65264711, 0.02141693],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.02545656, 0.00855777],\n",
       "       [0.02545656, 0.58122414],\n",
       "       [0.00682531, 0.00821919],\n",
       "       [0.06235012, 0.00855777],\n",
       "       [0.00682531, 0.00833257],\n",
       "       [0.00700978, 0.02552273],\n",
       "       [0.00682531, 0.00844442],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.0051651 , 0.00734595],\n",
       "       [0.00682531, 0.00844442],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.00844442],\n",
       "       [0.00700978, 0.01630829],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.00844442],\n",
       "       [0.00682531, 0.00844442],\n",
       "       [0.00700978, 0.05787536],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00682531, 0.00844442],\n",
       "       [0.00664084, 0.00832952],\n",
       "       [0.00682531, 0.00833257],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00682531, 0.00821919],\n",
       "       [0.00700978, 0.00734595],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00682531, 0.00844442],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.02905399],\n",
       "       [0.00682531, 0.00821919],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00700978, 0.00855777],\n",
       "       [0.00682531, 0.00833257],\n",
       "       [0.00700978, 0.00844442],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64012878, 0.        ],\n",
       "       [0.00864939, 0.        ],\n",
       "       [0.00714712, 0.        ],\n",
       "       [0.00710919, 0.        ],\n",
       "       [0.00597457, 0.        ],\n",
       "       [0.09519946, 0.        ],\n",
       "       [0.00632972, 0.        ],\n",
       "       [0.00649346, 0.        ],\n",
       "       [0.00735496, 0.        ],\n",
       "       [0.00743004, 0.        ],\n",
       "       [0.00693599, 0.        ],\n",
       "       [0.00614232, 0.        ],\n",
       "       [0.00622218, 0.        ],\n",
       "       [0.00613831, 0.        ],\n",
       "       [0.00649346, 0.        ],\n",
       "       [0.0064649 , 0.        ],\n",
       "       [0.00613831, 0.        ],\n",
       "       [0.00614232, 0.        ],\n",
       "       [0.00676474, 0.        ],\n",
       "       [0.00622218, 0.        ],\n",
       "       [0.00637828, 0.        ],\n",
       "       [0.00614232, 0.        ],\n",
       "       [0.00606245, 0.        ],\n",
       "       [0.00605844, 0.        ],\n",
       "       [0.00992452, 0.        ],\n",
       "       [0.00621729, 0.        ],\n",
       "       [0.00565472, 0.        ],\n",
       "       [0.0220417 , 0.        ],\n",
       "       [0.00967323, 0.        ],\n",
       "       [0.00654113, 0.        ],\n",
       "       [0.00847112, 0.        ],\n",
       "       [0.00810085, 0.        ],\n",
       "       [0.00833528, 0.        ],\n",
       "       [0.00597457, 0.        ],\n",
       "       [0.00622218, 0.        ],\n",
       "       [0.00973848, 0.        ],\n",
       "       [0.00630116, 0.        ],\n",
       "       [0.00668086, 0.        ],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks[4][0]\n",
    "pY0f_X0fs[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.849119Z",
     "start_time": "2019-08-11T05:06:14.768669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 7412)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3Y1X012_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:14.944335Z",
     "start_time": "2019-08-11T05:06:14.853567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9172, 39, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5, 39, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks[4].shape\n",
    "pY0f_X0fs[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:15.071985Z",
     "start_time": "2019-08-11T05:06:14.948931Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_CM_for(x0f_WE, total_prefix_length, exact = False):\n",
    "    '''\n",
    "    total_prefix_length includes \n",
    "     - the \"⋊\" symbol,\n",
    "     - the actually and completely produced prefix,\n",
    "     - the next (i.e. upcoming) segment.\n",
    "     \n",
    "    Ex:\n",
    "      w = '⋊.aɪ.d.i.l.aɪ.z.⋉'\n",
    "      |'⋊.aɪ.d.i.l.aɪ.z.⋉'| = 8\n",
    "      l = 5\n",
    "    =>\n",
    "      'total_prefix' = '⋊.aɪ.d.i.l'\n",
    "      |'⋊.aɪ.d.i.l'| = 5\n",
    "      The associated channel matrix is of shape (|Y1s|, l-2 = 5-2 = 3).\n",
    "    '''\n",
    "    if not exact:\n",
    "        return pY0k_X0ks[total_prefix_length][Ws_t.index(x0f_WE)]\n",
    "    else:\n",
    "        return pY0f_X0fs[total_prefix_length][Ws_l_t[total_prefix_length].index(x0f_WE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:06:15.240679Z",
     "start_time": "2019-08-11T05:06:15.077029Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.l.aɪ.z.⋉.⋉'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('aɪ.d.i', 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('⋊.aɪ.d.i', 4)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('⋊.aɪ.d.i.l', 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65264711, 0.02141693, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.02545656, 0.00855777, 0.00703146],\n",
       "       [0.02545656, 0.58122414, 0.00693832],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.06235012, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.02552273, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.73787478],\n",
       "       [0.0051651 , 0.00734595, 0.00603577],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.01630829, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.05787536, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00664084, 0.00832952, 0.00684392],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.00700978, 0.00734595, 0.00603577],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.01339964],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.02905399, 0.00703146],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.l'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('⋊.aɪ.d', 'aɪ.d.i', 'd.i.l')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6923, 5, 498)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65264711, 0.02141693, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.02545656, 0.00855777, 0.00703146],\n",
       "       [0.02545656, 0.58122414, 0.00693832],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.06235012, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.02552273, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.73787478],\n",
       "       [0.0051651 , 0.00734595, 0.00603577],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.01630829, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.05787536, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00664084, 0.00832952, 0.00684392],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.00700978, 0.00734595, 0.00603577],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.01339964],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.02905399, 0.00703146],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_0 = Ws_t[0]; w_0\n",
    "w_0_produced_prefix_noLE = t2ds(ds2t(Ws_t[0])[1:3+1]); w_0_produced_prefix_noLE, len(ds2t(w_0_produced_prefix_noLE))\n",
    "w_0_produced_prefix = t2ds(ds2t(Ws_t[0])[0:3+1]); w_0_produced_prefix, len(ds2t(w_0_produced_prefix))\n",
    "w_0_produced_prefix_plus_next = t2ds(ds2t(Ws_t[0])[0:3+2]); w_0_produced_prefix_plus_next, len(ds2t(w_0_produced_prefix_plus_next))\n",
    "\n",
    "pY0k_X0ks[5][0].shape\n",
    "# pY0k_X0ks[3][0] #assume the produced prefix is of length i+1=3+1=4 (not including left word edge)\n",
    "pY0k_X0ks[5][0] # assume the produced prefix is of length i-2=3 (not including left word edge)\n",
    "                # assume the produced prefix is of length i-1=4 (including left word edge)\n",
    "                # assume the produced prefix + upcoming segment is of length i=5 (including left word edge)\n",
    "\n",
    "w_0_whole_prefix = t2ds(ds2t(Ws_t[0])[0:3+2]); w_0_whole_prefix\n",
    "w_0_whole_prefix_3factors = sourcePrefixToTriphones(w_0_whole_prefix); w_0_whole_prefix_3factors\n",
    "w_0_whole_prefix_3factor_indices = sourcePrefixToTriphoneIndices(w_0_whole_prefix); w_0_whole_prefix_3factor_indices\n",
    "w_0_prefix_CM = np.vstack([p3Y1X012_np[:,source_triph_idx] for source_triph_idx in w_0_whole_prefix_3factor_indices]).T; w_0_prefix_CM\n",
    "w_0_prefix_CM.shape\n",
    "\n",
    "assert np.allclose( w_0_prefix_CM, pY0k_X0ks[5][0] )\n",
    "assert np.allclose( pY0k_X0ks[5][0], retrieve_CM_for(Ws_t[0], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    " - `|pY0k_X0ks|` = $max_l = |w|. ∄w'. |w'| > |w|$ (around 16-18, usually) \n",
    " - `pY0k_X0ks[i]` = the lexical channel matrices for 'total prefixes' of length `i` (i.e. incl. word edges and upcoming segment)\n",
    " - `pY0k_X0ks[i]` =  the lexical channel matrices for prefixes of length `i-1` (i.e. *not* incl. word edges, but incl. upcoming segment)\n",
    " - `|pY0k_X0ks[i]|` = `(|W|, |Y1|, i-2)` = (segmental wordforms, Y1s, number of triphones)\n",
    " \n",
    "(Similar statements hold wrt `pY0fX0f`, mod earlier notes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load contextual distribution on segmental wordforms $p(W|C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.286831Z",
     "start_time": "2019-08-11T05:06:15.242255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9172, 106295)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.79950192"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pW_C = np.load(w)\n",
    "pW_C.shape\n",
    "pW_C.dtype\n",
    "pW_C.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.293913Z",
     "start_time": "2019-08-11T05:07:21.289959Z"
    }
   },
   "outputs": [],
   "source": [
    "if pW_C.shape[1] != len(Cs_t):\n",
    "    raise Exception(f'# of contexts in metadata file does not match context dimension of pW_C matrix: {len(Cs_t)} vs. {pW_C.shape[1]}\\n\\t{s}\\n\\t{w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.479328Z",
     "start_time": "2019-08-11T05:07:21.296160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "len(Cs_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.568905Z",
     "start_time": "2019-08-11T05:07:21.484089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a couple of'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2.52036749e-10, 1.50634197e-08, 2.52036749e-10, ...,\n",
       "       5.54693797e-10, 4.15967189e-08, 6.22123621e-07])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs_t[Cs_t.index('a couple of')]\n",
    "pW_C[:,Cs_t.index('a couple of')]\n",
    "isNormalized_np(pW_C[:,Cs_t.index('a couple of')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.641225Z",
     "start_time": "2019-08-11T05:07:21.573423Z"
    }
   },
   "outputs": [],
   "source": [
    "def pW_C_lookup(w=None,c=None):\n",
    "    if w is None and c is None:\n",
    "        raise Exception('Must specify at least one of a context string or segmental wordform string')\n",
    "    if w is None:\n",
    "        my_pW_c = pW_C[:,Cs_t.index(c)]\n",
    "        my_pW_c_as_dict = dict(zip(Ws_t, my_pW_c))\n",
    "        assert isNormalized(my_pW_c_as_dict, epsilon = 1e-6)\n",
    "        return ProbDist(my_pW_c_as_dict)\n",
    "    if w is not None and c is not None:\n",
    "        my_pw_c = pW_C[Ws_t.index(w), Cs_t.index(c)]\n",
    "        return my_pw_c\n",
    "    if c is None:\n",
    "        my_pw_C = pW_C[Ws_t.index(w), :]\n",
    "        my_pw_C_as_dict = dict(zip(Cs_t, my_pw_C))\n",
    "        return my_pw_C_as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.796536Z",
     "start_time": "2019-08-11T05:07:21.645886Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dist = pW_C_lookup(c='a couple of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:21.891229Z",
     "start_time": "2019-08-11T05:07:21.801385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('⋊.t.aɪ.m.z.⋉.⋉', 0.7017068824069426),\n",
       " ('⋊.ð.ɛ.m.⋉.⋉', 0.058586970250377776),\n",
       " ('⋊.ð.ə.⋉.⋉', 0.05467041905649899),\n",
       " ('⋊.ʌ.ð.ɚ.⋉.⋉', 0.03664541602803625),\n",
       " ('⋊.m.aɪ.⋉.⋉', 0.028159696907432537),\n",
       " ('⋊.ð.oʊ.z.⋉.⋉', 0.020634293629461325),\n",
       " ('⋊.h.ʌ.n.d.ɹ.ə.d.⋉.⋉', 0.01748920205729206),\n",
       " ('⋊.l.aɪ.k.⋉.⋉', 0.014006091693604115),\n",
       " ('⋊.g.ʊ.d.⋉.⋉', 0.005842215226429354),\n",
       " ('⋊.m.ɪ.l.i.ə.n.⋉.⋉', 0.005304906857139398)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:22.002606Z",
     "start_time": "2019-08-11T05:07:21.895947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right yeah well'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "59734"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('⋊.aɪ.⋉.⋉', 0.8038854945877595),\n",
       " ('⋊.j.u.⋉.⋉', 0.05961778775433437),\n",
       " ('⋊.w.i.⋉.⋉', 0.022756717198857943),\n",
       " ('⋊.ð.ə.⋉.⋉', 0.020517328336076567),\n",
       " ('⋊.m.aɪ.⋉.⋉', 0.01917511991263336),\n",
       " ('⋊.ɪ.t.⋉.⋉', 0.007016147837544381),\n",
       " ('⋊.æ.n.d.⋉.⋉', 0.00516328623558489),\n",
       " ('⋊.ð.eɪ.⋉.⋉', 0.004734345378218211),\n",
       " ('⋊.ð.æ.t.⋉.⋉', 0.004231753849583734),\n",
       " ('⋊.h.w.ɑ.t.⋉.⋉', 0.004064795540676732)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_context = choice(Cs_t); random_context\n",
    "Cs_t.index(random_context)\n",
    "pW_C_lookup(c=random_context).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load lexicon metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:22.047752Z",
     "start_time": "2019-08-11T05:07:22.004811Z"
    }
   },
   "outputs": [],
   "source": [
    "cousin_fn_map = {i:'{0}cousinsOf.npz'.format(i) \n",
    "                 for i in range(5)}\n",
    "sphere_fn_map = {i:'{0}spheresOf.npz'.format(i) \n",
    "                 for i in range(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:22.135089Z",
     "start_time": "2019-08-11T05:07:22.051487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0cousinsOf.npz',\n",
       " 1: '1cousinsOf.npz',\n",
       " 2: '2cousinsOf.npz',\n",
       " 3: '3cousinsOf.npz',\n",
       " 4: '4cousinsOf.npz'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cousin_fn_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:22.227274Z",
     "start_time": "2019-08-11T05:07:22.139556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0spheresOf.npz',\n",
       " 1: '1spheresOf.npz',\n",
       " 2: '2spheresOf.npz',\n",
       " 3: '3spheresOf.npz',\n",
       " 4: '4spheresOf.npz'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sphere_fn_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:22.310387Z",
     "start_time": "2019-08-11T05:07:22.231957Z"
    }
   },
   "outputs": [],
   "source": [
    "assert all(fn in listdir(m) for fn in cousin_fn_map.values())\n",
    "assert all(fn in listdir(m) for fn in sphere_fn_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:22.392233Z",
     "start_time": "2019-08-11T05:07:22.315639Z"
    }
   },
   "outputs": [],
   "source": [
    "chdir(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:26.893603Z",
     "start_time": "2019-08-11T05:07:22.397272Z"
    }
   },
   "outputs": [],
   "source": [
    "cousin_mats = mapValues(sparse.load_npz, cousin_fn_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.298681Z",
     "start_time": "2019-08-11T05:07:26.894576Z"
    }
   },
   "outputs": [],
   "source": [
    "sphere_mats = mapValues(sparse.load_npz, sphere_fn_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.301212Z",
     "start_time": "2019-08-11T05:07:27.299646Z"
    }
   },
   "outputs": [],
   "source": [
    "chdir(repo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $k$th-cousin/sphere matrix $m$ is a matrix of shape $|P| \\times |W|$, where $m_{i,j}$ = 1 iff prefix $p_i$ is in a $k$-cousin/sphere relation to wordform $w_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.381020Z",
     "start_time": "2019-08-11T05:07:27.302094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42231"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ps_t)\n",
    "len(Ws_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.456136Z",
     "start_time": "2019-08-11T05:07:27.381866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <COO: shape=(42231, 9172), dtype=uint8, nnz=79727, fill_value=0>,\n",
       " 1: <COO: shape=(42231, 9172), dtype=uint8, nnz=1000076, fill_value=0>,\n",
       " 2: <COO: shape=(42231, 9172), dtype=uint8, nnz=9307972, fill_value=0>,\n",
       " 3: <COO: shape=(42231, 9172), dtype=uint8, nnz=39821468, fill_value=0>,\n",
       " 4: <COO: shape=(42231, 9172), dtype=uint8, nnz=71449640, fill_value=0>}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.001355359, 1: 0.017001292, 2: 0.158235524, 3: 0.676964956, 4: 1.21464388}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cousin_mats\n",
    "mapValues(lambda m: m.nbytes / 1e9,\n",
    "          cousin_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.531823Z",
     "start_time": "2019-08-11T05:07:27.457001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <COO: shape=(42231, 9172), dtype=uint8, nnz=9172, fill_value=0>,\n",
       " 1: <COO: shape=(42231, 9172), dtype=uint8, nnz=30652, fill_value=0>,\n",
       " 2: <COO: shape=(42231, 9172), dtype=uint8, nnz=370148, fill_value=0>,\n",
       " 3: <COO: shape=(42231, 9172), dtype=uint8, nnz=2062370, fill_value=0>,\n",
       " 4: <COO: shape=(42231, 9172), dtype=uint8, nnz=3207990, fill_value=0>}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.000155924, 1: 0.000521084, 2: 0.006292516, 3: 0.03506029, 4: 0.05453583}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sphere_mats\n",
    "mapValues(lambda m: m.nbytes / 1e9,\n",
    "          sphere_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.613523Z",
     "start_time": "2019-08-11T05:07:27.532797Z"
    }
   },
   "outputs": [],
   "source": [
    "# c1.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.732082Z",
     "start_time": "2019-08-11T05:07:27.615293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42229, 6949)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.θ.ʌ.n.d.ɚ.⋉'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.w.ʌ.n.d.ɚ.⋉.⋉'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = cousin_mats[1]\n",
    "(c1.coords[0][-2], c1.coords[1][-2])\n",
    "Ps_t[c1.coords[0][-2]]\n",
    "Ws_t[c1.coords[1][-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.820831Z",
     "start_time": "2019-08-11T05:07:27.736670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LTR_newdic_destressed_aligned_w_GD_AmE_destressed'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.901143Z",
     "start_time": "2019-08-11T05:07:27.825492Z"
    }
   },
   "outputs": [],
   "source": [
    "# segmental_wordforms = importSeqs(path.join(m, 'LTR_Buckeye_aligned_CM_filtered_LM_filtered.pW_V_Transcriptions.txt'))\n",
    "# len(segmental_wordforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:27.984604Z",
     "start_time": "2019-08-11T05:07:27.905876Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(segmental_wordforms)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.088419Z",
     "start_time": "2019-08-11T05:07:27.989070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ws_t = tuple(sorted(list(map(padInputSequenceWithBoundaries,\n",
    "#                              segmental_wordforms))))\n",
    "# len(Ws_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.229426Z",
     "start_time": "2019-08-11T05:07:28.093568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps = union(map(lambda w: getPrefixes(padInputSequenceWithBoundaries(w)), segmental_wordforms))\n",
    "# len(Ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.342534Z",
     "start_time": "2019-08-11T05:07:28.234352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ps_t = tuple(sorted(list(Ps)))\n",
    "# len(Ps_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow, but sanity-checking calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(C_0^i | X_0^i; X_{i+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_i = (Y_{i-1}^{x_i}, Y_i^{x_i}, Y_{i+1}^{x_i})$\n",
    "\n",
    "$p(y_{i-1}, y_i; y_{i+1} | x_{i-1}^i; x_{i+1}) = p(y_{i-1} | x_{i-1}, x_i;) p(y_i | x_{i-1}^i ; x_{i+1}) p(y_{i+1} | x_i ; x_{i+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(c_0^i | x_0^i; x_{i+1}) = \\prod\\limits_{j=0}^{j=i} p(c_i | x_{i-1}^i ; x_{i+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.432381Z",
     "start_time": "2019-08-11T05:07:28.347066Z"
    }
   },
   "outputs": [],
   "source": [
    "# def pC1_X012(y012, x012):\n",
    "#     x012_t = ds2t(x012)\n",
    "#     y012_t = ds2t(y012)\n",
    "    \n",
    "#     x0, x1, x2 = x012_t[0], x012_t[1], x012_t[2]\n",
    "#     x01 = (x0, x1)\n",
    "#     x12 = (x1, x2)\n",
    "    \n",
    "#     y0, y1, y2 = y012_t[0], y012_t[1], y012_t[2]\n",
    "    \n",
    "#     if x0 == leftEdge:\n",
    "#         if y0 == leftEdge:\n",
    "#             left_term = 1.0\n",
    "#         else:\n",
    "#             left_term = 0.0\n",
    "#     else:\n",
    "#         if y0 == leftEdge:\n",
    "#             left_term = 0.0\n",
    "#         else:\n",
    "#             left_term = p6Y0X01[x01][y0]\n",
    "    \n",
    "#     center_term = p3Y1X012[x012][y1]\n",
    "    \n",
    "#     if x1 == rightEdge:\n",
    "#         if y1 == rightEdge:\n",
    "#             right_term = 1.0\n",
    "#         else:\n",
    "#             right_term = 0.0\n",
    "#     else:\n",
    "#         if y1 == rightEdge:\n",
    "#             right_term = 0.0\n",
    "#         else:\n",
    "#             right_term = p3Y1X01[x12][y2]\n",
    "    \n",
    "#     terms = (left_term, center_term, right_term)\n",
    "    \n",
    "#     result = prod(terms)\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# def pC0iX0k(c0i, x0k):\n",
    "#     xp_t = ds2t(x0k)\n",
    "#     three_factor_seq = dsToKfactorSequence(3, x0k)\n",
    "    \n",
    "#     inputs = zip(c0i, three_factor_seq)\n",
    "    \n",
    "#     terms = starmap(pC1_X012, inputs)\n",
    "    \n",
    "#     result = prod(terms)\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.515772Z",
     "start_time": "2019-08-11T05:07:28.436829Z"
    }
   },
   "outputs": [],
   "source": [
    "# s = leftEdge + '.i.p.i.' + rightEdge; s\n",
    "# dsToKfactorSequence(3, s)\n",
    "# threeFactorSequenceToDS(dsToKfactorSequence(3, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.599094Z",
     "start_time": "2019-08-11T05:07:28.520705Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(Y012s)\n",
    "# len(X012s)\n",
    "# len(Y012s) * len(X012s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.673837Z",
     "start_time": "2019-08-11T05:07:28.603621Z"
    }
   },
   "outputs": [],
   "source": [
    "# # takes 5.5m on sidious and 45GB\n",
    "# square = set(product(Y012s, X012s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.747210Z",
     "start_time": "2019-08-11T05:07:28.678039Z"
    }
   },
   "outputs": [],
   "source": [
    "# def pY012_X012_calc(y012, x012):\n",
    "#     return (x012, pC1_X012(y012, x012))\n",
    "\n",
    "# pY012_X012 = dict(par(delayed(pY012_X012_calc)(y012, x012) for y012, x012 in product(Y012s, X012s)))\n",
    "\n",
    "# # def pY012_X012_calc(y012_x012_pair):\n",
    "# #     y012, x012 = y012_x012_pair\n",
    "# #     return (x012, pC1_X012(y012, x012))\n",
    "\n",
    "# # pY012_X012 = dict(par(delayed(pY012_X012_calc)(y012_x012_pair) for y012_x012_pair in product(Y012s, X012s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(Y_0^i|X_0^k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.831466Z",
     "start_time": "2019-08-11T05:07:28.749455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pY0k_X0ks)\n",
    "sorted(wordlengthsInclEdges)\n",
    "assert len(pY0k_X0ks)-1 == sorted(wordlengthsInclEdges)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:28.934268Z",
     "start_time": "2019-08-11T05:07:28.836008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "42231"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws)\n",
    "len(Ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.043980Z",
     "start_time": "2019-08-11T05:07:28.938811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0k_X0ks[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.129818Z",
     "start_time": "2019-08-11T05:07:29.050618Z"
    }
   },
   "outputs": [],
   "source": [
    "def pY0iX0k(y0i, x0k, debug = False):\n",
    "    xp_t = ds2t(x0k) #\"x prefix\"\n",
    "    yp_t = ds2t(y0i) #\"y prefix\"\n",
    "#     assert xp_t[0] == leftEdge\n",
    "#     assert yp_t[0] == leftEdge\n",
    "    if len(xp_t) < 3:\n",
    "        raise Exception('|x0k| must be ≥ 3.')\n",
    "    if (len(yp_t)+1 != len(xp_t)) and not ((yp_t[-1] == rightEdge) and len(yp_t) == len(xp_t)):\n",
    "        raise Exception('|y0i| must = |x0k|-1, or |y0k| == |x0k| and y_k == ⋉.')\n",
    "#     if len(yp_t) != len(xp_t):\n",
    "#         raise Exception('Lengths of y0i and x0k must match.')\n",
    "    # if len(xp_t) == 1:\n",
    "    #     if xp_t[0] != leftEdge:\n",
    "    #         raise Exception('First symbol of x0k must be left word edge symbol.')    \n",
    "    #     if yp_t[0] == leftEdge:\n",
    "    #         return 1.0\n",
    "    #     else:\n",
    "    #         return 0.0\n",
    "    if yp_t[-1] == rightEdge:\n",
    "        #if y_{f+1} == ⋉, then \n",
    "        # the only strings x_0^f that could generate it\n",
    "        # have exactly the same length and also end with ⋉\n",
    "        if len(yp_t) != len(xp_t):\n",
    "            return 0.0\n",
    "        \n",
    "        x_k = xp_t[-1]\n",
    "        if x_k != rightEdge:\n",
    "            return 0.0\n",
    "        \n",
    "        #if |x_0^f| == |y_0^f| ∧ (y_{f+1} == x_{f+1} == ⋉),\n",
    "        # then remove y_{f+1} and proceed with the calculation\n",
    "        # as normal...\n",
    "        y_k = rightEdge\n",
    "        yp_t = yp_t[:-1]\n",
    "    elif xp_t[-1] == rightEdge:\n",
    "        # if x_k = ⋉ and y_k != ⋉, then the probability of that channel string is 0.0...\n",
    "        return 0.0\n",
    "    \n",
    "#     xi = xp_t[-2] #just-completed segment\n",
    "#     xk = xp_t[-1] #upcoming segment that we only get coarticulatory information about\n",
    "    # yk = yp_t[-1]\n",
    "    # xik_ds = t2ds((xi, xk))\n",
    "    # preview_dist = p3Y1X01[xik_ds]\n",
    "#     if yk not in preview_dist:\n",
    "#         print('y0i: {0}\\nx0k: {1}\\nxi: {2}\\nxk: {3}\\nyk: {4}\\nxik: {5}'.format(y0i, x0k, xi, xk, yk, xik_ds))\n",
    "#     preview_term = preview_dist[yk]\n",
    "    \n",
    "#     if debug:\n",
    "#         print('xi = {0}\\nxk = {1}\\nyk = {2}'.format(xi, xk, yk))\n",
    "#         print('preview term = {0}'.format(preview_term))\n",
    "    \n",
    "#     x0i_t = xp_t[:-1] #prefix of intended wordform that has actually been produced\n",
    "    # y0i_t = yp_t[:-1]\n",
    "#     x0i_ds = t2ds(x0i_t)\n",
    "#     y0i_ds = t2ds(y0i_t)\n",
    "\n",
    "#     if debug:\n",
    "#         x0i_t = xp_t[:-1] #prefix of intended wordform that has actually been produced\n",
    "#         x0i_ds = t2ds(x0i_t)\n",
    "#         y0i_ds = t2ds(y0i_t)\n",
    "#         print('produced prefix x0i = {0}'.format(x0i_ds))\n",
    "#         print('perceived prefix y0i = {0}'.format(y0i_ds))\n",
    "    \n",
    "#     x012s = dsToKfactorSequence(3, x0i_ds)\n",
    "#     x012s = dsToKfactorSequence(3, t2ds(xp_t))\n",
    "    x012s = dsToKfactorSequence(3, x0k)\n",
    "    # y1s = y0i_t[1:]\n",
    "    y1s = yp_t[1:]\n",
    "#     pairs = list(zip(x012s, y1s))\n",
    "#     produced_terms = tuple([p3Y1X012[x012][y1] for x012, y1 in pairs])\n",
    "    pairs = zip(x012s, y1s)\n",
    "    produced_terms = (p3Y1X012[x012][y1] for x012, y1 in pairs)\n",
    "    \n",
    "#     result = preview_term * prod(produced_terms)\n",
    "    result = prod(produced_terms)\n",
    "\n",
    "#     if debug:\n",
    "#         print('x012s: {0}'.format(x012s))\n",
    "#         print('y1s: {0}'.format(y1s))\n",
    "#         print('main terms: {0}'.format(produced_terms))\n",
    "#         print('end result = {0}'.format(result))\n",
    "    \n",
    "    if debug:\n",
    "#         return result, [p3Y1X012[x012] for x012 in x012s]\n",
    "        return result, np.array([[p3Y1X012[x012][k] for k in sorted(p3Y1X012[x012].keys())] for x012 in x012s]).T\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.259451Z",
     "start_time": "2019-08-11T05:07:29.134502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.l.aɪ.z.⋉.⋉'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.l'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.aɪ.d.i.l.aɪ'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65264711, 0.02141693, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.02545656, 0.00855777, 0.00703146],\n",
       "       [0.02545656, 0.58122414, 0.00693832],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.06235012, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.02552273, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.73787478],\n",
       "       [0.0051651 , 0.00734595, 0.00603577],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.01630829, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.05787536, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00664084, 0.00832952, 0.00684392],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.00700978, 0.00734595, 0.00603577],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00844442, 0.00693832],\n",
       "       [0.00700978, 0.00855777, 0.01339964],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.02905399, 0.00703146],\n",
       "       [0.00682531, 0.00821919, 0.00675326],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00700978, 0.00855777, 0.00703146],\n",
       "       [0.00682531, 0.00833257, 0.00684642],\n",
       "       [0.00700978, 0.00844442, 0.00693832],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_0\n",
    "# w_0_prefix = \n",
    "w_0_3 = t2ds(ds2t(w_0)[:3+2]); w_0_3# + 1\n",
    "w_0_4 = t2ds(ds2t(w_0)[:4+2]); w_0_4# + 1\n",
    "pY0k_X0ks[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.371461Z",
     "start_time": "2019-08-11T05:07:29.265869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1983147788326225"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65264711, 0.02141693, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.02545656, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.02545656, 0.58122414, 0.00693832, 0.00713029],\n",
       "       [0.00682531, 0.00821919, 0.00675326, 0.00694011],\n",
       "       [0.06235012, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00682531, 0.00833257, 0.00684642, 0.00703584],\n",
       "       [0.00700978, 0.02552273, 0.00703146, 0.007226  ],\n",
       "       [0.00682531, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00700978, 0.00855777, 0.73787478, 0.007226  ],\n",
       "       [0.0051651 , 0.00734595, 0.00603577, 0.00620276],\n",
       "       [0.00682531, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.70851712],\n",
       "       [0.00700978, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00700978, 0.01630829, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.02155085],\n",
       "       [0.00700978, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00682531, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00700978, 0.05787536, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.02155085],\n",
       "       [0.00682531, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00664084, 0.00832952, 0.00684392, 0.00703327],\n",
       "       [0.00682531, 0.00833257, 0.00684642, 0.00703584],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00682531, 0.00821919, 0.00675326, 0.00694011],\n",
       "       [0.00700978, 0.00734595, 0.00603577, 0.00620276],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00682531, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.00700978, 0.00855777, 0.01339964, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.02905399, 0.00703146, 0.007226  ],\n",
       "       [0.00682531, 0.00821919, 0.00675326, 0.00694011],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00700978, 0.00855777, 0.00703146, 0.007226  ],\n",
       "       [0.00682531, 0.00833257, 0.00684642, 0.00703584],\n",
       "       [0.00700978, 0.00844442, 0.00693832, 0.00713029],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0iX0k(w_0_3, w_0_4)\n",
    "pY0iX0k(w_0_3, w_0_4, True)[1]\n",
    "assert np.allclose( pY0k_X0ks[6][0], pY0iX0k(w_0_3, w_0_4, True)[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.497580Z",
     "start_time": "2019-08-11T05:07:29.377745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.14201210183923127"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0iX0k('⋊.k.ɑ.n.t', '⋊.k.ɑ.n.t.⋉')\n",
    "pY0iX0k('⋊.k.ɑ.n.t.⋉', '⋊.k.ɑ.n.t.⋉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.581036Z",
     "start_time": "2019-08-11T05:07:29.504086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25068286913932425"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0034938697256087312"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0iX0k('⋊.k.ɑ.n', '⋊.k.ɑ.n.t')\n",
    "pY0iX0k('⋊.k.ɑ.m', '⋊.k.ɑ.n.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.676754Z",
     "start_time": "2019-08-11T05:07:29.585267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t.u.p.l'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'t.u.p'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'t.u.p'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'t.u.p.l.?.?'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trimToMatch(y0i, x0f):\n",
    "    x0f_t = ds2t(x0f)\n",
    "    y0i_t = ds2t(y0i)\n",
    "    l = len(y0i_t)\n",
    "    if len(x0f_t) < l+1:\n",
    "        raise Exception('|x0f| must ≥ |y0i| + 1.')\n",
    "    x0k_t = x0f_t[:l+1]\n",
    "    x0k = t2ds(x0k_t)\n",
    "    return x0k\n",
    "\n",
    "def trimToLength(l, x0f, pad=False, padSymbol='?'):\n",
    "    x0f_t = ds2t(x0f)\n",
    "#     y0i_t = ds2t(y0i)\n",
    "#     l = len(y0i_t)\n",
    "    if len(x0f_t) < l and not pad:\n",
    "        raise Exception('x0f must be at least as long as l.')\n",
    "    if len(x0f_t) < l and pad:\n",
    "        x0k_t = x0f_t[:l]\n",
    "        x0k_t_padded = tuple( list(x0k_t) + [padSymbol] * (l - len(x0k_t)) )\n",
    "        return t2ds(x0k_t_padded)\n",
    "    else:\n",
    "        x0k_t = x0f_t[:l]\n",
    "        x0k = t2ds(x0k_t)\n",
    "        return x0k\n",
    "    \n",
    "# trimToMatch('t.u.p', 't.u.p')\n",
    "trimToMatch('t.u.p', 't.u.p.l')\n",
    "trimToLength(3, 't.u.p')\n",
    "trimToLength(3, 't.u.p.l')\n",
    "trimToLength(6, 't.u.p.l', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.819867Z",
     "start_time": "2019-08-11T05:07:29.677985Z"
    }
   },
   "outputs": [],
   "source": [
    "def pY0iX0f(y0i, x0f, debug = False):\n",
    "    x0f_t = ds2t(x0f)\n",
    "    y0i_t = ds2t(y0i)\n",
    "    l = len(y0i_t)\n",
    "    if len(x0f_t) < l+1 and not ((y0i_t[-1] == rightEdge) and len(y0i_t) == len(x0f_t)):\n",
    "        raise Exception('|x0f| must ≥ |y0i| + 1 or |x0f| = |y0k| ∧ y_k = ⋉')\n",
    "    x0k_t = x0f_t[:l+1]\n",
    "    x0k = t2ds(x0k_t)\n",
    "#     print(y0i)\n",
    "#     print(x0k)\n",
    "    return pY0iX0k(y0i, x0k, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.909852Z",
     "start_time": "2019-08-11T05:07:29.821002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25068286913932425"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.25068286913932425"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pY0iX0f('⋊.k.ɑ.n', '⋊.k.ɑ.n.t')\n",
    "pY0iX0f('⋊.k.ɑ.n', '⋊.k.ɑ.n.t.⋉')\n",
    "pY0iX0f('⋊.k.ɑ.n.t', '⋊.k.ɑ.n.t.⋉')\n",
    "pY0iX0f('⋊.k.ɑ.n.t', '⋊.k.ɑ.n.t.⋉')\n",
    "pY0iX0f('⋊.k.ɑ.n.t.⋉', '⋊.k.ɑ.n.t.⋉.⋉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:29.992694Z",
     "start_time": "2019-08-11T05:07:29.911056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.n.⋉.⋉'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.ʌ.h.ɪ'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.oʊ.n.⋉.⋉'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.ʌ.h.ɪ'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x0f = choice(Ws_t); random_x0f\n",
    "lw = len(ds2t(random_x0f))\n",
    "while lw-1 <= 2:\n",
    "    random_x0f = getRandomKey(pW); random_x0f\n",
    "    lw = len(ds2t(random_x0f))\n",
    "\n",
    "random_y0i = randomPrefix(choice(range(2,lw-1)), alphabet=Y1s); random_y0i\n",
    "random_x0f\n",
    "random_y0i\n",
    "# pY0iX0f(random_y0i, random_x0f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(X_0^f|C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:30.065233Z",
     "start_time": "2019-08-11T05:07:29.993837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9172, 106295)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9172, 106295)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pW_C.shape\n",
    "(len(Ws_t), len(Cs_t))\n",
    "assert pW_C.shape[0] == len(Ws_t)\n",
    "assert pW_C.shape[1] == len(Cs_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:30.138651Z",
     "start_time": "2019-08-11T05:07:30.066411Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    Cs_t[Cs_t.index('a couple of')]\n",
    "\n",
    "    pX0f = pW_C[:,Cs_t.index('a couple of')]\n",
    "\n",
    "    pW = pW_C_lookup(c = Cs_t[Cs_t.index('a couple of')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:30.379831Z",
     "start_time": "2019-08-11T05:07:30.139775Z"
    }
   },
   "outputs": [],
   "source": [
    "def pX0f_C(w, c):\n",
    "    return pW_C[:, Cs_t.index(c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(Y_0^i | c)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:30.514252Z",
     "start_time": "2019-08-11T05:07:30.381084Z"
    }
   },
   "outputs": [],
   "source": [
    "def pXhat0fY0i_unnormalized(xhat0f, y0i, c):\n",
    "    likelihood = pY0iX0f(y0i, xhat0f)\n",
    "#     prior = pW[xhat0f]\n",
    "    prior = pW_C_lookup(xhat0f, c)\n",
    "    return likelihood * prior\n",
    "\n",
    "def pY0i(y0i, c):\n",
    "#     l = len(ds2t(y0i))\n",
    "    y0i_t = ds2t(y0i)\n",
    "    l = len(y0i_t)\n",
    "    if y0i_t[-1] == rightEdge:\n",
    "        possible_source_wordforms = {w for w in Ws if len(ds2t(w)) == l}\n",
    "    else:\n",
    "        possible_source_wordforms = {w for w in Ws if len(ds2t(w)) >= l+1}\n",
    "#     x0ksWithLengthl = prefixesWithLength(l)\n",
    "#     py0kx0ks = tuple(pXhat0fY0k_unnormalized(x0k, y0k) for x0k in x0ksWithLengthl)\n",
    "\n",
    "#     sufficiently_long_words = {w for w in Ws if len(ds2t(w)) >= l+1}\n",
    "#     print(len(sufficiently_long_words))\n",
    "    #line below is slower by about a third (pypy/kotoba)\n",
    "#     sufficiently_long_words = wordformsAtLeastLlong(l, True)\n",
    "\n",
    "    py0ix0fs = (pXhat0fY0i_unnormalized(x0f, y0i, c) for x0f in possible_source_wordforms)\n",
    "#     def foo(x0f):\n",
    "#         return pXhat0fY0k_unnormalized(x0f, y0k)\n",
    "    # there's no apparent benefit to using foo + generator\n",
    "#     py0kx0fs = (foo(x0f) for x0f in sufficiently_long_words)\n",
    "# Parallel(n_jobs=-1, verbose=50, batch_size=4, prefer=\"processes\", backend=\"multiprocessing\")\n",
    "#     py0kx0fs = Parallel(n_jobs=8, batch_size=4, verbose=50, prefer=\"threads\", backend=\"multiprocessing\")(delayed(pXhat0fY0k_unnormalized)(x0f, y0k) for x0f in sufficiently_long_words)\n",
    "#     py0kx0fs = Parallel(n_jobs=8, prefer=\"threads\")(delayed(pXhat0fY0k_unnormalized)(x0f, y0k) for x0f in sufficiently_long_words)\n",
    "    return sum(py0ix0fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:31.671001Z",
     "start_time": "2019-08-11T05:07:30.515532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and stress disorders'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.6368955055803817e-06"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_context = choice(Cs_t); random_context\n",
    "pY0i('⋊.k.ɑ.n.t', random_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:31.674432Z",
     "start_time": "2019-08-11T05:07:31.672395Z"
    }
   },
   "outputs": [],
   "source": [
    "# {w for w in Ws if (w,'⋊.k.ɑ.n.t') in prefix_relation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:31.810398Z",
     "start_time": "2019-08-11T05:07:31.675692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'take their own'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6.889596570332141e-07"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_context = choice(Cs_t); random_context\n",
    "pXhat0fY0i_unnormalized('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(Y_0^i|x_0^k)$ sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:31.997852Z",
     "start_time": "2019-08-11T05:07:31.817080Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_pY0iX0k(x0k, debug = False):\n",
    "    xp_t = ds2t(x0k) #\"x prefix\"\n",
    "#     yp_t = ds2t(y0i) #\"y prefix\"\n",
    "#     if len(yp_t) != len(xp_t):\n",
    "#         raise Exception('Lengths of y0i and x0i must match.')\n",
    "    if len(xp_t) == 1:\n",
    "        if xp_t[0] != leftEdge:\n",
    "            raise Exception('First symbol of x0k must be left word edge symbol.')\n",
    "        else:\n",
    "            return leftEdge\n",
    "    if len(xp_t) < 3:\n",
    "        raise Exception('|x0k| must be ≥ 3')\n",
    "    \n",
    "    # xi = xp_t[-2] #just-completed segment\n",
    "    # xk = xp_t[-1] #upcoming segment that we only get coarticulatory information about\n",
    "    # xik = t2ds((xi, xk))\n",
    "    # yk = sampleFrom(p3Y1X01[xik])\n",
    "#     yk = yp_t[-1]\n",
    "#     preview_term = p3Y1X01[t2ds((xi, xk))][yk]\n",
    "    \n",
    "#     if debug:\n",
    "#         print('xi = {0}\\nxk = {1}\\nyk = {2}'.format(xi, xk, yk))\n",
    "#         print('preview term = {0}'.format(preview_term))\n",
    "    \n",
    "#     x0i_t = xp_t[:-1] #prefix of intended wordform that has actually been produced\n",
    "#     y0i_t = yp_t[:-1]\n",
    "#     x0i_ds = t2ds(x0i_t)\n",
    "#     y0i_ds = t2ds(y0i_t)\n",
    "\n",
    "#     if debug:\n",
    "#         print('produced prefix x0i = {0}'.format(x0i_ds))\n",
    "#         print('perceived prefix y0i = {0}'.format(y0i_ds))\n",
    "    \n",
    "    x012s = dsToKfactorSequence(3, t2ds(xp_t))\n",
    "#     print('x012s: {0}'.format(x012s))\n",
    "#     y1s = y0i_t[1:]\n",
    "    y1s = [sampleFrom(p3Y1X012[x012]) for x012 in x012s]\n",
    "#     print('y1s: {0}'.format(y1s))\n",
    "#     pairs = list(zip(x012s, y1s))\n",
    "#     produced_terms = tuple([p3Y1X012[x012][y1] for x012, y1 in pairs])\n",
    "    y0i_t = tuple( [leftEdge] + y1s )\n",
    "#     print('y0i_t = {0}'.format(y0i_t))\n",
    "    y0i_ds = t2ds(y0i_t)\n",
    "#     print('y0i_ds = {0}'.format(y0i_ds))\n",
    "#     assert len(y0i_t) == len(x0i_t)\n",
    "    # yp_t = tuple([leftEdge] + y1s + [yk])\n",
    "    # y0i = t2ds(yp_t)\n",
    "    \n",
    "    if xp_t[-1] == rightEdge:\n",
    "        y0i_ds = y0i_ds + '.' + rightEdge\n",
    "    \n",
    "    if debug:\n",
    "#         sorted_outcomes = Y1s_t\n",
    "        return y0i_ds, np.array([[p3Y1X012[x012][k] for k in Y1s_t] for x012 in x012s]).T\n",
    "#         return y0i_ds, np.array([[p3Y1X012[x012][k] for k in sorted(p3Y1X012[x012].keys())] for x012 in x012s]).T\n",
    "#         print('x012s: {0}'.format(x012s))\n",
    "#         print('y1s: {0}'.format(tuple(y1s)))\n",
    "#         print('main terms: {0}'.format(produced_terms))\n",
    "\n",
    "    return y0i_ds\n",
    "#     return preview_term * prod(produced_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:32.181000Z",
     "start_time": "2019-08-11T05:07:31.999094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.æ.k.t.ɪ.v.ə.t.i.⋉.⋉'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.t.ʌ.t.f.v.l.ɑ.i.⋉.⋉',\n",
       " '⋊.aɪ.s.aɪ.ɪ.v.ɔɪ.t.i.⋉.⋉',\n",
       " '⋊.ɑ.ɪ.t.h.v.ɪ.t.j.⋉.⋉',\n",
       " '⋊.oʊ.ʊ.t.ɪ.v.ɑ.t.ʃ.⋉.⋉',\n",
       " '⋊.ŋ.n.t.eɪ.v.ɪ.t.h.⋉.⋉',\n",
       " '⋊.ɑ.w.t.ŋ.v.ʌ.t.i.⋉.⋉',\n",
       " '⋊.k.k.ʃ.ɪ.v.ɑ.t.i.⋉.⋉',\n",
       " '⋊.n.æ.t.ɪ.ɪ.ʌ.ɛ.i.⋉.⋉',\n",
       " '⋊.v.k.eɪ.h.p.ɔɪ.n.i.⋉.⋉',\n",
       " '⋊.aɪ.k.t.ɪ.v.ʒ.t.i.⋉.⋉',\n",
       " '⋊.ɑ.k.t.ʌ.j.ɛ.t.ɑ.⋉.⋉',\n",
       " '⋊.ɑ.k.t.ɪ.z.k.t.i.⋉.⋉',\n",
       " '⋊.ʒ.k.t.ʊ.v.ɔɪ.z.i.⋉.⋉',\n",
       " '⋊.ɑ.ʃ.t.u.f.ʌ.t.i.⋉.⋉',\n",
       " '⋊.æ.k.t.ɪ.v.ʃ.t.w.⋉.⋉',\n",
       " '⋊.ɛ.k.tʃ.ɪ.æ.ɛ.t.i.⋉.⋉',\n",
       " '⋊.æ.æ.d.v.v.ʊ.h.i.⋉.⋉',\n",
       " '⋊.eɪ.k.t.ʌ.v.ʌ.dʒ.i.⋉.⋉',\n",
       " '⋊.ʒ.k.ð.ɔɪ.v.ɚ.t.i.⋉.⋉',\n",
       " '⋊.aɪ.k.t.ɪ.v.aʊ.t.i.⋉.⋉']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.æ.k.t.f.v.ɪ.t.i.⋉',\n",
       " '⋊.g.k.tʃ.eɪ.v.b.z.i.⋉',\n",
       " '⋊.ɑ.k.ʊ.ɪ.v.h.t.ð.⋉',\n",
       " '⋊.æ.ɔɪ.ʌ.ɪ.k.t.oʊ.i.⋉',\n",
       " '⋊.b.k.t.d.v.n.t.i.⋉',\n",
       " '⋊.æ.k.t.ʊ.ʊ.t.t.p.⋉',\n",
       " '⋊.ɑ.k.t.ɪ.tʃ.ɔɪ.ɔɪ.ɛ.⋉',\n",
       " '⋊.aɪ.k.t.aʊ.v.ʌ.dʒ.i.⋉',\n",
       " '⋊.aɪ.k.t.ɪ.v.f.u.i.⋉',\n",
       " '⋊.aɪ.k.t.ɪ.v.ʊ.eɪ.d.⋉',\n",
       " '⋊.æ.k.t.ɪ.j.eɪ.t.i.⋉',\n",
       " '⋊.æ.θ.t.ɪ.v.ʌ.t.t.⋉',\n",
       " '⋊.ŋ.k.t.ɪ.v.ɪ.ɚ.i.⋉',\n",
       " '⋊.ɑ.d.d.ɛ.ɚ.eɪ.b.i.⋉',\n",
       " '⋊.ɑ.j.eɪ.ɪ.ɹ.p.ʊ.i.⋉',\n",
       " '⋊.ɑ.k.ŋ.ɪ.v.ʌ.ʊ.i.⋉',\n",
       " '⋊.ɑ.k.ʌ.eɪ.v.h.t.i.⋉',\n",
       " '⋊.b.ŋ.t.ɪ.ʃ.aɪ.θ.i.⋉',\n",
       " '⋊.aɪ.f.t.ɪ.v.ɛ.t.i.⋉',\n",
       " '⋊.æ.ɚ.t.ɪ.v.d.t.i.⋉']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.oʊ.æ.ɪ.ɪ.v.eɪ.dʒ',\n",
       " '⋊.æ.ɔɪ.t.ɛ.u.ɪ.t',\n",
       " '⋊.æ.eɪ.t.ɪ.v.p.t',\n",
       " '⋊.æ.tʃ.t.ɛ.v.æ.t',\n",
       " '⋊.ɑ.n.t.ɪ.v.g.t']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'⋊.æ.k.t.ɪ.v.ə.t.i.⋉.⋉'\n",
    "activity_samples1 = [sample_pY0iX0k('⋊.æ.k.t.ɪ.v.ə.t.i.⋉.⋉') for each in range(20)]; activity_samples1\n",
    "activity_samples2 = [sample_pY0iX0k('⋊.æ.k.t.ɪ.v.ə.t.i.⋉') for each in range(20)]; activity_samples2\n",
    "activity_samples3 = [sample_pY0iX0k('⋊.æ.k.t.ɪ.v.ə.t.i') for each in range(5)]; activity_samples3\n",
    "del activity_samples1, activity_samples2, activity_samples3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:32.317080Z",
     "start_time": "2019-08-11T05:07:32.182012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.m.ɪ.s.k.ɪ'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.m.ɪ.s.k',\n",
       " '⋊.m.ɪ.s.k',\n",
       " '⋊.m.k.s.k',\n",
       " '⋊.m.ɪ.s.t',\n",
       " '⋊.m.k.s.u',\n",
       " '⋊.m.θ.ɔɪ.ʒ',\n",
       " '⋊.dʒ.ʃ.b.k',\n",
       " '⋊.m.eɪ.s.k',\n",
       " '⋊.m.ɪ.s.f',\n",
       " '⋊.m.ɪ.s.d',\n",
       " '⋊.m.ɛ.s.k',\n",
       " '⋊.m.ɪ.s.ɔɪ',\n",
       " '⋊.n.ð.s.k',\n",
       " '⋊.ɪ.ɪ.s.k',\n",
       " '⋊.m.ʒ.ʃ.k',\n",
       " '⋊.ʒ.z.s.k',\n",
       " '⋊.p.ɪ.z.k',\n",
       " '⋊.m.j.s.k',\n",
       " '⋊.m.l.ʒ.k',\n",
       " '⋊.b.ɪ.s.k',\n",
       " '⋊.m.ɛ.s.k',\n",
       " '⋊.m.eɪ.s.ʌ',\n",
       " '⋊.m.ɛ.p.ʊ',\n",
       " '⋊.m.w.s.k',\n",
       " '⋊.m.ɪ.s.k',\n",
       " '⋊.m.ɪ.s.k',\n",
       " '⋊.f.m.s.k',\n",
       " '⋊.m.ɛ.l.k',\n",
       " '⋊.ʌ.eɪ.ʃ.k',\n",
       " '⋊.m.ɪ.p.ʌ',\n",
       " '⋊.m.l.æ.j',\n",
       " '⋊.m.i.s.g',\n",
       " '⋊.m.ɪ.s.k',\n",
       " '⋊.n.ʒ.l.k',\n",
       " '⋊.m.ʒ.ŋ.k',\n",
       " '⋊.m.m.aʊ.θ',\n",
       " '⋊.ʃ.ɪ.s.g',\n",
       " '⋊.m.ɪ.s.n',\n",
       " '⋊.u.eɪ.s.k',\n",
       " '⋊.m.s.ɪ.k',\n",
       " '⋊.m.ʒ.p.k',\n",
       " '⋊.n.ɪ.b.g',\n",
       " '⋊.m.ɪ.s.k',\n",
       " '⋊.m.eɪ.v.k',\n",
       " '⋊.m.ɪ.m.v',\n",
       " '⋊.m.ɛ.ɹ.aʊ',\n",
       " '⋊.ɛ.ɪ.s.k',\n",
       " '⋊.m.t.s.k',\n",
       " '⋊.m.ɪ.s.aʊ',\n",
       " '⋊.n.eɪ.v.eɪ']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_prefix\n",
    "random_channel_samples = [sample_pY0iX0k(random_source_prefix) for each in range(50)]; random_channel_samples\n",
    "del random_channel_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:32.411655Z",
     "start_time": "2019-08-11T05:07:32.319397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['⋊.k.ɑ.n',\n",
       " '⋊.l.ɑ.n',\n",
       " '⋊.k.ɹ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ɑ.ʌ',\n",
       " '⋊.aɪ.ɑ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ɑ.oʊ',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ʌ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.p.ɑ.n',\n",
       " '⋊.k.ɑ.aɪ',\n",
       " '⋊.k.ʌ.n',\n",
       " '⋊.k.ʌ.aɪ',\n",
       " '⋊.l.ɑ.n',\n",
       " '⋊.z.ɑ.tʃ',\n",
       " '⋊.k.ʌ.n',\n",
       " '⋊.k.ʌ.aʊ',\n",
       " '⋊.k.f.n',\n",
       " '⋊.k.ɑ.ɑ',\n",
       " '⋊.g.ɑ.n',\n",
       " '⋊.k.tʃ.tʃ',\n",
       " '⋊.k.tʃ.u',\n",
       " '⋊.k.ɑ.ʃ',\n",
       " '⋊.b.oʊ.n',\n",
       " '⋊.eɪ.ʊ.n',\n",
       " '⋊.k.ɑ.ɛ',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.g.ɑ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.b.tʃ.n',\n",
       " '⋊.k.ɹ.ʌ',\n",
       " '⋊.k.ɑ.m',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.k.ɑ.θ',\n",
       " '⋊.k.ʌ.v',\n",
       " '⋊.k.ɑ.ʌ',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.aɪ.ɑ.j',\n",
       " '⋊.k.ɑ.ɑ',\n",
       " '⋊.ʒ.ɑ.ɔɪ',\n",
       " '⋊.ʒ.ɑ.æ',\n",
       " '⋊.k.p.n',\n",
       " '⋊.k.ɑ.n',\n",
       " '⋊.aɪ.ɑ.n',\n",
       " '⋊.k.ɹ.n']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_samples = [sample_pY0iX0k('⋊.k.ɑ.n.t') for each in range(50)]; cont_samples\n",
    "del cont_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:32.502303Z",
     "start_time": "2019-08-11T05:07:32.416063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04390334, 0.01805178, 0.00911065],\n",
       "       [0.00700978, 0.01374583, 0.00911065],\n",
       "       [0.02545656, 0.00721312, 0.00911065],\n",
       "       [0.00700978, 0.00711758, 0.00898997],\n",
       "       [0.00682531, 0.00692774, 0.01700733],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00682531, 0.0070233 , 0.0088709 ],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00682531, 0.00711758, 0.00898997],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.0051651 , 0.00619171, 0.00782054],\n",
       "       [0.65246265, 0.00711758, 0.00898997],\n",
       "       [0.02545656, 0.00721312, 0.00911065],\n",
       "       [0.00700978, 0.00711758, 0.00898997],\n",
       "       [0.00700978, 0.00721312, 0.6450247 ],\n",
       "       [0.00700978, 0.01374583, 0.00911065],\n",
       "       [0.00700978, 0.00711758, 0.00898997],\n",
       "       [0.00682531, 0.00711758, 0.00898997],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00682531, 0.00711758, 0.00898997],\n",
       "       [0.00664084, 0.00702074, 0.00886765],\n",
       "       [0.00682531, 0.0070233 , 0.0088709 ],\n",
       "       [0.00700978, 0.01805178, 0.00911065],\n",
       "       [0.00682531, 0.00692774, 0.0087502 ],\n",
       "       [0.00700978, 0.00619171, 0.01490336],\n",
       "       [0.00700978, 0.59565208, 0.00911065],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00682531, 0.00711758, 0.00898997],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.00700978, 0.01374583, 0.00911065],\n",
       "       [0.00682531, 0.00692774, 0.0087502 ],\n",
       "       [0.00700978, 0.00721312, 0.00911065],\n",
       "       [0.02545656, 0.10792075, 0.01736189],\n",
       "       [0.00682531, 0.0070233 , 0.0088709 ],\n",
       "       [0.00700978, 0.00711758, 0.00898997],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pY0iX0k('⋊.k.ɑ.n.t', debug=True)[1].shape\n",
    "sample_pY0iX0k('⋊.k.ɑ.n.t', debug=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(\\widehat{X_0^f}|Y_0^{i}, C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\widehat{x_0^f}|y_0^{i}, c) = \\frac{p(y_0^{i} | \\widehat{x_0^f})p(\\widehat{x_0^f} | c)}{p(y_0^{i})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.340464Z",
     "start_time": "2019-08-11T05:07:32.507024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"that's the half\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('⋊.b.ɹ.u.h.ɑ.h.ɑ.⋉.⋉', '⋊.p.ʊ.f.t.d', \"that's the half\")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8.333147900706623e-07"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pXhat0fY0i_old(xhat0f, y0i, c):\n",
    "    numerator = pXhat0fY0i_unnormalized(xhat0f, y0i, c)\n",
    "    denominator = pY0i(y0i, c)\n",
    "    if denominator == 0.0:\n",
    "#         if numerator == 0.0:\n",
    "#             print('both numerator and denominator are 0')\n",
    "#         else:\n",
    "#             print('just the denominator is 0')\n",
    "        return 0\n",
    "    return numerator / denominator\n",
    "\n",
    "random_context = choice(Cs_t); random_context\n",
    "(random_source_wordform, random_channel_prefix, random_context)\n",
    "pXhat0fY0i_old(random_source_wordform, random_channel_prefix, random_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\widehat{p}(\\widehat{X_0^f}|X_0^i;X_{i+1}, C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\widehat{x_0^f} | x_0^i;x_{i+1}, c) = \\sum\\limits_{y_0^{i}} p(\\widehat{x_0^f} | y_0^{i}, c)p(y_0^{i}|x_0^{i};x_{i+1}, c)$\n",
    "\n",
    "$\\widehat{p}(\\widehat{x_0^f}|x_0^i;x_{i+1}, c) = \\frac{1}{m}\\sum\\limits_{m \\text{ sampled } y_0^{i}\\text{s from } p(Y_0^{i} | x_0^{i};x_{i+1})} p(\\widehat{x_0^f} | y_0^{i}, c)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.344778Z",
     "start_time": "2019-08-11T05:07:37.341616Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE = OLD\n",
    "def phatXhat0fX0k_baseline(xhat0f, x0k, c, m = 50, my_j=None):\n",
    "#     y0ks = tuple(sample_pY0kX0k(x0k) for each in range(n))\n",
    "#     terms = (pXhat0fY0k(xhat0f, y0k) for y0k in y0ks)\n",
    "\n",
    "#     foo = partial(pXhat0fY0i, xhat0f)\n",
    "#     def foo(y0i):\n",
    "#         return pXhat0fY0i(xhat0f, y0i)\n",
    "#     terms = (foo(y0i) for y0i in (sample_pY0iX0i(x0i) for each in range(n)))\n",
    "#     terms = Parallel(n_jobs=8, prefer=\"threads\")(delayed(foo)(y0i) for y0i in y0is)\n",
    "#     terms = Parallel(n_jobs=8, prefer=\"threads\")(delayed(foo)(y0i) for y0i in (sample_pY0iX0i(x0i) for each in range(n)))\n",
    "#     terms = Parallel(n_jobs=5, verbose=50, batch_size=10, prefer=\"threads\")(delayed(pXhat0fY0i)(xhat0f, y0i) for y0i in (sample_pY0iX0i(x0i) for each in range(n)))\n",
    "#     terms = Parallel(n_jobs=-1, verbose=50, batch_size=round(n/12), prefer=\"processes\", backend=\"multiprocessing\")(delayed(pXhat0fY0i)(xhat0f, y0i) for y0i in (sample_pY0iX0i(x0i) for each in range(n)))\n",
    "\n",
    "#     terms = Parallel(n_jobs=-1, batch_size=round(n/12), prefer=\"processes\", backend=\"multiprocessing\")(delayed(pXhat0fY0k_old)(xhat0f, y0k) for y0k in (sample_pY0kX0k(x0k) for each in range(n)))\n",
    "#     terms = Parallel(n_jobs=-1, batch_size='auto', prefer=\"processes\", backend=\"multiprocessing\")(delayed(pXhat0fY0i_old)(xhat0f, y0i) for y0i in (sample_pY0iX0k(x0k) for each in range(m)))\n",
    "    if my_j is None:\n",
    "        my_j = -1\n",
    "    terms = Parallel(n_jobs=my_j, batch_size='auto', prefer=\"processes\", backend=\"multiprocessing\")(delayed(pXhat0fY0i_old)(xhat0f, y0i, c) for y0i in (sample_pY0iX0k(x0k) for each in range(m)))\n",
    "#     terms = (pXhat0fY0k_old(xhat0f, y0k) for y0k in (sample_pY0kX0k(x0k) for each in range(n)))\n",
    "    s = sum(terms)\n",
    "    sbar = (1.0 * s) / m\n",
    "    return sbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.540014Z",
     "start_time": "2019-08-11T05:07:37.345616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you know another'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_context = choice(Cs_t); random_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.623550Z",
     "start_time": "2019-08-11T05:07:37.544428Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.707138Z",
     "start_time": "2019-08-11T05:07:37.628166Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.791737Z",
     "start_time": "2019-08-11T05:07:37.711747Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    {w for w in Ws if (w,'⋊.k.ɑ.n.t') in prefix_relation}\n",
    "    [f\"p(W' = {w}) → {pW[w]}\"\n",
    "     for w in sorted(list({w for w in Ws if (w,'⋊.k.ɑ.n.t') in prefix_relation}),\n",
    "                     key=lambda w:pW_C_lookup(w=w, c=random_context), reverse=True)]\n",
    "\n",
    "    [f\"p(W' = {w}|r = '⋊.k.ɑ.n.t') → {phatXhat0fX0k_baseline(w, '⋊.k.ɑ.n.t', random_context, 50, -1)}\"\n",
    "     for w in sorted(list({w for w in Ws if (w,'⋊.k.ɑ.n.t') in prefix_relation}),\n",
    "                     key=lambda w:phatXhat0fX0k_baseline(w, '⋊.k.ɑ.n.t', random_context, 50, -1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:37.959024Z",
     "start_time": "2019-08-11T05:07:37.796383Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    {w for w in Ws if (w,'⋊.k.ɑ.n') in prefix_relation}\n",
    "\n",
    "    [f\"p(W' = {w}) → {pW_C_lookup(w=w, c=random_context)}\"\n",
    "     for w in sorted(list({w for w in Ws if (w,'⋊.k.ɑ.n') in prefix_relation}),\n",
    "                     key=lambda w:pW_C_lookup(w=w, c=random_context), reverse=True)]\n",
    "\n",
    "    [f\"p(W' = {w}|r = '⋊.k.ɑ.n.t') → {phatXhat0fX0k_baseline(w, '⋊.k.ɑ.n.t', random_context, 50, -1)}\"\n",
    "     for w in sorted(list({w for w in Ws if (w,'⋊.k.ɑ.n') in prefix_relation}),\n",
    "                     key=lambda w:pW_C_lookup(w=w, c=random_context), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:38.070651Z",
     "start_time": "2019-08-11T05:07:37.963537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.k.ɑ.n.t'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04390334, 0.01805178],\n",
       "       [0.00700978, 0.01374583],\n",
       "       [0.02545656, 0.00721312],\n",
       "       [0.00700978, 0.00711758],\n",
       "       [0.00682531, 0.00692774],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00682531, 0.0070233 ],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00682531, 0.00711758],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.0051651 , 0.00619171],\n",
       "       [0.65246265, 0.00711758],\n",
       "       [0.02545656, 0.00721312],\n",
       "       [0.00700978, 0.00711758],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00700978, 0.01374583],\n",
       "       [0.00700978, 0.00711758],\n",
       "       [0.00682531, 0.00711758],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00682531, 0.00711758],\n",
       "       [0.00664084, 0.00702074],\n",
       "       [0.00682531, 0.0070233 ],\n",
       "       [0.00700978, 0.01805178],\n",
       "       [0.00682531, 0.00692774],\n",
       "       [0.00700978, 0.00619171],\n",
       "       [0.00700978, 0.59565208],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00682531, 0.00711758],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.00700978, 0.01374583],\n",
       "       [0.00682531, 0.00692774],\n",
       "       [0.00700978, 0.00721312],\n",
       "       [0.02545656, 0.10792075],\n",
       "       [0.00682531, 0.0070233 ],\n",
       "       [0.00700978, 0.00711758],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'⋊.k.ɑ.n.t'\n",
    "len( ds2t('⋊.k.ɑ.n.t') )\n",
    "len( ds2t('⋊.k.ɑ.n.t') ) - 1\n",
    "retrieve_CM_for('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', 4)\n",
    "\n",
    "np.allclose( retrieve_CM_for('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', 4), \n",
    "             pY0k_X0ks[4][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of core calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:38.265504Z",
     "start_time": "2019-08-11T05:07:38.075251Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:38.379611Z",
     "start_time": "2019-08-11T05:07:38.270218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.ɹ.ɪ.d.i.m.⋉.⋉', 8715, 8)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform = choice(Ws_t)\n",
    "random_wordform_length = len(ds2t(random_wordform))\n",
    "random_wordform_idx = Ws_t.index(random_wordform)\n",
    "random_wordform, random_wordform_idx, random_wordform_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:38.494513Z",
     "start_time": "2019-08-11T05:07:38.380833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9172, 106295)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(9172,)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pW_C)\n",
    "pW_C.shape\n",
    "pW_C[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:38.598449Z",
     "start_time": "2019-08-11T05:07:38.495510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a couple of'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs_t[Cs_t.index('a couple of')]\n",
    "random_context = 'a couple of'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:38.935718Z",
     "start_time": "2019-08-11T05:07:38.603121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G         13G        9.6G        8.2M        8.5G         17G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.142184Z",
     "start_time": "2019-08-11T05:07:38.937298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pX0f = pW_C[:,Cs_t.index('a couple of')]\n",
    "# pX0f_torch = torch.from_numpy(pX0f)\n",
    "pW_C_torch = torch.from_numpy(pW_C).type(my_tt)\n",
    "pW_C_torch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.144984Z",
     "start_time": "2019-08-11T05:07:41.143236Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pW_t(c_idx):\n",
    "    return pW_C_torch[:,c_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.435395Z",
     "start_time": "2019-08-11T05:07:41.145838Z"
    }
   },
   "outputs": [],
   "source": [
    "# if r:\n",
    "CMsByLengthByWordformIndex = pY0k_X0ks\n",
    "CMsByLengthByWordformIndex_torch = [torch.from_numpy(each).type(my_tt) \n",
    "                                    for each in CMsByLengthByWordformIndex]\n",
    "exactCMsByLengthByWordformIndex = pY0f_X0fs\n",
    "exactCMsByLengthByWordformIndex_torch = [torch.tensor(each).type(my_tt) \n",
    "                                         for each in exactCMsByLengthByWordformIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.437992Z",
     "start_time": "2019-08-11T05:07:41.436590Z"
    }
   },
   "outputs": [],
   "source": [
    "# CMsByLengthByWordformIndex_cupy = cupy.array(CMsByLengthByWordformIndex)\n",
    "# CMsByLengthByWordformIndex_cupy.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.538980Z",
     "start_time": "2019-08-11T05:07:41.438923Z"
    }
   },
   "outputs": [],
   "source": [
    "# CMsByLengthByWordformIndex = [cupy.array(each.numpy()).get()\n",
    "#                               for each in CMsByLengthByWordformIndex_torch]\n",
    "# type(CMsByLengthByWordformIndex[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.630269Z",
     "start_time": "2019-08-11T05:07:41.540587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMsByLengthByWordformIndex[10].dtype\n",
    "CMsByLengthByWordformIndex_torch[10].dtype\n",
    "\n",
    "exactCMsByLengthByWordformIndex[10].dtype\n",
    "exactCMsByLengthByWordformIndex_torch[10].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:41.706228Z",
     "start_time": "2019-08-11T05:07:41.631235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CMsByLengthByWordformIndex_torch)\n",
    "len(exactCMsByLengthByWordformIndex_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.017309Z",
     "start_time": "2019-08-11T05:07:41.710727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɪ.d.i.m.⋉.⋉'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8715"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0140, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0244, 0.0134, 0.0070],\n",
       "        [0.0070, 0.0073, 0.5550, 0.0070, 0.0068],\n",
       "        [0.0068, 0.0071, 0.0078, 0.0068, 0.0066],\n",
       "        [0.0255, 0.1365, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0068, 0.0072, 0.0080, 0.0069, 0.0068],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.7307, 0.0070],\n",
       "        [0.0052, 0.0063, 0.0070, 0.0061, 0.0070],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0081, 0.0133, 0.7078],\n",
       "        [0.0070, 0.0073, 0.0156, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0138, 0.0081, 0.0070, 0.0068],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070],\n",
       "        [0.0070, 0.0073, 0.1053, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0255],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070],\n",
       "        [0.0066, 0.0072, 0.0080, 0.0069, 0.0070],\n",
       "        [0.0068, 0.0072, 0.0080, 0.0069, 0.0068],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0068, 0.0071, 0.0153, 0.0068, 0.0066],\n",
       "        [0.0070, 0.0063, 0.0070, 0.0061, 0.0236],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070],\n",
       "        [0.0070, 0.0810, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.5166, 0.0082, 0.0071, 0.0070],\n",
       "        [0.7264, 0.0073, 0.0277, 0.0071, 0.0070],\n",
       "        [0.0068, 0.0071, 0.0078, 0.0068, 0.0066],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070],\n",
       "        [0.0068, 0.0072, 0.0080, 0.0069, 0.0068],\n",
       "        [0.0070, 0.0073, 0.0081, 0.0070, 0.0068],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform\n",
    "random_wordform_idx\n",
    "random_wordform_length\n",
    "torch.equal(CMsByLengthByWordformIndex_torch[random_wordform_length][random_wordform_idx],\n",
    "            exactCMsByLengthByWordformIndex_torch[random_wordform_length][Ws_l_t[random_wordform_length].index(random_wordform)])\n",
    "CMsByLengthByWordformIndex_torch[random_wordform_length-1][random_wordform_idx]\n",
    "random_wordform in Ws_l_t[random_wordform_length-1]\n",
    "# exactCMsByLengthByWordformIndex_torch[random_wordform_length-1][Ws_l_t[random_wordform_length-1].index(random_wordform)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.020717Z",
     "start_time": "2019-08-11T05:07:42.018513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([173, 39, 3])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exactCMsByLengthByWordformIndex_torch[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.107063Z",
     "start_time": "2019-08-11T05:07:42.021506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMsByLengthByWordformIndex_torch[10].dtype\n",
    "exactCMsByLengthByWordformIndex_torch[10].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.189516Z",
     "start_time": "2019-08-11T05:07:42.108257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɪ.d.i.m.⋉.⋉'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('ɹ', 'ɪ', 'd', 'i', 'm', '⋉')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform\n",
    "ds2t(random_wordform)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.315845Z",
     "start_time": "2019-08-11T05:07:42.192146Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɪ.d.i.m.⋉.⋉'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('⋊', 'ɹ', 'ɪ', 'd', 'i', 'm', '⋉', '⋉')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8715"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'--'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00700978, 0.01400384, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.02436973, 0.01344191, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00725118, 0.55496706, 0.00696021, 0.00682531,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00705778, 0.00784789, 0.00677457, 0.00664084,\n",
       "        0.        ],\n",
       "       [0.02545656, 0.13652874, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00715513, 0.00795614, 0.00686802, 0.00682531,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00725118, 0.00806294, 0.00696021, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.73074413, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.0051651 , 0.00630793, 0.00701409, 0.00605481, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00725118, 0.00806294, 0.00696021, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00725118, 0.00806294, 0.01326387, 0.70780299,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.01557155, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.01381835, 0.00806294, 0.00696021, 0.00682531,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00725118, 0.00806294, 0.00696021, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.10530888, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.02545656,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00725118, 0.00806294, 0.00696021, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00664084, 0.00715252, 0.00795323, 0.00686551, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00715513, 0.00795614, 0.00686802, 0.00682531,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00705778, 0.01525355, 0.00677457, 0.00664084,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00630793, 0.00701409, 0.00605481, 0.02361188,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00725118, 0.00806294, 0.00696021, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.08104618, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.51661013, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.72643424, 0.00734851, 0.02774147, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00705778, 0.00784789, 0.00677457, 0.00664084,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00734851, 0.00817117, 0.00705364, 0.00700978,\n",
       "        0.        ],\n",
       "       [0.00682531, 0.00715513, 0.00795614, 0.00686802, 0.00682531,\n",
       "        0.        ],\n",
       "       [0.00700978, 0.00725118, 0.00806294, 0.00696021, 0.00682531,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'--'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 6])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0140, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0244, 0.0134, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.5550, 0.0070, 0.0068, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0078, 0.0068, 0.0066, 0.0000],\n",
       "        [0.0255, 0.1365, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0072, 0.0080, 0.0069, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.7307, 0.0070, 0.0000],\n",
       "        [0.0052, 0.0063, 0.0070, 0.0061, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0081, 0.0133, 0.7078, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0156, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0138, 0.0081, 0.0070, 0.0068, 0.0000],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.1053, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0255, 0.0000],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070, 0.0000],\n",
       "        [0.0066, 0.0072, 0.0080, 0.0069, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0072, 0.0080, 0.0069, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0153, 0.0068, 0.0066, 0.0000],\n",
       "        [0.0070, 0.0063, 0.0070, 0.0061, 0.0236, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0073, 0.0081, 0.0070, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0810, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.5166, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.7264, 0.0073, 0.0277, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0078, 0.0068, 0.0066, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0082, 0.0071, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0072, 0.0080, 0.0069, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0073, 0.0081, 0.0070, 0.0068, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform\n",
    "ds2t(random_wordform)\n",
    "random_wordform_idx\n",
    "random_wordform_length\n",
    "random_wordform_CM = CMsByLengthByWordformIndex_torch[random_wordform_length][random_wordform_idx]\n",
    "'--'\n",
    "retrieve_CM_for(random_wordform, len(ds2t(random_wordform)))\n",
    "np.allclose(retrieve_CM_for(random_wordform, len(ds2t(random_wordform))),\n",
    "            CMsByLengthByWordformIndex[random_wordform_length][random_wordform_idx])\n",
    "'--'\n",
    "CMsByLengthByWordformIndex_torch[random_wordform_length][random_wordform_idx].shape\n",
    "random_wordform_CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.711417Z",
     "start_time": "2019-08-11T05:07:42.317809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G         17G        5.7G        8.2M        8.5G         13G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:42.976872Z",
     "start_time": "2019-08-11T05:07:42.717453Z"
    }
   },
   "outputs": [],
   "source": [
    "if not benchmark:\n",
    "    del pY0k_X0ks\n",
    "    del pY0f_X0fs\n",
    "    del CMsByLengthByWordformIndex\n",
    "    del exactCMsByLengthByWordformIndex\n",
    "    del pW_C\n",
    "    del pX0f_C\n",
    "    del p3Y1X012\n",
    "    if not r and e:\n",
    "        del cousin_mats\n",
    "        del sphere_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:43.315299Z",
     "start_time": "2019-08-11T05:07:42.977960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        7.5G         15G        8.2M        8.5G         23G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:43.327164Z",
     "start_time": "2019-08-11T05:07:43.321339Z"
    }
   },
   "outputs": [],
   "source": [
    "# del exactCMsByLengthByWordformIndex_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:43.569997Z",
     "start_time": "2019-08-11T05:07:43.330801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        7.5G         15G        8.2M        8.5G         23G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:43.579062Z",
     "start_time": "2019-08-11T05:07:43.576245Z"
    }
   },
   "outputs": [],
   "source": [
    "# del Ws_l_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:43.859483Z",
     "start_time": "2019-08-11T05:07:43.580273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        7.5G         15G        8.2M        8.5G         23G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:43.876559Z",
     "start_time": "2019-08-11T05:07:43.865648Z"
    }
   },
   "outputs": [],
   "source": [
    "# if not r:\n",
    "def depthSampler2a_t(CM, m=1):\n",
    "    '''\n",
    "    Given \n",
    "     - a sequence of channel distributions (i.e. a pytorch tensor)\n",
    "       associated with some prefix x_0^i of the lexicon\n",
    "     - a number of samples m\n",
    "    this returns m samples from the channel distribution p(Y_0^i|x_0^i),\n",
    "    where each 'sample' (i.e. channel string) is a sequence of one hot vectors.\n",
    "\n",
    "    Let l = i+1:\n",
    "    |depthSampler2a_t(|CM| = (|Y1|, l), m)| = (m, l, |Y1|)\n",
    "    '''\n",
    "    stack = torch.zeros((m, CM.shape[1], CM.shape[0]))\n",
    "#         print(f'{stack.dtype}')\n",
    "    for eachStack in torch.arange(m):\n",
    "        for i in torch.arange(CM.shape[1]):\n",
    "            stack[eachStack, i] = torch.distributions.Multinomial(1, CM[:,i]).sample()\n",
    "    return stack\n",
    "#         return torch.squeeze(stack)\n",
    "# else:\n",
    "#     def depthSampler2a_t(xCM, m=1):\n",
    "#         stack = torch.zeros((m, xCM.shape[1], xCM.shape[0]))\n",
    "#         for eachStack in torch.arange(m):\n",
    "#             for i in torch.arange(xCM.shape[1]):\n",
    "#                 stack[eachStack, i] = torch.distributions.Multinomial(1, xCM[:,i]).sample()\n",
    "#         return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.012487Z",
     "start_time": "2019-08-11T05:07:43.877659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 6])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform_CM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.196641Z",
     "start_time": "2019-08-11T05:07:44.017324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɪ.d.i.m.⋉.⋉'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'i.eɪ.n.z.m.⋉'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.i.eɪ.n.z.m.⋉'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 39])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform\n",
    "sampled_channel_sequences = depthSampler2a_t(random_wordform_CM, m=2); sampled_channel_sequences\n",
    "channelSeqOHs2ds(sampled_channel_sequences.numpy()[0], False)\n",
    "channelSeqOHs2ds(sampled_channel_sequences.numpy()[0], True)\n",
    "sampled_channel_sequences.shape\n",
    "del sampled_channel_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.313127Z",
     "start_time": "2019-08-11T05:07:44.197532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɪ.d.i.m.⋉.⋉'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['⋊.eɪ.ɪ.b.i.ŋ.⋉',\n",
       " '⋊.ɛ.ɪ.u.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.ʃ.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɔɪ.t.i.m.⋉',\n",
       " '⋊.ɹ.ʊ.t.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.u.⋉',\n",
       " '⋊.ɛ.eɪ.d.ɛ.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.z.t.i.ð.⋉',\n",
       " '⋊.ɹ.ɛ.d.tʃ.ŋ.⋉',\n",
       " '⋊.ɹ.ɪ.t.ɔɪ.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.ŋ.⋉',\n",
       " '⋊.ɹ.ɪ.t.i.m.⋉',\n",
       " '⋊.i.dʒ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.eɪ.w.m.⋉',\n",
       " '⋊.ɹ.ɪ.ɹ.oʊ.m.⋉',\n",
       " '⋊.d.ʌ.d.i.m.⋉',\n",
       " '⋊.ɹ.l.d.k.m.⋉',\n",
       " '⋊.ʌ.aʊ.d.ɚ.m.⋉',\n",
       " '⋊.ɹ.ʌ.θ.aʊ.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.ɚ.⋉',\n",
       " '⋊.ɹ.ɛ.d.i.m.⋉',\n",
       " '⋊.l.ɪ.d.θ.m.⋉',\n",
       " '⋊.z.ɪ.d.m.u.⋉',\n",
       " '⋊.p.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.ɹ.ɛ.⋉',\n",
       " '⋊.ɹ.ɪ.ʊ.i.m.⋉',\n",
       " '⋊.s.ɑ.d.i.l.⋉',\n",
       " '⋊.ɑ.ɪ.t.ð.m.⋉',\n",
       " '⋊.ɹ.ɪ.g.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.n.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.æ.i.m.⋉',\n",
       " '⋊.ŋ.p.æ.i.m.⋉',\n",
       " '⋊.g.p.aʊ.i.m.⋉',\n",
       " '⋊.s.ɪ.k.tʃ.ɪ.⋉',\n",
       " '⋊.ɹ.ɪ.ɑ.m.u.⋉',\n",
       " '⋊.ɹ.s.d.i.ɑ.⋉',\n",
       " '⋊.v.ɪ.d.i.u.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.u.ɪ.d.v.m.⋉',\n",
       " '⋊.aɪ.eɪ.d.oʊ.m.⋉',\n",
       " '⋊.ɹ.ɛ.n.i.m.⋉',\n",
       " '⋊.ɹ.ɛ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɛ.ɑ.ʒ.ŋ.⋉',\n",
       " '⋊.ɹ.ʒ.d.ʌ.m.⋉',\n",
       " '⋊.g.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.j.oʊ.i.ŋ.⋉',\n",
       " '⋊.n.ɛ.t.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.l.u.ð.⋉',\n",
       " '⋊.b.ɛ.d.i.f.⋉',\n",
       " '⋊.h.oʊ.ʃ.i.k.⋉',\n",
       " '⋊.ɹ.ɪ.d.dʒ.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.f.m.⋉',\n",
       " '⋊.ɹ.s.t.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɑ.ɪ.t.i.m.⋉',\n",
       " '⋊.ɹ.ɚ.d.i.l.⋉',\n",
       " '⋊.ɑ.ɛ.t.ʃ.ɔɪ.⋉',\n",
       " '⋊.ɹ.eɪ.ʊ.i.b.⋉',\n",
       " '⋊.ɹ.aɪ.d.m.m.⋉',\n",
       " '⋊.ɹ.ɪ.f.s.m.⋉',\n",
       " '⋊.ɹ.ɪ.ʌ.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.t.i.m.⋉',\n",
       " '⋊.ɹ.f.ɹ.i.m.⋉',\n",
       " '⋊.θ.ɪ.d.i.u.⋉',\n",
       " '⋊.ɹ.ɛ.d.i.m.⋉',\n",
       " '⋊.ɪ.l.d.i.i.⋉',\n",
       " '⋊.ɹ.ɪ.s.ɹ.m.⋉',\n",
       " '⋊.v.eɪ.d.v.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.eɪ.f.⋉',\n",
       " '⋊.ɹ.ɪ.ɹ.i.m.⋉',\n",
       " '⋊.ɹ.h.d.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.θ.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.ɹ.i.⋉',\n",
       " '⋊.g.ɛ.æ.h.m.⋉',\n",
       " '⋊.ɹ.ɛ.d.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.v.i.m.⋉',\n",
       " '⋊.ɹ.ɛ.z.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.d.ð.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.ŋ.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.t.ʌ.m.⋉',\n",
       " '⋊.ɪ.ɪ.d.i.m.⋉',\n",
       " '⋊.ʃ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.b.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.m.⋉',\n",
       " '⋊.ɹ.eɪ.d.i.m.⋉',\n",
       " '⋊.ɛ.eɪ.j.i.m.⋉',\n",
       " '⋊.ʊ.w.d.i.m.⋉',\n",
       " '⋊.f.ɪ.d.tʃ.m.⋉',\n",
       " '⋊.ɹ.eɪ.d.i.u.⋉',\n",
       " '⋊.u.ɪ.v.i.m.⋉',\n",
       " '⋊.oʊ.ɪ.d.θ.m.⋉',\n",
       " '⋊.ɛ.k.p.aɪ.m.⋉',\n",
       " '⋊.ɹ.ɪ.d.i.θ.⋉',\n",
       " '⋊.ɹ.ɑ.t.i.m.⋉',\n",
       " '⋊.ɹ.ɪ.t.i.m.⋉']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform\n",
    "sampled_channel_sequences2 = depthSampler2a_t(random_wordform_CM, m=100)\n",
    "[channelSeqOHs2ds(each.numpy(), True) for each in sampled_channel_sequences2]\n",
    "del sampled_channel_sequences2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.323318Z",
     "start_time": "2019-08-11T05:07:44.314244Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_wordform\n",
    "    sampled_channel_sequences3 = [sample_pY0iX0k(random_wordform) for each in range(50)]; sampled_channel_sequences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.426754Z",
     "start_time": "2019-08-11T05:07:44.324283Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    len(ds2t('⋊.ɔɪ.ŋ.dʒ.l.aɪ.h'))\n",
    "    y0kOHmap('⋊.ɔɪ.ŋ.dʒ.l.aɪ.h')\n",
    "    y0kOHmap('⋊.ɔɪ.ŋ.dʒ.l.aɪ.h').shape\n",
    "\n",
    "    np.array(list(map(y0kOHmap, sampled_channel_sequences3))).shape\n",
    "    np.array(list(map(y0kOHmap, [sample_pY0iX0k(random_wordform) for each in range(50)])))\n",
    "    del sampled_channel_sequences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.518192Z",
     "start_time": "2019-08-11T05:07:44.431739Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_wordform_CM.dtype\n",
    "    type(sample_pY0iX0k(random_wordform, debug=True)[1])\n",
    "    sample_pY0iX0k(random_wordform, debug=True)[1].dtype\n",
    "\n",
    "    torch.equal(torch.tensor(sample_pY0iX0k(random_wordform, debug=True)[1]).type(my_tt), \n",
    "                random_wordform_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.644504Z",
     "start_time": "2019-08-11T05:07:44.523271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɪ.d.i.m.⋉.⋉'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 6])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 6, 39])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform\n",
    "random_wordform_length\n",
    "random_wordform_CM.shape\n",
    "depthSampler2a_t(random_wordform_CM, m=50).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.698444Z",
     "start_time": "2019-08-11T05:07:44.652058Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSampler2a_t(random_wordform_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.783946Z",
     "start_time": "2019-08-11T05:07:44.700783Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSampler2a_t(random_wordform_CM, m=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:44.868017Z",
     "start_time": "2019-08-11T05:07:44.788424Z"
    }
   },
   "outputs": [],
   "source": [
    "def depthSamplerB_t(CM, m=1):\n",
    "    '''\n",
    "    Given \n",
    "     - a sequence of channel distributions (i.e. a pytorch tensor)\n",
    "       associated with some prefix x_0^i of the lexicon\n",
    "     - a number of samples m\n",
    "    this returns m samples from the channel distribution p(Y_0^i|x_0^i),\n",
    "    where each 'sample' (i.e. channel string) is a sequence of one hot vectors.\n",
    "\n",
    "    Let l = i+1:\n",
    "    |depthSamplerB_t(|CM| = (|Y1|, l), m)| = (m, l, |Y1|)\n",
    "    '''\n",
    "    return torch.stack([torch.stack([torch.distributions.Multinomial(1, CM[:,i]).sample()\n",
    "                                      for i in torch.arange(CM.shape[1])]).type(torch.uint8) \n",
    "                        for eachStack in torch.arange(m)])\n",
    "#     stack = torch.zeros((m, CM.shape[1], CM.shape[0]))\n",
    "# #         print(f'{stack.dtype}')\n",
    "#     for eachStack in torch.arange(m):\n",
    "#         for i in torch.arange(CM.shape[1]):\n",
    "#             stack[eachStack, i] = torch.distributions.Multinomial(1, CM[:,i]).sample()\n",
    "#     return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.017524Z",
     "start_time": "2019-08-11T05:07:44.872494Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerB_t(random_wordform_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.100956Z",
     "start_time": "2019-08-11T05:07:45.022162Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit torch.distributions.Multinomial(100, random_wordform_CM[:,0]).sample().type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.216782Z",
     "start_time": "2019-08-11T05:07:45.105729Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit torch.distributions.Multinomial(1, random_wordform_CM[:,0]).sample(sample_shape=(100,)).type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.309148Z",
     "start_time": "2019-08-11T05:07:45.221354Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit random_wordform_CM[:,0].multinomial(100, replacement=True) #already shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.416509Z",
     "start_time": "2019-08-11T05:07:45.313802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 16, 16, 16, 16, 16,  4])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getBatchSizes(size_to_batch, num_batches):\n",
    "    elements_per_batch = size_to_batch // num_batches\n",
    "    batch_sizes = elements_per_batch * torch.ones((num_batches,), dtype=torch.int64)\n",
    "    final_adjustment_batch_size = size_to_batch % num_batches\n",
    "    if final_adjustment_batch_size != 0:\n",
    "        batch_sizes = list(batch_sizes)\n",
    "        batch_sizes = batch_sizes + [final_adjustment_batch_size]\n",
    "        batch_sizes = torch.tensor(batch_sizes)\n",
    "    return batch_sizes\n",
    "\n",
    "getBatchSizes(100, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.495318Z",
     "start_time": "2019-08-11T05:07:45.417726Z"
    }
   },
   "outputs": [],
   "source": [
    "def depthSamplerC_t(CM, m=1):\n",
    "# def depthSamplerC_t(CM, m=1, parallel=False, numBatches=-1):\n",
    "    '''\n",
    "    Given \n",
    "     - a sequence of channel distributions (i.e. a pytorch tensor)\n",
    "       associated with some prefix x_0^i of the lexicon\n",
    "     - a number of samples m\n",
    "    this returns m samples from the channel distribution p(Y_0^i|x_0^i),\n",
    "    where each 'sample' (i.e. channel string) is a sequence of one hot vectors.\n",
    "\n",
    "    Let l = i+1:\n",
    "    |depthSamplerC_t(|CM| = (|Y1|, l), m)| = (m, l, |Y1|)    \n",
    "    '''\n",
    "#     If parallel is True and numBatches is an int > 0, then the m samples will be \n",
    "#     generated in parallel, in numBatches batches via joblib. \n",
    "    \n",
    "    s = CM.shape[0]\n",
    "    l = CM.shape[1]\n",
    "    \n",
    "#     stampedNote('Generating samples...')\n",
    "    #each of the l rows contains m sampled Y1 indices\n",
    "    # where the samples in each row are drawn from the l'th column of CM\n",
    "    stack_of_sampled_Y1_indices = torch.multinomial(CM.t(), m, replacement=True) #:: (l, m)\n",
    "\n",
    "#     if not parallel:\n",
    "#         #each of the l rows contains m sampled Y1 indices\n",
    "#         # where the samples in each row are drawn from the l'th column of CM\n",
    "#         stack_of_sampled_Y1_indices = torch.multinomial(CM.t(), m, replacement=True) #:: (l, m)\n",
    "#     elif parallel and numBatches > 0:\n",
    "#         CM_t = CM.t()\n",
    "#         batch_sizes = getBatchSizes(m, numBatches)\n",
    "        \n",
    "#         stack_of_sampled_Y1_indices = torch.cat(par(delayed(torch.multinomial)(CM_t, batch_size, replacement=True)\n",
    "#                                                     for batch_size in batch_sizes), \n",
    "#                                                 dim=1) #:: (l, m)\n",
    "#     else:\n",
    "#         raise Exception(f'If parallel is True, numbatches must be > 0, got {numBatches} instead.')\n",
    "#     print(f'sample dtype: {stack_of_sampled_Y1_indices.dtype}')\n",
    "#     print(f'sample shape: {stack_of_sampled_Y1_indices.shape}')\n",
    "    \n",
    "#     stampedNote('Converting to OH vectors...')\n",
    "    #convert each of the l rows (of length m) into a cat'd sequence (of length s * m) of OH vectors\n",
    "    deck_of_stacks_of_OHs = torch.zeros((l, s * m), dtype=torch.uint8) # :: (l, s * m)\n",
    "    \n",
    "#     stampedNote('Scattering...')\n",
    "    # stack_of_sampled_Y1_indices[i] is a sequence of m Y1 indices, but\n",
    "    # WRT deck_of_stacks_of_OHs, stack_of_sampled_Y1_indices[i] * offset represents \n",
    "    #   a set of column indices to set to 1\n",
    "    offset = s * torch.arange(m)\n",
    "    deck_of_stacks_of_OHs.scatter_(1, # we are specifying m *columns* (hence 1) for each row\n",
    "                                   stack_of_sampled_Y1_indices + offset, # each row is a sequence of columns to be filled with...\n",
    "                                   1) #...a 1 at all column indices\n",
    "#     return deck_of_stacks_of_OHs\n",
    "\n",
    "    # PERFORMANCE NOTE: *this* is by far the slowest part of sample generation when split+stack is used rather than reshape\n",
    "#     stampedNote('Splitting...')\n",
    "    #split along axis=1 into s-sized chunks\n",
    "    deck_of_stacks_of_OHs = torch.stack( torch.split( deck_of_stacks_of_OHs, s, 1) ) # :: = (m, l, s) => each of the m (l,s) matrices is a channel sequence represented as l (s,) OH vectors\n",
    "    #2-6x faster at scale and simplistitc testing shows the result is the same as stack->split, but downstream results are *clearly wrong*\n",
    "#     deck_of_stacks_of_OHs2 = torch.reshape(deck_of_stacks_of_OHs, (m, l, s)) \n",
    "#     return deck_of_stacks_of_OHs, deck_of_stacks_of_OHs2\n",
    "#     stampedNote('Done.')\n",
    "#     deck_of_stacks_of_OHs = torch.reshape(deck_of_stacks_of_OHs, (m, l, s))\n",
    "    \n",
    "    return deck_of_stacks_of_OHs\n",
    "\n",
    "# @torch.jit.script\n",
    "def depthSamplerD_t(CM, m=1, numBatches=1):\n",
    "    '''\n",
    "    Wrapper call for using joblib to parallelize sampling using\n",
    "    depthSamplerC_t. \n",
    "    \n",
    "    Performance gain comes from two properties of depthSamplerC_t\n",
    "        - the single-process nature of the pytorch sampling calls\n",
    "        - the poor scaling of the last step of depthSamplerC_t\n",
    "    and a balance of properties of m and numBatches\n",
    "        - m must be fairly large (>> 10^6)\n",
    "        - the number of batches must be appropriately sized.\n",
    "    \n",
    "    E.g. For \n",
    "      (machine, input data, m, numBatches) = (Quine, newdic, 5e6, 10)\n",
    "    depthSamplerD_t is about 1.5x faster than depthSamplerC_t.\n",
    "    '''\n",
    "    sample_batch_sizes = getBatchSizes(m, numBatches)\n",
    "    \n",
    "    sample_batches = tuple(par(delayed(depthSamplerC_t)(CM, m=batch_size)\n",
    "                               for batch_size in sample_batch_sizes))\n",
    "    combined_samples = torch.cat(sample_batches)\n",
    "    return combined_samples\n",
    "\n",
    "def depthSamplerE_t(CM, m=1):\n",
    "    return torch.distributions.Multinomial(1, CM.t()).sample(sample_shape=(m,)).type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.610637Z",
     "start_time": "2019-08-11T05:07:45.500082Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerC_t(random_wordform_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.690113Z",
     "start_time": "2019-08-11T05:07:45.615248Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerE_t(random_wordform_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.767420Z",
     "start_time": "2019-08-11T05:07:45.691081Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerC_t(random_wordform_CM, m=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.850864Z",
     "start_time": "2019-08-11T05:07:45.772027Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerE_t(random_wordform_CM, m=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:45.934243Z",
     "start_time": "2019-08-11T05:07:45.855408Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #42.6s / quine\n",
    "    #15.1s / kotoba\n",
    "    exampleSample = depthSamplerC_t(random_wordform_CM, m=5000000).shape\n",
    "    del exampleSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.017729Z",
     "start_time": "2019-08-11T05:07:45.938904Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #28.1s / quine\n",
    "    #6.92s / kotoba\n",
    "    exampleSample = depthSamplerD_t(random_wordform_CM, m=5000000, numBatches=10).shape\n",
    "    del exampleSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.101303Z",
     "start_time": "2019-08-11T05:07:46.022365Z"
    }
   },
   "outputs": [],
   "source": [
    "# 30.7s / quine, random_wordform_CM.shape = (39,6), using stack+split at end instead of reshape\n",
    "if benchmark:\n",
    "    %timeit depthSamplerC_t(random_wordform_CM, m=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.199813Z",
     "start_time": "2019-08-11T05:07:46.106074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 39])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_OH(size, hot_bit_idx):\n",
    "    locations = torch.tensor([hot_bit_idx], dtype=torch.long)\n",
    "    values = torch.ones(1, dtype=torch.uint8)\n",
    "    return torch.zeros(size, dtype=torch.uint8).scatter_(0,\n",
    "                                                         locations,\n",
    "                                                         values)\n",
    "\n",
    "def make_n_OHs(n, size, hot_bit_idx):\n",
    "    index_vector = torch.arange(n)\n",
    "    offsets = (size * index_vector)\n",
    "    locations = hot_bit_idx + offsets\n",
    "    # line below makes function 10-12x slower\n",
    "#     locations = torch.tensor([hot_bit_idx + i * size for i in torch.arange(n)], dtype=torch.long)\n",
    "    values = torch.ones(n, dtype=torch.uint8)\n",
    "    vstacked = torch.zeros(size*n, dtype=torch.uint8).scatter_(0,\n",
    "                                                               locations,\n",
    "                                                               values)\n",
    "\n",
    "    #two lines below are basically the same time/memory wise\n",
    "    OHs = torch.stack(torch.split(vstacked, size)) #mildly more memory efficient\n",
    "#     OHs = torch.reshape(vstacked, (n, size)) #slightly faster, but may risk weird copy vs. view behavior downstream\n",
    "    return OHs\n",
    "\n",
    "def make_OHs_helper(types_and_counts, size, m):\n",
    "    '''\n",
    "    types_and_counts :: (m, 2)\n",
    "    types_and_counts[i] = a column vector representing (type_idx, type_count), where\n",
    "                           - 0 <= type_idx <= size-1\n",
    "    '''\n",
    "    tc = types_and_counts\n",
    "#     index_vector = torch.arange(n)\n",
    "#     locations = hot_bit_idx + (size * index_vector)\n",
    "    num_types = tc.shape[0]\n",
    "    \n",
    "    #each index appears only in a 'chunk' of copies of itself...\n",
    "    # 'type_index' = hot_bit_idx in simpler function above...\n",
    "    type_index_of_each_OH_token = torch.cat([tc[i,0] * torch.ones(tc[i,1], dtype=torch.uint8) \n",
    "                                             for i in torch.arange(num_types)])\n",
    "    \n",
    "    shuffled_type_index_of_each_OH_token = type_index_of_each_OH_token\n",
    "    \n",
    "    OH_token_index_vector = torch.arange(m)\n",
    "    offsets = (size * OH_token_index_vector)\n",
    "    locations = shuffled_type_index_of_each_OH_token.type(torch.long) + offsets\n",
    "    \n",
    "#     locations = []\n",
    "#     for type_idx in tc[:,0]: #first column is the set of type indices\n",
    "#         for each in range(tc):\n",
    "#             locations.append(type_idx)\n",
    "#     locations = torch.tensor([tc[i,0] + j * size for j in torch.arange(tc[i,1])], dtype=torch.long)\n",
    "#     locations = torch.tensor([hot_bit_idx + i * size for i in torch.arange(m)], dtype=torch.long)\n",
    "    values = torch.ones(m, dtype=torch.uint8)\n",
    "    vstacked = torch.zeros(size*m, dtype=torch.uint8).scatter_(0,\n",
    "                                                               locations,\n",
    "                                                               values)\n",
    "    OHs = torch.stack(torch.split(vstacked, size)) #mildly more memory efficient\n",
    "#     OHs = torch.reshape(vstacked, (n, size)) #slightly faster, but may risk weird copy vs. view behavior downstream\n",
    "    return OHs\n",
    "\n",
    "def makeTypeCountMatrix(sampleVector):\n",
    "    type_indices = sampleVector.nonzero().squeeze().type(torch.uint8)\n",
    "    type_counts = torch.gather(sampleVector, 0, type_indices).type(torch.uint8)\n",
    "#     type_counts = torch.index_select(sampleVector, 0, type_indices)\n",
    "    return torch.stack((type_indices, type_counts)).t()\n",
    "\n",
    "def make_OHs(sampleVector):\n",
    "    '''\n",
    "    sampleVector is a sparse non-negative integer vector of shape (|Y1s|,).\n",
    "    \n",
    "    It represents a sample of size m from a distribution over Y1s, where \n",
    "     - the value at index i indicates the count of sampled objects associated with index i.\n",
    "    \n",
    "    This returns a uniformly shuffled stack of one-hot vectors representing the sample.\n",
    "    '''\n",
    "    my_size = sampleVector.shape[0]\n",
    "    m = sampleVector.sum().item()\n",
    "    sample_type_indices = sampleVector.nonzero().squeeze().type(torch.long)\n",
    "    sample_counts = torch.gather(sampleVector, 0, sample_type_indices).type(torch.long)\n",
    "#     sample_counts = torch.index_select(sampleVector, 0, sample_type_indices)\n",
    "    types_and_counts = torch.stack((sample_type_indices, sample_counts)).type(torch.uint8)\n",
    "    return types_and_counts\n",
    "\n",
    "# make_OH(39, 6).shape\n",
    "# make_n_OHs(2, 39, 6).shape\n",
    "make_n_OHs(20, 39, 6).shape\n",
    "# print('----')\n",
    "# make_n_OHs_alt(20, 39, 6).shape\n",
    "# make_OHs(ten_samples).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.337952Z",
     "start_time": "2019-08-11T05:07:46.204489Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit make_n_OHs(100000, 39, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.429690Z",
     "start_time": "2019-08-11T05:07:46.342675Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerB_t(random_wordform_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.559684Z",
     "start_time": "2019-08-11T05:07:46.434338Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerB_t(random_wordform_CM, m=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.642132Z",
     "start_time": "2019-08-11T05:07:46.564483Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerC_t(random_wordform_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.748192Z",
     "start_time": "2019-08-11T05:07:46.646661Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit depthSamplerC_t(random_wordform_CM, m=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample-parallel posterior estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:46.918122Z",
     "start_time": "2019-08-11T05:07:46.749199Z"
    }
   },
   "outputs": [],
   "source": [
    "# import opt_einsum as oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.012401Z",
     "start_time": "2019-08-11T05:07:46.919173Z"
    }
   },
   "outputs": [],
   "source": [
    "# if not r:\n",
    "#     def pXhat0fX0i_pxt(xhat0f_idx, x0k_CM=None, m = 50, x0k=None):\n",
    "def pXhat0fX0i_pxt(xhat0f_idx, x0k_CM, c_idx, m = 50):\n",
    "    '''\n",
    "    If ⋊ x_0 x_1 ... x_i x_k denotes\n",
    "    the produced prefix r of the speaker's intended wordform w,\n",
    "     where\n",
    "       x_i = the last fully produced segment\n",
    "       k = i+1\n",
    "       x_k = the next segment\n",
    "       |⋊ x_0 x_1 ... x_i x_k| = l + 2\n",
    "       l = i+1 = the length of the produced prefix (not incl. \n",
    "                 the left word edge or the next segment)\n",
    "\n",
    "    then\n",
    "\n",
    "    x0k_CM :: (|Y1|, l) is the associated l-length stack of size |Y1| vectors\n",
    "     where x0k_CM[:,j] is the distribution p(Y_j|X0^k has been produced)\n",
    "\n",
    "    xhat0f_idx is the index of a wordform w' s.t. \n",
    "\n",
    "    pXhat0fX0i_pxt(xhat0f_idx, x0k_CM) ≈ p(w'|r)\n",
    "    '''\n",
    "    shape_info = False\n",
    "    pW = get_pW_t(c_idx)\n",
    "#         if x0k_CM is None and x0k is None:\n",
    "#             raise Exception('Must specify one of x0k_CM or x0k.')\n",
    "\n",
    "    # Computation proceeds in two steps:\n",
    "    # calculate the denominator p(y0i) for m = 50 sampled y0i's\n",
    "    # calculate the numerator p(y0i|w')p(w') for m = 50 sampled y0i's\n",
    "\n",
    "\n",
    "#     xhat0f_idx = Wmap[xhat0f]\n",
    "\n",
    "#     l = len(ds2t(x0i))\n",
    "#     x0k_CM = CMsByPrefixIndex[prefixMap[x0i]]\n",
    "\n",
    "#     my_Q_l = CMsByLengthByWordformIndex[l - 2]\n",
    "\n",
    "    #Collect m samples from p(Y0i|X0k) = p(Y0i|r), \n",
    "    # where each sample is an l-length stack of one-hot vectors\n",
    "    # where each one-hot vector corresponds to a channel symbol:\n",
    "#         Y_prime = depthSampler2a_t(x0k_CM, m)#.float() #:: (m, l, |Y1|)\n",
    "    Y_prime = depthSamplerC_t(x0k_CM, m)#.float() #:: (m, l, |Y1|)\n",
    "#         if x0k_CM is not None:\n",
    "#             Y_prime = depthSampler2a_t(x0k_CM, m)#.float() #:: (m, l, |Y1|)\n",
    "#             if x0k is not None:\n",
    "# #                 print('foo')\n",
    "#                 print(type(x0k_CM))\n",
    "#                 print(x0k_CM.shape)\n",
    "#                 generated_CM = sample_pY0iX0k(x0k, debug=True)[1]\n",
    "#                 print(type(generated_CM))\n",
    "#                 print(generated_CM.shape)\n",
    "#                 generated_CM_t = torch.tensor(generated_CM)\n",
    "#                 assert torch.allclose(x0k_CM, torch.tensor(sample_pY0iX0k(x0k, debug=True)[1]))\n",
    "# #                 print('bar')\n",
    "#         else:\n",
    "#             Y_prime = torch.tensor(list(map(y0kOHmap, [sample_pY0iX0k(x0k) for each in range(m)])))\n",
    "#         print('baz')\n",
    "    l = Y_prime.shape[1]# + 1\n",
    "    if shape_info:\n",
    "        print(f'|Y_prime| = {Y_prime.shape} = (m, l, |Y1|)')\n",
    "\n",
    "    #Grab ALL the relevant-prefix-length channel matrices \n",
    "    # for every segmental wordform in the lexicon:\n",
    "#         my_Q_l = CMsByLengthByWordformIndex_torch[l - 3]#.float()\n",
    "#         my_Q_l = CMsByLengthByWordformIndex_torch[l - 1]#.float() #:: (|W|, |Y1|, l)\n",
    "    my_Q_l = CMsByLengthByWordformIndex_torch[l+2]#.float() #:: (|W|, |Y1|, l)\n",
    "    if shape_info:\n",
    "        print(f'|Q_l| = {my_Q_l.shape} = (|W|=n, |Y1|, l)')\n",
    "\n",
    "#         print(f'{Y_prime.dtype}, {my_Q_l.dtype}')\n",
    "\n",
    "    # NORMALIZATION\n",
    "#         print(Y_prime.dtype)\n",
    "#         print(my_Q_l.dtype)\n",
    "#         V_prime = oe.contract('mli,kil->mkl', Y_prime.type(my_tt), my_Q_l, backend='torch')  # :: (m,n,l)\n",
    "    V_prime = torch.einsum('mli,kil->mkl', Y_prime.type(my_tt), my_Q_l)  # :: (m,n,l)\n",
    "#         print(V_prime.dtype)\n",
    "#         print(f\"|V'| = {V_prime.shape} = (m, n, l)\")\n",
    "    M_prime = torch.prod(V_prime, 2) # :: (m,n)\n",
    "#         print(f\"|M'| = {M_prime.shape} = (m, n)\")\n",
    "#         N_prime = torch.matmul(M_prime, pX0f_torch) # :: (m, ) <- prior probabilities of each of the m sampled channel prefixes\n",
    "    N_prime = torch.matmul(M_prime, pW)\n",
    "#         print(f\"|N'| = {N_prime.shape} = (m, )\")\n",
    "#         Z_prime = 1.0 / N_prime # :: (m, )\n",
    "    Z_prime = torch.ones(N_prime.shape, dtype=my_tt)\n",
    "    torch.div(input=Z_prime,\n",
    "              other=N_prime,\n",
    "              out=Z_prime)\n",
    "#         print(f\"|Z'| = {Z_prime.shape} = (m, )\")\n",
    "    if shape_info:\n",
    "        print(f\"|V'| = {V_prime.shape} = (m, n, l)\")\n",
    "        print(f\"|M'| = {M_prime.shape} = (m, n)\")\n",
    "        print(f\"|N'| = {N_prime.shape} = (m, )\")\n",
    "        print(f\"|Z'| = {Z_prime.shape} = (m, )\")\n",
    "\n",
    "    # NUMERATOR\n",
    "    L_w = my_Q_l[xhat0f_idx]#.float()\n",
    "#         print(L_w.dtype)\n",
    "    V_prime_w = torch.einsum('mij,ji->mi',Y_prime.type(my_tt), L_w)\n",
    "#         print(V_prime_w.dtype)\n",
    "#         print(f\"|V'_w| = {V_prime_w.shape} = (m, l)\")\n",
    "    O_w = torch.prod(V_prime_w, 1) # :: (m,) likelihoods of each of the m sampled channel prefixes\n",
    "#         print(f\"|O_w| = {O_w.shape} = (m, )\")\n",
    "#         U_w = pX0f_torch[xhat0f_idx] * O_w ## :: (m,) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "    U_w = pW[xhat0f_idx] * O_w ## :: (m,) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "#         print(f\"|U_w| = {U_w.shape} = (m, )\")\n",
    "    if shape_info:\n",
    "        print(f\"|V'_w| = {V_prime_w.shape} = (m, l)\")\n",
    "        print(f\"|O_w| = {O_w.shape} = (m, )\")\n",
    "        print(f\"|U_w| = {U_w.shape} = (m, )\")\n",
    "\n",
    "\n",
    "    if shape_info:\n",
    "        E = torch.dot(Z_prime, U_w) / m\n",
    "        print(f\"|E| = scalar: type(E) = {type(E)}\")\n",
    "    return torch.dot(Z_prime, U_w) / m\n",
    "\n",
    "#     return torch.dot( 1.0 / torch.matmul(torch.prod(torch.einsum('mli,kil->mkl', Y_prime, my_Q_l), 2), pX0f_torch) , \n",
    "#        pX0f_torch[xhat0f_idx] * torch.prod(torch.einsum('mij,ji->mi',Y_prime, L_w), 1) ) / m\n",
    "# else:\n",
    "#     def pXhat0fX0k_pxt(xhat0f_idx, x0i_xCM, m = 50):\n",
    "#     #     xhat0f_idx = Wmap[xhat0f]\n",
    "\n",
    "#     #     l = len(ds2t(x0i))\n",
    "#     #     x0i_xCM = xCMsByPrefixIndex[prefixMap[x0i]]\n",
    "\n",
    "#     #     my_Q_l = xCMsByLengthByWordformIndex[l - 2]\n",
    "\n",
    "#         Y_prime = depthSampler2a_t(x0i_xCM, m)#.float()\n",
    "#         l = Y_prime.shape[1] + 1\n",
    "\n",
    "#         my_Q_l = xCMsByLengthByWordformIndex_torch[l - 3]#.float()\n",
    "\n",
    "#         # NORMALIZATION\n",
    "#         V_prime = torch.einsum('mli,kil->mkl', Y_prime, my_Q_l)  # :: (m,n,l)\n",
    "#         M_prime = torch.prod(V_prime, 2) # :: (m,n)\n",
    "#         N_prime = torch.matmul(M_prime, pX0f_torch) # :: (m, 1) <- prior probabilities of each of the m sampled channel prefixes\n",
    "#         Z_prime = 1.0 / N_prime # :: (m, 1)\n",
    "\n",
    "#         # NUMERATOR\n",
    "#         L_w = my_Q_l[xhat0f_idx]#.float()\n",
    "#         V_prime_w = torch.einsum('mij,ji->mi',Y_prime, L_w)\n",
    "#         O_w = torch.prod(V_prime_w, 1) # :: (m,1) likelihoods of each of the m sampled channel prefixes\n",
    "#         U_w = pX0f_torch[xhat0f_idx] * O_w ## :: (m,1) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "\n",
    "#         return torch.dot(Z_prime, U_w) / m\n",
    "\n",
    "#     #     return torch.dot( 1.0 / torch.matmul(torch.prod(torch.einsum('mli,kil->mkl', Y_prime, my_Q_l), 2), pX0f_torch) , \n",
    "#     #        pX0f_torch[xhat0f_idx] * torch.prod(torch.einsum('mij,ji->mi',Y_prime, L_w), 1) ) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.174466Z",
     "start_time": "2019-08-11T05:07:47.017117Z"
    }
   },
   "outputs": [],
   "source": [
    "def pXhat0fX0i_pxtn(xhat0f_idx, x0k_CM, c_idx, m = 50):\n",
    "    return pXhat0fX0i_pxt(xhat0f_idx, x0k_CM, c_idx, m = 50).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.273923Z",
     "start_time": "2019-08-11T05:07:47.179525Z"
    }
   },
   "outputs": [],
   "source": [
    "def prefixTox0kCM(r):\n",
    "    source_wf = list(wordsWithPrefix(r, Ws))[0]\n",
    "    source_wf_idx = Ws_t.index(source_wf)\n",
    "    \n",
    "    r_t = ds2t(r)\n",
    "    total_x0k_length = len(r_t)# includes left edge symbol + upcoming segment\n",
    "#     prefix_length_noWE = total_x0k_length - 1 #includes upcoming segment\n",
    "#     prefix_length_produced_so_far = prefix_length_noWE - 1\n",
    "#     offset = 1\n",
    "#     x0k_cm = CMsByLengthByWordformIndex_torch[prefix_length_produced_so_far - offset][source_wf_idx]\n",
    "    x0k_cm = CMsByLengthByWordformIndex_torch[total_x0k_length][source_wf_idx]\n",
    "    return x0k_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.359875Z",
     "start_time": "2019-08-11T05:07:47.275027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 0])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9172, 39, 2])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMsByLengthByWordformIndex_torch[3].shape\n",
    "CMsByLengthByWordformIndex_torch[4].shape\n",
    "len(CMsByLengthByWordformIndex_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.453890Z",
     "start_time": "2019-08-11T05:07:47.364428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.551614Z",
     "start_time": "2019-08-11T05:07:47.458620Z"
    }
   },
   "outputs": [],
   "source": [
    "def wordformTox0kCM(w=None, w_idx=None):\n",
    "#     if w is None and w_idx is None:\n",
    "#         raise Exception('At least one argument must be specified.')\n",
    "    if w is None:\n",
    "        w = Ws_t[w_idx]\n",
    "        w_t = ds2t(w)\n",
    "    else:\n",
    "        w_t = ds2t(w)\n",
    "        w_idx = Ws_t.index(w)\n",
    "    \n",
    "    total_x0f_length = len(w_t) #includes both edge symbols\n",
    "#     word_length_noLE = total_x0f_length - 1 #still includes right edge symbol = \"upcoming segment\"\n",
    "#     word_length_noRE = word_length_noLE - 1\n",
    "#     offset = 2\n",
    "#     assert word_length_produced_so_far - offset >= 0 , f\"{word_length_produced_so_far} - {offset} < 0; w = {w}\"\n",
    "#     assert word_length_produced_so_far - offset < len(CMsByLengthByWordformIndex_torch), f\"{word_length_produced_so_far} - {offset} >= {len(CMsByLengthByWordformIndex_torch)}; w = {w}\"\n",
    "#     assert w_idx in range(CMsByLengthByWordformIndex_torch[word_length_produced_so_far - offset].shape[0]), f\"{w_idx}; w = {w}\"\n",
    "#     x0f_cm = CMsByLengthByWordformIndex_torch[word_length_produced_so_far - offset][w_idx]\n",
    "    x0f_cm = CMsByLengthByWordformIndex_torch[total_x0f_length][w_idx]\n",
    "    return x0f_cm\n",
    "\n",
    "# def wordformTox0fCM(w=None, w_idx=None):\n",
    "# #     if w is None and w_idx is None:\n",
    "# #         raise Exception('At least one argument must be specified.')\n",
    "#     if w is None:\n",
    "#         w = Ws_t[w_idx]\n",
    "#         w_t = ds2t(w)\n",
    "#     else:\n",
    "#         w_t = ds2t(w)\n",
    "#         w_idx = Ws_t.index(w)\n",
    "    \n",
    "#     total_x0f_length = len(w_t) #includes both edge symbols\n",
    "# #     word_length_noLE = total_x0f_length - 1 #still includes right edge symbol = \"upcoming segment\"\n",
    "# #     word_length_noRE = word_length_noLE - 1\n",
    "# #     offset = 2\n",
    "# #     assert word_length_produced_so_far - offset >= 0 , f\"{word_length_produced_so_far} - {offset} < 0; w = {w}\"\n",
    "# #     assert word_length_produced_so_far - offset < len(CMsByLengthByWordformIndex_torch), f\"{word_length_produced_so_far} - {offset} >= {len(CMsByLengthByWordformIndex_torch)}; w = {w}\"\n",
    "# #     assert w_idx in range(CMsByLengthByWordformIndex_torch[word_length_produced_so_far - offset].shape[0]), f\"{w_idx}; w = {w}\"\n",
    "# #     x0f_cm = CMsByLengthByWordformIndex_torch[word_length_produced_so_far - offset][w_idx]\n",
    "#     x0f_cm = exactCMsByLengthByWordformIndex_torch[total_x0f_length][w_idx]\n",
    "#     return x0f_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.771877Z",
     "start_time": "2019-08-11T05:07:47.556252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 5])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 6])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 7])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 8])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t('⋊.m.ɪ.n.ɪ.s.t'))\n",
    "len(dsTo3factors('⋊.m.ɪ.n.ɪ.s.t'))\n",
    "prefixTox0kCM('⋊.m.ɪ.n.ɪ.s.t').shape\n",
    "\n",
    "len(ds2t('⋊.m.ɪ.n.ɪ.s.t.ɚ'))\n",
    "len(dsTo3factors('⋊.m.ɪ.n.ɪ.s.t.ɚ'))\n",
    "prefixTox0kCM('⋊.m.ɪ.n.ɪ.s.t.ɚ').shape\n",
    "\n",
    "len(ds2t('⋊.m.ɪ.n.ɪ.s.t.ɚ.⋉'))\n",
    "len(dsTo3factors('⋊.m.ɪ.n.ɪ.s.t.ɚ.⋉'))\n",
    "prefixTox0kCM('⋊.m.ɪ.n.ɪ.s.t.ɚ.⋉').shape\n",
    "\n",
    "len(ds2t('⋊.m.ɪ.n.ɪ.s.t.ɚ.⋉.⋉'))\n",
    "len(dsTo3factors('⋊.m.ɪ.n.ɪ.s.t.ɚ.⋉.⋉'))\n",
    "prefixTox0kCM('⋊.m.ɪ.n.ɪ.s.t.ɚ.⋉.⋉').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.839219Z",
     "start_time": "2019-08-11T05:07:47.772852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.m.ɪ.s.k.ɪ'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 4])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0068, 0.0102, 0.0087, 0.0086],\n",
       "        [0.0070, 0.0950, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0103, 0.0088, 0.0087],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0105, 0.0089, 0.0170],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0052, 0.0091, 0.0077, 0.0077],\n",
       "        [0.0068, 0.0105, 0.0089, 0.6665],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.6711, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0808, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0105, 0.0170, 0.0088],\n",
       "        [0.0068, 0.0105, 0.6474, 0.0088],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0066, 0.0103, 0.0088, 0.0087],\n",
       "        [0.0068, 0.0103, 0.0169, 0.0087],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0102, 0.0087, 0.0086],\n",
       "        [0.0070, 0.0091, 0.0077, 0.0077],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0070, 0.1076, 0.0090, 0.0089],\n",
       "        [0.0070, 0.4320, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0102, 0.0168, 0.0086],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0103, 0.0088, 0.0087],\n",
       "        [0.0070, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_prefix\n",
    "len(ds2t(random_source_prefix)) - 2\n",
    "prefixTox0kCM(random_source_prefix).shape\n",
    "prefixTox0kCM(random_source_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:47.934752Z",
     "start_time": "2019-08-11T05:07:47.840333Z"
    }
   },
   "outputs": [],
   "source": [
    "# for convenience\n",
    "def pXhat0fX0i_pxtn_conv(w, r, c, m = 50):\n",
    "    w_idx = Ws_t.index(w)\n",
    "\n",
    "#     r_idx = Ps_t.index(r)\n",
    "    source_wf = list(wordsWithPrefix(r, Ws))[0]\n",
    "    source_wf_idx = Ws_t.index(source_wf)\n",
    "    \n",
    "    total_x0k_length = len(ds2t(r))# includes left edge symbol + upcoming segment\n",
    "#     prefix_length_noWE = total_x0k_length - 1 #includes upcoming segment\n",
    "#     prefix_length_produced_so_far = prefix_length_noWE - 1\n",
    "#     offset = 1\n",
    "#     x0k_cm = CMsByLengthByWordformIndex_torch[prefix_length_produced_so_far - offset][source_wf_idx]\n",
    "    x0k_cm = CMsByLengthByWordformIndex_torch[total_x0k_length][source_wf_idx]\n",
    "    \n",
    "    c_idx = Cs_t.index(c)\n",
    "    \n",
    "    return pXhat0fX0i_pxtn(w_idx, x0k_cm, c_idx, m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.112259Z",
     "start_time": "2019-08-11T05:07:47.939590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.m.ɪ.s.k.ɪ'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 4])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0068, 0.0102, 0.0087, 0.0086],\n",
       "        [0.0070, 0.0950, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0103, 0.0088, 0.0087],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0105, 0.0089, 0.0170],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0052, 0.0091, 0.0077, 0.0077],\n",
       "        [0.0068, 0.0105, 0.0089, 0.6665],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.6711, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0808, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0105, 0.0170, 0.0088],\n",
       "        [0.0068, 0.0105, 0.6474, 0.0088],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0066, 0.0103, 0.0088, 0.0087],\n",
       "        [0.0068, 0.0103, 0.0169, 0.0087],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0102, 0.0087, 0.0086],\n",
       "        [0.0070, 0.0091, 0.0077, 0.0077],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0070, 0.1076, 0.0090, 0.0089],\n",
       "        [0.0070, 0.4320, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0102, 0.0168, 0.0086],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0070, 0.0106, 0.0090, 0.0089],\n",
       "        [0.0068, 0.0103, 0.0088, 0.0087],\n",
       "        [0.0070, 0.0105, 0.0089, 0.0088],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_prefix\n",
    "len(ds2t(random_source_prefix)) - 2\n",
    "CMsByLengthByWordformIndex_torch[len(ds2t(random_source_prefix))][Ws_t.index(list(wordsWithPrefix(random_source_prefix, Ws))[0])].shape\n",
    "CMsByLengthByWordformIndex_torch[len(ds2t(random_source_prefix))][Ws_t.index(list(wordsWithPrefix(random_source_prefix, Ws))[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.320236Z",
     "start_time": "2019-08-11T05:07:48.113368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.b.ɹ.u.h.ɑ.h.ɑ.⋉.⋉', '⋊.m.ɪ.s.k.ɪ', 'a couple of')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(5.3868027e-10, dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(random_source_wordform, random_source_prefix, random_context)\n",
    "pXhat0fX0i_pxtn_conv(random_source_wordform, random_source_prefix, random_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.324110Z",
     "start_time": "2019-08-11T05:07:48.321325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_context = choice(Cs_t); random_context\n",
    "random_context = 'a couple of'\n",
    "random_context_idx = Cs_t.index(random_context); random_context_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.412533Z",
     "start_time": "2019-08-11T05:07:48.325080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.ɹ.ɪ.d.i.m.⋉.⋉', '⋊.ɹ.ɪ.d.i.m.⋉.⋉', 'a couple of')"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0109)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform, random_wordform, random_context\n",
    "pXhat0fX0i_pxt(random_wordform_idx, \n",
    "               random_wordform_CM,\n",
    "               random_context_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.537890Z",
     "start_time": "2019-08-11T05:07:48.413574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('⋊.ɹ.ɪ.d.i.m.⋉.⋉', '⋊.ɹ.ɪ.d.i.m.⋉.⋉', 'a couple of')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0166)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_wordform, random_wordform, random_context\n",
    "pXhat0fX0i_pxt(random_wordform_idx, \n",
    "               random_wordform_CM,\n",
    "               random_context_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.618202Z",
     "start_time": "2019-08-11T05:07:48.538936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2773"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.k.ɑ.n.t'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')\n",
    "\n",
    "'⋊.k.ɑ.n.t'\n",
    "len( ds2t('⋊.k.ɑ.n.t') )\n",
    "len( ds2t('⋊.k.ɑ.n.t') ) - 2\n",
    "# retrieve_CM_for('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', 5)\n",
    "\n",
    "# np.allclose( retrieve_CM_for('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', 5), \n",
    "#              CMsByLengthByWordformIndex[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.706407Z",
     "start_time": "2019-08-11T05:07:48.619170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0032)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'),\n",
    "               CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')],\n",
    "               Cs_t.index('a couple of'),\n",
    "               m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.807791Z",
     "start_time": "2019-08-11T05:07:48.707459Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    f\"m = 10    → {sum([phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 10) for each in range(10)])/10}\"\n",
    "    f\"m = 50    → {sum([phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 50) for each in range(10)])/10}\"\n",
    "    f\"m = 100   → {sum([phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 100) for each in range(10)])/10}\"\n",
    "    f\"m = 250   → {phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 250)}\"\n",
    "    f\"m = 500   → {phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 500)}\"\n",
    "    f\"m = 1000  → {phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 1000)}\"\n",
    "    f\"m = 2500  → {phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 2500)}\"\n",
    "    f\"m = 5000  → {phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 5000)}\"\n",
    "    f\"m = 10000 → {phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉', '⋊.k.ɑ.n.t', random_context, 10000)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:48.920192Z",
     "start_time": "2019-08-11T05:07:48.808786Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    f\"m = 50   → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 50)}\"\n",
    "    f\"m = 100  → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 100)}\"\n",
    "    f\"m = 200  → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 200)}\"\n",
    "    f\"m = 500  → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 500)}\"\n",
    "    f\"m = 1000 → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 1000)}\"\n",
    "    f\"m = 2000 → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 2000)}\"\n",
    "    f\"m = 5000 → {pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], random_context_idx, m = 5000)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.026335Z",
     "start_time": "2019-08-11T05:07:48.921148Z"
    }
   },
   "outputs": [],
   "source": [
    "# formerly mean 75.9ms / quine\n",
    "# formerly mean 39.7ms / quine\n",
    "# mean 27.6 ms / quine\n",
    "# mean 3.73 ms / kotoba\n",
    "if benchmark:\n",
    "    %timeit pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], Cs_t.index('a couple of'),m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.168066Z",
     "start_time": "2019-08-11T05:07:49.028146Z"
    }
   },
   "outputs": [],
   "source": [
    "# formerly mean 80ms on quine\n",
    "# formerly mean 41.8ms on quine\n",
    "# mean 27.3ms / quine\n",
    "# mean 3.35ms / kotoba\n",
    "if benchmark:\n",
    "    %timeit pXhat0fX0i_pxtn(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], Cs_t.index('a couple of'), m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.259981Z",
     "start_time": "2019-08-11T05:07:49.172976Z"
    }
   },
   "outputs": [],
   "source": [
    "#formerly mean 221ms / quine\n",
    "# formerly mean 122ms / quine\n",
    "# formerly mean 69.4ms\n",
    "# mean 83ms / quine\n",
    "# mean 7.27ms / kotoba\n",
    "if benchmark:\n",
    "    %timeit pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], Cs_t.index('a couple of'), m = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportionally, what parts of the calculation take the most time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.379803Z",
     "start_time": "2019-08-11T05:07:49.264686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2773"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12129"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')\n",
    "Ps_t.index('⋊.k.ɑ.n.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.521816Z",
     "start_time": "2019-08-11T05:07:49.381286Z"
    }
   },
   "outputs": [],
   "source": [
    "contact_idx = Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')\n",
    "cont_idx = Ps_t.index('⋊.k.ɑ.n.t')\n",
    "cont_l = len(ds2t('⋊.k.ɑ.n.t')) # 5\n",
    "cont_triph_l = cont_l - 2 # 3\n",
    "cont_CM = CMsByLengthByWordformIndex_torch[cont_l][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')]\n",
    "assert cont_triph_l == cont_CM.shape[1] # 3\n",
    "acoupleof_idx = Cs_t.index('a couple of')\n",
    "acouple_of_pW = get_pW_t(acoupleof_idx)\n",
    "cont_Q_l = CMsByLengthByWordformIndex_torch[cont_triph_l+2]#.float() #:: (|W|, |Y1|, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.609889Z",
     "start_time": "2019-08-11T05:07:49.526482Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit -r 10 -n 10 depthSampler2a_t(cont_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.701338Z",
     "start_time": "2019-08-11T05:07:49.614476Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit -r 10 -n 10 depthSamplerC_t(cont_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:49.814867Z",
     "start_time": "2019-08-11T05:07:49.705973Z"
    }
   },
   "outputs": [],
   "source": [
    "cont_Y_prime = depthSamplerC_t(cont_CM, m=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:50.274197Z",
     "start_time": "2019-08-11T05:07:49.819429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.69 ms ± 820 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 10\n",
    "\n",
    "#denominator profiling\n",
    "\n",
    "cont_Q_l = CMsByLengthByWordformIndex_torch[cont_triph_l+2]#.float() #:: (|W|, |Y1|, l)\n",
    "cont_V_prime = torch.einsum('mli,kil->mkl', cont_Y_prime.type(my_tt), cont_Q_l)  # :: (m,n,l)\n",
    "cont_M_prime = torch.prod(cont_V_prime, 2) # :: (m,n)\n",
    "cont_N_prime = torch.matmul(cont_M_prime, acouple_of_pW) # :: (m, )\n",
    "# cont_N_prime = torch.einsum('mn,n->m', cont_M_prime, acouple_of_pW) #pretty much the same as two cells below\n",
    "cont_Z_prime = torch.ones(cont_N_prime.shape, dtype=my_tt)\n",
    "torch.div(cont_Z_prime, cont_N_prime, out=cont_Z_prime)\n",
    "# cont_Z_prime = 1.0 / cont_N_prime # :: (m, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:50.276622Z",
     "start_time": "2019-08-11T05:07:50.275186Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%timeit -r 10 -n 10\n",
    "\n",
    "# cont_Q_l = CMsByLengthByWordformIndex_torch[cont_triph_l+2]#.float() #:: (|W|, |Y1|, l)\n",
    "# cont_V_prime = torch.einsum('mli,kil->mkl', cont_Y_prime.type(my_tt), cont_Q_l)  # :: (m,n,l)\n",
    "# cont_M_prime = torch.prod(cont_V_prime, 2) # :: (m,n)\n",
    "# cont_N_prime = torch.ones((50,))\n",
    "# torch.matmul(cont_M_prime, acouple_of_pW, out=cont_N_prime) # :: (m, ) #pretty much the same as the cell above and below\n",
    "# # cont_N_prime = torch.matmul(cont_M_prime, acouple_of_pW) # :: (m, )\n",
    "# # cont_N_prime = torch.einsum('mn,n->m', cont_M_prime, acouple_of_pW) \n",
    "# cont_Z_prime = torch.ones(cont_N_prime.shape, dtype=my_tt)\n",
    "# torch.div(cont_Z_prime, cont_N_prime, out=cont_Z_prime)\n",
    "# # cont_Z_prime = 1.0 / cont_N_prime # :: (m, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:50.929995Z",
     "start_time": "2019-08-11T05:07:50.277466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28 ms ± 2.41 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 10\n",
    "\n",
    "#denominator profiling - including time for lexicon prior lookup\n",
    "\n",
    "cont_Q_l = CMsByLengthByWordformIndex_torch[cont_triph_l+2]#.float() #:: (|W|, |Y1|, l)\n",
    "cont_V_prime = torch.einsum('mli,kil->mkl', cont_Y_prime.type(my_tt), cont_Q_l)  # :: (m,n,l)\n",
    "cont_M_prime = torch.prod(cont_V_prime, 2) # :: (m,n)\n",
    "cont_N_prime = torch.matmul(cont_M_prime, get_pW_t(acoupleof_idx)) # <<<< includes time for lexicon prior lookup\n",
    "cont_Z_prime = torch.ones(cont_N_prime.shape, dtype=my_tt)\n",
    "torch.div(cont_Z_prime, cont_N_prime, out=cont_Z_prime)\n",
    "# cont_Z_prime = 1.0 / cont_N_prime # :: (m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:50.938649Z",
     "start_time": "2019-08-11T05:07:50.930990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.5 µs ± 4.86 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 10\n",
    "\n",
    "#numerator profiling\n",
    "\n",
    "contact_L_w = cont_Q_l[contact_idx]#.float()\n",
    "contact_cont_V_prime_w = torch.einsum('mij,ji->mi',cont_Y_prime.type(my_tt), contact_L_w)\n",
    "contact_cont_O_w = torch.prod(contact_cont_V_prime_w, 1) # :: (m,1) likelihoods of each of the m sampled channel prefixes\n",
    " # U_w = pX0f_torch[xhat0f_idx] * O_w ## :: (m,1) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "contact_cont_U_w = acouple_of_pW[contact_idx] * contact_cont_O_w ## :: (m,1) joint probabilities of xhat0f with each of the m sampled channel prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Old* Takeaway**: Sampling and the normalization term (denominator) each take up about half the total time.\n",
    "\n",
    "***Current* takeaway**: the normalization term takes up nearly all of the calculation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization over samples and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.116380Z",
     "start_time": "2019-08-11T05:07:50.939544Z"
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def memAvailable(units='GB'):\n",
    "    if units == 'GB':\n",
    "        scale = 1e9\n",
    "    elif units == 'MB':\n",
    "        scale = 1e6\n",
    "    return psutil.virtual_memory().available / scale\n",
    "\n",
    "def memUsed(units='GB'):\n",
    "    if units == 'GB':\n",
    "        scale = 1e9\n",
    "    elif units == 'MB':\n",
    "        scale = 1e6\n",
    "    return psutil.virtual_memory().used / scale\n",
    "\n",
    "if g:\n",
    "    total_mem_MB = torch.cuda.get_device_properties(0).total_memory / 1e6\n",
    "\n",
    "def gpuMem():\n",
    "#     if g and torch.cuda.is_available():\n",
    "    info = {'total':total_mem_MB,\n",
    "            'allocated':torch.cuda.memory_allocated(0) / (10^6),\n",
    "            'cached':torch.cuda.memory_cached(0) / (10^6)}\n",
    "    return info\n",
    "\n",
    "    print('Total Memory: {0}'.format(total_mem_MB) )\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "        \n",
    "def stampedMemNote(msg='', units='GB', includeGPU=False):\n",
    "    mem_usage = 'VM used vs. available: {0:.2f}{2} vs. {1:.2f}{2}'.format(memUsed(units), memAvailable(units), units)\n",
    "    if g and includeGPU:\n",
    "#         g_info = gpuMem()\n",
    "#         total, alloc, cached = g_info['total'], g_info['allocated'], g_info['cached']\n",
    "#         gpu_usage = 'GPU mem allocated, cached, total: {0:.2f}MB vs. {1:.2f}MB vs. {1:.2f}MB'.format(alloc, cached, total)\n",
    "        pass\n",
    "    if msg == '':\n",
    "        stampedNote(mem_usage)\n",
    "#         if g and includeGPU:\n",
    "#             print(gpu_usage)\n",
    "        \n",
    "    stampedNote(msg)\n",
    "    print('\\t'+mem_usage)\n",
    "#     if g and includeGPU:\n",
    "#         print('\\t'+gpu_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.232662Z",
     "start_time": "2019-08-11T05:07:51.117399Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/a/6909532\n",
    "import math\n",
    "def factors(n):\n",
    "    step = 2 if n%2 else 1\n",
    "    fs =    set(reduce(list.__add__,\n",
    "                ([i, n//i] for i in range(1, int(math.sqrt(n))+1, step) if n % i == 0)))\n",
    "    return np.array(sorted(list(fs)))\n",
    "\n",
    "def closest_factor(target, factors):\n",
    "#     fs = np.array(sorted(list(factors)))\n",
    "    fs = factors\n",
    "    distances = np.abs( target - fs )\n",
    "    min_dist = np.min(distances)\n",
    "    min_dist_idx = np.where( distances == min_dist )[0][0]\n",
    "    return int(fs[min_dist_idx])\n",
    "\n",
    "def pXhat0fX0i_pxtc(xhat0f_idx, x0k_CM, m = 50, target_num_batches=30):\n",
    "    '''\n",
    "    This function is exactly like \n",
    "        pXhat0fX0i_pxt\n",
    "    except it uses einsum (and batched computation) to calculate \n",
    "        p(xhat0f|x0k, c) \n",
    "    for *all* contexts c, in target_num_batches batches of contexts\n",
    "    at a time.\n",
    "    \n",
    "    \n",
    "    If ⋊ x_0 x_1 ... x_i x_k denotes\n",
    "    the produced prefix r of the speaker's intended wordform w,\n",
    "     where\n",
    "       x_i = the last fully produced segment\n",
    "       k = i+1\n",
    "       x_k = the next segment\n",
    "       |⋊ x_0 x_1 ... x_i x_k| = l + 2\n",
    "       l = i+1 = the length of the produced prefix (not incl. \n",
    "                 the left word edge or the next segment)\n",
    "\n",
    "    then\n",
    "\n",
    "    x0k_CM :: (|Y1|, l) is the associated l-length stack of size |Y1| vectors\n",
    "     where x0k_CM[:,j] is the distribution p(Y_j|X0^k has been produced)\n",
    "\n",
    "    xhat0f_idx is the index of a wordform w' s.t. \n",
    "\n",
    "    pXhat0fX0i_pxt(xhat0f_idx, x0k_CM) ≈ [p(w'|r)]_c for each context c\n",
    "    '''\n",
    "    stampedNote('> Begin calculation.')\n",
    "    l = x0k_CM.shape[1]\n",
    "    \n",
    "    m_C = len(Cs_t) * m\n",
    "    stampedMemNote('Sampling...')\n",
    "#     stampedNote('Sampling...')\n",
    "    # :: (c*m, l, s)\n",
    "#     Y_prime_C = depthSamplerC_t(x0k_CM, m=m_C)\n",
    "    Y_prime_C = depthSamplerD_t(x0k_CM, m=m_C, numBatches = 10)\n",
    "    \n",
    "    # :: (c, m, l, s)\n",
    "    stampedMemNote('Splitting by context...')\n",
    "#     stampedNote('Splitting by context...')\n",
    "    Y_prime_C_split = torch.stack(torch.chunk(Y_prime_C, len(Cs_t), 0))\n",
    "#     stampedMemNote('Contexts split.')\n",
    "#     del Y_prime_C\n",
    "#     stampedMemNote('Deleted Y_prime_C.')\n",
    "    Q_l = CMsByLengthByWordformIndex_torch[l+2]#.float() #:: (|W|, |Y1|, l)\n",
    "    \n",
    "    \n",
    "    num_contexts = len(Cs_t); num_contexts # c\n",
    "    target_num_batches = target_num_batches\n",
    "    num_batches = closest_factor(target_num_batches, factors(num_contexts))\n",
    "    print(f'Target num batches = {target_num_batches}')\n",
    "    print(f'Actual num batches = {num_batches}')\n",
    "    stampedNote('Batching contexts...')\n",
    "    # (b, c/b, m, l, s)\n",
    "    Y_prime_C_split_batched = torch.stack(torch.chunk(Y_prime_C_split, \n",
    "                                                      num_batches,\n",
    "                                                      0))\n",
    "#     stampedMemNote('Contexts batched.')\n",
    "    \n",
    "    num_batches = Y_prime_C_split_batched.shape[0] # b\n",
    "    num_contexts_per_batch = Y_prime_C_split_batched.shape[1] # c/b\n",
    "    print(f'Contexts per batch = {num_contexts_per_batch}')\n",
    "    \n",
    "    stampedMemNote('Calculating denominator batches...')\n",
    "    Z_prime_C = torch.ones((num_contexts, m), dtype=my_tt)\n",
    "#     stampedMemNote('Z_prime_C created.')\n",
    "#     denominator_batches = []\n",
    "    for b in tqdm(range(num_batches), total=num_batches):\n",
    "        stampedNote('\\t>> Begin batch.')\n",
    "        stampedMemNote('\\t>> V_prime_C_b...')\n",
    "        # :: (c/b, m, n, l)\n",
    "        V_prime_C_batch = torch.einsum('cmli,kil->cmkl',\n",
    "                                       Y_prime_C_split_batched.type(my_tt)[b],\n",
    "                                       Q_l)\n",
    "#         stampedMemNote('V_prime_C_b created.')\n",
    "        \n",
    "        stampedMemNote('\\t>> M_prime_C_b...')\n",
    "        # :: (c/b, m, n)\n",
    "        M_prime_C_batch = torch.prod(V_prime_C_batch, 3)\n",
    "#         stampedMemNote('M_prime_C_b created.')\n",
    "        del V_prime_C_batch\n",
    "#         stampedMemNote('V_prime_C_b deleted.')\n",
    "        \n",
    "        stampedMemNote('\\t>> Creating pW_context_b...')\n",
    "        context_indices = torch.arange(num_contexts_per_batch * b, num_contexts_per_batch * b + num_contexts_per_batch)\n",
    "        # :: (n, c/b)\n",
    "        pW_context_batch = pW_C_torch[:,context_indices]\n",
    "#         del context_indices\n",
    "#         stampedMemNote('pW_context_b created.')\n",
    "        \n",
    "        stampedMemNote('\\t>> N_prime_C_b...')\n",
    "        # :: (c/b, m)\n",
    "        N_prime_C_batch = torch.einsum('cmn,nc->cm', M_prime_C_batch, pW_context_batch) # :: (c/b,m)\n",
    "#         stampedMemNote('N_prime_C_b created.')\n",
    "        del M_prime_C_batch\n",
    "#         del pW_context_batch\n",
    "#         stampedMemNote('M_prime_C_b and pW_context_b deleted.')\n",
    "#         stampedMemNote('M_prime_C_b deleted.')\n",
    "        stampedMemNote('\\t>> Z_prime_C_b...')\n",
    "#         Z_prime_C_batch_old = 1.0 / N_prime_C_batch # :: (c/b,m)\n",
    "#         Z_prime_C_batch_local = torch.ones(N_prime_C_batch.shape, dtype=my_tt)\n",
    "        my_Z_prime_C_batch_region = Z_prime_C[context_indices]\n",
    "        torch.div(input=my_Z_prime_C_batch_region,\n",
    "                  other=N_prime_C_batch,\n",
    "                  out=my_Z_prime_C_batch_region)\n",
    "        Z_prime_C[context_indices] = my_Z_prime_C_batch_region\n",
    "#         torch.div(input=Z_prime_C_batch_local,\n",
    "#                   other=N_prime_C_batch,\n",
    "#                   out=Z_prime_C_batch_local)\n",
    "#         if (not torch.equal(Z_prime_C_batch_local, my_Z_prime_C_batch_region)) or (not torch.equal(my_Z_prime_C_batch_region, Z_prime_C[context_indices])):\n",
    "#             print(f'Z_prime_C_batch_local.shape = {Z_prime_C_batch_local.shape}')\n",
    "#             print(f'Z_prime_C[context_indices].shape = {my_Z_prime_C_batch_region.shape}')\n",
    "#             print( Z_prime_C_batch_local == Z_prime_C[context_indices])\n",
    "#             print( Z_prime_C_batch_local == my_Z_prime_C_batch_region )\n",
    "#             return Z_prime_C_batch_local, Z_prime_C[context_indices], my_Z_prime_C_batch_region\n",
    "#         assert torch.equal(Z_prime_C_batch_local, Z_prime_C[context_indices])\n",
    "#         del context_indices\n",
    "#         del M_prime_C_batch\n",
    "#         del context_indices\n",
    "#         del pW_context_batch\n",
    "#         del N_prime_C_batch\n",
    "#         stampedMemNote('context_indices and N_prime_C_batch deleted.')\n",
    "        stampedNote('\\t>> End batch.')\n",
    "#         stampedNote('Appending Z_prime_C_b...')\n",
    "#         denominator_batches.append(Z_prime_C_batch)\n",
    "\n",
    "#     stampedNote('Consolidating Z_prime_C')\n",
    "#     Z_prime_C = torch.cat(denominator_batches)\n",
    "#     Z_prime_C.shape # (c,m)\n",
    "#     del denominator_batches\n",
    "    del Y_prime_C_split_batched\n",
    "#     stampedMemNote('Y_prime_C_split_batched deleted.')\n",
    "    \n",
    "    stampedMemNote('Calculating numerator...')\n",
    "    stampedNote('Calculating V_prime_w_C...')\n",
    "    xhat0f_L_w = Q_l[xhat0f_idx]#.float() # :: (s, l)\n",
    "    V_prime_w_C = torch.einsum('cmij,ji->cmi',Y_prime_C_split.type(my_tt), xhat0f_L_w) # :: (c,m,l)\n",
    "#     stampedMemNote('V_prime_w_C created.')\n",
    "#     del xhat0f_L_w\n",
    "#     del Y_prime_C_split\n",
    "#     stampedMemNote('xhat0f_L_w and Y_prime_C_split deleted.')\n",
    "    stampedNote('Calculating O_w_C...')\n",
    "    O_w_C = torch.prod(V_prime_w_C, 2) # :: (c,m) likelihoods of each of the m sampled channel prefixes for each of c contexts\n",
    "#     stampedMemNote('O_w_C created.')\n",
    "#     del V_prime_w_C\n",
    "#     stampedMemNote('V_prime_w_C deleted.')\n",
    "    stampedNote('Calculating U_w_C...')\n",
    "    # contact_cont_U_w_ALL = pW_C_torch[contact_idx] * contact_cont_O_w_ALL ## :: (c,m) joint probabilities of xhat0f with each of the m sampled channel prefixes for each of the c contexts\n",
    "    U_w_C = torch.einsum('c,cm->cm', pW_C_torch[xhat0f_idx], O_w_C) ## :: (c,m) joint probabilities of xhat0f with each of the m sampled channel prefixes for each of the c contexts\n",
    "#     stampedMemNote('U_w_C created.')\n",
    "#     del O_w_C\n",
    "#     stampedMemNote('O_w_C deleted.')\n",
    "    \n",
    "    stampedMemNote('Calculating E_w_C...')\n",
    "#     return torch.dot(Z_prime_C, U_w_C) / m\n",
    "    E_w_C = torch.einsum('cm,cm->c', Z_prime_C, U_w_C) / m\n",
    "#     stampedMemNote('E_w_C created.')\n",
    "#     del Z_prime_C\n",
    "#     del U_w_C\n",
    "#     stampedMemNote('Z_prime_C and U_w_C deleted.')\n",
    "    stampedNote('> End calculation.')\n",
    "    return E_w_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.564737Z",
     "start_time": "2019-08-11T05:07:51.234238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        7.5G         15G        8.2M        8.5G         23G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.582258Z",
     "start_time": "2019-08-11T05:07:51.570912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      5,      7,     35,   3037,  15185,  21259, 106295])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors(len(Cs_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.713233Z",
     "start_time": "2019-08-11T05:07:51.587184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_factor(30, factors(len(Cs_t)))\n",
    "# np.min(closest_factor(10, factors(len(Cs_t))))\n",
    "# np.where( closest_factor(10, factors(len(Cs_t))) == np.min(closest_factor(10, factors(len(Cs_t)))) )\n",
    "# np.where( closest_factor(10, factors(len(Cs_t))) == np.min(closest_factor(10, factors(len(Cs_t)))) )[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.875759Z",
     "start_time": "2019-08-11T05:07:51.717450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9]))"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 6, 9])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  6,  9, 10])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  3,  6,  9],\n",
       "        [ 3,  6,  9, 10]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_range = torch.arange(10); my_range\n",
    "my_batches = torch.split(my_range, 3, 0); my_batches\n",
    "my_starts = torch.tensor(list(map(lambda b: b[0], my_batches)))\n",
    "my_ends = torch.tensor(list(map(lambda b: b[-1]+1, my_batches)))\n",
    "my_starts\n",
    "my_ends\n",
    "torch.stack([my_starts, my_ends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:51.961284Z",
     "start_time": "2019-08-11T05:07:51.876694Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dimension(size_or_index_range, target_batch_size, startEndRange=False):\n",
    "    '''\n",
    "    This is a helper function for use with torch.split. Given the total size \n",
    "    (or a range of indices) of one dimension of a tensor and a target number\n",
    "    of indices per batch size, this returns a structure describing the indices\n",
    "    in each batch.\n",
    "    \n",
    "    If size_or_index_range is an int it represents the size of a dimension\n",
    "    to split into batches, where each batch (except possibly the last) is of \n",
    "    size target_batch_size.\n",
    "    \n",
    "    If size_or_index_range is a 1D tensor of indices, it represents a tensor\n",
    "    of indices to split into batches, wher each batch (except possibly the last)\n",
    "    is of size target_batch_size.\n",
    "    \n",
    "    If startEndRange is True, this returns a shape (b,2) tensor where b is the\n",
    "    number of batches and each column contains the start index and end index+1\n",
    "    of a batch. Note that size_or_index_range must be interpretable as a\n",
    "    contiguous range of indices.\n",
    "    \n",
    "    If startEndRange is False, this returns a tuple of b 1D tensors, where b is\n",
    "    the number of batches and each tensor contains the indices of a batch.\n",
    "    \n",
    "    TODO: generalize for use with whatever numpy's analogue of torch.split is...\n",
    "    '''\n",
    "    if type(size_or_index_range) == int:\n",
    "        index_range = torch.arange(size_or_index_range)\n",
    "    else:\n",
    "        index_range = size_or_index_range\n",
    "    \n",
    "    index_batches = torch.split(index_range, target_batch_size, 0)\n",
    "    \n",
    "    if not startEndRange:\n",
    "        return index_batches\n",
    "    \n",
    "    starts = torch.tensor(list(map(lambda b: b[0], index_batches)))\n",
    "    ends = torch.tensor(list(map(lambda b: b[-1]+1, index_batches)))\n",
    "    startEndRange = torch.stack([starts, ends])\n",
    "    return startEndRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:52.089331Z",
     "start_time": "2019-08-11T05:07:51.965779Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.dlpack import to_dlpack\n",
    "from torch.utils.dlpack import from_dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:52.347351Z",
     "start_time": "2019-08-11T05:07:52.094029Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pW_C_cupy = cupy.array(pW_C_torch.numpy())\n",
    "# type(pW_C_cupy)\n",
    "# pW_C_cupy.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:52.434683Z",
     "start_time": "2019-08-11T05:07:52.353169Z"
    }
   },
   "outputs": [],
   "source": [
    "# del pW_C_cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:52.576767Z",
     "start_time": "2019-08-11T05:07:52.440785Z"
    }
   },
   "outputs": [],
   "source": [
    "# def denominator_batch_process_c(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices):\n",
    "# # def denominator_batch_process_g(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, V_prime_ce, N_prime_ce):\n",
    "#     if benchmark:\n",
    "#         profilingStamps = True\n",
    "#     else:\n",
    "#         profilingStamps = False\n",
    "    \n",
    "#     profilingStamps = True\n",
    "#     paranoid = True\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\t>> Begin batch.', includeGPU=True)\n",
    "    \n",
    "# #     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    "# #     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch # :: (c/b, m, l, s)\n",
    "#     with cupy.cuda.Device(0):\n",
    "#         Y_prime_ALL_batch = cupy.asarray(Y_prime_ALL_split_batched_batch) # :: (c/b, m, l, s)\n",
    "    \n",
    "#     cupy.cuda.Device(0).use()\n",
    "#     mempool = cupy.get_default_memory_pool()\n",
    "\n",
    "# #     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "# #     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tV_prime...', includeGPU=True)\n",
    "#     # ::(c/b, m, n, l)\n",
    "#     V_prime_ALL_batch = cupy.einsum('cmli,kil->cmkl',\n",
    "#                                      Y_prime_ALL_batch,\n",
    "#                                      Q_l)\n",
    "# #     V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "# #                                      Y_prime_ALL_batch,\n",
    "# #                                      Q_l)\n",
    "# #     V_prime_ALL_batch = V_prime_ce(Y_prime_ALL_batch, Q_l, backend='torch')\n",
    "# #     if paranoid:\n",
    "# #         hasInf = (V_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('V_prime_ALL_batch has infinities...')\n",
    "#     del Y_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tM_prime...', includeGPU=True)\n",
    "#     # :: (c/b, m, n)\n",
    "#     M_prime_ALL_batch = cupy.prod(V_prime_ALL_batch, 3)\n",
    "# #     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "# #     if paranoid:\n",
    "# #         hasInf = (M_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('M_prime_ALL_batch has infinities...')\n",
    "#     del V_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tpW_C...', includeGPU=True)\n",
    "#     # :: (n, c/b)\n",
    "# #     pW_context_batch = pW_C_torch[:, batch_context_indices].cuda()\n",
    "# #     pW_context_batch = cupy.asarray(pW_C_cupy[:, batch_context_indices])\n",
    "#     pW_context_batch = pW_C_cupy[:, batch_context_indices]\n",
    "#     del batch_context_indices\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tN_prime...', includeGPU=True)\n",
    "#     # :: (c/b, m)\n",
    "#     N_prime_ALL_batch = cupy.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "# #     N_prime_ALL_batch = N_prime_ce(M_prime_ALL_batch, pW_context_batch, backend='torch') # :: (c/b,m)\n",
    "# #     if paranoid:\n",
    "# #         hasInf = (N_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('N_prime_ALL_batch has infinities...')\n",
    "#     del M_prime_ALL_batch\n",
    "#     del pW_context_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tZ_prime...', includeGPU=True)\n",
    "#     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "# #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "# #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch.type(torch.float64) # :: (c/b,m)\n",
    "# #     Z_prime_ALL_batch = torch.pow(N_prime_ALL_batch, -1)\n",
    "# #     Z_prime_ALL_batch = torch.pow(N_prime_ALL_batch.type(torch.float64), -1).type(my_tt)\n",
    "# #     Z_prime_ALL_batch = torch.reciprocal(N_prime_ALL_batch)\n",
    "# #     Z_prime_ALL_batch = torch.reciprocal(N_prime_ALL_batch.type(torch.float64)).type(my_tt)\n",
    "# #     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt, device=gpu)\n",
    "# #     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=torch.float64, device=gpu)\n",
    "# #     torch.div(input=Z_prime_ALL_batch,\n",
    "# # #               other=N_prime_ALL_batch,\n",
    "# #               other=N_prime_ALL_batch.type(torch.float64),\n",
    "# #               out=Z_prime_ALL_batch)\n",
    "# #     Z_prime_ALL_batch = Z_prime_ALL_batch.type(my_tt)\n",
    "#     if paranoid:\n",
    "#         hasInf = (Z_prime_ALL_batch.get() == float(\"inf\")).any().item()\n",
    "#         if hasInf:\n",
    "#             print('Z_prime_ALL_batch has infinities...')\n",
    "# #     del M_prime_ALL_batch\n",
    "# #     del batch_context_indices\n",
    "# #     del pW_context_batch\n",
    "#     del N_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\t>> End batch.', includeGPU=True)\n",
    "    \n",
    "#     cupy.cuda.Device(0).use()\n",
    "#     result = Z_prime_ALL_batch.get()\n",
    "# #     result = Z_prime_ALL_batch.cpu()\n",
    "#     del Z_prime_ALL_batch\n",
    "    \n",
    "#     mempool.free_all_blocks()\n",
    "# #     torch.cuda.empty_cache()\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:52.694456Z",
     "start_time": "2019-08-11T05:07:52.582303Z"
    }
   },
   "outputs": [],
   "source": [
    "# def denominator_batch_process_g(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, exact_wf=False):\n",
    "# # def denominator_batch_process_g(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, V_prime_ce, N_prime_ce):\n",
    "#     if benchmark:\n",
    "#         profilingStamps = False\n",
    "#         paranoid = True\n",
    "#     else:\n",
    "#         profilingStamps = False\n",
    "    \n",
    "# #     profilingStamps = False\n",
    "#     paranoid = True\n",
    "# #     mempool = cupy.get_default_memory_pool()\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\t>> Begin batch.', includeGPU=True)\n",
    "    \n",
    "# #     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    "#     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch # :: (c/b, m, l, s)\n",
    " \n",
    "#     l = Y_prime_ALL_batch.shape[2]\n",
    "#     L = l+2\n",
    "\n",
    "# #     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "# #     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tV_prime...', includeGPU=True)\n",
    "#     # ::(c/b, m, n, l)\n",
    "# #     V_prime_ALL_batch = V_prime_ce(Y_prime_ALL_batch, Q_l, backend='torch')\n",
    "#     V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "#                                      Y_prime_ALL_batch,\n",
    "#                                      Q_l)\n",
    "# #     if paranoid:\n",
    "# #         hasInf = (V_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('V_prime_ALL_batch has infinities...')\n",
    "#     del Y_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tM_prime...', includeGPU=True)\n",
    "#     # :: (c/b, m, n)\n",
    "# #     M_prime_ALL_batch = cupy.prod(cupy.fromDlpack(to_dlpack(V_prime_ALL_batch)), 3)\n",
    "# #     M_prime_ALL_batch = from_dlpack(M_prime_ALL_batch.toDlpack())\n",
    "# #     M_prime_ALL_batch = torch.exp(torch.sum(torch.log(V_prime_ALL_batch), 3))\n",
    "# #     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch.type(torch.float64), 3).type(my_tt)\n",
    "#     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "# #     if paranoid:\n",
    "# #         hasInf = (M_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('M_prime_ALL_batch has infinities...')\n",
    "#     del V_prime_ALL_batch\n",
    "# #     mempool.free_all_blocks()\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tpW_C...', includeGPU=True)\n",
    "#     # :: (n, c/b)\n",
    "#     if not exact_wf:\n",
    "#         pW_context_batch = pW_C_torch[:, batch_context_indices].cuda()\n",
    "#     else:\n",
    "#         pW_context_batch = torch.index_select(pW_C_torch[l_to_w_idxs[L]],\n",
    "#                                               1,\n",
    "#                                               batch_context_indices)\n",
    "# #         pW_context_batch = pW_C_torch[l_to_w_idxs[L], batch_context_indices]\n",
    "#         if pW_context_batch.dim() == 1:\n",
    "# #             torch.unsqueeze(pW_context_batch, -1, out=pW_context_batch)\n",
    "#             pW_context_batch = torch.unsqueeze(pW_context_batch, 0)\n",
    "#         pW_context_batch = pW_context_batch.cuda()\n",
    "#     del batch_context_indices\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tN_prime...', includeGPU=True)\n",
    "#     # :: (c/b, m)\n",
    "# #     N_prime_ALL_batch = cupy.einsum('cmn,nc->cm', M_prime_ALL_batch, \n",
    "# #                                     cupy.fromDlpack(to_dlpack(pW_context_batch))) # :: (c/b,m)\n",
    "#     N_prime_ALL_batch = torch.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "# #     N_prime_ALL_batch = N_prime_ce(M_prime_ALL_batch, pW_context_batch, backend='torch') # :: (c/b,m)\n",
    "# #     N_prime_ALL_batch_cupy = N_prime_ALL_batch\n",
    "# #     del N_prime_ALL_batch\n",
    "# #     if paranoid:\n",
    "# #         hasInf = (N_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('N_prime_ALL_batch has infinities...')\n",
    "#     del M_prime_ALL_batch\n",
    "#     del pW_context_batch\n",
    "    \n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tZ_prime...', includeGPU=True)\n",
    "# #     N_prime_ALL_batch_cupy = cupy.asarray(N_prime_ALL_batch.cpu().numpy())\n",
    "# #     N_prime_ALL_batch_dlpack = to_dlpack(N_prime_ALL_batch)\n",
    "# #     del N_prime_ALL_batch\n",
    "# #     N_prime_ALL_batch_cupy = cupy.fromDlpack(N_prime_ALL_batch_dlpack)\n",
    "# #     del N_prime_ALL_batch_dlpack\n",
    "# #     Z_prime_ALL_batch_cupy = 1.0 / N_prime_ALL_batch_cupy\n",
    "# #     Z_prime_ALL_batch_cupy = cupy.reciprocal(N_prime_ALL_batch_cupy)\n",
    "# #     Z_prime_ALL_batch_cupy = cupy.divide(cupy.ones(N_prime_ALL_batch_cupy.shape, dtype=cupy.float32),\n",
    "# #                                          N_prime_ALL_batch_cupy)\n",
    "# #     Z_prime_ALL_batch_cupy = cupy.power(N_prime_ALL_batch_cupy, -1.0 * cupy.ones(N_prime_ALL_batch_cupy.shape))\n",
    "# #     del N_prime_ALL_batch_cupy\n",
    "# #     Z_prime_ALL_batch = from_dlpack(Z_prime_ALL_batch_cupy.toDlpack())\n",
    "# #     del Z_prime_ALL_batch_cupy\n",
    "# #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "# #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch.type(torch.float64) # :: (c/b,m)\n",
    "# #     Z_prime_ALL_batch = torch.pow(N_prime_ALL_batch, -1)\n",
    "# #     Z_prime_ALL_batch = torch.pow(N_prime_ALL_batch.type(torch.float64), -1).type(my_tt)\n",
    "# #     Z_prime_ALL_batch = torch.reciprocal(N_prime_ALL_batch)\n",
    "# #     Z_prime_ALL_batch = torch.reciprocal(N_prime_ALL_batch.type(torch.float64)).type(my_tt)\n",
    "#     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt, device=gpu)\n",
    "# #     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=torch.float64, device=gpu)\n",
    "#     torch.div(input=Z_prime_ALL_batch,\n",
    "#               other=N_prime_ALL_batch,\n",
    "# #               other=N_prime_ALL_batch.type(torch.float64),\n",
    "#               out=Z_prime_ALL_batch)\n",
    "#     Z_prime_ALL_batch = Z_prime_ALL_batch.type(my_tt)\n",
    "#     if paranoid:\n",
    "#         hasInf = (Z_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "#         if hasInf:\n",
    "#             print('Z_prime_ALL_batch has infinities...')\n",
    "# #         hasInf = (Z_prime_ALL_batch_cupy == float(\"inf\")).any().item()\n",
    "# #         if hasInf:\n",
    "# #             print('Z_prime_ALL_batch_cupy has infinities...')\n",
    "# #     del Z_prime_ALL_batch_cupy\n",
    "# #     del M_prime_ALL_batch\n",
    "# #     del batch_context_indices\n",
    "# #     del pW_context_batch\n",
    "#     del N_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\t>> End batch.', includeGPU=True)\n",
    "#     result = Z_prime_ALL_batch.cpu()\n",
    "#     del Z_prime_ALL_batch\n",
    "#     torch.cuda.empty_cache()\n",
    "# #     mempool.free_all_blocks()\n",
    "#     return result\n",
    "\n",
    "# # def denominator_batch_process_oe(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, V_prime_ce, N_prime_ce):\n",
    "# #     profilingStamps = False\n",
    "# #     if profilingStamps:\n",
    "# #         stampedMemNote('\\t>> Begin batch.')\n",
    "    \n",
    "# #     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    " \n",
    "# # #     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "# # #     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "# #     if profilingStamps:\n",
    "# #         stampedNote('\\tV_prime...')\n",
    "# #     # ::(c/b, m, n, l)\n",
    "# #     V_prime_ALL_batch = V_prime_ce(Y_prime_ALL_batch, Q_l, backend='torch')\n",
    "# # #     V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "# # #                                      Y_prime_ALL_batch,\n",
    "# # #                                      Q_l)\n",
    "# # #     del Y_prime_ALL_batch\n",
    "    \n",
    "# #     if profilingStamps:\n",
    "# #         stampedMemNote('\\tM_prime...')\n",
    "# #     # :: (c/b, m, n)\n",
    "# #     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "# #     del V_prime_ALL_batch\n",
    "    \n",
    "# #     if profilingStamps:\n",
    "# #         stampedMemNote('\\tpW_C...')\n",
    "# #     # :: (n, c/b)\n",
    "# #     pW_context_batch = pW_C_torch[:, batch_context_indices]\n",
    "# # #     del batch_context_indices\n",
    "    \n",
    "# #     if profilingStamps:\n",
    "# #         stampedNote('\\tN_prime...')\n",
    "# #     # :: (c/b, m)\n",
    "# #     N_prime_ALL_batch = N_prime_ce(M_prime_ALL_batch, pW_context_batch, backend='torch') # :: (c/b,m)\n",
    "# # #     N_prime_ALL_batch = torch.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "# #     del M_prime_ALL_batch\n",
    "# # #     del pW_context_batch\n",
    "    \n",
    "# #     if profilingStamps:\n",
    "# #         stampedMemNote('\\tZ_prime...')\n",
    "# # #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "# #     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt)\n",
    "# #     torch.div(input=Z_prime_ALL_batch,\n",
    "# #               other=N_prime_ALL_batch,\n",
    "# #               out=Z_prime_ALL_batch)\n",
    "# # #     del M_prime_ALL_batch\n",
    "# # #     del batch_context_indices\n",
    "# # #     del pW_context_batch\n",
    "# # #     del N_prime_ALL_batch\n",
    "# #     if profilingStamps:\n",
    "# #         stampedNote('\\t>> End batch.')\n",
    "# #     return Z_prime_ALL_batch\n",
    "\n",
    "# def denominator_batch_process(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, exact_wf=False):\n",
    "#     profilingStamps = False\n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\t>> Begin batch.')\n",
    "    \n",
    "#     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    " \n",
    "#     l = Y_prime_ALL_batch.shape[2]\n",
    "#     L = l+2\n",
    "\n",
    "# #     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "# #     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedNote('\\tV_prime...')\n",
    "#     # ::(c/b, m, n, l)\n",
    "#     V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "#                                      Y_prime_ALL_batch,\n",
    "#                                      Q_l)\n",
    "# #     del Y_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tM_prime...')\n",
    "#     # :: (c/b, m, n)\n",
    "#     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "#     del V_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tpW_C...')\n",
    "#     # :: (n, c/b)\n",
    "#     if not exact_wf:\n",
    "#         pW_context_batch = pW_C_torch[:, batch_context_indices]\n",
    "#     else:\n",
    "#         pW_context_batch = pW_C_torch[l_to_w_idxs[L], batch_context_indices]\n",
    "#         if pW_context_batch.dim() == 1:\n",
    "# #             torch.unsqueeze(pW_context_batch, -1, out=pW_context_batch)\n",
    "#             pW_context_batch = torch.unsqueeze(pW_context_batch, 0)\n",
    "# #     del batch_context_indices\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedNote('\\tN_prime...')\n",
    "#     # :: (c/b, m)\n",
    "#     N_prime_ALL_batch = torch.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "#     del M_prime_ALL_batch\n",
    "# #     del pW_context_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tZ_prime...')\n",
    "# #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "#     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt)\n",
    "#     torch.div(input=Z_prime_ALL_batch,\n",
    "#               other=N_prime_ALL_batch,\n",
    "#               out=Z_prime_ALL_batch)\n",
    "# #     del M_prime_ALL_batch\n",
    "# #     del batch_context_indices\n",
    "# #     del pW_context_batch\n",
    "# #     del N_prime_ALL_batch\n",
    "#     if profilingStamps:\n",
    "#         stampedNote('\\t>> End batch.')\n",
    "#     return Z_prime_ALL_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:52.850587Z",
     "start_time": "2019-08-11T05:07:52.699781Z"
    }
   },
   "outputs": [],
   "source": [
    "def denominator_batch_process_g(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, exact_wf=False):\n",
    "# def denominator_batch_process_g(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, V_prime_ce, N_prime_ce):\n",
    "    if benchmark:\n",
    "        profilingStamps = False\n",
    "        paranoid = True\n",
    "    else:\n",
    "        profilingStamps = False\n",
    "    \n",
    "#     profilingStamps = False\n",
    "    paranoid = True\n",
    "#     mempool = cupy.get_default_memory_pool()\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\t>> Begin batch.', includeGPU=True)\n",
    "    \n",
    "#     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    "    Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch # :: (c/b, m, l, s)\n",
    " \n",
    "    l = Y_prime_ALL_batch.shape[2]\n",
    "    L = l+2\n",
    "\n",
    "#     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "#     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tV_prime...', includeGPU=True)\n",
    "    # ::(c/b, m, n, l)\n",
    "#     V_prime_ALL_batch = V_prime_ce(Y_prime_ALL_batch, Q_l, backend='torch')\n",
    "    V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "                                     Y_prime_ALL_batch,\n",
    "                                     Q_l)\n",
    "#     if paranoid:\n",
    "#         hasInf = (V_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "#         if hasInf:\n",
    "#             print('V_prime_ALL_batch has infinities...')\n",
    "    del Y_prime_ALL_batch\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tM_prime...', includeGPU=True)\n",
    "    # :: (c/b, m, n)\n",
    "    M_prime_ALL_batch = cupy.prod(cupy.fromDlpack(to_dlpack(V_prime_ALL_batch)), 3)\n",
    "    M_prime_ALL_batch = from_dlpack(M_prime_ALL_batch.toDlpack())\n",
    "##     M_prime_ALL_batch = torch.exp(torch.sum(torch.log(V_prime_ALL_batch), 3))\n",
    "#     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch.type(torch.float64), 3).type(my_tt)\n",
    "#     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "#     if paranoid:\n",
    "#         hasInf = (M_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "#         if hasInf:\n",
    "#             print('M_prime_ALL_batch has infinities...')\n",
    "    del V_prime_ALL_batch\n",
    "#     mempool.free_all_blocks()\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tpW_C...', includeGPU=True)\n",
    "    # :: (n, c/b)\n",
    "    if not exact_wf:\n",
    "        pW_context_batch = pW_C_torch[:, batch_context_indices].cuda()\n",
    "    else:\n",
    "        pW_context_batch = torch.index_select(pW_C_torch[l_to_w_idxs[L]],\n",
    "                                              1,\n",
    "                                              batch_context_indices)\n",
    "#         pW_context_batch = pW_C_torch[l_to_w_idxs[L], batch_context_indices]\n",
    "        if pW_context_batch.dim() == 1:\n",
    "#             torch.unsqueeze(pW_context_batch, -1, out=pW_context_batch)\n",
    "            pW_context_batch = torch.unsqueeze(pW_context_batch, 0)\n",
    "        pW_context_batch = pW_context_batch.cuda()\n",
    "    del batch_context_indices\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tN_prime...', includeGPU=True)\n",
    "    # :: (c/b, m)\n",
    "#     N_prime_ALL_batch = cupy.einsum('cmn,nc->cm', M_prime_ALL_batch, \n",
    "#                                     cupy.fromDlpack(to_dlpack(pW_context_batch))) # :: (c/b,m)\n",
    "    N_prime_ALL_batch = torch.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "#     N_prime_ALL_batch = N_prime_ce(M_prime_ALL_batch, pW_context_batch, backend='torch') # :: (c/b,m)\n",
    "#     N_prime_ALL_batch_cupy = N_prime_ALL_batch\n",
    "#     del N_prime_ALL_batch\n",
    "#     if paranoid:\n",
    "#         hasInf = (N_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "#         if hasInf:\n",
    "#             print('N_prime_ALL_batch has infinities...')\n",
    "    del M_prime_ALL_batch\n",
    "    del pW_context_batch\n",
    "    \n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tZ_prime...', includeGPU=True)\n",
    "##     N_prime_ALL_batch_cupy = cupy.asarray(N_prime_ALL_batch.cpu().numpy())\n",
    "#     N_prime_ALL_batch_dlpack = to_dlpack(N_prime_ALL_batch)\n",
    "#     del N_prime_ALL_batch\n",
    "#     N_prime_ALL_batch_cupy = cupy.fromDlpack(N_prime_ALL_batch_dlpack)\n",
    "#     del N_prime_ALL_batch_dlpack\n",
    "#     Z_prime_ALL_batch_cupy = cupy.reciprocal(N_prime_ALL_batch_cupy)\n",
    "##     Z_prime_ALL_batch_cupy = 1.0 / N_prime_ALL_batch_cupy\n",
    "##     Z_prime_ALL_batch_cupy = cupy.divide(cupy.ones(N_prime_ALL_batch_cupy.shape, dtype=cupy.float32),\n",
    "##                                          N_prime_ALL_batch_cupy)\n",
    "##     Z_prime_ALL_batch_cupy = cupy.power(N_prime_ALL_batch_cupy, -1.0 * cupy.ones(N_prime_ALL_batch_cupy.shape))\n",
    "##     del N_prime_ALL_batch_cupy\n",
    "#     Z_prime_ALL_batch = from_dlpack(Z_prime_ALL_batch_cupy.toDlpack())\n",
    "#     del Z_prime_ALL_batch_cupy\n",
    "##     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "##     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch.type(torch.float64) # :: (c/b,m)\n",
    "##     Z_prime_ALL_batch = torch.pow(N_prime_ALL_batch, -1)\n",
    "##     Z_prime_ALL_batch = torch.pow(N_prime_ALL_batch.type(torch.float64), -1).type(my_tt)\n",
    "##     Z_prime_ALL_batch = torch.reciprocal(N_prime_ALL_batch)\n",
    "##     Z_prime_ALL_batch = torch.reciprocal(N_prime_ALL_batch.type(torch.float64)).type(my_tt)\n",
    "    Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt, device=gpu)\n",
    "##     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=torch.float64, device=gpu)\n",
    "    torch.div(input=Z_prime_ALL_batch,\n",
    "              other=N_prime_ALL_batch,\n",
    "#               other=N_prime_ALL_batch.type(torch.float64),\n",
    "              out=Z_prime_ALL_batch)\n",
    "    Z_prime_ALL_batch = Z_prime_ALL_batch.type(my_tt)\n",
    "    if paranoid:\n",
    "        hasInf = (Z_prime_ALL_batch == float(\"inf\")).any().item()\n",
    "        if hasInf:\n",
    "            print('Z_prime_ALL_batch has infinities...')\n",
    "#         hasInf = (Z_prime_ALL_batch_cupy == float(\"inf\")).any().item()\n",
    "#         if hasInf:\n",
    "#             print('Z_prime_ALL_batch_cupy has infinities...')\n",
    "#     del Z_prime_ALL_batch_cupy\n",
    "#     del M_prime_ALL_batch\n",
    "#     del batch_context_indices\n",
    "#     del pW_context_batch\n",
    "    del N_prime_ALL_batch\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\t>> End batch.', includeGPU=True)\n",
    "    result = Z_prime_ALL_batch.cpu()\n",
    "    del Z_prime_ALL_batch\n",
    "    torch.cuda.empty_cache()\n",
    "#     mempool.free_all_blocks()\n",
    "    return result\n",
    "\n",
    "# def denominator_batch_process_oe(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, V_prime_ce, N_prime_ce):\n",
    "#     profilingStamps = False\n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\t>> Begin batch.')\n",
    "    \n",
    "#     Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    " \n",
    "# #     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "# #     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedNote('\\tV_prime...')\n",
    "#     # ::(c/b, m, n, l)\n",
    "#     V_prime_ALL_batch = V_prime_ce(Y_prime_ALL_batch, Q_l, backend='torch')\n",
    "# #     V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "# #                                      Y_prime_ALL_batch,\n",
    "# #                                      Q_l)\n",
    "# #     del Y_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tM_prime...')\n",
    "#     # :: (c/b, m, n)\n",
    "#     M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "#     del V_prime_ALL_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tpW_C...')\n",
    "#     # :: (n, c/b)\n",
    "#     pW_context_batch = pW_C_torch[:, batch_context_indices]\n",
    "# #     del batch_context_indices\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedNote('\\tN_prime...')\n",
    "#     # :: (c/b, m)\n",
    "#     N_prime_ALL_batch = N_prime_ce(M_prime_ALL_batch, pW_context_batch, backend='torch') # :: (c/b,m)\n",
    "# #     N_prime_ALL_batch = torch.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "#     del M_prime_ALL_batch\n",
    "# #     del pW_context_batch\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('\\tZ_prime...')\n",
    "# #     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "#     Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt)\n",
    "#     torch.div(input=Z_prime_ALL_batch,\n",
    "#               other=N_prime_ALL_batch,\n",
    "#               out=Z_prime_ALL_batch)\n",
    "# #     del M_prime_ALL_batch\n",
    "# #     del batch_context_indices\n",
    "# #     del pW_context_batch\n",
    "# #     del N_prime_ALL_batch\n",
    "#     if profilingStamps:\n",
    "#         stampedNote('\\t>> End batch.')\n",
    "#     return Z_prime_ALL_batch\n",
    "\n",
    "def denominator_batch_process(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, exact_wf=False):\n",
    "    profilingStamps = False\n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\t>> Begin batch.')\n",
    "    \n",
    "    Y_prime_ALL_batch = Y_prime_ALL_split_batched_batch.type(my_tt) # :: (c/b, m, l, s)\n",
    " \n",
    "    l = Y_prime_ALL_batch.shape[2]\n",
    "    L = l+2\n",
    "\n",
    "#     print(f'shape Y_prime_ALL_batch = {Y_prime_ALL_batch.shape}')\n",
    "#     print(f'shape Q_l = {Q_l.shape}')\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('\\tV_prime...')\n",
    "    # ::(c/b, m, n, l)\n",
    "    V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n",
    "                                     Y_prime_ALL_batch,\n",
    "                                     Q_l)\n",
    "#     del Y_prime_ALL_batch\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tM_prime...')\n",
    "    # :: (c/b, m, n)\n",
    "    M_prime_ALL_batch = torch.prod(V_prime_ALL_batch, 3)\n",
    "    del V_prime_ALL_batch\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tpW_C...')\n",
    "    # :: (n, c/b)\n",
    "    if not exact_wf:\n",
    "        pW_context_batch = pW_C_torch[:, batch_context_indices]\n",
    "    else:\n",
    "        pW_context_batch = pW_C_torch[l_to_w_idxs[L], batch_context_indices]\n",
    "        if pW_context_batch.dim() == 1:\n",
    "#             torch.unsqueeze(pW_context_batch, -1, out=pW_context_batch)\n",
    "            pW_context_batch = torch.unsqueeze(pW_context_batch, 0)\n",
    "#     del batch_context_indices\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('\\tN_prime...')\n",
    "    # :: (c/b, m)\n",
    "    N_prime_ALL_batch = torch.einsum('cmn,nc->cm', M_prime_ALL_batch, pW_context_batch) # :: (c/b,m)\n",
    "    del M_prime_ALL_batch\n",
    "#     del pW_context_batch\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('\\tZ_prime...')\n",
    "#     Z_prime_ALL_batch = 1.0 / N_prime_ALL_batch # :: (c/b,m)\n",
    "    Z_prime_ALL_batch = torch.ones(N_prime_ALL_batch.shape, dtype=my_tt)\n",
    "    torch.div(input=Z_prime_ALL_batch,\n",
    "              other=N_prime_ALL_batch,\n",
    "              out=Z_prime_ALL_batch)\n",
    "#     del M_prime_ALL_batch\n",
    "#     del batch_context_indices\n",
    "#     del pW_context_batch\n",
    "#     del N_prime_ALL_batch\n",
    "    if profilingStamps:\n",
    "        stampedNote('\\t>> End batch.')\n",
    "    return Z_prime_ALL_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:53.001522Z",
     "start_time": "2019-08-11T05:07:52.855685Z"
    }
   },
   "outputs": [],
   "source": [
    "def denominator_calc(CM, m, Q_l, target_contexts_per_batch=500, parallel=False):\n",
    "    profilingStamps = True\n",
    "    if profilingStamps:\n",
    "        stampedMemNote('> Begin calculation.')\n",
    "    num_contexts = len(Cs_t) #c\n",
    "#     num_batches = len(Y_prime_ALL_split_batched) #b\n",
    "#     num_contexts_per_batch = torch.tensor(tuple(map(len, Y_prime_ALL_split_batched_indices))) #c/b\n",
    "    l = CM.shape[1]\n",
    "#     print(f'l = {l}')\n",
    "    \n",
    "    num_samples = m * num_contexts\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('Generating samples...')\n",
    "    #collect enough sampled channel sequences for all c contexts \n",
    "    Y_prime_ALL = depthSamplerD_t(CM, m=num_samples, numBatches = 10)\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('Splitting samples by context...')\n",
    "    #split the samples into stacks of m samples per context\n",
    "    Y_prime_ALL_split = torch.stack(torch.chunk(Y_prime_ALL, num_contexts, 0))\n",
    "#     print(f'shape Y_prime_ALL_split = {Y_prime_ALL_split.shape}')\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('Splitting contexts into batches ...')\n",
    "    #split the contexts into batches\n",
    "#     target_contexts_per_batch = 1000\n",
    "    Y_prime_ALL_split_batched = torch.split(Y_prime_ALL_split,\n",
    "                                            target_contexts_per_batch,\n",
    "                                            0)\n",
    "    Y_prime_ALL_split_batched_indices = split_dimension(num_contexts, target_contexts_per_batch)\n",
    "    num_batches = len(Y_prime_ALL_split_batched)\n",
    "    if profilingStamps:\n",
    "        print(f'Num batches = {num_batches}')\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('Processing batches...')\n",
    "    #process the batches\n",
    "    if parallel:\n",
    "        Z_prime_ALL = torch.cat(list( par(delayed(denominator_batch_process)(Y_prime_ALL_split_batched_batch, Q_l, indices)\n",
    "                                      for Y_prime_ALL_split_batched_batch, indices in zip(Y_prime_ALL_split_batched, \n",
    "                                                                                          Y_prime_ALL_split_batched_indices)) ))\n",
    "    else:\n",
    "        Z_prime_ALL = torch.cat([denominator_batch_process(Y_prime_ALL_split_batched_batch, Q_l, indices)\n",
    "                                 for Y_prime_ALL_split_batched_batch, indices in tqdm(zip(Y_prime_ALL_split_batched,\n",
    "                                                                                          Y_prime_ALL_split_batched_indices),\n",
    "                                                                                      total=num_batches)]) \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('> Batches processed.')\n",
    "    return Z_prime_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T06:51:32.272993Z",
     "start_time": "2019-08-11T06:51:32.261023Z"
    }
   },
   "outputs": [],
   "source": [
    "def pXhat0fX0i_ptc(xhat0f_idx, x0k_CM, m = 50, target_contexts_per_batch=600, parallel=True, use_gpu=False, exact_wf=False):\n",
    "    '''\n",
    "    This function is exactly like \n",
    "        pXhat0fX0i_pxt\n",
    "    except it uses einsum (and batched computation) to calculate \n",
    "        p(xhat0f|x0k, c) \n",
    "    for *all* contexts c, in batches of target_contexts_per_batch\n",
    "    contexts at a time (default 750).\n",
    "    \n",
    "    Currently known optimal target_contexts_per_batch settings:\n",
    "    Quine CPU/Parallel newdic -> 750\n",
    "    Solomonoff CPU/Parallel newdic -> 750\n",
    "    Kotoba CPU/Parallel newdic -> 600-650\n",
    "    Kotoba GPU newdic -> 300-375\n",
    "    \n",
    "    \n",
    "    If ⋊ x_0 x_1 ... x_i x_k denotes\n",
    "    the produced prefix r of the speaker's intended wordform w,\n",
    "     where\n",
    "       x_i = the last fully produced segment\n",
    "       k = i+1\n",
    "       x_k = the next segment\n",
    "       |⋊ x_0 x_1 ... x_i x_k| = l + 2\n",
    "       l = i+1 = the length of the produced prefix (not incl. \n",
    "                 the left word edge or the next segment)\n",
    "\n",
    "    then\n",
    "\n",
    "    x0k_CM :: (|Y1|, l) is the associated l-length stack of size |Y1| vectors\n",
    "     where x0k_CM[:,j] is the distribution p(Y_j|X0^k has been produced)\n",
    "\n",
    "    xhat0f_idx is the index of a wordform w' s.t. \n",
    "\n",
    "    pXhat0fX0i_ptc(xhat0f_idx, x0k_CM) ≈ [p(w'|r)]_c for each context c\n",
    "    '''\n",
    "    profilingStamps = True\n",
    "#     if not benchmark:\n",
    "    mininterval = 10 #minimum of 10 seconds between tqdm progress updates\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('> Begin calculation.')\n",
    "    l = x0k_CM.shape[1]\n",
    "    num_contexts = len(Cs_t) #c\n",
    "    \n",
    "    if profilingStamps:\n",
    "        print(f'l = {l}')\n",
    "        \n",
    "    if exact_wf:\n",
    "        if xhat0f_idx not in l_to_w_idxs[x0k_CM.shape[1]+2]:\n",
    "            return torch.zeros((num_contexts,))\n",
    "        else:\n",
    "            L, xhat0f_l_idx = w_idx_to_l_w_l_idx(xhat0f_idx) # L = l+2\n",
    "    \n",
    "    m_C = num_contexts * m\n",
    "\n",
    "    if profilingStamps:\n",
    "        stampedMemNote('Sampling...')\n",
    "    # :: (c*m, l, s)\n",
    "#     Y_prime_C = depthSamplerC_t(x0k_CM, m=m_C)\n",
    "    Y_prime_C = depthSamplerD_t(x0k_CM, m=m_C, numBatches = 10)\n",
    "    \n",
    "    # :: (c, m, l, s)\n",
    "    if profilingStamps:\n",
    "        stampedMemNote('Splitting samples by context...')\n",
    "    Y_prime_C_split = torch.stack(torch.chunk(Y_prime_C, len(Cs_t), 0))\n",
    "#     stampedMemNote('Contexts split.')\n",
    "#     del Y_prime_C\n",
    "#     stampedMemNote('Deleted Y_prime_C.')\n",
    "    if not exact_wf:\n",
    "        Q_l = CMsByLengthByWordformIndex_torch[l+2]#.float() #:: (|W|, |Y1|, l)\n",
    "    else:\n",
    "        Q_l = exactCMsByLengthByWordformIndex_torch[l+2]\n",
    "    if use_gpu:\n",
    "        Q_l_g = Q_l.cuda()\n",
    "    \n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedNote('Splitting contexts into batches ...')\n",
    "    #split the contexts into batches\n",
    "    Y_prime_C_split_batched = torch.split(Y_prime_C_split,\n",
    "                                          target_contexts_per_batch,\n",
    "                                          0)\n",
    "    Y_prime_C_split_batched_indices = split_dimension(num_contexts, target_contexts_per_batch)\n",
    "    num_batches = len(Y_prime_C_split_batched)\n",
    "    if profilingStamps:\n",
    "        print(f'Num batches = {num_batches}')\n",
    "    \n",
    "#     if profilingStamps:\n",
    "#         stampedMemNote('Pre-calculating contract expressions for each batch...')\n",
    "#     #calculate contract expressions for each batch\n",
    "#     main_batch_size = len(Y_prime_C_split_batched_indices[0])\n",
    "#     final_batch_size = len(Y_prime_C_split_batched_indices[-1])\n",
    "#     batch_sizes = tuple(map(len, Y_prime_C_split_batched_indices))\n",
    "#     n = pW_C_torch.shape[0]\n",
    "#     s = Y_prime_C.shape[2]\n",
    "    \n",
    "#     V_prime_index_str = 'cmli,kil->cmkl'\n",
    "#     Y_prime_ALL_batch_shape = lambda contexts_per_batch: (contexts_per_batch, m, l, s) # (c/b, m, l, s)\n",
    "#     Q_l_batch_shape = tuple(Q_l.shape) # (n, s, l) = (|W|, |Y1|, l)\n",
    "#     V_prime_ALL_shape_for_batch = lambda contexts_per_batch: (Y_prime_ALL_batch_shape(contexts_per_batch), Q_l_batch_shape)\n",
    "#     V_prime_ALL_shape_main_batch = Y_prime_ALL_batch_shape(main_batch_size), Q_l_batch_shape\n",
    "#     V_prime_ALL_shape_final_batch = Y_prime_ALL_batch_shape(final_batch_size), Q_l_batch_shape\n",
    "#     V_prime_ALL_shapes_by_batch_size = {main_batch_size:V_prime_ALL_shape_main_batch,\n",
    "#                                         final_batch_size:V_prime_ALL_shape_main_batch}\n",
    "# #     V_prime_ALL_shapes_by_batch = tuple(map(V_prime_ALL_shape_for_batch, batch_sizes))\n",
    "#     V_prime_contract_expr_by_batch_size = {main_batch_size:oe.contract_expression(V_prime_index_str, *(V_prime_ALL_shapes_by_batch_size[main_batch_size])),\n",
    "#                                            final_batch_size:oe.contract_expression(V_prime_index_str, *(V_prime_ALL_shapes_by_batch_size[final_batch_size]))}\n",
    "# #     V_prime_contract_exprs_by_batch = tuple(map(lambda shapes: oe.contract_expression(V_prime_index_str, *shapes),\n",
    "# #                                                 V_prime_ALL_shapes_by_batch))    \n",
    "#     N_prime_index_str = 'cmn,nc->cm'\n",
    "#     M_prime_ALL_batch_shape = lambda contexts_per_batch: (contexts_per_batch, m, n) # (c/b, m, n)\n",
    "#     pW_context_batch_shape = lambda contexts_per_batch: (n, contexts_per_batch) # (n, c/b)\n",
    "#     N_prime_shape_for_batch = lambda contexts_per_batch: (M_prime_ALL_batch_shape(contexts_per_batch), pW_context_batch_shape(contexts_per_batch))\n",
    "#     N_prime_shapes_by_batch_size = {main_batch_size:N_prime_shape_for_batch(main_batch_size),\n",
    "#                                     final_batch_size:N_prime_shape_for_batch(final_batch_size)}\n",
    "# #     N_prime_shapes_by_batch = tuple(map(N_prime_shape_for_batch, batch_sizes))\n",
    "#     N_prime_contract_expr_by_batch_size = {main_batch_size:oe.contract_expression(N_prime_index_str, *(N_prime_shapes_by_batch_size[main_batch_size])),\n",
    "#                                            final_batch_size:oe.contract_expression(N_prime_index_str, *(N_prime_shapes_by_batch_size[final_batch_size]))}\n",
    "# #     N_prime_contract_exprs_by_batch = tuple(map(lambda shapes: oe.contract_expression(N_prime_index_str, *shapes),\n",
    "# #                                                 N_prime_shapes_by_batch))\n",
    "    \n",
    "#     with cupy.cuda.Device(0):\n",
    "#         Q_l_g = cupy.array(Q_l.numpy())\n",
    "#     Y_prime_C_split_batched = tuple(map(lambda batch: batch.numpy().astype(np.float32),\n",
    "#                                         Y_prime_C_split_batched))\n",
    "# #     cupy.array(Y_prime_C_split_batched.numpy().astype(np.float32))\n",
    "# #     Y_prime_C_split_batched = cupy.array(Y_prime_C_split_batched.numpy().astype(np.float32))\n",
    "#     Y_prime_C_split_batched_indices = tuple(map(lambda index_batch: cupy.array(index_batch.numpy()),\n",
    "#                                                Y_prime_C_split_batched_indices))\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('Processing batches...')\n",
    "    #process the batches\n",
    "    if parallel:\n",
    "#         print('Parallelizing across CPUs cores...')\n",
    "        Z_prime_C = torch.cat(list( par(delayed(denominator_batch_process)(Y_prime_C_split_batched_batch, Q_l, indices, exact_wf=exact_wf)\n",
    "                                        for Y_prime_C_split_batched_batch, indices in zip(Y_prime_C_split_batched,\n",
    "                                                                                          Y_prime_C_split_batched_indices)) ))\n",
    "\n",
    "#         Z_prime_C = torch.cat(list( par(delayed(denominator_batch_process_oe)(Y_prime_C_split_batched_batch, Q_l, indices, \n",
    "#                                                                               V_prime_contract_expr_by_batch_size[len(indices)], \n",
    "#                                                                               N_prime_contract_expr_by_batch_size[len(indices)])\n",
    "#                                         for Y_prime_C_split_batched_batch, indices in zip(Y_prime_C_split_batched,\n",
    "#                                                                                           Y_prime_C_split_batched_indices)) ))\n",
    "#         Z_prime_C = torch.cat(list( par(delayed(denominator_batch_process_oe)(Y_prime_C_split_batched_batch, Q_l, indices, V_ce, N_ce)\n",
    "#                                         for Y_prime_C_split_batched_batch, indices, V_ce, N_ce in zip(Y_prime_C_split_batched,\n",
    "#                                                                                                       Y_prime_C_split_batched_indices,\n",
    "#                                                                                                       V_prime_contract_exprs_by_batch,\n",
    "#                                                                                                       N_prime_contract_exprs_by_batch)) ))\n",
    "    elif use_gpu:\n",
    "#         print('Using the GPU...')\n",
    "#         Z_prime_C = torch.cat([torch.tensor(cupy.asnumpy(denominator_batch_process_c(Y_prime_C_split_batched_batch, Q_l_g, indices)))\n",
    "#                        for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n",
    "#                                                                               Y_prime_C_split_batched_indices),\n",
    "#                                                                           total=num_batches,\n",
    "#                                                                           mininterval=mininterval)]) \n",
    "        Z_prime_C = torch.cat([denominator_batch_process_g(Y_prime_C_split_batched_batch.type(my_tt).cuda(), Q_l_g, indices, exact_wf=exact_wf)\n",
    "                       for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n",
    "                                                                              Y_prime_C_split_batched_indices),\n",
    "                                                                          total=num_batches,\n",
    "                                                                          mininterval=mininterval,\n",
    "                                                                          unit_scale=target_contexts_per_batch,\n",
    "                                                                          unit=\"calc\")]) \n",
    "#         Z_prime_C = torch.cat([denominator_batch_process_g(Y_prime_C_split_batched_batch.type(my_tt).cuda(), Q_l_g, indices, \n",
    "#                                                             V_prime_contract_expr_by_batch_size[len(indices)], \n",
    "#                                                             N_prime_contract_expr_by_batch_size[len(indices)])\n",
    "#                        for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n",
    "#                                                                               Y_prime_C_split_batched_indices),\n",
    "#                                                                           total=num_batches)]) \n",
    "    else:\n",
    "#         print('Serially on the CPU...')\n",
    "        Z_prime_C = torch.cat([denominator_batch_process(Y_prime_C_split_batched_batch, Q_l, indices, exact_wf=exact_wf)\n",
    "                               for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n",
    "                                                                                      Y_prime_C_split_batched_indices),\n",
    "                                                                                  total=num_batches,\n",
    "                                                                                  mininterval=mininterval,\n",
    "                                                                                  unit_scale=target_contexts_per_batch,\n",
    "                                                                                  unit=\"calc\")]) \n",
    "\n",
    "#         Z_prime_C = torch.cat([denominator_batch_process_oe(Y_prime_C_split_batched_batch, Q_l, indices, \n",
    "#                                                             V_prime_contract_expr_by_batch_size[len(indices)], \n",
    "#                                                             N_prime_contract_expr_by_batch_size[len(indices)])\n",
    "#                                for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n",
    "#                                                                                       Y_prime_C_split_batched_indices),\n",
    "#                                                                                   total=num_batches)]) \n",
    "#         Z_prime_C = torch.cat([denominator_batch_process_oe(Y_prime_C_split_batched_batch, Q_l, indices, V_ce, N_ce)\n",
    "#                                for Y_prime_C_split_batched_batch, indices, V_ce, N_ce in tqdm(zip(Y_prime_C_split_batched,\n",
    "#                                                                                                   Y_prime_C_split_batched_indices,\n",
    "#                                                                                                   V_prime_contract_exprs_by_batch,\n",
    "#                                                                                                   N_prime_contract_exprs_by_batch),\n",
    "#                                                                                                  total=num_batches)]) \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('> Batches processed.')\n",
    "    if use_gpu:\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('Calculating numerator...')\n",
    "        stampedNote('Calculating V_prime_w_C...')\n",
    "    if not exact_wf:\n",
    "        xhat0f_L_w = Q_l[xhat0f_idx]#.float() # :: (s, l)\n",
    "    else:\n",
    "        xhat0f_L_w = Q_l[xhat0f_l_idx]#.float() # :: (s, l)\n",
    "#     V_prime_w_C = oe.contract('cmij,ji->cmi',Y_prime_C_split.type(my_tt), xhat0f_L_w, backend='torch') # :: (c,m,l)\n",
    "    V_prime_w_C = torch.einsum('cmij,ji->cmi',Y_prime_C_split.type(my_tt), xhat0f_L_w) # :: (c,m,l)\n",
    "#     stampedMemNote('V_prime_w_C created.')\n",
    "#     del xhat0f_L_w\n",
    "#     del Y_prime_C_split\n",
    "#     stampedMemNote('xhat0f_L_w and Y_prime_C_split deleted.')\n",
    "    if profilingStamps:\n",
    "        stampedNote('Calculating O_w_C...')\n",
    "    O_w_C = torch.prod(V_prime_w_C, 2) # :: (c,m) likelihoods of each of the m sampled channel prefixes for each of c contexts\n",
    "#     stampedMemNote('O_w_C created.')\n",
    "#     del V_prime_w_C\n",
    "#     stampedMemNote('V_prime_w_C deleted.')\n",
    "    if profilingStamps:\n",
    "        stampedNote('Calculating U_w_C...')\n",
    "    if not exact_wf:\n",
    "        U_w_C = torch.einsum('c,cm->cm', pW_C_torch[xhat0f_idx], O_w_C) ## :: (c,m) joint probabilities of xhat0f with each of the m sampled channel prefixes for each of the c contexts\n",
    "    else:\n",
    "        U_w_C = torch.einsum('c,cm->cm', pW_C_torch[xhat0f_l_idx], O_w_C) ## :: (c,m) joint probabilities of xhat0f with each of the m sampled channel prefixes for each of the c contexts\n",
    "    \n",
    "#     stampedMemNote('U_w_C created.')\n",
    "#     del O_w_C\n",
    "#     stampedMemNote('O_w_C deleted.')\n",
    "    \n",
    "    if profilingStamps:\n",
    "        stampedMemNote('Calculating E_w_C...')\n",
    "#     return torch.dot(Z_prime_C, U_w_C) / m\n",
    "    E_w_C = torch.einsum('cm,cm->c', Z_prime_C, U_w_C) / m\n",
    "#     stampedMemNote('E_w_C created.')\n",
    "#     del Z_prime_C\n",
    "#     del U_w_C\n",
    "#     stampedMemNote('Z_prime_C and U_w_C deleted.')\n",
    "    if profilingStamps:\n",
    "        stampedNote('> End calculation.')\n",
    "    return E_w_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:07:53.333901Z",
     "start_time": "2019-08-11T05:07:53.157213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_long_word = choice(list({w for w in Ws if len(ds2t(w)) == max(wordlengthsInclEdges)}))\n",
    "random_long_word\n",
    "rlw_idx = Ws_t.index(random_long_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:10:10.587976Z",
     "start_time": "2019-08-11T05:07:53.334981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 22:07:53\n",
      "l = 17\n",
      "Sampling... @ 22:07:53\n",
      "\tVM used vs. available: 8.06GB vs. 25.16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.4s remaining:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.5s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.5s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 22:08:04\n",
      "\tVM used vs. available: 11.65GB vs. 21.57GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 22:08:14\n",
      "Num batches = 2126\n",
      "Processing batches... @ 22:08:14\n",
      "\tVM used vs. available: 16.97GB vs. 16.24GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 192/2126 [00:10<01:40, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 392/2126 [00:20<01:29, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 593/2126 [00:30<01:18, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 794/2126 [00:40<01:07, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 995/2126 [00:50<00:57, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 1195/2126 [01:00<00:46, 19.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 1395/2126 [01:10<00:36, 19.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 1595/2126 [01:20<00:26, 19.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 1795/2126 [01:30<00:16, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 1995/2126 [01:40<00:06, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2126/2126 [01:46<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 22:10:01\n",
      "\tVM used vs. available: 17.05GB vs. 16.16GB\n",
      "Calculating numerator... @ 22:10:01\n",
      "\tVM used vs. available: 17.05GB vs. 16.16GB\n",
      "Calculating V_prime_w_C... @ 22:10:01\n",
      "Calculating O_w_C... @ 22:10:10\n",
      "Calculating U_w_C... @ 22:10:10\n",
      "Calculating E_w_C... @ 22:10:10\n",
      "\tVM used vs. available: 17.46GB vs. 15.75GB\n",
      "> End calculation. @ 22:10:10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(random_long_word))\n",
    "rlw_slice = pXhat0fX0i_ptc(rlw_idx, CMsByLengthByWordformIndex_torch[len(ds2t(random_long_word))][rlw_idx],\n",
    "                           m=n, target_contexts_per_batch=50, parallel=l, use_gpu=g)\n",
    "rlw_slice.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:08.261831Z",
     "start_time": "2019-08-11T05:10:10.589260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 22:10:10\n",
      "l = 7\n",
      "Sampling... @ 22:10:10\n",
      "\tVM used vs. available: 10.05GB vs. 23.16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.5s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.9s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.4s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 22:10:16\n",
      "\tVM used vs. available: 11.52GB vs. 21.69GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/709 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 22:10:17\n",
      "Num batches = 709\n",
      "Processing batches... @ 22:10:17\n",
      "\tVM used vs. available: 12.97GB vs. 20.24GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 709/709 [00:47<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 22:11:04\n",
      "\tVM used vs. available: 12.97GB vs. 20.24GB\n",
      "Calculating numerator... @ 22:11:04\n",
      "\tVM used vs. available: 12.97GB vs. 20.24GB\n",
      "Calculating V_prime_w_C... @ 22:11:04\n",
      "Calculating O_w_C... @ 22:11:08\n",
      "Calculating U_w_C... @ 22:11:08\n",
      "Calculating E_w_C... @ 22:11:08\n",
      "\tVM used vs. available: 13.15GB vs. 20.06GB\n",
      "> End calculation. @ 22:11:08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(Ws_t[0]))\n",
    "idealize_slice2 = pXhat0fX0i_ptc(0, CMsByLengthByWordformIndex_torch[len(ds2t(Ws_t[0]))][0],\n",
    "                                m=n, target_contexts_per_batch=150, parallel=l, use_gpu=g)\n",
    "idealize_slice2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:08.798559Z",
     "start_time": "2019-08-11T05:11:08.263002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9651)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(9.8052e-06)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(idealize_slice2 == float('inf')).any()\n",
    "max(idealize_slice2)\n",
    "min(idealize_slice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:08.992565Z",
     "start_time": "2019-08-11T05:11:08.799625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        9.4G         20G         14M        1.7G         21G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.180115Z",
     "start_time": "2019-08-11T05:11:08.998715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5314750"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Cs_t)\n",
    "len(Cs_t) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.265674Z",
     "start_time": "2019-08-11T05:11:09.185260Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    wlr_n = np.array(sorted(list(wordlengthsInclEdges)))\n",
    "    benchmark_lengths = torch.tensor(list(wlr_n[ np.where(wlr_n % 4 == 0)[0]  ]) + [max(wordlengthsInclEdges)])\n",
    "    benchmark_wordform_idxs = tuple([Ws_t.index(choice(list(wordformsOfLength(l, Ws_t, True))))\n",
    "                                     for l in benchmark_lengths])\n",
    "    benchmark_wordforms = tuple([Ws_t[w_idx] for w_idx in benchmark_wordform_idxs])\n",
    "    dict(zip(list(map(lambda t: t.item(), benchmark_lengths)), \n",
    "             benchmark_wordforms))\n",
    "    benchmark_CMs = tuple([CMsByLengthByWordformIndex_torch[len(ds2t(w))][Ws_t.index(w)]\n",
    "                           for w in benchmark_wordforms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.353335Z",
     "start_time": "2019-08-11T05:11:09.270317Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # iterate through batch sizes, leaving large batch sizes for last, \n",
    "    # since they're most likely to cause crashes and this way we collect more useful data first...\n",
    "    for batch_size in [50, 100, 200, 300, 500, 600, 750, 1000, 1250, 1500]:\n",
    "        print(f\"### Batch size: {batch_size}\")\n",
    "        for b_l, w_idx, CM in zip(benchmark_lengths, benchmark_wordform_idxs, benchmark_CMs):\n",
    "            stampedMemNote(f'## L={b_l}, b={batch_size}', includeGPU=True)\n",
    "            post = pXhat0fX0i_ptc(w_idx, CM, m=n, target_contexts_per_batch=batch_size, parallel=l, use_gpu=g, exact_wf=False)\n",
    "            print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.483529Z",
     "start_time": "2019-08-11T05:11:09.354689Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 50, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 40.2s = 106295c/40.2 = 2644.15cps\n",
    "    # peak memory usage is about 1.0GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=50, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.572321Z",
     "start_time": "2019-08-11T05:11:09.485930Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 200, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 32.1s = 106295c/32.1 = 3311.37cps\n",
    "    # peak GPU memory usage ~2.0 GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=200, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.655446Z",
     "start_time": "2019-08-11T05:11:09.577111Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 350, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 28.7s = 106295c/28.7s = 3703.66cps\n",
    "    # peak GPU memory usage ~3.1 GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=350, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.738639Z",
     "start_time": "2019-08-11T05:11:09.660161Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 375, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 28.6s = 106295c/28.6 = 3716.61cps\n",
    "    # peak GPU memory usage ~3.3 GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=375, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.833711Z",
     "start_time": "2019-08-11T05:11:09.743254Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 375, kotoba, gpu, float32, opt_einsum\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 103s = 106295c/103s = 1032cps\n",
    "    # peak GPU memory usage ~? GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=375, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:09.951109Z",
     "start_time": "2019-08-11T05:11:09.838364Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 400, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 94s = 106295c/94s = 1130.80cps\n",
    "    # peak GPU memory usage ~3.1 GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=400, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.039056Z",
     "start_time": "2019-08-11T05:11:09.955796Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 500, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 93.0s = 106295c/93.0s = 1142.96cps\n",
    "    # peak GPU memory usage ~4.2 GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=500, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.139047Z",
     "start_time": "2019-08-11T05:11:10.043629Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # batch size 750, kotoba, gpu, float32\n",
    "    # 5s on sample generation, 1s to split into batches of contexts\n",
    "    # 252s = 106295c/252s = 421.81cps\n",
    "    # peak GPU memory usage ~5.9 GB / 8GB\n",
    "    pContact_cont_C = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=750, parallel=False, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.230461Z",
     "start_time": "2019-08-11T05:11:10.143739Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #batch size 500, quine, serial\n",
    "    # 40s on sample generation, 1s to split into batches of contexts / float64 / quine\n",
    "    # 6s on sample generation, <1s to split into batches of contexts / float32 / kotoba\n",
    "    # ≈10s per batch, 213 batches = 35m4s = 106295c/2104s = 50.52 cps / float64 / quine\n",
    "    # ≈5s per batch, 213 batches = 17m47s = 106295c/1067s = 99.62 cps / float32 / quine\n",
    "    # 1.16s per batch, 213 batches = 247.08s = 4m7s = 106295c/247s = 430.34 cps / float32 / kotoba\n",
    "    #  - pytorch does make use of all available cpus (for a significant stretch) \n",
    "    #    of each batch step, and the memory overhead is low enough to run on kotoba,\n",
    "    #    but it's clearly possible (serial processing w/ batch size 3000 only takes 90s for all 106295c)\n",
    "    #      - parallelization over (smaller? larger?) batches \n",
    "    #    would waste less time\n",
    "    cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.346194Z",
     "start_time": "2019-08-11T05:11:10.235088Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #batch size 500, quine, parallel\n",
    "    # 30s on sample generation, 1s to split into batches of contexts\n",
    "    # 13m39s = 819s = 106295c/819s = 129.79 cps / float64 / quine\n",
    "    # 4-5s per batch, 213 batches ≈10^3s to do ≈10^5c = ≈10^2 cps / float64 / quine\n",
    "    #   = about twice as fast as serial processing with same batch size\n",
    "    # cpu utilization is more consistent per core but far from full utilization\n",
    "    # 11m46s = 706s = 106295c/706s = 150.56 cps / float32 / quine\n",
    "    # 3m59s = 239s = 106295c/239s = 444.75 cps / float32 / kotoba / peak 25GB RAM usage\n",
    "    cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 500, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.629809Z",
     "start_time": "2019-08-11T05:11:10.350723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        9.4G         20G         14M        1.7G         21G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.644006Z",
     "start_time": "2019-08-11T05:11:10.636037Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    #batch size 650, quine, parallel\n",
    "    # 24s on sample generation, 1s to split into batches of contexts / float64 / quine\n",
    "    # 12m21s = 741s = 106295c/741s = 143.45 cps / float64 / quine\n",
    "    # 9m14s = 554s = 106295c/554s = 191.87 cps / float32 / quine\n",
    "    # ?m?s = ?s = 106295c/? = ? cps / float32 / kotoba / peak ?GB RAM usage = too high...\n",
    "    cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 650, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T19:37:49.146133Z",
     "start_time": "2019-08-06T19:24:47.590503Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 19:24:47\n",
      "Sampling... @ 19:24:47\n",
      "\tVM used vs. available: 19.74GB vs. 144.22GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    6.5s remaining:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    7.6s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    9.0s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 19:25:05\n",
      "\tVM used vs. available: 19.77GB vs. 144.20GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/142 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 19:25:06\n",
      "Num batches = 142\n",
      "Pre-calculating contract expressions for each batch... @ 19:25:06\n",
      "\tVM used vs. available: 20.39GB vs. 143.58GB\n",
      "Processing batches... @ 19:25:06\n",
      "\tVM used vs. available: 20.39GB vs. 143.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/142 [01:06<2:37:12, 66.90s/it]\u001b[A\n",
      "  1%|▏         | 2/142 [02:17<2:39:01, 68.15s/it]\u001b[A\n",
      "  2%|▏         | 3/142 [03:30<2:40:52, 69.44s/it]\u001b[A\n",
      "  3%|▎         | 4/142 [04:42<2:41:49, 70.36s/it]\u001b[A\n",
      "  4%|▎         | 5/142 [06:22<3:00:59, 79.27s/it]\u001b[A\n",
      "  4%|▍         | 6/142 [07:38<2:56:50, 78.02s/it]\u001b[A\n",
      "  5%|▍         | 7/142 [08:59<2:57:40, 78.97s/it]\u001b[A\n",
      "  6%|▌         | 8/142 [10:12<2:52:15, 77.13s/it]\u001b[A\n",
      "  6%|▋         | 9/142 [11:36<2:55:52, 79.34s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-1dce3e393056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#batch size 750, quine, serial, oe test (reused paths, no storage of constant Q_l, efficient reused path expr calc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcont_Z_prime_ALL_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpXhat0fX0i_ptc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontact_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_CM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_contexts_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-287-3e4292f765f6>\u001b[0m in \u001b[0;36mpXhat0fX0i_ptc\u001b[0;34m(xhat0f_idx, x0k_CM, m, target_contexts_per_batch, parallel)\u001b[0m\n\u001b[1;32m    274\u001b[0m                                for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n\u001b[1;32m    275\u001b[0m                                                                                       Y_prime_C_split_batched_indices),\n\u001b[0;32m--> 276\u001b[0;31m                                                                                   total=num_batches)]) \n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;31m#         Z_prime_C = torch.cat([denominator_batch_process_oe(Y_prime_C_split_batched_batch, Q_l, indices, V_ce, N_ce)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;31m#                                for Y_prime_C_split_batched_batch, indices, V_ce, N_ce in tqdm(zip(Y_prime_C_split_batched,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-287-3e4292f765f6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                                             \u001b[0mV_prime_contract_expr_by_batch_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                                             N_prime_contract_expr_by_batch_size[len(indices)])\n\u001b[0;32m--> 274\u001b[0;31m                                for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n\u001b[0m\u001b[1;32m    275\u001b[0m                                                                                       Y_prime_C_split_batched_indices),\n\u001b[1;32m    276\u001b[0m                                                                                   total=num_batches)]) \n",
      "\u001b[0;32m<ipython-input-287-3e4292f765f6>\u001b[0m in \u001b[0;36mdenominator_batch_process_oe\u001b[0;34m(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices, V_prime_ce, N_prime_ce)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mstampedMemNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tM_prime...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# :: (c/b, m, n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mM_prime_ALL_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_prime_ALL_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mV_prime_ALL_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch size 750, quine, serial, oe test (reused paths, no storage of constant Q_l, efficient reused path expr calc)\n",
    "cont_Z_prime_ALL_p = pXhat0fX0i_ptc(contact_idx, cont_CM, m=50, target_contexts_per_batch=750, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:44:17.431378Z",
     "start_time": "2019-08-06T09:35:39.369095Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 09:35:39\n",
      "\tVM used vs. available: 21.11GB vs. 142.86GB\n",
      "Generating samples... @ 09:35:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    7.0s remaining:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    8.0s remaining:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    8.6s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 09:36:03\n",
      "Splitting contexts into batches ... @ 09:36:04\n",
      "Num batches = 142\n",
      "Processing batches... @ 09:36:04\n",
      "\tVM used vs. available: 21.11GB vs. 142.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 142 | elapsed:  6.4min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 142 | elapsed:  7.2min remaining:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 142 | elapsed:  8.0min remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 142 out of 142 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 09:44:17\n",
      "\tVM used vs. available: 21.13GB vs. 142.85GB\n"
     ]
    }
   ],
   "source": [
    "#batch size 750, quine, parallel\n",
    "# 19s on sample generation, 1s to split into batches of contexts\n",
    "# 10m37s = 637s = 106295c/637s = 166.87 cps / float64\n",
    "# 8m38s = 478s = 106295c/?s = 222.37 cps / float32\n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 750, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:52:18.010581Z",
     "start_time": "2019-08-06T09:44:17.438110Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 09:44:17\n",
      "\tVM used vs. available: 21.11GB vs. 142.86GB\n",
      "Generating samples... @ 09:44:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    8.1s remaining:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    8.8s remaining:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   10.0s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 09:44:41\n",
      "Splitting contexts into batches ... @ 09:44:42\n",
      "Num batches = 126\n",
      "Processing batches... @ 09:44:42\n",
      "\tVM used vs. available: 21.11GB vs. 142.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 126 | elapsed:  5.6min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 126 | elapsed:  6.4min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 126 | elapsed:  7.0min remaining:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 126 out of 126 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 09:52:17\n",
      "\tVM used vs. available: 21.11GB vs. 142.86GB\n"
     ]
    }
   ],
   "source": [
    "#batch size 850, quine, parallel\n",
    "# 21s on sample generation, 1s to split into batches of contexts\n",
    "# 10m46s = 646s = 106295c/646s = 164.54 cps / float64\n",
    "# 8m1s = 481s = 106295c/481s = 220.99 cps / float32\n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 850, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:10.969758Z",
     "start_time": "2019-08-11T05:11:10.649455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        9.4G         20G         14M        1.7G         21G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# batch size 1000, quine, parallel\n",
    "# 30s sample generation\n",
    "# peak memory usage is too high\n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 1000, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T08:19:16.759632Z",
     "start_time": "2019-08-06T08:19:16.720786Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'denominator_calc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a007a830483c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   = about ? as fast as ? processing with batch size ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# cpu utilization is ? per core but ? ? full utilization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcont_Z_prime_ALL_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenominator_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_CM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_Q_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'denominator_calc' is not defined"
     ]
    }
   ],
   "source": [
    "#batch size 100, quine, parallel\n",
    "# ?s on sample generation, 1s to split into batches of contexts\n",
    "# ?m?s = ?s = 106295c/?s = ?.? cps\n",
    "# ?s per batch, ? batches ≈?s to do ≈10^5c = ≈? cps\n",
    "#   = about ? as fast as ? processing with batch size ?\n",
    "# cpu utilization is ? per core but ? ? full utilization\n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 100, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T21:20:03.223368Z",
     "start_time": "2019-08-04T21:16:00.673038Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating samples... @ 21:16:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    8.1s remaining:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    9.2s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    9.8s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 21:16:30\n",
      "Splitting contexts into batches ... @ 21:16:31\n",
      "Num batches = 107\n",
      "Processing batches... @ 21:16:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  2.7min\n",
      "Process ForkPoolWorker-591:\n",
      "Process ForkPoolWorker-595:\n",
      "Process ForkPoolWorker-590:\n",
      "Process ForkPoolWorker-584:\n",
      "Process ForkPoolWorker-580:\n",
      "Process ForkPoolWorker-585:\n",
      "Process ForkPoolWorker-583:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-581:\n",
      "Process ForkPoolWorker-582:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-588:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "Process ForkPoolWorker-586:\n",
      "Process ForkPoolWorker-587:\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-589:\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 147, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-579:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\", line 149, in get\n",
      "    return recv()\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "  File \"/home/AD/emeinhar/anaconda3/envs/anvil/lib/python3.6/site-packages/torch/storage.py\", line 125, in _load_from_bytes\n",
      "    def _load_from_bytes(b):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-650d61ac2888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 30s sample generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcont_Z_prime_ALL_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenominator_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_CM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_Q_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-439-169d631102fc>\u001b[0m in \u001b[0;36mdenominator_calc\u001b[0;34m(CM, m, Q_l, target_contexts_per_batch, parallel)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         Z_prime_ALL = torch.cat(list( par(delayed(denominator_batch_process)(Y_prime_ALL_split_batched_batch, Q_l, indices)\n\u001b[0;32m---> 76\u001b[0;31m                                       for Y_prime_ALL_split_batched_batch, indices in zip(Y_prime_ALL_split_batched, Y_prime_ALL_split_batched_indices)) ))\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         Z_prime_ALL = torch.cat((denominator_batch_process(Y_prime_ALL_split_batched_batch, Q_l, indices)\n",
      "\u001b[0;32m<ipython-input-18-501a20251bb0>\u001b[0m in \u001b[0;36mpar\u001b[0;34m(gen_expr)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBACKEND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREFER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmappingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining task handler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mtask_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining result handler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch size 1000, quine, parallel\n",
    "# 30s sample generation\n",
    "# peak memory usage is too high\n",
    "# cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 1000, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T21:29:39.804338Z",
     "start_time": "2019-08-04T21:23:27.784Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#batch size 50, quine, parallel\n",
    "# 30s sample generation\n",
    "# \n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 50, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T21:29:39.798857Z",
     "start_time": "2019-08-04T21:23:08.957810Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating samples... @ 21:23:08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    6.7s remaining:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    7.4s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    8.2s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 21:23:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 21:23:34\n",
      "Num batches = 54\n",
      "Processing batches... @ 21:23:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 10/54 [05:37<24:36, 33.56s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-444-f615f5b16cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 30s sample generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcont_Z_prime_ALL_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenominator_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_CM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_Q_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-443-640f59e1b8c0>\u001b[0m in \u001b[0;36mdenominator_calc\u001b[0;34m(CM, m, Q_l, target_contexts_per_batch, parallel)\u001b[0m\n\u001b[1;32m     80\u001b[0m                                  for Y_prime_ALL_split_batched_batch, indices in tqdm(zip(Y_prime_ALL_split_batched,\n\u001b[1;32m     81\u001b[0m                                                                                           Y_prime_ALL_split_batched_indices),\n\u001b[0;32m---> 82\u001b[0;31m                                                                                       total=num_batches)]) \n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mstampedNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batches processed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mZ_prime_ALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-443-640f59e1b8c0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         Z_prime_ALL = torch.cat([denominator_batch_process(Y_prime_ALL_split_batched_batch, Q_l, indices)\n\u001b[0;32m---> 80\u001b[0;31m                                  for Y_prime_ALL_split_batched_batch, indices in tqdm(zip(Y_prime_ALL_split_batched,\n\u001b[0m\u001b[1;32m     81\u001b[0m                                                                                           Y_prime_ALL_split_batched_indices),\n\u001b[1;32m     82\u001b[0m                                                                                       total=num_batches)]) \n",
      "\u001b[0;32m<ipython-input-443-640f59e1b8c0>\u001b[0m in \u001b[0;36mdenominator_batch_process\u001b[0;34m(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstampedNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tM_prime...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# :: (c/b, m, n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mM_prime_ALL_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_prime_ALL_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mV_prime_ALL_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch size 2000, quine, serial\n",
    "# 30s sample generation\n",
    "# 34s/batch -> 54 batches = 1836s = 106295c/1836s = 57.90 cps\n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 2000, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T08:19:16.765164Z",
     "start_time": "2019-08-06T08:19:16.628Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#batch size 5000, quine, serial\n",
    "# 17s sample generation (?????)\n",
    "# mem usage beforehand ≈16GB\n",
    "# each batch initially requires ≈+70GB \n",
    "# 53m30s = 3810s -> 106295c/3810s = 27.90 cps\n",
    "cont_Z_prime_ALL_p = denominator_calc(cont_CM, 50, cont_Q_l, 5000, parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact/full wordform-length variant functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variant versions of the functions from section 5.2 are used for Case 3 calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:11.470837Z",
     "start_time": "2019-08-11T05:11:10.975554Z"
    }
   },
   "outputs": [],
   "source": [
    "def w_l_idx_to_w_idx(l, w_l_idx):\n",
    "    w = Ws_l_t[l][w_l_idx]\n",
    "    w_idx = Ws_t.index(w)\n",
    "    return w_idx\n",
    "\n",
    "l_to_w_idxs = {l:torch.tensor([w_l_idx_to_w_idx(l, w_l_idx)\n",
    "                               for w_l_idx in torch.arange(len(Ws_l_t[l]))]).type(torch.long)\n",
    "               for l in wordlengthsInclEdges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:11.474660Z",
     "start_time": "2019-08-11T05:11:11.471943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  35, 2283, 4298, 7418, 7724])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_to_w_idxs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:11.675620Z",
     "start_time": "2019-08-11T05:11:11.475547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9172, 106295])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pW_C_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:11.817906Z",
     "start_time": "2019-08-11T05:11:11.680449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5595e-02, 1.9239e-06, 3.3584e-06, 5.0495e-08, 1.6083e-02])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pW_C_torch[l_to_w_idxs[4],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:11.905764Z",
     "start_time": "2019-08-11T05:11:11.822396Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pW_t_l(l, c_idx):\n",
    "    return pW_C_torch[l_to_w_idxs[l], c_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.005537Z",
     "start_time": "2019-08-11T05:11:11.910570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4, 0)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w_idx_to_l_w_l_idx(w_idx):\n",
    "    w = Ws_t[w_idx]\n",
    "    w_t = ds2t(w)\n",
    "    l = len(w_t)\n",
    "    w_l_idx = Ws_l_t[l].index(w)\n",
    "    return (l, w_l_idx)\n",
    "\n",
    "w_l_idx_to_w_idx(4, 0)\n",
    "w_idx_to_l_w_l_idx(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.097777Z",
     "start_time": "2019-08-11T05:11:12.010495Z"
    }
   },
   "outputs": [],
   "source": [
    "def pXhat0fX0f_pxt(xhat0f_idx, x0f_CM, c_idx, m = 50):\n",
    "    '''\n",
    "    If ⋊ x_0 x_1 ... x_i x_k denotes\n",
    "    the produced prefix r of the speaker's intended wordform w,\n",
    "     where\n",
    "       x_i = the last fully produced segment\n",
    "       k = i+1\n",
    "       x_k = the next segment\n",
    "       |⋊ x_0 x_1 ... x_i x_k| = l + 2\n",
    "       l = i+1 = the length of the produced prefix (not incl. \n",
    "                 the left word edge or the next segment)\n",
    "    and this function concerns the special case where always\n",
    "    i = f wrt the source sequence.\n",
    "    \n",
    "    then\n",
    "\n",
    "    x0f_CM :: (|Y1|, l) is the associated l-length stack of size |Y1| vectors\n",
    "     where x0f_CM[:,j] is the distribution p(Y_j|X0^f has been produced)\n",
    "\n",
    "    xhat0f_idx is the index of a wordform w' s.t. \n",
    "        pXhat0fX0f_pxt(xhat0f_idx, x0f_CM) ≈ p(w'|w)\n",
    "    '''\n",
    "    shape_info = False\n",
    "#     pW = get_pW_t_l(l, c_idx)\n",
    "#     if x0k_CM is None and x0k is None:\n",
    "#         raise Exception('Must specify one of x0k_CM or x0k.')\n",
    "\n",
    "    # Computation proceeds in two steps:\n",
    "    # calculate the denominator p(y0i) for m = 50 sampled y0i's\n",
    "    # calculate the numerator p(y0i|w')p(w') for m = 50 sampled y0i's\n",
    "\n",
    "    if xhat0f_idx not in l_to_w_idxs[x0f_CM.shape[1]+2]:\n",
    "        return torch.tensor([0.]) # <<<< this is one of the non-cosmetic (variable-renaming) differences from the main version of this function\n",
    "\n",
    "    L, xhat0f_l_idx = w_idx_to_l_w_l_idx(xhat0f_idx) # L = l+2\n",
    "\n",
    "#     xhat0f_idx = Wmap[xhat0f]\n",
    "\n",
    "#     l = len(ds2t(x0i))\n",
    "#     x0k_CM = CMsByPrefixIndex[prefixMap[x0i]]\n",
    "\n",
    "#     my_Q_l = CMsByLengthByWordformIndex[l - 2]\n",
    "\n",
    "    #Collect m samples from p(Y0i|X0k) = p(Y0i|r), \n",
    "    # where each sample is an l-length stack of one-hot vectors\n",
    "    # where each one-hot vector corresponds to a channel symbol:\n",
    "    Y_prime = depthSamplerC_t(x0f_CM, m)#.float() #:: (m, l, |Y1|)\n",
    "#         if x0k_CM is not None:\n",
    "#             Y_prime = depthSampler2a_t(x0k_CM, m)#.float() #:: (m, l, |Y1|)\n",
    "#             if x0k is not None:\n",
    "# #                 print('foo')\n",
    "#                 print(type(x0k_CM))\n",
    "#                 print(x0k_CM.shape)\n",
    "#                 generated_CM = sample_pY0iX0k(x0k, debug=True)[1]\n",
    "#                 print(type(generated_CM))\n",
    "#                 print(generated_CM.shape)\n",
    "#                 generated_CM_t = torch.tensor(generated_CM)\n",
    "#                 assert torch.allclose(x0k_CM, torch.tensor(sample_pY0iX0k(x0k, debug=True)[1]))\n",
    "# #                 print('bar')\n",
    "#         else:\n",
    "#             Y_prime = torch.tensor(list(map(y0kOHmap, [sample_pY0iX0k(x0k) for each in range(m)])))\n",
    "#         print('baz')\n",
    "    l = Y_prime.shape[1]# + 1\n",
    "    if shape_info:\n",
    "        print(f'|Y_prime| = {Y_prime.shape} = (m, l, |Y1|)')\n",
    "        \n",
    "    pW = get_pW_t_l(L, c_idx) # (|W_l| = n_L) # <<<< this is one of the non-cosmetic (variable-renaming) differences from the main version of this function\n",
    "    \n",
    "    #Grab ALL the relevant-prefix-length channel matrices \n",
    "    # for every segmental wordform in the lexicon:\n",
    "#         my_Q_l = CMsByLengthByWordformIndex_torch[l - 3]#.float()\n",
    "#         my_Q_l = CMsByLengthByWordformIndex_torch[l - 1]#.float() #:: (|W_l|, |Y1|, l)\n",
    "    my_Q_l = exactCMsByLengthByWordformIndex_torch[l+2]#.float() #:: (|W_l|, |Y1|, l) # <<<< this is one of the non-cosmetic (variable-renaming) differences from the main version of this function\n",
    "\n",
    "    if shape_info:\n",
    "        print(f'|Q_l| = {my_Q_l.shape} = (|W_l| = n_L, |Y1|, l)')\n",
    "\n",
    "#         print(f'{Y_prime.dtype}, {my_Q_l.dtype}')\n",
    "\n",
    "    # NORMALIZATION\n",
    "    V_prime = torch.einsum('mli,kil->mkl', Y_prime.type(my_tt), my_Q_l)  # :: (m,n_L,l)\n",
    "#         print(f\"|V'| = {V_prime.shape} = (m, n_L, l)\")\n",
    "    M_prime = torch.prod(V_prime, 2) # :: (m,n_L)\n",
    "#         print(f\"|M'| = {M_prime.shape} = (m, n_l)\")\n",
    "#         N_prime = torch.matmul(M_prime, pX0f_torch) # :: (m, ) <- prior probabilities of each of the m sampled channel prefixes\n",
    "    N_prime = torch.matmul(M_prime, pW)\n",
    "#         print(f\"|N'| = {N_prime.shape} = (m, )\")\n",
    "#     Z_prime = 1.0 / N_prime # :: (m, )\n",
    "    Z_prime = torch.ones(N_prime.shape, dtype=my_tt)\n",
    "    torch.div(Z_prime,\n",
    "              N_prime,\n",
    "              out=Z_prime)\n",
    "#         print(f\"|Z'| = {Z_prime.shape} = (m, )\")\n",
    "    if shape_info:\n",
    "        print(f\"|V'| = {V_prime.shape} = (m, n_L, l)\")\n",
    "        print(f\"|M'| = {M_prime.shape} = (m, n_L)\")\n",
    "        print(f\"|N'| = {N_prime.shape} = (m, )\")\n",
    "        print(f\"|Z'| = {Z_prime.shape} = (m, )\")\n",
    "\n",
    "    # NUMERATOR\n",
    "    L_w = my_Q_l[xhat0f_l_idx]#.float()\n",
    "#     L_w = my_Q_l[xhat0f_idx]#.float()\n",
    "    V_prime_w = torch.einsum('mij,ji->mi',Y_prime.type(my_tt), L_w)\n",
    "#         print(f\"|V'_w| = {V_prime_w.shape} = (m, l)\")\n",
    "    O_w = torch.prod(V_prime_w, 1) # :: (m,) likelihoods of each of the m sampled channel prefixes\n",
    "#         print(f\"|O_w| = {O_w.shape} = (m, )\")\n",
    "#         U_w = pX0f_torch[xhat0f_idx] * O_w ## :: (m,) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "    U_w = pW[xhat0f_l_idx] * O_w ## :: (m,) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "#     U_w = pW[xhat0f_idx] * O_w ## :: (m,) joint probabilities of xhat0f with each of the m sampled channel prefixes\n",
    "#         print(f\"|U_w| = {U_w.shape} = (m, )\")\n",
    "    if shape_info:\n",
    "        print(f\"|V'_w| = {V_prime_w.shape} = (m, l)\")\n",
    "        print(f\"|O_w| = {O_w.shape} = (m, )\")\n",
    "        print(f\"|U_w| = {U_w.shape} = (m, )\")\n",
    "\n",
    "\n",
    "    if shape_info:\n",
    "        E = torch.dot(Z_prime, U_w) / m\n",
    "        print(f\"|E| = scalar: type(E) = {type(E)}\")\n",
    "    return torch.dot(Z_prime, U_w) / m\n",
    "\n",
    "def pXhat0fX0f_pxtn(xhat0f_idx, x0f_CM, c_idx, m = 50):\n",
    "    return pXhat0fX0f_pxt(xhat0f_idx, x0f_CM, c_idx, m = 50).numpy()\n",
    "\n",
    "def wordformTox0fCM(w=None, w_idx=None):\n",
    "#     if w is None and w_idx is None and w_l_idx is None:\n",
    "#         raise Exception('At least one argument must be specified.')\n",
    "    if w is not None:\n",
    "        w_t = ds2t(w)\n",
    "        w_idx = Ws_t.index(w)\n",
    "    else:\n",
    "        w = Ws_t[w_idx]\n",
    "        w_t = ds2t(w)\n",
    "    \n",
    "    total_x0f_length = len(w_t) #includes both edge symbols\n",
    "#     word_length_noLE = total_x0f_length - 1 #still includes right edge symbol = \"upcoming segment\"\n",
    "#     word_length_noRE = word_length_noLE - 1\n",
    "#     offset = 2\n",
    "#     assert word_length_produced_so_far - offset >= 0 , f\"{word_length_produced_so_far} - {offset} < 0; w = {w}\"\n",
    "#     assert word_length_produced_so_far - offset < len(CMsByLengthByWordformIndex_torch), f\"{word_length_produced_so_far} - {offset} >= {len(CMsByLengthByWordformIndex_torch)}; w = {w}\"\n",
    "#     assert w_idx in range(CMsByLengthByWordformIndex_torch[word_length_produced_so_far - offset].shape[0]), f\"{w_idx}; w = {w}\"\n",
    "#     x0f_cm = CMsByLengthByWordformIndex_torch[word_length_produced_so_far - offset][w_idx]\n",
    "    w_l_idx = Ws_l_t[total_x0f_length].index(w)\n",
    "    x0f_cm = exactCMsByLengthByWordformIndex_torch[total_x0f_length][w_l_idx]\n",
    "    return x0f_cm\n",
    "\n",
    "# for convenience\n",
    "def pXhat0fX0f_pxtn_conv(w_hat, w, c, m = 50):\n",
    "    w_idx = Ws_t.index(w_hat)\n",
    "\n",
    "#     r_idx = Ps_t.index(r)\n",
    "    source_wf = list(wordsWithPrefix(w, Ws))[0]\n",
    "    source_wf_idx = Ws_t.index(source_wf)\n",
    "    \n",
    "    total_x0f_length = len(ds2t(w))# includes left edge symbol + upcoming segment\n",
    "#     prefix_length_noWE = total_x0k_length - 1 #includes upcoming segment\n",
    "#     prefix_length_produced_so_far = prefix_length_noWE - 1\n",
    "#     offset = 1\n",
    "#     x0k_cm = CMsByLengthByWordformIndex_torch[prefix_length_produced_so_far - offset][source_wf_idx]\n",
    "    w_l_idx = Ws_l_t[total_x0f_length].index(w)\n",
    "    x0f_cm = exactCMsByLengthByWordformIndex_torch[total_x0f_length][w_l_idx]\n",
    "    \n",
    "    c_idx = Cs_t.index(c)\n",
    "    \n",
    "    return pXhat0fX0f_pxtn(w_idx, x0f_cm, c_idx, m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.215658Z",
     "start_time": "2019-08-11T05:11:12.099653Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    phatXhat0fX0k_baseline('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉',\n",
    "                           '⋊.k.ɑ.n.t.æ.k.t.⋉.⋉',\n",
    "                           'a couple of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.314209Z",
     "start_time": "2019-08-11T05:11:12.220206Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'),\n",
    "                   CMsByLengthByWordformIndex_torch[5][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')],\n",
    "                   Cs_t.index('a couple of'),\n",
    "                   m = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.404388Z",
     "start_time": "2019-08-11T05:11:12.318892Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'),\n",
    "                   CMsByLengthByWordformIndex_torch[9][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')],\n",
    "                   Cs_t.index('a couple of'),\n",
    "                   m = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.740421Z",
     "start_time": "2019-08-11T05:11:12.406984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        9.4G         20G         14M        1.7G         21G\r\n",
      "Swap:          2.0G        1.3G        723M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.755623Z",
     "start_time": "2019-08-11T05:11:12.746370Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'),\n",
    "                   CMsByLengthByWordformIndex_torch[10][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')],\n",
    "                   Cs_t.index('a couple of'),\n",
    "                   m = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:12.928276Z",
     "start_time": "2019-08-11T05:11:12.759079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlengthsInclEdges\n",
    "len(wordlengthsInclEdges)\n",
    "len([None for each in range(min(wordlengthsInclEdges))])\n",
    "len(exactCMsByLengthByWordformIndex_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.049698Z",
     "start_time": "2019-08-11T05:11:12.932901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1052, 39, 8])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 8])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0439, 0.0181, 0.0091, 0.0090, 0.2037, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0137, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0255, 0.0072, 0.0091, 0.0090, 0.0188, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0071, 0.0090, 0.0171, 0.0074, 0.0092, 0.0108, 0.0000],\n",
       "        [0.0068, 0.0069, 0.0170, 0.0087, 0.0072, 0.0090, 0.0105, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0710, 0.0351, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0070, 0.0089, 0.0088, 0.0073, 0.0091, 0.0108, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0075, 0.0178, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0090, 0.0089, 0.0074, 0.0176, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0052, 0.0062, 0.0078, 0.0077, 0.0064, 0.0080, 0.0111, 0.0000],\n",
       "        [0.6525, 0.0071, 0.0090, 0.0089, 0.0074, 0.5897, 0.0403, 0.0000],\n",
       "        [0.0255, 0.0072, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0071, 0.0090, 0.0089, 0.0074, 0.0092, 0.0108, 0.0000],\n",
       "        [0.0070, 0.0072, 0.6450, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0137, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0071, 0.0090, 0.0089, 0.0074, 0.0092, 0.0108, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0090, 0.0089, 0.0074, 0.0092, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.6638, 0.0075, 0.0093, 0.5665, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0090, 0.0089, 0.0074, 0.0092, 0.0111, 0.0000],\n",
       "        [0.0066, 0.0070, 0.0089, 0.0088, 0.0073, 0.0091, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0070, 0.0089, 0.0088, 0.0073, 0.0091, 0.0108, 0.0000],\n",
       "        [0.0070, 0.0181, 0.0091, 0.0090, 0.2893, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0069, 0.0088, 0.0087, 0.0072, 0.0090, 0.0105, 0.0000],\n",
       "        [0.0070, 0.0062, 0.0149, 0.0077, 0.0064, 0.0080, 0.0082, 0.0000],\n",
       "        [0.0070, 0.5957, 0.0091, 0.0090, 0.1543, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0071, 0.0090, 0.0089, 0.0074, 0.0092, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0143, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0143, 0.0234, 0.0111, 0.0000],\n",
       "        [0.0070, 0.0137, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0069, 0.0088, 0.0087, 0.0072, 0.0090, 0.0105, 0.0000],\n",
       "        [0.0070, 0.0072, 0.0091, 0.0090, 0.0075, 0.0093, 0.0111, 0.0000],\n",
       "        [0.0255, 0.1079, 0.0174, 0.0090, 0.0143, 0.0234, 0.0111, 0.0000],\n",
       "        [0.0068, 0.0070, 0.0089, 0.0088, 0.0073, 0.0091, 0.0108, 0.0000],\n",
       "        [0.0070, 0.0071, 0.0090, 0.0089, 0.0074, 0.0092, 0.0108, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exactCMsByLengthByWordformIndex_torch[10].shape\n",
    "exactCMsByLengthByWordformIndex_torch[10][Ws_l_t[10].index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')].shape\n",
    "exactCMsByLengthByWordformIndex_torch[10][Ws_l_t[10].index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.129506Z",
     "start_time": "2019-08-11T05:11:13.054247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.222618Z",
     "start_time": "2019-08-11T05:11:13.130516Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit pXhat0fX0i_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), exactCMsByLengthByWordformIndex_torch[10][Ws_l_t[10].index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], Cs_t.index('a couple of'), m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.314355Z",
     "start_time": "2019-08-11T05:11:13.227342Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    %timeit pXhat0fX0f_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'), exactCMsByLengthByWordformIndex_torch[10][Ws_l_t[10].index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], Cs_t.index('a couple of'), m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.439788Z",
     "start_time": "2019-08-11T05:11:13.319105Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    len(ds2t('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')) - 2\n",
    "    pXhat0fX0f_pxt(Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉'),\n",
    "                   exactCMsByLengthByWordformIndex_torch[10][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')],\n",
    "                   Cs_t.index('a couple of'),\n",
    "                   m = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.574025Z",
     "start_time": "2019-08-11T05:11:13.444390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(exactCMsByLengthByWordformIndex_torch[10][Ws_l_t[10].index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')], \n",
    "            CMsByLengthByWordformIndex_torch[10][Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:13.692224Z",
     "start_time": "2019-08-11T05:11:13.578740Z"
    }
   },
   "outputs": [],
   "source": [
    "n_test_cases = 1000\n",
    "random_wordform_idxs = choices(list(range(len(Ws_t))), k=n_test_cases)\n",
    "random_context_idxs = choices(list(range(len(Cs_t))), k=n_test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:23.932590Z",
     "start_time": "2019-08-11T05:11:13.696183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1 ms ± 765 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 10\n",
    "\n",
    "rand_w_idx = choice(random_wordform_idxs)\n",
    "rand_c_idx = choice(random_context_idxs)\n",
    "\n",
    "# 10.5ms on kotoba\n",
    "pXhat0fX0i_pxt(rand_w_idx, wordformTox0fCM(w_idx=rand_w_idx), rand_c_idx, m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:26.766044Z",
     "start_time": "2019-08-11T05:11:23.933713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83 ms ± 119 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 10\n",
    "\n",
    "rand_w_idx = choice(random_wordform_idxs)\n",
    "rand_c_idx = choice(random_context_idxs)\n",
    "\n",
    "# ≈130-150ms on new sidious (pre-sampling+Z_prime change)\n",
    "# ≈132ms on quine\n",
    "# prev 10.9ms on kotoba\n",
    "# 2.75ms on kotoba\n",
    "pXhat0fX0f_pxt(rand_w_idx, wordformTox0fCM(w_idx=rand_w_idx), rand_c_idx, m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:29.692255Z",
     "start_time": "2019-08-11T05:11:26.767110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.92 ms ± 104 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 10\n",
    "\n",
    "rand_w_idx = choice(random_wordform_idxs)\n",
    "rand_c_idx = choice(random_context_idxs)\n",
    "\n",
    "# ≈130-150ms on new sidious (pre-sampling+Z_prime change)\n",
    "# ≈132ms on quine\n",
    "# prev 10.9ms on kotoba\n",
    "# 2.65ms on kotoba\n",
    "pXhat0fX0f_pxt(rand_w_idx, wordformTox0fCM(w_idx=rand_w_idx), rand_c_idx, m = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:11:29.694873Z",
     "start_time": "2019-08-11T05:11:29.693203Z"
    }
   },
   "outputs": [],
   "source": [
    "del random_wordform_idxs\n",
    "del random_context_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:50:11.844446Z",
     "start_time": "2019-08-11T05:50:11.785755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 5,\n",
       " 5: 173,\n",
       " 6: 1266,\n",
       " 7: 1790,\n",
       " 8: 1646,\n",
       " 9: 1328,\n",
       " 10: 1052,\n",
       " 11: 828,\n",
       " 12: 508,\n",
       " 13: 329,\n",
       " 14: 150,\n",
       " 15: 66,\n",
       " 16: 24,\n",
       " 17: 6,\n",
       " 19: 1}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exactLengthFreqs = {l:len({w for w in Ws_t if len(ds2t(w)) == l})\n",
    "                    for l in wordlengthsInclEdges}\n",
    "exactLengthFreqs\n",
    "mostFreq_length_freq = max(exactLengthFreqs.values())\n",
    "mostFreq_length = [l for l in wordlengthsInclEdges if exactLengthFreqs[l] == mostFreq_length_freq]\n",
    "mostFreq_length\n",
    "mostFreq_length = mostFreq_length[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:12:01.238246Z",
     "start_time": "2019-08-11T05:11:29.903746Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 22:11:29\n",
      "l = 17\n",
      "Sampling... @ 22:11:29\n",
      "\tVM used vs. available: 10.08GB vs. 23.13GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 22:11:40\n",
      "\tVM used vs. available: 13.67GB vs. 19.54GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 22:11:42\n",
      "Num batches = 304\n",
      "Processing batches... @ 22:11:42\n",
      "\tVM used vs. available: 17.20GB vs. 16.01GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [00:10<00:00, 30.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 22:11:52\n",
      "\tVM used vs. available: 17.20GB vs. 16.02GB\n",
      "Calculating numerator... @ 22:11:52\n",
      "\tVM used vs. available: 17.20GB vs. 16.02GB\n",
      "Calculating V_prime_w_C... @ 22:11:52\n",
      "Calculating O_w_C... @ 22:12:01\n",
      "Calculating U_w_C... @ 22:12:01\n",
      "Calculating E_w_C... @ 22:12:01\n",
      "\tVM used vs. available: 17.56GB vs. 15.65GB\n",
      "> End calculation. @ 22:12:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are infinities even when n_l is exactly 1 and batch sizes are fairly small...\n",
    "len(ds2t(random_long_word))\n",
    "rlw_slice_x = pXhat0fX0i_ptc(rlw_idx, CMsByLengthByWordformIndex_torch[len(ds2t(random_long_word))][rlw_idx],\n",
    "                             m=n, target_contexts_per_batch=350, parallel=l, use_gpu=g, exact_wf=True)\n",
    "rlw_slice_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:12:01.240831Z",
     "start_time": "2019-08-11T05:12:01.239316Z"
    }
   },
   "outputs": [],
   "source": [
    "# pick a word of length 7, check if you get infinities at various batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T06:51:46.821706Z",
     "start_time": "2019-08-11T06:51:46.816114Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T06:53:35.045232Z",
     "start_time": "2019-08-11T06:53:34.906522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: '⋊.aɪ.⋉.⋉',\n",
       " 8: '⋊.n.ɛ.k.s.t.⋉.⋉',\n",
       " 12: '⋊.æ.k.tʃ.u.æ.l.ɪ.t.i.⋉.⋉',\n",
       " 16: '⋊.m.ə.t.ɪ.ɹ.i.ə.l.ɪ.s.t.ɪ.k.⋉.⋉',\n",
       " 19: '⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉'}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if benchmark:\n",
    "    wlr_n = np.array(sorted(list(wordlengthsInclEdges)))\n",
    "    benchmark_lengths = torch.tensor(list(wlr_n[ np.where(wlr_n % 4 == 0)[0]  ]) + [sorted(list(wordlengthsInclEdges))[-2]] + [max(wordlengthsInclEdges)])\n",
    "    benchmark_wordform_idxs = tuple([Ws_t.index(choice(list(wordformsOfLength(l, Ws_t, True))))\n",
    "                                     for l in benchmark_lengths])\n",
    "    benchmark_wordforms = tuple([Ws_t[w_idx] for w_idx in benchmark_wordform_idxs])\n",
    "    dict(zip(list(map(lambda t: t.item(), benchmark_lengths)), \n",
    "             benchmark_wordforms))\n",
    "    benchmark_CMs = tuple([exactCMsByLengthByWordformIndex_torch[len(ds2t(w))][w_idx_to_l_w_l_idx(Ws_t.index(w))[1]]\n",
    "                           for w in benchmark_wordforms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T07:37:13.750093Z",
     "start_time": "2019-08-11T06:54:08.818321Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch size: 50\n",
      "## L=4, b=50, |W_L| = 5 @ 23:54:08\n",
      "\tVM used vs. available: 8.21GB vs. 25.01GB\n",
      "> Begin calculation. @ 23:54:08\n",
      "l = 2\n",
      "Sampling... @ 23:54:08\n",
      "\tVM used vs. available: 8.21GB vs. 25.01GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.5s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 23:54:12\n",
      "\tVM used vs. available: 8.63GB vs. 24.59GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 23:54:12\n",
      "Num batches = 2126\n",
      "Processing batches... @ 23:54:12\n",
      "\tVM used vs. available: 9.04GB vs. 24.18GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:01<00:00, 62514.93calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 23:54:14\n",
      "\tVM used vs. available: 9.04GB vs. 24.18GB\n",
      "Calculating numerator... @ 23:54:14\n",
      "\tVM used vs. available: 9.04GB vs. 24.18GB\n",
      "Calculating V_prime_w_C... @ 23:54:14\n",
      "Calculating O_w_C... @ 23:54:15\n",
      "Calculating U_w_C... @ 23:54:15\n",
      "Calculating E_w_C... @ 23:54:15\n",
      "\tVM used vs. available: 9.07GB vs. 24.15GB\n",
      "> End calculation. @ 23:54:15\n",
      "\n",
      "## L=8, b=50, |W_L| = 1646 @ 23:54:15\n",
      "\tVM used vs. available: 8.15GB vs. 25.07GB\n",
      "> Begin calculation. @ 23:54:15\n",
      "l = 6\n",
      "Sampling... @ 23:54:15\n",
      "\tVM used vs. available: 8.15GB vs. 25.07GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.1s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 23:54:21\n",
      "\tVM used vs. available: 9.40GB vs. 23.82GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 23:54:21\n",
      "Num batches = 2126\n",
      "Processing batches... @ 23:54:21\n",
      "\tVM used vs. available: 10.64GB vs. 22.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [07:19<00:00, 242.11calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:01:40\n",
      "\tVM used vs. available: 10.71GB vs. 22.50GB\n",
      "Calculating numerator... @ 00:01:40\n",
      "\tVM used vs. available: 10.71GB vs. 22.50GB\n",
      "Calculating V_prime_w_C... @ 00:01:40\n",
      "Calculating O_w_C... @ 00:01:44\n",
      "Calculating U_w_C... @ 00:01:44\n",
      "Calculating E_w_C... @ 00:01:44\n",
      "\tVM used vs. available: 10.89GB vs. 22.32GB\n",
      "> End calculation. @ 00:01:44\n",
      "\n",
      "## L=12, b=50, |W_L| = 508 @ 00:01:44\n",
      "\tVM used vs. available: 8.27GB vs. 24.95GB\n",
      "> Begin calculation. @ 00:01:44\n",
      "l = 10\n",
      "Sampling... @ 00:01:44\n",
      "\tVM used vs. available: 8.27GB vs. 24.95GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.0s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:01:51\n",
      "\tVM used vs. available: 10.35GB vs. 22.87GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:01:52\n",
      "Num batches = 2126\n",
      "Processing batches... @ 00:01:52\n",
      "\tVM used vs. available: 12.42GB vs. 20.79GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [02:16<00:00, 778.68calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:04:09\n",
      "\tVM used vs. available: 12.41GB vs. 20.80GB\n",
      "Calculating numerator... @ 00:04:09\n",
      "\tVM used vs. available: 12.41GB vs. 20.80GB\n",
      "Calculating V_prime_w_C... @ 00:04:09\n",
      "Calculating O_w_C... @ 00:04:14\n",
      "Calculating U_w_C... @ 00:04:14\n",
      "Calculating E_w_C... @ 00:04:14\n",
      "\tVM used vs. available: 12.64GB vs. 20.57GB\n",
      "> End calculation. @ 00:04:14\n",
      "\n",
      "## L=16, b=50, |W_L| = 24 @ 00:04:14\n",
      "\tVM used vs. available: 8.27GB vs. 24.94GB\n",
      "> Begin calculation. @ 00:04:14\n",
      "l = 14\n",
      "Sampling... @ 00:04:14\n",
      "\tVM used vs. available: 8.27GB vs. 24.94GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.7s remaining:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.5s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:04:24\n",
      "\tVM used vs. available: 11.18GB vs. 22.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:04:25\n",
      "Num batches = 2126\n",
      "Processing batches... @ 00:04:25\n",
      "\tVM used vs. available: 14.08GB vs. 19.14GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:07<00:00, 13664.98calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:04:32\n",
      "\tVM used vs. available: 14.08GB vs. 19.14GB\n",
      "Calculating numerator... @ 00:04:32\n",
      "\tVM used vs. available: 14.08GB vs. 19.14GB\n",
      "Calculating V_prime_w_C... @ 00:04:32\n",
      "Calculating O_w_C... @ 00:04:40\n",
      "Calculating U_w_C... @ 00:04:40\n",
      "Calculating E_w_C... @ 00:04:40\n",
      "\tVM used vs. available: 14.38GB vs. 18.84GB\n",
      "> End calculation. @ 00:04:40\n",
      "\n",
      "## L=19, b=50, |W_L| = 1 @ 00:04:40\n",
      "\tVM used vs. available: 8.28GB vs. 24.94GB\n",
      "> Begin calculation. @ 00:04:40\n",
      "l = 17\n",
      "Sampling... @ 00:04:40\n",
      "\tVM used vs. available: 8.28GB vs. 24.94GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.5s remaining:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.6s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.7s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:04:51\n",
      "\tVM used vs. available: 11.80GB vs. 21.41GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:04:52\n",
      "Num batches = 2126\n",
      "Processing batches... @ 00:04:52\n",
      "\tVM used vs. available: 15.32GB vs. 17.89GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:06<00:00, 15322.82calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:04:59\n",
      "\tVM used vs. available: 15.32GB vs. 17.89GB\n",
      "Calculating numerator... @ 00:04:59\n",
      "\tVM used vs. available: 15.32GB vs. 17.89GB\n",
      "Calculating V_prime_w_C... @ 00:04:59\n",
      "Calculating O_w_C... @ 00:05:08\n",
      "Calculating U_w_C... @ 00:05:08\n",
      "Calculating E_w_C... @ 00:05:08\n",
      "\tVM used vs. available: 15.71GB vs. 17.50GB\n",
      "> End calculation. @ 00:05:08\n",
      "\n",
      "## L=19, b=50, |W_L| = 1 @ 00:05:08\n",
      "\tVM used vs. available: 8.28GB vs. 24.94GB\n",
      "> Begin calculation. @ 00:05:08\n",
      "l = 17\n",
      "Sampling... @ 00:05:08\n",
      "\tVM used vs. available: 8.28GB vs. 24.94GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.4s remaining:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.5s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.6s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:05:20\n",
      "\tVM used vs. available: 11.80GB vs. 21.41GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:05:21\n",
      "Num batches = 2126\n",
      "Processing batches... @ 00:05:21\n",
      "\tVM used vs. available: 15.33GB vs. 17.89GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:07<00:00, 15021.55calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:05:28\n",
      "\tVM used vs. available: 15.32GB vs. 17.89GB\n",
      "Calculating numerator... @ 00:05:28\n",
      "\tVM used vs. available: 15.32GB vs. 17.89GB\n",
      "Calculating V_prime_w_C... @ 00:05:28\n",
      "Calculating O_w_C... @ 00:05:37\n",
      "Calculating U_w_C... @ 00:05:37\n",
      "Calculating E_w_C... @ 00:05:37\n",
      "\tVM used vs. available: 15.69GB vs. 17.53GB\n",
      "> End calculation. @ 00:05:37\n",
      "\n",
      "\n",
      "### Batch size: 100\n",
      "## L=4, b=100, |W_L| = 5 @ 00:05:37\n",
      "\tVM used vs. available: 8.28GB vs. 24.93GB\n",
      "> Begin calculation. @ 00:05:37\n",
      "l = 2\n",
      "Sampling... @ 00:05:37\n",
      "\tVM used vs. available: 8.28GB vs. 24.93GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.2s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.7s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:05:41\n",
      "\tVM used vs. available: 8.68GB vs. 24.53GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:05:41\n",
      "Num batches = 1063\n",
      "Processing batches... @ 00:05:41\n",
      "\tVM used vs. available: 9.10GB vs. 24.12GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:01<00:00, 84966.70calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:05:43\n",
      "\tVM used vs. available: 9.09GB vs. 24.12GB\n",
      "Calculating numerator... @ 00:05:43\n",
      "\tVM used vs. available: 9.09GB vs. 24.12GB\n",
      "Calculating V_prime_w_C... @ 00:05:43\n",
      "Calculating O_w_C... @ 00:05:44\n",
      "Calculating U_w_C... @ 00:05:44\n",
      "Calculating E_w_C... @ 00:05:44\n",
      "\tVM used vs. available: 9.12GB vs. 24.09GB\n",
      "> End calculation. @ 00:05:44\n",
      "\n",
      "## L=8, b=100, |W_L| = 1646 @ 00:05:44\n",
      "\tVM used vs. available: 8.29GB vs. 24.93GB\n",
      "> Begin calculation. @ 00:05:44\n",
      "l = 6\n",
      "Sampling... @ 00:05:44\n",
      "\tVM used vs. available: 8.29GB vs. 24.93GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.4s remaining:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.7s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.1s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:05:50\n",
      "\tVM used vs. available: 9.53GB vs. 23.68GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:05:50\n",
      "Num batches = 1063\n",
      "Processing batches... @ 00:05:50\n",
      "\tVM used vs. available: 10.78GB vs. 22.43GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [03:45<00:00, 471.21calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:09:36\n",
      "\tVM used vs. available: 10.79GB vs. 22.36GB\n",
      "Calculating numerator... @ 00:09:36\n",
      "\tVM used vs. available: 10.79GB vs. 22.36GB\n",
      "Calculating V_prime_w_C... @ 00:09:36\n",
      "Calculating O_w_C... @ 00:09:39\n",
      "Calculating U_w_C... @ 00:09:39\n",
      "Calculating E_w_C... @ 00:09:39\n",
      "\tVM used vs. available: 10.93GB vs. 22.22GB\n",
      "> End calculation. @ 00:09:39\n",
      "\n",
      "## L=12, b=100, |W_L| = 508 @ 00:09:39\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:09:39\n",
      "l = 10\n",
      "Sampling... @ 00:09:39\n",
      "\tVM used vs. available: 8.31GB vs. 24.85GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:09:47\n",
      "\tVM used vs. available: 10.39GB vs. 22.77GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:09:47\n",
      "Num batches = 1063\n",
      "Processing batches... @ 00:09:47\n",
      "\tVM used vs. available: 12.46GB vs. 20.70GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [01:10<00:00, 1517.46calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:10:58\n",
      "\tVM used vs. available: 12.46GB vs. 20.70GB\n",
      "Calculating numerator... @ 00:10:58\n",
      "\tVM used vs. available: 12.46GB vs. 20.70GB\n",
      "Calculating V_prime_w_C... @ 00:10:58\n",
      "Calculating O_w_C... @ 00:11:03\n",
      "Calculating U_w_C... @ 00:11:03\n",
      "Calculating E_w_C... @ 00:11:03\n",
      "\tVM used vs. available: 12.69GB vs. 20.47GB\n",
      "> End calculation. @ 00:11:03\n",
      "\n",
      "## L=16, b=100, |W_L| = 24 @ 00:11:03\n",
      "\tVM used vs. available: 8.31GB vs. 24.85GB\n",
      "> Begin calculation. @ 00:11:03\n",
      "l = 14\n",
      "Sampling... @ 00:11:03\n",
      "\tVM used vs. available: 8.31GB vs. 24.85GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.8s remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.7s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:11:13\n",
      "\tVM used vs. available: 11.22GB vs. 21.94GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:11:14\n",
      "Num batches = 1063\n",
      "Processing batches... @ 00:11:14\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:06<00:00, 15787.97calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:11:20\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating numerator... @ 00:11:20\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating V_prime_w_C... @ 00:11:20\n",
      "Calculating O_w_C... @ 00:11:28\n",
      "Calculating U_w_C... @ 00:11:28\n",
      "Calculating E_w_C... @ 00:11:28\n",
      "\tVM used vs. available: 14.44GB vs. 18.71GB\n",
      "> End calculation. @ 00:11:28\n",
      "\n",
      "## L=19, b=100, |W_L| = 1 @ 00:11:28\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:11:28\n",
      "l = 17\n",
      "Sampling... @ 00:11:28\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.9s remaining:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    7.0s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    8.1s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:11:40\n",
      "\tVM used vs. available: 11.77GB vs. 21.38GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:11:41\n",
      "Num batches = 1063\n",
      "Processing batches... @ 00:11:41\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:06<00:00, 15202.83calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:11:48\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Calculating numerator... @ 00:11:48\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Calculating V_prime_w_C... @ 00:11:48\n",
      "Calculating O_w_C... @ 00:11:57\n",
      "Calculating U_w_C... @ 00:11:57\n",
      "Calculating E_w_C... @ 00:11:57\n",
      "\tVM used vs. available: 15.71GB vs. 17.45GB\n",
      "> End calculation. @ 00:11:57\n",
      "\n",
      "## L=19, b=100, |W_L| = 1 @ 00:11:57\n",
      "\tVM used vs. available: 8.29GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:11:57\n",
      "l = 17\n",
      "Sampling... @ 00:11:57\n",
      "\tVM used vs. available: 8.29GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:12:08\n",
      "\tVM used vs. available: 11.82GB vs. 21.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106300 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:12:09\n",
      "Num batches = 1063\n",
      "Processing batches... @ 00:12:09\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106300/106300 [00:06<00:00, 15481.46calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:12:16\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:12:16\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:12:16\n",
      "Calculating O_w_C... @ 00:12:25\n",
      "Calculating U_w_C... @ 00:12:25\n",
      "Calculating E_w_C... @ 00:12:25\n",
      "\tVM used vs. available: 15.71GB vs. 17.45GB\n",
      "> End calculation. @ 00:12:25\n",
      "\n",
      "\n",
      "### Batch size: 200\n",
      "## L=4, b=200, |W_L| = 5 @ 00:12:25\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:12:25\n",
      "l = 2\n",
      "Sampling... @ 00:12:25\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.5s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.7s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:12:29\n",
      "\tVM used vs. available: 8.70GB vs. 24.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106400 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:12:29\n",
      "Num batches = 532\n",
      "Processing batches... @ 00:12:29\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106400/106400 [00:01<00:00, 102153.37calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:12:30\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating numerator... @ 00:12:30\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating V_prime_w_C... @ 00:12:30\n",
      "Calculating O_w_C... @ 00:12:31\n",
      "Calculating U_w_C... @ 00:12:31\n",
      "Calculating E_w_C... @ 00:12:31\n",
      "\tVM used vs. available: 9.16GB vs. 23.99GB\n",
      "> End calculation. @ 00:12:31\n",
      "\n",
      "## L=8, b=200, |W_L| = 1646 @ 00:12:31\n",
      "\tVM used vs. available: 8.25GB vs. 24.91GB\n",
      "> Begin calculation. @ 00:12:31\n",
      "l = 6\n",
      "Sampling... @ 00:12:31\n",
      "\tVM used vs. available: 8.24GB vs. 24.91GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:12:37\n",
      "\tVM used vs. available: 9.49GB vs. 23.66GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106400 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:12:38\n",
      "Num batches = 532\n",
      "Processing batches... @ 00:12:38\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106400/106400 [01:54<00:00, 928.04calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:14:32\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n",
      "Calculating numerator... @ 00:14:32\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n",
      "Calculating V_prime_w_C... @ 00:14:32\n",
      "Calculating O_w_C... @ 00:14:35\n",
      "Calculating U_w_C... @ 00:14:35\n",
      "Calculating E_w_C... @ 00:14:35\n",
      "\tVM used vs. available: 10.91GB vs. 22.24GB\n",
      "> End calculation. @ 00:14:35\n",
      "\n",
      "## L=12, b=200, |W_L| = 508 @ 00:14:35\n",
      "\tVM used vs. available: 8.29GB vs. 24.87GB\n",
      "> Begin calculation. @ 00:14:35\n",
      "l = 10\n",
      "Sampling... @ 00:14:35\n",
      "\tVM used vs. available: 8.29GB vs. 24.87GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:14:43\n",
      "\tVM used vs. available: 10.36GB vs. 22.79GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106400 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:14:44\n",
      "Num batches = 532\n",
      "Processing batches... @ 00:14:44\n",
      "\tVM used vs. available: 12.44GB vs. 20.72GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106400/106400 [00:37<00:00, 2859.74calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:15:21\n",
      "\tVM used vs. available: 12.44GB vs. 20.72GB\n",
      "Calculating numerator... @ 00:15:21\n",
      "\tVM used vs. available: 12.44GB vs. 20.72GB\n",
      "Calculating V_prime_w_C... @ 00:15:21\n",
      "Calculating O_w_C... @ 00:15:26\n",
      "Calculating U_w_C... @ 00:15:26\n",
      "Calculating E_w_C... @ 00:15:26\n",
      "\tVM used vs. available: 12.66GB vs. 20.49GB\n",
      "> End calculation. @ 00:15:26\n",
      "\n",
      "## L=16, b=200, |W_L| = 24 @ 00:15:27\n",
      "\tVM used vs. available: 8.29GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:15:27\n",
      "l = 14\n",
      "Sampling... @ 00:15:27\n",
      "\tVM used vs. available: 8.29GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.7s remaining:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:15:36\n",
      "\tVM used vs. available: 11.20GB vs. 21.96GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106400 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:15:37\n",
      "Num batches = 532\n",
      "Processing batches... @ 00:15:37\n",
      "\tVM used vs. available: 14.10GB vs. 19.05GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106400/106400 [00:06<00:00, 17421.04calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:15:43\n",
      "\tVM used vs. available: 14.10GB vs. 19.06GB\n",
      "Calculating numerator... @ 00:15:43\n",
      "\tVM used vs. available: 14.10GB vs. 19.06GB\n",
      "Calculating V_prime_w_C... @ 00:15:43\n",
      "Calculating O_w_C... @ 00:15:51\n",
      "Calculating U_w_C... @ 00:15:51\n",
      "Calculating E_w_C... @ 00:15:51\n",
      "\tVM used vs. available: 14.42GB vs. 18.73GB\n",
      "> End calculation. @ 00:15:51\n",
      "\n",
      "## L=19, b=200, |W_L| = 1 @ 00:15:51\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:15:51\n",
      "l = 17\n",
      "Sampling... @ 00:15:51\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.3s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:16:02\n",
      "\tVM used vs. available: 11.82GB vs. 21.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106400 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:16:03\n",
      "Num batches = 532\n",
      "Processing batches... @ 00:16:03\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106400/106400 [00:06<00:00, 16024.23calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:16:10\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:16:10\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:16:10\n",
      "Calculating O_w_C... @ 00:16:19\n",
      "Calculating U_w_C... @ 00:16:19\n",
      "Calculating E_w_C... @ 00:16:19\n",
      "\tVM used vs. available: 15.73GB vs. 17.42GB\n",
      "> End calculation. @ 00:16:19\n",
      "\n",
      "## L=19, b=200, |W_L| = 1 @ 00:16:19\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:16:19\n",
      "l = 17\n",
      "Sampling... @ 00:16:19\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:16:30\n",
      "\tVM used vs. available: 11.82GB vs. 21.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106400 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:16:31\n",
      "Num batches = 532\n",
      "Processing batches... @ 00:16:31\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106400/106400 [00:06<00:00, 16069.42calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:16:38\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:16:38\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:16:38\n",
      "Calculating O_w_C... @ 00:16:47\n",
      "Calculating U_w_C... @ 00:16:47\n",
      "Calculating E_w_C... @ 00:16:47\n",
      "\tVM used vs. available: 15.70GB vs. 17.45GB\n",
      "> End calculation. @ 00:16:47\n",
      "\n",
      "\n",
      "### Batch size: 300\n",
      "## L=4, b=300, |W_L| = 5 @ 00:16:47\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:16:47\n",
      "l = 2\n",
      "Sampling... @ 00:16:47\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.5s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.5s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.7s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:16:51\n",
      "\tVM used vs. available: 8.70GB vs. 24.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:16:51\n",
      "Num batches = 355\n",
      "Processing batches... @ 00:16:51\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:00<00:00, 110013.41calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:16:52\n",
      "\tVM used vs. available: 9.12GB vs. 24.04GB\n",
      "Calculating numerator... @ 00:16:52\n",
      "\tVM used vs. available: 9.12GB vs. 24.04GB\n",
      "Calculating V_prime_w_C... @ 00:16:52\n",
      "Calculating O_w_C... @ 00:16:53\n",
      "Calculating U_w_C... @ 00:16:53\n",
      "Calculating E_w_C... @ 00:16:53\n",
      "\tVM used vs. available: 9.14GB vs. 24.02GB\n",
      "> End calculation. @ 00:16:53\n",
      "\n",
      "## L=8, b=300, |W_L| = 1646 @ 00:16:53\n",
      "\tVM used vs. available: 8.31GB vs. 24.85GB\n",
      "> Begin calculation. @ 00:16:53\n",
      "l = 6\n",
      "Sampling... @ 00:16:53\n",
      "\tVM used vs. available: 8.31GB vs. 24.85GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:16:59\n",
      "\tVM used vs. available: 9.55GB vs. 23.60GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:16:59\n",
      "Num batches = 355\n",
      "Processing batches... @ 00:16:59\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [01:19<00:00, 1345.55calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:18:18\n",
      "\tVM used vs. available: 10.80GB vs. 22.36GB\n",
      "Calculating numerator... @ 00:18:18\n",
      "\tVM used vs. available: 10.80GB vs. 22.36GB\n",
      "Calculating V_prime_w_C... @ 00:18:18\n",
      "Calculating O_w_C... @ 00:18:22\n",
      "Calculating U_w_C... @ 00:18:22\n",
      "Calculating E_w_C... @ 00:18:22\n",
      "\tVM used vs. available: 10.93GB vs. 22.22GB\n",
      "> End calculation. @ 00:18:22\n",
      "\n",
      "## L=12, b=300, |W_L| = 508 @ 00:18:22\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n",
      "> Begin calculation. @ 00:18:22\n",
      "l = 10\n",
      "Sampling... @ 00:18:22\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.8s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.1s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:18:29\n",
      "\tVM used vs. available: 10.39GB vs. 22.77GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:18:30\n",
      "Num batches = 355\n",
      "Processing batches... @ 00:18:30\n",
      "\tVM used vs. available: 12.46GB vs. 20.70GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:26<00:00, 4034.92calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:18:56\n",
      "\tVM used vs. available: 12.46GB vs. 20.70GB\n",
      "Calculating numerator... @ 00:18:56\n",
      "\tVM used vs. available: 12.46GB vs. 20.70GB\n",
      "Calculating V_prime_w_C... @ 00:18:56\n",
      "Calculating O_w_C... @ 00:19:02\n",
      "Calculating U_w_C... @ 00:19:02\n",
      "Calculating E_w_C... @ 00:19:02\n",
      "\tVM used vs. available: 12.69GB vs. 20.47GB\n",
      "> End calculation. @ 00:19:02\n",
      "\n",
      "## L=16, b=300, |W_L| = 24 @ 00:19:02\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:19:02\n",
      "l = 14\n",
      "Sampling... @ 00:19:02\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.8s remaining:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.7s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:19:11\n",
      "\tVM used vs. available: 11.22GB vs. 21.94GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:19:12\n",
      "Num batches = 355\n",
      "Processing batches... @ 00:19:12\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:05<00:00, 18534.14calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:19:18\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating numerator... @ 00:19:18\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating V_prime_w_C... @ 00:19:18\n",
      "Calculating O_w_C... @ 00:19:25\n",
      "Calculating U_w_C... @ 00:19:25\n",
      "Calculating E_w_C... @ 00:19:25\n",
      "\tVM used vs. available: 14.44GB vs. 18.71GB\n",
      "> End calculation. @ 00:19:25\n",
      "\n",
      "## L=19, b=300, |W_L| = 1 @ 00:19:26\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:19:26\n",
      "l = 17\n",
      "Sampling... @ 00:19:26\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.4s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.5s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:19:37\n",
      "\tVM used vs. available: 11.78GB vs. 21.38GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:19:38\n",
      "Num batches = 355\n",
      "Processing batches... @ 00:19:38\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:10<00:00, 10387.81calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:19:48\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Calculating numerator... @ 00:19:48\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Calculating V_prime_w_C... @ 00:19:48\n",
      "Calculating O_w_C... @ 00:19:57\n",
      "Calculating U_w_C... @ 00:19:57\n",
      "Calculating E_w_C... @ 00:19:57\n",
      "\tVM used vs. available: 15.71GB vs. 17.45GB\n",
      "> End calculation. @ 00:19:57\n",
      "\n",
      "## L=19, b=300, |W_L| = 1 @ 00:19:57\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:19:57\n",
      "l = 17\n",
      "Sampling... @ 00:19:57\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:20:08\n",
      "\tVM used vs. available: 11.82GB vs. 21.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:20:10\n",
      "Num batches = 355\n",
      "Processing batches... @ 00:20:10\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:06<00:00, 16085.94calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:20:16\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:20:16\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:20:16\n",
      "Calculating O_w_C... @ 00:20:25\n",
      "Calculating U_w_C... @ 00:20:25\n",
      "Calculating E_w_C... @ 00:20:25\n",
      "\tVM used vs. available: 15.71GB vs. 17.45GB\n",
      "> End calculation. @ 00:20:25\n",
      "\n",
      "\n",
      "### Batch size: 500\n",
      "## L=4, b=500, |W_L| = 5 @ 00:20:25\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:20:25\n",
      "l = 2\n",
      "Sampling... @ 00:20:25\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.5s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:20:29\n",
      "\tVM used vs. available: 8.70GB vs. 24.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:20:29\n",
      "Num batches = 213\n",
      "Processing batches... @ 00:20:29\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:00<00:00, 116651.90calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:20:30\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating numerator... @ 00:20:30\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating V_prime_w_C... @ 00:20:30\n",
      "Calculating O_w_C... @ 00:20:31\n",
      "Calculating U_w_C... @ 00:20:31\n",
      "Calculating E_w_C... @ 00:20:31\n",
      "\tVM used vs. available: 9.16GB vs. 23.99GB\n",
      "> End calculation. @ 00:20:31\n",
      "\n",
      "## L=8, b=500, |W_L| = 1646 @ 00:20:31\n",
      "\tVM used vs. available: 8.33GB vs. 24.83GB\n",
      "> Begin calculation. @ 00:20:31\n",
      "l = 6\n",
      "Sampling... @ 00:20:31\n",
      "\tVM used vs. available: 8.33GB vs. 24.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.3s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.7s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:20:37\n",
      "\tVM used vs. available: 9.58GB vs. 23.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:20:38\n",
      "Num batches = 213\n",
      "Processing batches... @ 00:20:38\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:50<00:00, 2112.01calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:21:28\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n",
      "Calculating numerator... @ 00:21:28\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n",
      "Calculating V_prime_w_C... @ 00:21:28\n",
      "Calculating O_w_C... @ 00:21:31\n",
      "Calculating U_w_C... @ 00:21:31\n",
      "Calculating E_w_C... @ 00:21:31\n",
      "\tVM used vs. available: 10.89GB vs. 22.27GB\n",
      "> End calculation. @ 00:21:31\n",
      "\n",
      "## L=12, b=500, |W_L| = 508 @ 00:21:31\n",
      "\tVM used vs. available: 8.26GB vs. 24.89GB\n",
      "> Begin calculation. @ 00:21:31\n",
      "l = 10\n",
      "Sampling... @ 00:21:31\n",
      "\tVM used vs. available: 8.26GB vs. 24.89GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.0s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.3s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:21:39\n",
      "\tVM used vs. available: 10.34GB vs. 22.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:21:40\n",
      "Num batches = 213\n",
      "Processing batches... @ 00:21:40\n",
      "\tVM used vs. available: 12.41GB vs. 20.74GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:20<00:00, 5286.59calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:22:00\n",
      "\tVM used vs. available: 12.42GB vs. 20.74GB\n",
      "Calculating numerator... @ 00:22:00\n",
      "\tVM used vs. available: 12.42GB vs. 20.74GB\n",
      "Calculating V_prime_w_C... @ 00:22:00\n",
      "Calculating O_w_C... @ 00:22:05\n",
      "Calculating U_w_C... @ 00:22:05\n",
      "Calculating E_w_C... @ 00:22:05\n",
      "\tVM used vs. available: 12.64GB vs. 20.51GB\n",
      "> End calculation. @ 00:22:05\n",
      "\n",
      "## L=16, b=500, |W_L| = 24 @ 00:22:05\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n",
      "> Begin calculation. @ 00:22:05\n",
      "l = 14\n",
      "Sampling... @ 00:22:05\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.7s remaining:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.5s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:22:15\n",
      "\tVM used vs. available: 11.18GB vs. 21.98GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:22:16\n",
      "Num batches = 213\n",
      "Processing batches... @ 00:22:16\n",
      "\tVM used vs. available: 14.08GB vs. 19.08GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:08<00:00, 12521.09calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:22:24\n",
      "\tVM used vs. available: 14.08GB vs. 19.07GB\n",
      "Calculating numerator... @ 00:22:24\n",
      "\tVM used vs. available: 14.08GB vs. 19.07GB\n",
      "Calculating V_prime_w_C... @ 00:22:24\n",
      "Calculating O_w_C... @ 00:22:32\n",
      "Calculating U_w_C... @ 00:22:32\n",
      "Calculating E_w_C... @ 00:22:32\n",
      "\tVM used vs. available: 14.40GB vs. 18.75GB\n",
      "> End calculation. @ 00:22:32\n",
      "\n",
      "## L=19, b=500, |W_L| = 1 @ 00:22:32\n",
      "\tVM used vs. available: 8.28GB vs. 24.87GB\n",
      "> Begin calculation. @ 00:22:32\n",
      "l = 17\n",
      "Sampling... @ 00:22:32\n",
      "\tVM used vs. available: 8.28GB vs. 24.87GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:22:43\n",
      "\tVM used vs. available: 11.81GB vs. 21.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:22:44\n",
      "Num batches = 213\n",
      "Processing batches... @ 00:22:44\n",
      "\tVM used vs. available: 15.33GB vs. 17.82GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:10<00:00, 10618.28calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:22:54\n",
      "\tVM used vs. available: 15.33GB vs. 17.82GB\n",
      "Calculating numerator... @ 00:22:54\n",
      "\tVM used vs. available: 15.33GB vs. 17.82GB\n",
      "Calculating V_prime_w_C... @ 00:22:54\n",
      "Calculating O_w_C... @ 00:23:03\n",
      "Calculating U_w_C... @ 00:23:03\n",
      "Calculating E_w_C... @ 00:23:03\n",
      "\tVM used vs. available: 15.71GB vs. 17.45GB\n",
      "> End calculation. @ 00:23:03\n",
      "\n",
      "## L=19, b=500, |W_L| = 1 @ 00:23:03\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:23:03\n",
      "l = 17\n",
      "Sampling... @ 00:23:03\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.4s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.5s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:23:14\n",
      "\tVM used vs. available: 11.82GB vs. 21.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:23:16\n",
      "Num batches = 213\n",
      "Processing batches... @ 00:23:16\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:10<00:00, 10619.71calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:23:26\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:23:26\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:23:26\n",
      "Calculating O_w_C... @ 00:23:35\n",
      "Calculating U_w_C... @ 00:23:35\n",
      "Calculating E_w_C... @ 00:23:35\n",
      "\tVM used vs. available: 15.73GB vs. 17.42GB\n",
      "> End calculation. @ 00:23:35\n",
      "\n",
      "\n",
      "### Batch size: 600\n",
      "## L=4, b=600, |W_L| = 5 @ 00:23:35\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:23:35\n",
      "l = 2\n",
      "Sampling... @ 00:23:35\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.5s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.7s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:23:39\n",
      "\tVM used vs. available: 8.70GB vs. 24.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106800 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:23:39\n",
      "Num batches = 178\n",
      "Processing batches... @ 00:23:39\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106800/106800 [00:00<00:00, 112108.83calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:23:40\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating numerator... @ 00:23:40\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating V_prime_w_C... @ 00:23:40\n",
      "Calculating O_w_C... @ 00:23:41\n",
      "Calculating U_w_C... @ 00:23:41\n",
      "Calculating E_w_C... @ 00:23:41\n",
      "\tVM used vs. available: 9.18GB vs. 23.97GB\n",
      "> End calculation. @ 00:23:41\n",
      "\n",
      "## L=8, b=600, |W_L| = 1646 @ 00:23:41\n",
      "\tVM used vs. available: 8.24GB vs. 24.91GB\n",
      "> Begin calculation. @ 00:23:41\n",
      "l = 6\n",
      "Sampling... @ 00:23:41\n",
      "\tVM used vs. available: 8.24GB vs. 24.91GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.0s remaining:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:23:47\n",
      "\tVM used vs. available: 9.49GB vs. 23.67GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106800 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:23:47\n",
      "Num batches = 178\n",
      "Processing batches... @ 00:23:47\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106800/106800 [00:43<00:00, 2477.84calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:24:30\n",
      "\tVM used vs. available: 10.76GB vs. 22.39GB\n",
      "Calculating numerator... @ 00:24:30\n",
      "\tVM used vs. available: 10.76GB vs. 22.39GB\n",
      "Calculating V_prime_w_C... @ 00:24:30\n",
      "Calculating O_w_C... @ 00:24:33\n",
      "Calculating U_w_C... @ 00:24:33\n",
      "Calculating E_w_C... @ 00:24:33\n",
      "\tVM used vs. available: 10.93GB vs. 22.22GB\n",
      "> End calculation. @ 00:24:33\n",
      "\n",
      "## L=12, b=600, |W_L| = 508 @ 00:24:34\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:24:34\n",
      "l = 10\n",
      "Sampling... @ 00:24:34\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:24:41\n",
      "\tVM used vs. available: 10.39GB vs. 22.77GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106800 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:24:42\n",
      "Num batches = 178\n",
      "Processing batches... @ 00:24:42\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106800/106800 [00:15<00:00, 7019.21calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:24:57\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n",
      "Calculating numerator... @ 00:24:57\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n",
      "Calculating V_prime_w_C... @ 00:24:57\n",
      "Calculating O_w_C... @ 00:25:02\n",
      "Calculating U_w_C... @ 00:25:02\n",
      "Calculating E_w_C... @ 00:25:02\n",
      "\tVM used vs. available: 12.69GB vs. 20.46GB\n",
      "> End calculation. @ 00:25:02\n",
      "\n",
      "## L=16, b=600, |W_L| = 24 @ 00:25:02\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:25:02\n",
      "l = 14\n",
      "Sampling... @ 00:25:02\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.7s remaining:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.5s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:25:12\n",
      "\tVM used vs. available: 11.22GB vs. 21.93GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106800 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:25:13\n",
      "Num batches = 178\n",
      "Processing batches... @ 00:25:13\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106800/106800 [00:08<00:00, 12680.02calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:25:22\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating numerator... @ 00:25:22\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating V_prime_w_C... @ 00:25:22\n",
      "Calculating O_w_C... @ 00:25:29\n",
      "Calculating U_w_C... @ 00:25:29\n",
      "Calculating E_w_C... @ 00:25:29\n",
      "\tVM used vs. available: 14.42GB vs. 18.73GB\n",
      "> End calculation. @ 00:25:29\n",
      "\n",
      "## L=19, b=600, |W_L| = 1 @ 00:25:29\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:25:29\n",
      "l = 17\n",
      "Sampling... @ 00:25:29\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:25:40\n",
      "\tVM used vs. available: 11.84GB vs. 21.31GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106800 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:25:41\n",
      "Num batches = 178\n",
      "Processing batches... @ 00:25:41\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106800/106800 [00:09<00:00, 10697.74calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:25:51\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Calculating numerator... @ 00:25:51\n",
      "\tVM used vs. available: 15.30GB vs. 17.85GB\n",
      "Calculating V_prime_w_C... @ 00:25:51\n",
      "Calculating O_w_C... @ 00:26:00\n",
      "Calculating U_w_C... @ 00:26:00\n",
      "Calculating E_w_C... @ 00:26:00\n",
      "\tVM used vs. available: 15.70GB vs. 17.45GB\n",
      "> End calculation. @ 00:26:00\n",
      "\n",
      "## L=19, b=600, |W_L| = 1 @ 00:26:00\n",
      "\tVM used vs. available: 8.30GB vs. 24.85GB\n",
      "> Begin calculation. @ 00:26:00\n",
      "l = 17\n",
      "Sampling... @ 00:26:00\n",
      "\tVM used vs. available: 8.30GB vs. 24.85GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:26:11\n",
      "\tVM used vs. available: 11.82GB vs. 21.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106800 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:26:13\n",
      "Num batches = 178\n",
      "Processing batches... @ 00:26:13\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106800/106800 [00:10<00:00, 10625.98calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:26:23\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:26:23\n",
      "\tVM used vs. available: 15.34GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:26:23\n",
      "Calculating O_w_C... @ 00:26:32\n",
      "Calculating U_w_C... @ 00:26:32\n",
      "Calculating E_w_C... @ 00:26:32\n",
      "\tVM used vs. available: 15.71GB vs. 17.45GB\n",
      "> End calculation. @ 00:26:32\n",
      "\n",
      "\n",
      "### Batch size: 750\n",
      "## L=4, b=750, |W_L| = 5 @ 00:26:32\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n",
      "> Begin calculation. @ 00:26:32\n",
      "l = 2\n",
      "Sampling... @ 00:26:32\n",
      "\tVM used vs. available: 8.30GB vs. 24.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.3s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:26:36\n",
      "\tVM used vs. available: 8.70GB vs. 24.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:26:36\n",
      "Num batches = 142\n",
      "Processing batches... @ 00:26:36\n",
      "\tVM used vs. available: 9.12GB vs. 24.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:00<00:00, 115707.55calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:26:37\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating numerator... @ 00:26:37\n",
      "\tVM used vs. available: 9.11GB vs. 24.04GB\n",
      "Calculating V_prime_w_C... @ 00:26:37\n",
      "Calculating O_w_C... @ 00:26:38\n",
      "Calculating U_w_C... @ 00:26:38\n",
      "Calculating E_w_C... @ 00:26:38\n",
      "\tVM used vs. available: 9.16GB vs. 23.99GB\n",
      "> End calculation. @ 00:26:38\n",
      "\n",
      "## L=8, b=750, |W_L| = 1646 @ 00:26:38\n",
      "\tVM used vs. available: 8.24GB vs. 24.91GB\n",
      "> Begin calculation. @ 00:26:38\n",
      "l = 6\n",
      "Sampling... @ 00:26:38\n",
      "\tVM used vs. available: 8.24GB vs. 24.91GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:26:44\n",
      "\tVM used vs. available: 9.49GB vs. 23.66GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:26:44\n",
      "Num batches = 142\n",
      "Processing batches... @ 00:26:44\n",
      "\tVM used vs. available: 10.73GB vs. 22.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:36<00:00, 2911.35calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:27:21\n",
      "\tVM used vs. available: 10.78GB vs. 22.37GB\n",
      "Calculating numerator... @ 00:27:21\n",
      "\tVM used vs. available: 10.78GB vs. 22.37GB\n",
      "Calculating V_prime_w_C... @ 00:27:21\n",
      "Calculating O_w_C... @ 00:27:24\n",
      "Calculating U_w_C... @ 00:27:24\n",
      "Calculating E_w_C... @ 00:27:24\n",
      "\tVM used vs. available: 10.94GB vs. 22.22GB\n",
      "> End calculation. @ 00:27:24\n",
      "\n",
      "## L=12, b=750, |W_L| = 508 @ 00:27:24\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:27:24\n",
      "l = 10\n",
      "Sampling... @ 00:27:24\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:27:32\n",
      "\tVM used vs. available: 10.39GB vs. 22.76GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:27:32\n",
      "Num batches = 142\n",
      "Processing batches... @ 00:27:32\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:14<00:00, 7100.29calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:27:47\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n",
      "Calculating numerator... @ 00:27:47\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n",
      "Calculating V_prime_w_C... @ 00:27:47\n",
      "Calculating O_w_C... @ 00:27:53\n",
      "Calculating U_w_C... @ 00:27:53\n",
      "Calculating E_w_C... @ 00:27:53\n",
      "\tVM used vs. available: 12.69GB vs. 20.46GB\n",
      "> End calculation. @ 00:27:53\n",
      "\n",
      "## L=16, b=750, |W_L| = 24 @ 00:27:53\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:27:53\n",
      "l = 14\n",
      "Sampling... @ 00:27:53\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.7s remaining:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.5s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:28:02\n",
      "\tVM used vs. available: 11.22GB vs. 21.93GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:28:03\n",
      "Num batches = 142\n",
      "Processing batches... @ 00:28:03\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:08<00:00, 12616.46calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:28:12\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating numerator... @ 00:28:12\n",
      "\tVM used vs. available: 14.12GB vs. 19.03GB\n",
      "Calculating V_prime_w_C... @ 00:28:12\n",
      "Calculating O_w_C... @ 00:28:19\n",
      "Calculating U_w_C... @ 00:28:19\n",
      "Calculating E_w_C... @ 00:28:19\n",
      "\tVM used vs. available: 14.42GB vs. 18.73GB\n",
      "> End calculation. @ 00:28:19\n",
      "\n",
      "## L=19, b=750, |W_L| = 1 @ 00:28:19\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n",
      "> Begin calculation. @ 00:28:19\n",
      "l = 17\n",
      "Sampling... @ 00:28:19\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.4s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.5s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:28:31\n",
      "\tVM used vs. available: 11.84GB vs. 21.31GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:28:32\n",
      "Num batches = 142\n",
      "Processing batches... @ 00:28:32\n",
      "\tVM used vs. available: 15.37GB vs. 17.79GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:09<00:00, 10656.34calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:28:42\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Calculating numerator... @ 00:28:42\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Calculating V_prime_w_C... @ 00:28:42\n",
      "Calculating O_w_C... @ 00:28:51\n",
      "Calculating U_w_C... @ 00:28:51\n",
      "Calculating E_w_C... @ 00:28:51\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:28:51\n",
      "\n",
      "## L=19, b=750, |W_L| = 1 @ 00:28:51\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n",
      "> Begin calculation. @ 00:28:51\n",
      "l = 17\n",
      "Sampling... @ 00:28:51\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:29:02\n",
      "\tVM used vs. available: 11.87GB vs. 21.29GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:29:03\n",
      "Num batches = 142\n",
      "Processing batches... @ 00:29:03\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:09<00:00, 10671.95calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:29:13\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Calculating numerator... @ 00:29:13\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Calculating V_prime_w_C... @ 00:29:13\n",
      "Calculating O_w_C... @ 00:29:22\n",
      "Calculating U_w_C... @ 00:29:22\n",
      "Calculating E_w_C... @ 00:29:22\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:29:22\n",
      "\n",
      "\n",
      "### Batch size: 1000\n",
      "## L=4, b=1000, |W_L| = 5 @ 00:29:22\n",
      "\tVM used vs. available: 8.35GB vs. 24.81GB\n",
      "> Begin calculation. @ 00:29:22\n",
      "l = 2\n",
      "Sampling... @ 00:29:22\n",
      "\tVM used vs. available: 8.35GB vs. 24.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:29:26\n",
      "\tVM used vs. available: 8.68GB vs. 24.48GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107000 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:29:26\n",
      "Num batches = 107\n",
      "Processing batches... @ 00:29:26\n",
      "\tVM used vs. available: 9.10GB vs. 24.06GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107000/107000 [00:00<00:00, 118655.55calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:29:27\n",
      "\tVM used vs. available: 9.12GB vs. 24.04GB\n",
      "Calculating numerator... @ 00:29:27\n",
      "\tVM used vs. available: 9.12GB vs. 24.04GB\n",
      "Calculating V_prime_w_C... @ 00:29:27\n",
      "Calculating O_w_C... @ 00:29:28\n",
      "Calculating U_w_C... @ 00:29:28\n",
      "Calculating E_w_C... @ 00:29:28\n",
      "\tVM used vs. available: 9.20GB vs. 23.95GB\n",
      "> End calculation. @ 00:29:28\n",
      "\n",
      "## L=8, b=1000, |W_L| = 1646 @ 00:29:28\n",
      "\tVM used vs. available: 8.33GB vs. 24.82GB\n",
      "> Begin calculation. @ 00:29:28\n",
      "l = 6\n",
      "Sampling... @ 00:29:28\n",
      "\tVM used vs. available: 8.33GB vs. 24.82GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:29:34\n",
      "\tVM used vs. available: 9.51GB vs. 23.64GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107000 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:29:35\n",
      "Num batches = 107\n",
      "Processing batches... @ 00:29:35\n",
      "\tVM used vs. available: 10.76GB vs. 22.40GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107000/107000 [00:29<00:00, 3619.42calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:30:04\n",
      "\tVM used vs. available: 10.76GB vs. 22.39GB\n",
      "Calculating numerator... @ 00:30:04\n",
      "\tVM used vs. available: 10.76GB vs. 22.39GB\n",
      "Calculating V_prime_w_C... @ 00:30:04\n",
      "Calculating O_w_C... @ 00:30:07\n",
      "Calculating U_w_C... @ 00:30:07\n",
      "Calculating E_w_C... @ 00:30:07\n",
      "\tVM used vs. available: 10.94GB vs. 22.22GB\n",
      "> End calculation. @ 00:30:07\n",
      "\n",
      "## L=12, b=1000, |W_L| = 508 @ 00:30:08\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:30:08\n",
      "l = 10\n",
      "Sampling... @ 00:30:08\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.8s remaining:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.1s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:30:15\n",
      "\tVM used vs. available: 10.39GB vs. 22.76GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107000 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:30:16\n",
      "Num batches = 107\n",
      "Processing batches... @ 00:30:16\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107000/107000 [00:12<00:00, 8355.00calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:30:29\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n",
      "Calculating numerator... @ 00:30:29\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n",
      "Calculating V_prime_w_C... @ 00:30:29\n",
      "Calculating O_w_C... @ 00:30:34\n",
      "Calculating U_w_C... @ 00:30:34\n",
      "Calculating E_w_C... @ 00:30:34\n",
      "\tVM used vs. available: 12.71GB vs. 20.44GB\n",
      "> End calculation. @ 00:30:34\n",
      "\n",
      "## L=16, b=1000, |W_L| = 24 @ 00:30:34\n",
      "\tVM used vs. available: 8.34GB vs. 24.82GB\n",
      "> Begin calculation. @ 00:30:34\n",
      "l = 14\n",
      "Sampling... @ 00:30:34\n",
      "\tVM used vs. available: 8.34GB vs. 24.82GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.8s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.7s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.6s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:30:44\n",
      "\tVM used vs. available: 11.24GB vs. 21.91GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107000 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:30:45\n",
      "Num batches = 107\n",
      "Processing batches... @ 00:30:45\n",
      "\tVM used vs. available: 14.15GB vs. 19.00GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107000/107000 [00:08<00:00, 12746.37calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:30:53\n",
      "\tVM used vs. available: 14.14GB vs. 19.01GB\n",
      "Calculating numerator... @ 00:30:53\n",
      "\tVM used vs. available: 14.14GB vs. 19.01GB\n",
      "Calculating V_prime_w_C... @ 00:30:53\n",
      "Calculating O_w_C... @ 00:31:01\n",
      "Calculating U_w_C... @ 00:31:01\n",
      "Calculating E_w_C... @ 00:31:01\n",
      "\tVM used vs. available: 14.44GB vs. 18.71GB\n",
      "> End calculation. @ 00:31:01\n",
      "\n",
      "## L=19, b=1000, |W_L| = 1 @ 00:31:01\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n",
      "> Begin calculation. @ 00:31:01\n",
      "l = 17\n",
      "Sampling... @ 00:31:01\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:31:12\n",
      "\tVM used vs. available: 11.80GB vs. 21.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107000 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:31:13\n",
      "Num batches = 107\n",
      "Processing batches... @ 00:31:13\n",
      "\tVM used vs. available: 15.33GB vs. 17.83GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107000/107000 [00:10<00:00, 10680.66calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:31:23\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:31:23\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:31:23\n",
      "Calculating O_w_C... @ 00:31:32\n",
      "Calculating U_w_C... @ 00:31:32\n",
      "Calculating E_w_C... @ 00:31:32\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:31:32\n",
      "\n",
      "## L=19, b=1000, |W_L| = 1 @ 00:31:32\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n",
      "> Begin calculation. @ 00:31:32\n",
      "l = 17\n",
      "Sampling... @ 00:31:32\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.4s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:31:43\n",
      "\tVM used vs. available: 11.87GB vs. 21.29GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107000 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:31:44\n",
      "Num batches = 107\n",
      "Processing batches... @ 00:31:44\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107000/107000 [00:09<00:00, 10745.41calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:31:54\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Calculating numerator... @ 00:31:54\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Calculating V_prime_w_C... @ 00:31:54\n",
      "Calculating O_w_C... @ 00:32:03\n",
      "Calculating U_w_C... @ 00:32:03\n",
      "Calculating E_w_C... @ 00:32:03\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:32:03\n",
      "\n",
      "\n",
      "### Batch size: 1250\n",
      "## L=4, b=1250, |W_L| = 5 @ 00:32:03\n",
      "\tVM used vs. available: 8.28GB vs. 24.88GB\n",
      "> Begin calculation. @ 00:32:03\n",
      "l = 2\n",
      "Sampling... @ 00:32:03\n",
      "\tVM used vs. available: 8.28GB vs. 24.88GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:32:07\n",
      "\tVM used vs. available: 8.68GB vs. 24.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:32:07\n",
      "Num batches = 86\n",
      "Processing batches... @ 00:32:07\n",
      "\tVM used vs. available: 9.10GB vs. 24.06GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107500/107500 [00:00<00:00, 121460.39calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:32:08\n",
      "\tVM used vs. available: 9.10GB vs. 24.06GB\n",
      "Calculating numerator... @ 00:32:08\n",
      "\tVM used vs. available: 9.10GB vs. 24.06GB\n",
      "Calculating V_prime_w_C... @ 00:32:08\n",
      "Calculating O_w_C... @ 00:32:09\n",
      "Calculating U_w_C... @ 00:32:09\n",
      "Calculating E_w_C... @ 00:32:09\n",
      "\tVM used vs. available: 9.18GB vs. 23.97GB\n",
      "> End calculation. @ 00:32:09\n",
      "\n",
      "## L=8, b=1250, |W_L| = 1646 @ 00:32:09\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:32:09\n",
      "l = 6\n",
      "Sampling... @ 00:32:09\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:32:15\n",
      "\tVM used vs. available: 9.56GB vs. 23.60GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:32:16\n",
      "Num batches = 86\n",
      "Processing batches... @ 00:32:16\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107500/107500 [00:26<00:00, 4113.15calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:32:42\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n",
      "Calculating numerator... @ 00:32:42\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n",
      "Calculating V_prime_w_C... @ 00:32:42\n",
      "Calculating O_w_C... @ 00:32:45\n",
      "Calculating U_w_C... @ 00:32:45\n",
      "Calculating E_w_C... @ 00:32:45\n",
      "\tVM used vs. available: 10.96GB vs. 22.19GB\n",
      "> End calculation. @ 00:32:45\n",
      "\n",
      "## L=12, b=1250, |W_L| = 508 @ 00:32:45\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n",
      "> Begin calculation. @ 00:32:45\n",
      "l = 10\n",
      "Sampling... @ 00:32:45\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:32:53\n",
      "\tVM used vs. available: 10.34GB vs. 22.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:32:53\n",
      "Num batches = 86\n",
      "Processing batches... @ 00:32:53\n",
      "\tVM used vs. available: 12.42GB vs. 20.73GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107500/107500 [00:12<00:00, 8851.30calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:33:06\n",
      "\tVM used vs. available: 12.44GB vs. 20.71GB\n",
      "Calculating numerator... @ 00:33:06\n",
      "\tVM used vs. available: 12.44GB vs. 20.71GB\n",
      "Calculating V_prime_w_C... @ 00:33:06\n",
      "Calculating O_w_C... @ 00:33:11\n",
      "Calculating U_w_C... @ 00:33:11\n",
      "Calculating E_w_C... @ 00:33:11\n",
      "\tVM used vs. available: 12.71GB vs. 20.44GB\n",
      "> End calculation. @ 00:33:11\n",
      "\n",
      "## L=16, b=1250, |W_L| = 24 @ 00:33:11\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n",
      "> Begin calculation. @ 00:33:11\n",
      "l = 14\n",
      "Sampling... @ 00:33:11\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.7s remaining:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.5s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:33:21\n",
      "\tVM used vs. available: 11.18GB vs. 21.98GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:33:22\n",
      "Num batches = 86\n",
      "Processing batches... @ 00:33:22\n",
      "\tVM used vs. available: 14.08GB vs. 19.07GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107500/107500 [00:08<00:00, 12711.71calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:33:30\n",
      "\tVM used vs. available: 14.08GB vs. 19.07GB\n",
      "Calculating numerator... @ 00:33:30\n",
      "\tVM used vs. available: 14.08GB vs. 19.07GB\n",
      "Calculating V_prime_w_C... @ 00:33:30\n",
      "Calculating O_w_C... @ 00:33:38\n",
      "Calculating U_w_C... @ 00:33:38\n",
      "Calculating E_w_C... @ 00:33:38\n",
      "\tVM used vs. available: 14.42GB vs. 18.73GB\n",
      "> End calculation. @ 00:33:38\n",
      "\n",
      "## L=19, b=1250, |W_L| = 1 @ 00:33:38\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n",
      "> Begin calculation. @ 00:33:38\n",
      "l = 17\n",
      "Sampling... @ 00:33:38\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.4s remaining:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.5s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.6s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:33:49\n",
      "\tVM used vs. available: 11.85GB vs. 21.31GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:33:50\n",
      "Num batches = 86\n",
      "Processing batches... @ 00:33:50\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107500/107500 [00:10<00:00, 10709.13calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:34:00\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Calculating numerator... @ 00:34:00\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Calculating V_prime_w_C... @ 00:34:00\n",
      "Calculating O_w_C... @ 00:34:09\n",
      "Calculating U_w_C... @ 00:34:09\n",
      "Calculating E_w_C... @ 00:34:09\n",
      "\tVM used vs. available: 15.73GB vs. 17.42GB\n",
      "> End calculation. @ 00:34:09\n",
      "\n",
      "## L=19, b=1250, |W_L| = 1 @ 00:34:09\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n",
      "> Begin calculation. @ 00:34:09\n",
      "l = 17\n",
      "Sampling... @ 00:34:09\n",
      "\tVM used vs. available: 8.32GB vs. 24.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.5s remaining:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.6s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.7s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:34:21\n",
      "\tVM used vs. available: 11.84GB vs. 21.31GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/107500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:34:22\n",
      "Num batches = 86\n",
      "Processing batches... @ 00:34:22\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107500/107500 [00:09<00:00, 10822.25calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:34:32\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Calculating numerator... @ 00:34:32\n",
      "\tVM used vs. available: 15.37GB vs. 17.78GB\n",
      "Calculating V_prime_w_C... @ 00:34:32\n",
      "Calculating O_w_C... @ 00:34:41\n",
      "Calculating U_w_C... @ 00:34:41\n",
      "Calculating E_w_C... @ 00:34:41\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:34:41\n",
      "\n",
      "\n",
      "### Batch size: 1500\n",
      "## L=4, b=1500, |W_L| = 5 @ 00:34:41\n",
      "\tVM used vs. available: 8.28GB vs. 24.88GB\n",
      "> Begin calculation. @ 00:34:41\n",
      "l = 2\n",
      "Sampling... @ 00:34:41\n",
      "\tVM used vs. available: 8.28GB vs. 24.88GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.5s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.7s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:34:45\n",
      "\tVM used vs. available: 8.68GB vs. 24.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:34:45\n",
      "Num batches = 71\n",
      "Processing batches... @ 00:34:45\n",
      "\tVM used vs. available: 9.10GB vs. 24.06GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:00<00:00, 119050.07calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:34:46\n",
      "\tVM used vs. available: 9.14GB vs. 24.01GB\n",
      "Calculating numerator... @ 00:34:46\n",
      "\tVM used vs. available: 9.14GB vs. 24.01GB\n",
      "Calculating V_prime_w_C... @ 00:34:46\n",
      "Calculating O_w_C... @ 00:34:47\n",
      "Calculating U_w_C... @ 00:34:47\n",
      "Calculating E_w_C... @ 00:34:47\n",
      "\tVM used vs. available: 9.19GB vs. 23.96GB\n",
      "> End calculation. @ 00:34:47\n",
      "\n",
      "## L=8, b=1500, |W_L| = 1646 @ 00:34:47\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:34:47\n",
      "l = 6\n",
      "Sampling... @ 00:34:47\n",
      "\tVM used vs. available: 8.31GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:34:53\n",
      "\tVM used vs. available: 9.56GB vs. 23.59GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:34:53\n",
      "Num batches = 71\n",
      "Processing batches... @ 00:34:53\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:23<00:00, 4605.52calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:35:16\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n",
      "Calculating numerator... @ 00:35:16\n",
      "\tVM used vs. available: 10.80GB vs. 22.35GB\n",
      "Calculating V_prime_w_C... @ 00:35:16\n",
      "Calculating O_w_C... @ 00:35:19\n",
      "Calculating U_w_C... @ 00:35:19\n",
      "Calculating E_w_C... @ 00:35:19\n",
      "\tVM used vs. available: 10.94GB vs. 22.21GB\n",
      "> End calculation. @ 00:35:19\n",
      "\n",
      "## L=12, b=1500, |W_L| = 508 @ 00:35:19\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n",
      "> Begin calculation. @ 00:35:19\n",
      "l = 10\n",
      "Sampling... @ 00:35:19\n",
      "\tVM used vs. available: 8.32GB vs. 24.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.7s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.0s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:35:27\n",
      "\tVM used vs. available: 10.39GB vs. 22.76GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:35:28\n",
      "Num batches = 71\n",
      "Processing batches... @ 00:35:28\n",
      "\tVM used vs. available: 12.46GB vs. 20.69GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:10<00:00, 10006.29calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:35:38\n",
      "\tVM used vs. available: 12.47GB vs. 20.69GB\n",
      "Calculating numerator... @ 00:35:38\n",
      "\tVM used vs. available: 12.47GB vs. 20.69GB\n",
      "Calculating V_prime_w_C... @ 00:35:38\n",
      "Calculating O_w_C... @ 00:35:43\n",
      "Calculating U_w_C... @ 00:35:44\n",
      "Calculating E_w_C... @ 00:35:44\n",
      "\tVM used vs. available: 12.71GB vs. 20.45GB\n",
      "> End calculation. @ 00:35:44\n",
      "\n",
      "## L=16, b=1500, |W_L| = 24 @ 00:35:44\n",
      "\tVM used vs. available: 8.33GB vs. 24.82GB\n",
      "> Begin calculation. @ 00:35:44\n",
      "l = 14\n",
      "Sampling... @ 00:35:44\n",
      "\tVM used vs. available: 8.33GB vs. 24.82GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.6s remaining:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.5s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.4s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:35:53\n",
      "\tVM used vs. available: 11.24GB vs. 21.91GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:35:54\n",
      "Num batches = 71\n",
      "Processing batches... @ 00:35:54\n",
      "\tVM used vs. available: 14.14GB vs. 19.01GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:08<00:00, 12802.35calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:36:02\n",
      "\tVM used vs. available: 14.14GB vs. 19.01GB\n",
      "Calculating numerator... @ 00:36:02\n",
      "\tVM used vs. available: 14.14GB vs. 19.01GB\n",
      "Calculating V_prime_w_C... @ 00:36:02\n",
      "Calculating O_w_C... @ 00:36:10\n",
      "Calculating U_w_C... @ 00:36:10\n",
      "Calculating E_w_C... @ 00:36:10\n",
      "\tVM used vs. available: 14.44GB vs. 18.71GB\n",
      "> End calculation. @ 00:36:10\n",
      "\n",
      "## L=19, b=1500, |W_L| = 1 @ 00:36:10\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n",
      "> Begin calculation. @ 00:36:10\n",
      "l = 17\n",
      "Sampling... @ 00:36:10\n",
      "\tVM used vs. available: 8.27GB vs. 24.88GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.2s remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.3s remaining:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:36:21\n",
      "\tVM used vs. available: 11.80GB vs. 21.35GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:36:22\n",
      "Num batches = 71\n",
      "Processing batches... @ 00:36:22\n",
      "\tVM used vs. available: 15.33GB vs. 17.83GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:10<00:00, 10641.86calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:36:32\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Calculating numerator... @ 00:36:32\n",
      "\tVM used vs. available: 15.35GB vs. 17.81GB\n",
      "Calculating V_prime_w_C... @ 00:36:32\n",
      "Calculating O_w_C... @ 00:36:41\n",
      "Calculating U_w_C... @ 00:36:41\n",
      "Calculating E_w_C... @ 00:36:41\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:36:41\n",
      "\n",
      "## L=19, b=1500, |W_L| = 1 @ 00:36:41\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n",
      "> Begin calculation. @ 00:36:41\n",
      "l = 17\n",
      "Sampling... @ 00:36:41\n",
      "\tVM used vs. available: 8.34GB vs. 24.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.4s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.5s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 00:36:52\n",
      "\tVM used vs. available: 11.87GB vs. 21.29GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/106500 [00:00<?, ?calc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 00:36:54\n",
      "Num batches = 71\n",
      "Processing batches... @ 00:36:54\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n",
      "Z_prime_ALL_batch has infinities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106500/106500 [00:09<00:00, 10713.50calc/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 00:37:04\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Calculating numerator... @ 00:37:04\n",
      "\tVM used vs. available: 15.39GB vs. 17.76GB\n",
      "Calculating V_prime_w_C... @ 00:37:04\n",
      "Calculating O_w_C... @ 00:37:13\n",
      "Calculating U_w_C... @ 00:37:13\n",
      "Calculating E_w_C... @ 00:37:13\n",
      "\tVM used vs. available: 15.75GB vs. 17.40GB\n",
      "> End calculation. @ 00:37:13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if benchmark: #RESUME\n",
    "    # iterate through batch sizes, leaving large batch sizes for last, \n",
    "    # since they're most likely to cause crashes and this way we collect more useful data first...\n",
    "    for batch_size in [50, 100, 200, 300, 500, 600, 750, 1000, 1250, 1500]:\n",
    "        print(f\"### Batch size: {batch_size}\")\n",
    "        for b_l, w_idx, CM in zip(benchmark_lengths, benchmark_wordform_idxs, benchmark_CMs):\n",
    "            stampedMemNote(f'## L={b_l}, b={batch_size}, |W_L| = {exactLengthFreqs[b_l.item()]}', includeGPU=True)\n",
    "            post = pXhat0fX0i_ptc(w_idx, CM, m=n, target_contexts_per_batch=batch_size, parallel=l, use_gpu=g, exact_wf=True)\n",
    "            print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T07:57:03.347022Z",
     "start_time": "2019-08-11T07:57:03.342817Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:53:27.405796Z",
     "start_time": "2019-08-10T07:53:27.395398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'974,937,740 = 9.75E+08 calculations'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('2.68E+06', '4.47E+04', '7.45E+02', '3.10E+01')"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'est. 363.6363636363636 = 3.64E+02 cps'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Volume organization 3\n",
    "est_time_per_w_c = 2.75 #ms\n",
    "len(Ws_t)\n",
    "len(Cs_t)\n",
    "n_calcs = len(Ws_t) * len(Cs_t)\n",
    "\"{0:,} = {0:.2E} calculations\".format(n_calcs)\n",
    "\n",
    "serial_computation_time_est = est_time_per_w_c * len(Ws_t) * len(Cs_t) #ms\n",
    "est_s = serial_computation_time_est / 1e3\n",
    "est_m = est_s / 60\n",
    "est_h = est_m / 60\n",
    "est_d = est_h / 24\n",
    "\n",
    "est_at_scales = (est_s, est_m, est_h, est_d)\n",
    "\n",
    "toSN = lambda n: \"{0:.2E}\".format(n)\n",
    "\n",
    "tuple(map(toSN,\n",
    "          est_at_scales))\n",
    "\n",
    "est_cps = n_calcs / est_s\n",
    "\"est. {0:,} = {0:.2E} cps\".format(est_cps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation volume organization for Case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Section 6.2 for explanation of the \"cases\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slices: Calculate results for groups of reconstructed wordforms by (input prefix, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:14.746863Z",
     "start_time": "2019-08-10T07:57:14.742071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42231"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ps_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:15.054031Z",
     "start_time": "2019-08-10T07:57:15.043033Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieveKcousins(r, maxK):\n",
    "    word_cousin_indices = union([set(list(cousin_mats[k][Ps_t.index(r),:].nonzero()[0])) for k in range(maxK)])\n",
    "    word_cousins = list(map(lambda w_idx: Ws_t[w_idx], word_cousin_indices))\n",
    "    return word_cousins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:15.482047Z",
     "start_time": "2019-08-10T07:57:15.477249Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if r or not e:\n",
    "    retrieveKcousins('⋊.k.ɑ.n.t', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:15.852124Z",
     "start_time": "2019-08-10T07:57:15.847127Z"
    }
   },
   "outputs": [],
   "source": [
    "if r or not e:\n",
    "    cousin_mats[0].shape\n",
    "    cousin_mats[0][Ps_t.index('⋊.k.ɑ.n.t'), Ws_t.index('⋊.k.ɑ.n.t.æ.k.t.⋉.⋉')] #should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:16.432164Z",
     "start_time": "2019-08-10T07:57:16.418158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'⋊.k.ɑ.n.t.n.u.ɪ.t.i.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.n.ɪ.n.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.æ.k.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ə.m.p.l.eɪ.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɛ.k.s.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɛ.s.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.æ.k.t.ɚ.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.æ.k.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.æ.s.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.ə.b.j.u.ʃ.ɪ.n.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.ə.b.æ.n.d.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.ə.d.ɪ.k.t.⋉.⋉',\n",
       " '⋊.k.ɑ.n.t.ɹ.ə.v.ɚ.s.i.⋉.⋉'}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsWithPrefix('⋊.k.ɑ.n.t', Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:16.803063Z",
     "start_time": "2019-08-10T07:57:16.800440Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_nnz_word(my_k, j):\n",
    "    return cousin_mats[my_k][:,j].nnz\n",
    "\n",
    "if r or not e:\n",
    "    cousin_mats[1].shape\n",
    "    word_nnz_counts_by_k = {my_k:par(delayed(get_nnz_word)(my_k, j) for j in range(cousin_mats[my_k].shape[1]))\n",
    "                            for my_k in range(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:17.402006Z",
     "start_time": "2019-08-10T07:57:17.349128Z"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:17.734360Z",
     "start_time": "2019-08-10T07:57:17.729299Z"
    }
   },
   "outputs": [],
   "source": [
    "if r or not e:\n",
    "    for my_k in range(5):\n",
    "        print(f\"max number of {my_k}-cousins = {max(word_nnz_counts_by_k[my_k])}\")\n",
    "        print(f\"median number of {my_k}-cousins = {median(word_nnz_counts_by_k[my_k])}\")\n",
    "        print(f\"mean number of {my_k}-cousins = {mean(word_nnz_counts_by_k[my_k])}\")\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:18.318953Z",
     "start_time": "2019-08-10T07:57:18.316102Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nnz_prefix(my_k, i):\n",
    "    return cousin_mats[my_k][i,:].nnz\n",
    "\n",
    "if r or not e:\n",
    "    cousin_mats[1].shape\n",
    "    prefix_nnz_counts_by_k = {my_k:par(delayed(get_nnz_prefix)(my_k, i) for i in range(cousin_mats[my_k].shape[0]))\n",
    "                              for my_k in range(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:18.814424Z",
     "start_time": "2019-08-10T07:57:18.809260Z"
    }
   },
   "outputs": [],
   "source": [
    "if r or not e:\n",
    "    for my_k in range(5):\n",
    "        print(f\"max number of {my_k}-cousins = {max(prefix_nnz_counts_by_k[my_k])}\")\n",
    "        print(f\"median number of {my_k}-cousins = {median(prefix_nnz_counts_by_k[my_k])}\")\n",
    "        print(f\"mean number of {my_k}-cousins = {mean(prefix_nnz_counts_by_k[my_k])}\")\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:19.242234Z",
     "start_time": "2019-08-10T07:57:19.240089Z"
    }
   },
   "outputs": [],
   "source": [
    "if r or not e:\n",
    "    cousin_mats[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:20.634761Z",
     "start_time": "2019-08-10T07:57:19.676145Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0023s.) Setting batch_size=176.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0763s.) Setting batch_size=922.\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9172 out of 9172 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "def to_prefix_idx(w):\n",
    "    return Ps_t.index(w)\n",
    "\n",
    "prefix_indices_of_full_wordforms = par(delayed(to_prefix_idx)(w) for w in Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:20.638078Z",
     "start_time": "2019-08-10T07:57:20.635975Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_word_idx(p):\n",
    "    return Ws_t.index(p)\n",
    "\n",
    "def get_wordform_idx(prefix_idx):\n",
    "    return to_word_idx(Ps_t[prefix_idx])\n",
    "\n",
    "# get_wordform_idx = {prefix_idx:to_word_idx(Ps_t[prefix_idx])\n",
    "#                     for prefix_idx in prefix_indices_of_full_wordforms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:20.815115Z",
     "start_time": "2019-08-10T07:57:20.639195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.h.aɪ.k.⋉.⋉'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'⋊.h.aɪ.k.⋉.⋉'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_t[8370]\n",
    "get_wordform_idx(8370)\n",
    "Ws_t[get_wordform_idx(8370)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:20.887341Z",
     "start_time": "2019-08-10T07:57:20.820129Z"
    }
   },
   "outputs": [],
   "source": [
    "if r and not e:\n",
    "    cousin_mats[k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:20.973058Z",
     "start_time": "2019-08-10T07:57:20.893030Z"
    }
   },
   "outputs": [],
   "source": [
    "def getKcousin_idxs_of_wordform(w_idx, maxK, asType=None, onlyWordCousins = False, getPrefixIndices=True):\n",
    "    kcousin_indices = union([set(list(cousin_mats[k][:,w_idx].nonzero()[0])) for k in range(maxK)])\n",
    "    if onlyWordCousins:\n",
    "    # top line is ≈100x slower\n",
    "#         kcousin_indices = {prefix_idx for prefix_idx in kcousin_indices if prefix_idx in prefix_indices_of_full_wordforms}\n",
    "        kcousin_indices = set.intersection(kcousin_indices, prefix_indices_of_full_wordforms)\n",
    "    if not getPrefixIndices:\n",
    "        kcousin_indices = set(map(get_wordform_idx, kcousin_indices))\n",
    "    \n",
    "    if asType == 'ndarray':\n",
    "        kcousin_indices = np.array(sorted(list(kcousin_indices)), dtype='int32')\n",
    "        return kcousin_indices\n",
    "    elif asType == 'torch':\n",
    "        kcousin_indices = torch.tensor(sorted(list(kcousin_indices)), dtype=torch.int32)\n",
    "        return kcousin_indices\n",
    "    else:\n",
    "        return kcousin_indices\n",
    "    \n",
    "def getKcousin_idxs_of_prefix(p_idx, maxK, asType=None):\n",
    "    kcousin_indices = union([set(list(cousin_mats[k][p_idx].nonzero()[0])) for k in range(maxK)])\n",
    "    \n",
    "    if asType == 'ndarray':\n",
    "        kcousin_indices = np.array(sorted(list(kcousin_indices)), dtype='int32')\n",
    "        return kcousin_indices\n",
    "    elif asType == 'torch':\n",
    "        kcousin_indices = torch.tensor(sorted(list(kcousin_indices)), dtype=torch.int32)\n",
    "        return kcousin_indices\n",
    "    else:\n",
    "        return kcousin_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:21.200963Z",
     "start_time": "2019-08-10T07:57:21.195824Z"
    }
   },
   "outputs": [],
   "source": [
    "if r and not e:\n",
    "    random_source_wordform\n",
    "    getKcousin_idxs_of_wordform(Ws_t.index(random_source_wordform), 2, 'ndarray', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:21.647174Z",
     "start_time": "2019-08-10T07:57:21.642466Z"
    }
   },
   "outputs": [],
   "source": [
    "if r and not e:\n",
    "    random_source_prefix\n",
    "    getKcousin_idxs_of_prefix(Ps_t.index(random_source_prefix), 2, 'ndarray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:22.015550Z",
     "start_time": "2019-08-10T07:57:22.008149Z"
    }
   },
   "outputs": [],
   "source": [
    "def pXhat0fX0i_pxtn_by_rc(produced_prefix_idx, x0k_cm, c_idx, m = 50, asType='ndarray', parallel=False):\n",
    "    kCousin_idxs = getKcousin_idxs_of_prefix(produced_prefix_idx, k, 'ndarray')\n",
    "    \n",
    "    if x0k_cm is None:\n",
    "        x0k_cm = prefixTox0kCM(Ps_t[produced_prefix_idx])\n",
    "    \n",
    "    if parallel:\n",
    "        estimates = par(delayed(pXhat0fX0i_pxtn)(w_idx, x0k_cm, c_idx, m=m) for w_idx in kCousin_idxs)\n",
    "        estimates = np.array(list(estimates))\n",
    "    else:\n",
    "        estimates = np.array([pXhat0fX0i_pxtn(w_idx, x0k_cm, c_idx, m=m) for w_idx in kCousin_idxs])\n",
    "\n",
    "    if asType == 'ndarray':\n",
    "        return kCousin_idxs, estimates\n",
    "    elif asType == 'torch':\n",
    "#         return torch.tensor(kCousin_idxs), torch.tensor(estimates)\n",
    "        return torch.from_numpy(kCousin_idxs), torch.from_numpy(estimates)\n",
    "    else:\n",
    "        return tuple(kCousin_idxs), tuple(estimates)\n",
    "\n",
    "def pXhat0fX0i_pxtn_by_wc(produced_wordform_idx, x0k_cm, c_idx, m = 50, asType='ndarray', parallel=False):\n",
    "    equivalent_prefix_idx = Ps_t.index(Ws_t[produced_wordform_idx])\n",
    "    return pXhat0fX0i_pxtn_by_rc(equivalent_prefix_idx, x0k_cm, c_idx, m, asType, parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:22.514114Z",
     "start_time": "2019-08-10T07:57:22.499791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.d.eɪ.k.ɑ'"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_prefix\n",
    "random_source_prefix_idx = Ps_t.index(random_source_prefix)\n",
    "random_source_prefix_x0kcm = prefixTox0kCM(random_source_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:23.224221Z",
     "start_time": "2019-08-10T07:57:23.214142Z"
    }
   },
   "outputs": [],
   "source": [
    "if r and not e:\n",
    "    print(f'x0k = {random_source_prefix}')\n",
    "    print(f'c = {random_context}')\n",
    "    cousin_idxs, post_probs = pXhat0fX0i_pxtn_by_rc(random_source_prefix_idx, random_source_prefix_x0kcm, random_context_idx)\n",
    "    print(f'({k}-cousin W-hat, p(W-hat|X0k = {random_source_prefix}, C = {random_context}))')\n",
    "    [(Ws_t[cousin_idx], post_probs[i]) for i, cousin_idx in enumerate(cousin_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks: Calculate results for groups of input prefixes by context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:24.100914Z",
     "start_time": "2019-08-10T07:57:24.095752Z"
    }
   },
   "outputs": [],
   "source": [
    "#FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation volume organization 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Section 6.2 for explanation of the \"cases\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:24.991749Z",
     "start_time": "2019-08-10T07:57:24.986879Z"
    }
   },
   "outputs": [],
   "source": [
    "#FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation volume organization 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Section 6.2 for explanation of the \"cases\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slices: Calculate $\\{p(\\widehat{W} = w^* | W = w^*, C = c)\\}$ for all $W$ and for a single given $c$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:27.180543Z",
     "start_time": "2019-08-10T07:57:27.167444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{w for w in Ws_t if ds2t(w)[0] != leftEdge or ds2t(w)[-1] != rightEdge}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:28.137287Z",
     "start_time": "2019-08-10T07:57:28.131368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6304"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws_t.index('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉')\n",
    "len(ds2t('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉')) #19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:28.499307Z",
     "start_time": "2019-08-10T07:57:28.478965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 17])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0366, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0335, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0135, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0142, 0.0068, 0.0000],\n",
       "        [0.0068, 0.0086, 0.0068, 0.0068, 0.0088, 0.0169, 0.0110, 0.0089, 0.0068,\n",
       "         0.0088, 0.0153, 0.0086, 0.0069, 0.0068, 0.0072, 0.0066, 0.0000],\n",
       "        [0.0070, 0.0550, 0.0071, 0.2747, 0.0092, 0.1082, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.1078, 0.0089, 0.7089, 0.0071, 0.1108, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0087, 0.0069, 0.0069, 0.0090, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0089, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0230, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0175, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0135, 0.0071, 0.0092, 0.0176, 0.0114, 0.0409, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0136, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0052, 0.0077, 0.0061, 0.0061, 0.0079, 0.0151, 0.0098, 0.6208, 0.0060,\n",
       "         0.0078, 0.0137, 0.0077, 0.0062, 0.0061, 0.0064, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.6175, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.6665, 0.0071, 0.0070, 0.0074, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.7163, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.5485, 0.0092, 0.0069,\n",
       "         0.0172, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0335, 0.0217, 0.0093, 0.0070,\n",
       "         0.6378, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.7449, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0775, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0176, 0.0074, 0.0068, 0.0000],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0135, 0.0074, 0.0070, 0.0000],\n",
       "        [0.7449, 0.0170, 0.0135, 0.0071, 0.0175, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0170, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.7379,\n",
       "         0.0228, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074, 0.0070, 0.0000],\n",
       "        [0.0066, 0.0087, 0.0134, 0.0069, 0.0174, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0173, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0087, 0.0069, 0.0069, 0.0090, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0089, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0086, 0.0068, 0.0068, 0.0088, 0.0169, 0.0110, 0.0089, 0.0068,\n",
       "         0.0088, 0.0153, 0.0086, 0.0069, 0.0068, 0.0072, 0.0066, 0.0000],\n",
       "        [0.0070, 0.0077, 0.0061, 0.0061, 0.0079, 0.0151, 0.0187, 0.0080, 0.0060,\n",
       "         0.0078, 0.0137, 0.0077, 0.0062, 0.0061, 0.0064, 0.0052, 0.0000],\n",
       "        [0.0070, 0.0170, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0304, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074, 0.0070, 0.0000],\n",
       "        [0.0070, 0.5600, 0.0071, 0.1065, 0.0092, 0.0525, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0760, 0.0089, 0.0181, 0.0071, 0.1150, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.3742, 0.0092, 0.0525, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0579, 0.0089, 0.0245, 0.0071, 0.5043, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0086, 0.0068, 0.0068, 0.0088, 0.0169, 0.0110, 0.0089, 0.0068,\n",
       "         0.0088, 0.0153, 0.0086, 0.0069, 0.7174, 0.0139, 0.0066, 0.0000],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0335, 0.0114, 0.0093, 0.0134,\n",
       "         0.0091, 0.0541, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0070, 0.0336, 0.0071, 0.0071, 0.0175, 0.0920, 0.0286, 0.0177, 0.0070,\n",
       "         0.0091, 0.1734, 0.0089, 0.0072, 0.0071, 0.0075, 0.0070, 0.0000],\n",
       "        [0.0068, 0.0087, 0.0069, 0.0069, 0.0090, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0089, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073, 0.0068, 0.0000],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074, 0.0068, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CMsByLengthByWordformIndex_torch)\n",
    "CMsByLengthByWordformIndex_torch[19][6304].shape\n",
    "CMsByLengthByWordformIndex_torch[19][6304]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:28.990609Z",
     "start_time": "2019-08-10T07:57:28.929742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 14])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 15])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 16])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 17])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ'))\n",
    "len(dsToKfactorSequence(3, '⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ'))\n",
    "prefixTox0kCM('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ').shape\n",
    "\n",
    "len(ds2t('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n'))\n",
    "len(dsToKfactorSequence(3, '⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n'))\n",
    "prefixTox0kCM('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n').shape\n",
    "\n",
    "len(ds2t('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉'))\n",
    "len(dsToKfactorSequence(3, '⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉'))\n",
    "prefixTox0kCM('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉').shape\n",
    "\n",
    "len(ds2t('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉'))\n",
    "len(dsToKfactorSequence(3, '⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉'))\n",
    "prefixTox0kCM('⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n.⋉.⋉').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:29.425220Z",
     "start_time": "2019-08-10T07:57:29.395703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 15])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0366, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0335, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0089, 0.0135, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0142],\n",
       "        [0.0068, 0.0086, 0.0068, 0.0068, 0.0088, 0.0169, 0.0110, 0.0089, 0.0068,\n",
       "         0.0088, 0.0153, 0.0086, 0.0069, 0.0068, 0.0072],\n",
       "        [0.0070, 0.0550, 0.0071, 0.2747, 0.0092, 0.1082, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.1078, 0.0089, 0.7089, 0.0071, 0.1108],\n",
       "        [0.0068, 0.0087, 0.0069, 0.0069, 0.0090, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0089, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0230, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0175, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074],\n",
       "        [0.0070, 0.0089, 0.0135, 0.0071, 0.0092, 0.0176, 0.0114, 0.0409, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0136, 0.0075],\n",
       "        [0.0052, 0.0077, 0.0061, 0.0061, 0.0079, 0.0151, 0.0098, 0.6208, 0.0060,\n",
       "         0.0078, 0.0137, 0.0077, 0.0062, 0.0061, 0.0064],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.6175, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.6665, 0.0071, 0.0070, 0.0074],\n",
       "        [0.0070, 0.0089, 0.7163, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.5485, 0.0092, 0.0069,\n",
       "         0.0172, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0335, 0.0217, 0.0093, 0.0070,\n",
       "         0.6378, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0775, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0176, 0.0074],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0135, 0.0074],\n",
       "        [0.7449, 0.0170, 0.0135, 0.0071, 0.0175, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0170, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.7379,\n",
       "         0.0228, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074],\n",
       "        [0.0066, 0.0087, 0.0134, 0.0069, 0.0174, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0173, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073],\n",
       "        [0.0068, 0.0087, 0.0069, 0.0069, 0.0090, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0089, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0068, 0.0086, 0.0068, 0.0068, 0.0088, 0.0169, 0.0110, 0.0089, 0.0068,\n",
       "         0.0088, 0.0153, 0.0086, 0.0069, 0.0068, 0.0072],\n",
       "        [0.0070, 0.0077, 0.0061, 0.0061, 0.0079, 0.0151, 0.0187, 0.0080, 0.0060,\n",
       "         0.0078, 0.0137, 0.0077, 0.0062, 0.0061, 0.0064],\n",
       "        [0.0070, 0.0170, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0304, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0068, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074],\n",
       "        [0.0070, 0.5600, 0.0071, 0.1065, 0.0092, 0.0525, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0760, 0.0089, 0.0181, 0.0071, 0.1150],\n",
       "        [0.0070, 0.0089, 0.0071, 0.3742, 0.0092, 0.0525, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0579, 0.0089, 0.0245, 0.0071, 0.5043],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0176, 0.0114, 0.0093, 0.0070,\n",
       "         0.0091, 0.0159, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0068, 0.0086, 0.0068, 0.0068, 0.0088, 0.0169, 0.0110, 0.0089, 0.0068,\n",
       "         0.0088, 0.0153, 0.0086, 0.0069, 0.7174, 0.0139],\n",
       "        [0.0070, 0.0089, 0.0071, 0.0071, 0.0092, 0.0335, 0.0114, 0.0093, 0.0134,\n",
       "         0.0091, 0.0541, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0070, 0.0336, 0.0071, 0.0071, 0.0175, 0.0920, 0.0286, 0.0177, 0.0070,\n",
       "         0.0091, 0.1734, 0.0089, 0.0072, 0.0071, 0.0075],\n",
       "        [0.0068, 0.0087, 0.0069, 0.0069, 0.0090, 0.0171, 0.0111, 0.0090, 0.0068,\n",
       "         0.0089, 0.0155, 0.0087, 0.0070, 0.0069, 0.0073],\n",
       "        [0.0070, 0.0088, 0.0070, 0.0070, 0.0091, 0.0174, 0.0113, 0.0092, 0.0069,\n",
       "         0.0090, 0.0157, 0.0088, 0.0071, 0.0070, 0.0074],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2t(\"⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n\"))\n",
    "prefixTox0kCM(\"⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n\").shape\n",
    "prefixTox0kCM(\"⋊.t.ɛ.l.ɪ.k.ə.m.j.u.n.ə.k.eɪ.ʃ.ɪ.n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:30.045906Z",
     "start_time": "2019-08-10T07:57:30.041410Z"
    }
   },
   "outputs": [],
   "source": [
    "# CMsByLengthByWordformIndex_torch\n",
    "# X0f_CMs_by_wordform_index = [wordformTox0kCM(w, w_idx) for w_idx, w in enumerate(Ws_t)]\n",
    "# X0f_CMs_by_wordform_index_torch = torch.tensor([wordformTox0kCM(w, w_idx) for w_idx, w in enumerate(Ws_t)])\n",
    "# X0f_CMs_by_wordform_index_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:31.059207Z",
     "start_time": "2019-08-10T07:57:31.050426Z"
    }
   },
   "outputs": [],
   "source": [
    "def p_wstar_wstar_pxtn_by_wc(produced_wordform_idx, x0f_cm, c_idx, m = 50):\n",
    "    return pXhat0fX0f_pxtn(produced_wordform_idx, x0f_cm, c_idx, m = m)\n",
    "#     return pXhat0fX0i_pxtn(produced_wordform_idx, x0f_cm, c_idx, m = m)\n",
    "\n",
    "def p_wstar_wstar_pxtn_by_c(c_idx, m, asType='ndarray', parallel=True):\n",
    "    if parallel:\n",
    "        estimates = np.array(list(par(delayed(p_wstar_wstar_pxtn_by_wc)(w_idx, \n",
    "                                                                        wordformTox0fCM(w_idx=w_idx),\n",
    "                                                                        c_idx,\n",
    "                                                                        m)\n",
    "                                      for w_idx in range(len(Ws_t)))))\n",
    "    else:\n",
    "        estimates = np.array([p_wstar_wstar_pxtn_by_wc(w_idx, \n",
    "                                                       wordformTox0fCM(w_idx=w_idx),\n",
    "                                                       c_idx,\n",
    "                                                       m)\n",
    "                             for w_idx in np.arange(len(Ws_t))])\n",
    "    \n",
    "    if asType =='ndarray':\n",
    "        return estimates\n",
    "    elif asType == 'torch':\n",
    "        return torch.tensor(estimates)\n",
    "    else:\n",
    "        return tuple(estimates)\n",
    "    \n",
    "def p_wstar_wstar_pxt_by_wc(produced_wordform_idx, x0f_cm, c_idx, m = 50):\n",
    "    return pXhat0fX0f_pxt(produced_wordform_idx, x0f_cm, c_idx, m = m)\n",
    "#     return pXhat0fX0i_pxtn(produced_wordform_idx, x0f_cm, c_idx, m = m)\n",
    "\n",
    "def p_wstar_wstar_pxt_by_c(c_idx, m, asType='torch', parallel=True):\n",
    "    if parallel:\n",
    "        estimates = torch.tensor(list(par(delayed(p_wstar_wstar_pxt_by_wc)(w_idx, \n",
    "                                                                           wordformTox0fCM(w_idx=w_idx),\n",
    "                                                                           c_idx,\n",
    "                                                                           m)\n",
    "                                          for w_idx in range(len(Ws_t)))))\n",
    "    else:\n",
    "        estimates = torch.tensor([p_wstar_wstar_pxt_by_wc(w_idx,\n",
    "                                                          wordformTox0fCM(w_idx=w_idx),\n",
    "                                                          c_idx,\n",
    "                                                          m)\n",
    "                                  for w_idx in np.arange(len(Ws_t))])\n",
    "    \n",
    "    if asType =='ndarray':\n",
    "        return estimates.numpy()\n",
    "    elif asType == 'torch':\n",
    "        return estimates\n",
    "    else:\n",
    "        return tuple(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:31.902300Z",
     "start_time": "2019-08-10T07:57:31.887153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⋊.ɹ.ɛ.p.t.ɪ.l.i.ə.n.⋉.⋉'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 10])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0070, 0.0085, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0204, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0157, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0226, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0082, 0.0087, 0.0086, 0.0079, 0.0072, 0.0068, 0.0103, 0.0105,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0422, 0.0090, 0.0090, 0.0387, 0.0075, 0.0070, 0.0560, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0083, 0.0088, 0.0087, 0.0080, 0.0073, 0.0068, 0.0104, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0206, 0.0143, 0.7380, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0052, 0.0073, 0.0078, 0.0077, 0.0071, 0.0064, 0.0060, 0.0092, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0157, 0.6579, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.5957,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0160, 0.6491, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.6501, 0.0082, 0.0075, 0.0070, 0.0204, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0161, 0.0089, 0.0088, 0.0081, 0.0187, 0.0069, 0.0106, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0435, 0.0083, 0.0088, 0.0087, 0.0080, 0.0329, 0.0130, 0.0104, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0083, 0.0088, 0.0087, 0.0080, 0.0073, 0.0068, 0.0104, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0845, 0.0090, 0.0090, 0.0082, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0082, 0.0087, 0.0086, 0.0079, 0.0072, 0.0068, 0.0103, 0.0105,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0073, 0.0078, 0.0077, 0.0071, 0.0064, 0.0060, 0.0092, 0.0082,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0997, 0.0090, 0.0171, 0.0082, 0.0075, 0.0070, 0.0560, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.0206, 0.0075, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.4674, 0.0090, 0.0090, 0.0969, 0.0075, 0.0070, 0.1181, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0090, 0.4987, 0.0075, 0.0070, 0.0268, 0.0111,\n",
       "         0.0000],\n",
       "        [0.7080, 0.0162, 0.0090, 0.0090, 0.0082, 0.0272, 0.0070, 0.0107, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0082, 0.0087, 0.0086, 0.0079, 0.0072, 0.0068, 0.0103, 0.0105,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0090, 0.0171, 0.0280, 0.0075, 0.0070, 0.0204, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0085, 0.0172, 0.0171, 0.0310, 0.0143, 0.0070, 0.3674, 0.0111,\n",
       "         0.0000],\n",
       "        [0.0068, 0.0083, 0.0088, 0.0087, 0.0080, 0.0073, 0.0068, 0.0104, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0070, 0.0084, 0.0089, 0.0088, 0.0081, 0.0074, 0.0069, 0.0106, 0.0108,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.0000]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source_wordform\n",
    "random_source_wordform_idx = Ws_t.index(random_source_wordform)\n",
    "random_source_wordform_x0f_cm = wordformTox0fCM(random_source_wordform, random_source_wordform_idx)\n",
    "random_source_wordform_x0f_cm.shape\n",
    "random_source_wordform_x0f_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:32.392318Z",
     "start_time": "2019-08-10T07:57:32.387200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:33.468753Z",
     "start_time": "2019-08-10T07:57:33.273180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        7.7G         18G        9.8M        4.6G         23G\r\n",
      "Swap:          2.0G        1.0G        1.0G\r\n"
     ]
    }
   ],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:04:50.282392Z",
     "start_time": "2019-08-10T08:04:50.277297Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_context_idxs = set(map(lambda c: Cs_t.index(c),\n",
    "                                  choices(Cs_t, k=1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:57:46.997209Z",
     "start_time": "2019-08-10T07:57:46.991667Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # random_c_idx1 = choice(random_context_idxs); Cs_t[random_c_idx1]\n",
    "    random_c_idx1 = Cs_t.index('yeah philadelphia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:58:10.839541Z",
     "start_time": "2019-08-10T07:57:56.234932Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1494s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0464s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1274s.) Setting batch_size=50.\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 556 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1306 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2056 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2906 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3756 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4706 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 5656 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0058s.) Setting batch_size=25.\n",
      "[Parallel(n_jobs=-1)]: Done 6706 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 7531 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 8106 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 9172 out of 9172 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9172,)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.036688"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.6688e-05"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if benchmark:\n",
    "    # 1m56s = 116s = 9172c/116s = 79.069 cps / kotoba\n",
    "    # 14s = 9172/14s = 655.14 cps / kotoba\n",
    "    random_slice1 = p_wstar_wstar_pxtn_by_c(random_c_idx1, m=50, asType='ndarray', parallel=True)\n",
    "    random_slice1.shape\n",
    "    random_slice1.nbytes / 1e6\n",
    "    random_slice1.nbytes / 1e9\n",
    "    del random_slice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:02:38.411848Z",
     "start_time": "2019-08-10T08:02:38.407458Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    # random_c_idx2 = choice(random_context_idxs); Cs_t[random_c_idx2]\n",
    "    random_c_idx2 = Cs_t.index('<rem> little')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:02:57.706714Z",
     "start_time": "2019-08-10T08:02:45.334130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0125s.) Setting batch_size=30.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1638s.) Setting batch_size=72.\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 744 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1680 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0065s.) Setting batch_size=36.\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4426s.) Setting batch_size=18.\n",
      "[Parallel(n_jobs=-1)]: Done 3624 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4200 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4938 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5280 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 5622 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 6000 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 6378 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6792 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7206 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7656 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 8106 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 8592 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 9172 out of 9172 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9172,)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.036688"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.6688e-05"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if benchmark:\n",
    "    # 1m49s = 109s = 9172c/109s = 84.15 cps / kotoba\n",
    "    # 12.4s = 9172c/12.4s = 739.68 cps / kotoba\n",
    "    random_slice2 = p_wstar_wstar_pxtn_by_c(random_c_idx2, m=50, asType='ndarray', parallel=True)\n",
    "    random_slice2.shape\n",
    "    random_slice2.nbytes / 1e6\n",
    "    random_slice2.nbytes / 1e9\n",
    "    del random_slice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:03:57.353463Z",
     "start_time": "2019-08-10T08:03:57.125693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        7.8G         18G        9.8M        4.6G         23G\r\n",
      "Swap:          2.0G        1.0G        1.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:03:58.235782Z",
     "start_time": "2019-08-10T08:03:58.231746Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    J = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:05:05.514298Z",
     "start_time": "2019-08-10T08:05:05.509321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ultimately'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if benchmark:\n",
    "    random_c_idx3 = choice(list(random_context_idxs)); Cs_t[random_c_idx3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T08:05:29.733432Z",
     "start_time": "2019-08-10T08:05:16.939710Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0105s.) Setting batch_size=38.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1430 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1924 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2494 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3064 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3710 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4356 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5078 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5800 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 6598 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 7396 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 8270 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9172 out of 9172 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9172,)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.036688"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.6688e-05"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if benchmark:\n",
    "    random_slice3 = p_wstar_wstar_pxtn_by_c(random_c_idx3, m=50, asType='ndarray', parallel=True)\n",
    "    random_slice3.shape\n",
    "    random_slice3.nbytes / 1e6\n",
    "    random_slice3.nbytes / 1e9\n",
    "    del random_slice3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:41.770664Z",
     "start_time": "2019-08-10T07:59:41.765149Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    J = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:42.546176Z",
     "start_time": "2019-08-10T07:59:42.544083Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_c_idx4 = choice(random_context_idxs); Cs_t[random_c_idx4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:43.625563Z",
     "start_time": "2019-08-10T07:59:43.617425Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_slice4 = p_wstar_wstar_pxtn_by_c(random_c_idx4, m=50, asType='ndarray', parallel=True)\n",
    "    random_slice4.shape\n",
    "    random_slice4.nbytes / 1e6\n",
    "    random_slice4.nbytes / 1e9\n",
    "    del random_slice4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:44.497609Z",
     "start_time": "2019-08-10T07:59:44.493788Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    J = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:45.260019Z",
     "start_time": "2019-08-10T07:59:45.253718Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_c_idx5 = choice(random_context_idxs); Cs_t[random_c_idx5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:46.166558Z",
     "start_time": "2019-08-10T07:59:46.164059Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_slice5 = p_wstar_wstar_pxtn_by_c(random_c_idx5, m=50, asType='ndarray', parallel=True)\n",
    "    random_slice5.shape\n",
    "    random_slice5.nbytes / 1e6\n",
    "    random_slice5.nbytes / 1e9\n",
    "    del random_slice5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:46.942559Z",
     "start_time": "2019-08-10T07:59:46.933612Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_c_idx6 = random_c_idx5\n",
    "\n",
    "    random_slice6 = p_wstar_wstar_pxt_by_c(random_c_idx6, m=50, asType='torch', parallel=True)\n",
    "    random_slice6.shape\n",
    "    torch_nbytes(random_slice6) / 1e6\n",
    "    torch_nbytes(random_slice6) / 1e9\n",
    "    del random_slice6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:47.666604Z",
     "start_time": "2019-08-10T07:59:47.661289Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    random_c_idx6 = random_c_idx5\n",
    "\n",
    "    random_slice6 = p_wstar_wstar_pxt_by_c(random_c_idx6, m=50, asType='torch', parallel=True)\n",
    "    random_slice6.shape\n",
    "    torch_nbytes(random_slice6) / 1e6\n",
    "    torch_nbytes(random_slice6) / 1e9\n",
    "    del random_slice6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T07:59:48.521151Z",
     "start_time": "2019-08-10T07:59:48.515399Z"
    }
   },
   "outputs": [],
   "source": [
    "if benchmark:\n",
    "    J = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slices: Calculate $\\{p(\\widehat{W} = w^* | W = w^*, C = c)\\}$ for all $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.943489Z",
     "start_time": "2019-08-08T05:35:29.112Z"
    }
   },
   "outputs": [],
   "source": [
    "# pXhat0fX0i_ptc(xhat0f_idx, x0k_CM, m = 50, target_contexts_per_batch=750, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of calculations necessary under different calculation criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the full distribution that could be calculated is $$p(\\widehat{X}_0^f | X_0^k, C) = p(\\widehat{W} | R, C)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:48.068688Z",
     "start_time": "2019-08-10T23:19:48.052856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "42231"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'41,172,595,697,940'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'4.12E+13'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "len(Ps_t)\n",
    "len(Cs_t)\n",
    "\"{0:,}\".format( len(Ws_t) * len(Ps_t) * len(Cs_t) )\n",
    "\"{0:.2E}\".format( len(Ws_t) * len(Ps_t) * len(Cs_t) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the chosen value of $k$, there are this many $(w,r)$ pairs to be calculated (for every $c$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:49.046254Z",
     "start_time": "2019-08-10T23:19:49.041906Z"
    }
   },
   "outputs": [],
   "source": [
    "# cousin_mats[k].shape\n",
    "# sum([cousin_mats[k][i,:].nnz for i in range(len(Ps))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:49.284555Z",
     "start_time": "2019-08-10T23:19:49.278072Z"
    }
   },
   "outputs": [],
   "source": [
    "if r and not e:\n",
    "    print(f'k = {k}')\n",
    "\n",
    "    cousin_mats[k].shape\n",
    "\n",
    "    def calc_count(i):\n",
    "        return cousin_mats[k][i,:].nnz\n",
    "\n",
    "    num_seq_pairs_case1 = sum(list(par(delayed(calc_count)(i) for i in range(len(Ps)))))\n",
    "    num_calcs_case1 = len(Cs_t) * num_seq_pairs_case1\n",
    "\n",
    "    print('|(w,r)| pairs to do calculations for every c = {0:,}'.format( num_seq_pairs_case1 ))\n",
    "    print(\"|(w,r)| pairs there would be without the k-edit-distance-restriction = {0:,}\".format( len(Ws) * len(Ps) ))\n",
    "    print(f'|Cs| = {len(Cs_t)}')\n",
    "    print('Est. of total number of calculations to do = {0:,} = {0:.2E}'.format(num_calcs_case1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $r$ is `False`, then the dimensions and number of calculations reduce to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:49.767001Z",
     "start_time": "2019-08-10T23:19:49.751563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'8,942,128,951,280'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'8.94E+12'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "len(Ws_t)\n",
    "len(Cs_t)\n",
    "\"{0:,}\".format( len(Ws_t) * len(Ws_t) * len(Cs_t) )\n",
    "\"{0:.2E}\".format( len(Ws_t) * len(Ws_t) * len(Cs_t) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $r$ is `False`, then for the chosen value of $k$, there are this many $(w',w)$ pairs to be calculated (for every $c$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:50.143783Z",
     "start_time": "2019-08-10T23:19:50.137678Z"
    }
   },
   "outputs": [],
   "source": [
    "if r or not e:\n",
    "    print(f'k = {k}')\n",
    "\n",
    "    cousin_mats[k].shape\n",
    "\n",
    "    def calc_count(i):\n",
    "        if Ps_t[i] in Ws:\n",
    "            return cousin_mats[k][i,:].nnz\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    num_seq_pairs_case2 = sum(list(par(delayed(calc_count)(i) for i in range(len(Ps)))))\n",
    "    num_calcs_case2 = len(Cs_t) * num_seq_pairs_case2\n",
    "\n",
    "    print(\"|(w',w)| pairs to do calculations for every c = {0:,}\".format( num_seq_pairs_case2 ))\n",
    "    print(\"|(w',w)| pairs there would be without the k-edit-distance-restriction = {0:,}\".format( len(Ws) * len(Ws) ))\n",
    "    print(f'|Cs| = {len(Cs_t)}')\n",
    "    print('Est. of total number of calculations to do = {0:,} = {0:.2E}'.format(num_calcs_case2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T01:43:02.693343Z",
     "start_time": "2019-07-23T01:43:02.435505Z"
    }
   },
   "source": [
    "If $r$ is `False` and $e$ is `True`, then the dimensions and number of calculations reduce to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:51.503591Z",
     "start_time": "2019-08-10T23:19:51.496060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "106295"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'974,937,740'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'9.75E+08'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws)\n",
    "len(Cs_t)\n",
    "num_calcs_case3 = len(Ws_t) * len(Cs_t)\n",
    "\"{0:,}\".format( num_calcs_case3 )\n",
    "\"{0:.2E}\".format( num_calcs_case3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine dimensions and cells to be calculated vs. ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:52.326729Z",
     "start_time": "2019-08-10T23:19:52.321399Z"
    }
   },
   "outputs": [],
   "source": [
    "assert (k != 0 and r) or (k != 0 and (not r) and (not e)) or (k == 0 and (not r) and e) or (k > 0 and (not r) and e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option: Only calculate full source wordforms rather than all source prefixes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:53.064203Z",
     "start_time": "2019-08-10T23:19:53.058568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = False\n",
      "Performing calculations only for all complete source wordforms (and *not* all prefixes thereof).\n",
      "|source_sequences| = 9172\n"
     ]
    }
   ],
   "source": [
    "print(f\"r = {r}\")\n",
    "\n",
    "if r:\n",
    "    source_sequences = Ps_t\n",
    "    print(\"Performing calculations for all source prefixes.\")\n",
    "else:\n",
    "    source_sequences = Ws_t\n",
    "    print(\"Performing calculations only for all complete source wordforms (and *not* all prefixes thereof).\")\n",
    "\n",
    "Ss_t = source_sequences    \n",
    "\n",
    "print(f\"|source_sequences| = {len(source_sequences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suboption: Given $\\neg r$ and a full source wordform $w^*$, only calculate posterior probability $p(\\widehat{W} = w^* | W = w^*, C = c)$, $\\forall w^*$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:54.142828Z",
     "start_time": "2019-08-10T23:19:54.138177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬r ∧ e = True ∧ True = True\n",
      "Performing calculations only for those cases where the reconstructed wordform exactly matches the source wordform.\n"
     ]
    }
   ],
   "source": [
    "print(f\"¬r ∧ e = {not r} ∧ {e} = {(not r) and e}\")\n",
    "\n",
    "if (not r) and e:\n",
    "    print(\"Performing calculations only for those cases where the reconstructed wordform exactly matches the source wordform.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Calculations not restricted only to exact reconstructed wordform matches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suboption: Restrict calculations only to (source sequence, reconstruction sequence) pairs within edit distance $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:55.514741Z",
     "start_time": "2019-08-10T23:19:55.509702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2\n",
      "¬r ∧ e is equivalent to restricting calculations only to (source sequence, reconstructed sequence) pairs within edit distance 0.\n"
     ]
    }
   ],
   "source": [
    "print(f\"k = {k}\")\n",
    "\n",
    "if r or ((not r) and (not e)):\n",
    "    print(f\"Restricting calculations only to (source sequence, reconstructed sequence) pairs within edit distance {k}.\")\n",
    "elif (not r) and e:\n",
    "    print(f\"¬r ∧ e is equivalent to restricting calculations only to (source sequence, reconstructed sequence) pairs within edit distance 0.\")\n",
    "else:\n",
    "    print(\"No restrictions on (source sequence, reconstructed sequence) pairs to be calculated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altogether..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:57.208066Z",
     "start_time": "2019-08-10T23:19:57.204726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:58.047252Z",
     "start_time": "2019-08-10T23:19:58.038432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:\n",
      "\t3\n",
      "Shape of matrix:\n",
      "\t(9172, 106295)\n",
      "Num elements:\n",
      "\t974,937,740 = 9.75E+08\n",
      "Num calculations:\n",
      "\t974,937,740 = 9.75E+08\n",
      "Est. size in GB of result:\n",
      "\t7.79950192 = 7.80E+00\n",
      "Density:\n",
      "\t1.0\n",
      "Result suffix:\n",
      "\tpW_WC_e\n"
     ]
    }
   ],
   "source": [
    "if r and (0 < k <= 4):\n",
    "    case = 1    \n",
    "    myShape = (len(Ws_t), len(Ps-t), len(Cs_t))\n",
    "    my_num_calcs = num_calcs_case1\n",
    "    \n",
    "    my_type = f'pW_RC_k{k}'\n",
    "    status = '_unnormalized'\n",
    "\n",
    "if (not r) and (0 < k <= 4) and (not e):\n",
    "    case = 2\n",
    "    myShape = (len(Ws_t), len(Ws_t), len(Cs_t))\n",
    "    my_num_calcs = num_calcs_case2\n",
    "    \n",
    "    my_type = f'pW_WC_k{k}'\n",
    "    status = '_unnormalized'\n",
    "    \n",
    "if (not r) and e:\n",
    "    case = 3\n",
    "#     myShape = (len(Ws), len(Ws), len(Cs))\n",
    "    myShape = (len(Ws_t), len(Cs_t))\n",
    "    my_num_calcs = num_calcs_case3\n",
    "\n",
    "    my_type = f'pW_WC_e'\n",
    "    status = ''\n",
    "\n",
    "print(f'Case:\\n\\t{case}')\n",
    "print(f'Shape of matrix:\\n\\t{myShape}')\n",
    "print('Num elements:')\n",
    "print(\"\\t{0:,} = {0:.2E}\".format(prod(myShape)))\n",
    "print('Num calculations:')\n",
    "print(\"\\t{0:,} = {0:.2E}\".format(my_num_calcs))\n",
    "print('Est. size in GB of result:')\n",
    "print(\"\\t{0:,} = {0:.2E}\".format(my_num_calcs * 8 / 1e9))\n",
    "print(\"Density:\")\n",
    "print(\"\\t{0:,}\".format(my_num_calcs / prod(myShape)))    \n",
    "\n",
    "print('Result suffix:')\n",
    "my_fn_suffix = my_type + status\n",
    "print(f\"\\t{my_fn_suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:59.055300Z",
     "start_time": "2019-08-10T23:19:59.050518Z"
    }
   },
   "outputs": [],
   "source": [
    "abort_threshold_GB = 250\n",
    "size_est_GB = (my_num_calcs * 8 / 1e9)\n",
    "assert size_est_GB <= abort_threshold_GB, \"Estimated size of resulting matrix is ≥ {1} GB:\\n\\tEst. size = {0:,}GB = {0:.2E}GB\\n\\tAborting calculation.\".format(size_est_GB, abort_threshold_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:19:59.711394Z",
     "start_time": "2019-08-10T23:19:59.707005Z"
    }
   },
   "outputs": [],
   "source": [
    "# if exists(o + my_fn_suffix):\n",
    "#     unnormalized_posterior = np.load(o + my_fn_suffix + '.npy',\n",
    "#                                      allow_pickle = False)\n",
    "# assert not exists(o + my_fn_suffix + '.npy'), 'Unnormalized distribution already found at filepath \\n\\t{0}'.format( o + my_fn_suffix + '.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:00.416629Z",
     "start_time": "2019-08-10T23:20:00.411900Z"
    }
   },
   "outputs": [],
   "source": [
    "# unnormalized_posterior_torch = np.zeros(myShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: $r \\land (0 < k \\leq 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: $\\neg r \\land (0 < k \\leq 4) \\land \\neg e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: $\\neg r \\land e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:03.290594Z",
     "start_time": "2019-08-10T23:20:03.279455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9172, 106295)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 106295)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myShape\n",
    "# blockShape = (myShape[0], 1) #every context is a slice\n",
    "blockShape = (1, myShape[1]) #every source wordform is a slice\n",
    "blockShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:03.787598Z",
     "start_time": "2019-08-10T23:20:03.780803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9172, 106295)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 9171)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0, 106294)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myShape #dim of eventual tensor representing desired portion of distribution\n",
    "\n",
    "# segWordDomain = (wStart, wEnd); segWordDomain\n",
    "segWordDomain = (0, myShape[0]-1); segWordDomain\n",
    "contextDomain = (0, myShape[1]-1); contextDomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:04.118495Z",
     "start_time": "2019-08-10T23:20:04.105707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_w.0-9171'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'_w.0-9171'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segWordDomainStr = '_' + 'w' + '.' + str(wStart) + '-' + str(wEnd); segWordDomainStr\n",
    "domainRegionStr = segWordDomainStr; domainRegionStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:04.528406Z",
     "start_time": "2019-08-10T23:20:04.523822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pW_WC_e'"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dbName = my_fn_suffix + domainRegionStr; dbName\n",
    "dbName = my_fn_suffix# + domainRegionStr; dbName\n",
    "dbName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:05.139795Z",
     "start_time": "2019-08-10T23:20:05.077852Z"
    }
   },
   "outputs": [],
   "source": [
    "dom = tiledb.Domain(tiledb.Dim(name=\"segWord\", domain=segWordDomain, tile=blockShape[0], dtype=np.uint32),\n",
    "                    tiledb.Dim(name=\"context\", domain=contextDomain, tile=blockShape[1], dtype=np.uint32))\n",
    "\n",
    "schema = tiledb.ArraySchema(domain=dom, sparse=False,\n",
    "                            attrs=[tiledb.Attr(name=dbName, dtype=np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:05.989748Z",
     "start_time": "2019-08-10T23:20:05.982452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'pW_WC_e'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'pW_WC_e'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o\n",
    "my_fn_suffix\n",
    "# domainRegionStr\n",
    "dbName\n",
    "o + '.' + dbName\n",
    "array_name = o + '.' + dbName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:08.535769Z",
     "start_time": "2019-08-10T23:20:08.497813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array with name\n",
      "\tLD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e\n",
      "already exists.\n"
     ]
    }
   ],
   "source": [
    "if tiledb.object_type(array_name) == \"array\":\n",
    "        print(f\"Array with name\\n\\t{array_name}\\nalready exists.\")\n",
    "else:\n",
    "    tiledb.DenseArray.create(array_name, schema)\n",
    "    print(f'Array with name\\n\\t{array_name}\\ncreated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:12.447537Z",
     "start_time": "2019-08-10T23:20:12.442217Z"
    }
   },
   "outputs": [],
   "source": [
    "# rm -r 'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:13.193116Z",
     "start_time": "2019-08-10T23:20:13.188558Z"
    }
   },
   "outputs": [],
   "source": [
    "# will also work if if given a range of indices and a range of slices...\n",
    "# def slice_writer(slice_context_index, context_slice, A):\n",
    "# # #     with tiledb.SparseArray(arr_name, mode='w') as A:\n",
    "#         A[:,slice_context_index] = context_slice\n",
    "\n",
    "def slice_writer(slice_word_index, word_slice, A):\n",
    "# #     with tiledb.SparseArray(arr_name, mode='w') as A:\n",
    "        A[slice_word_index,:] = word_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:13.656752Z",
     "start_time": "2019-08-10T23:20:13.654470Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_reader(indices):\n",
    "    with tiledb.DenseArray(array_name, mode='r') as A:\n",
    "        return A[indices][dbName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:14.739946Z",
     "start_time": "2019-08-10T23:20:14.737448Z"
    }
   },
   "outputs": [],
   "source": [
    "config = tiledb.Config()\n",
    "# config[\"sm.consolidation.steps\"] = 10\n",
    "config[\"sm.consolidation.steps\"] = 600\n",
    "config[\"sm.consolidation.step_min_frags\"] = 2\n",
    "config[\"sm.consolidation.step_max_frags\"] = 20\n",
    "# tiledb.consolidate(array_name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:15.691836Z",
     "start_time": "2019-08-10T23:20:15.685868Z"
    }
   },
   "outputs": [],
   "source": [
    "# if cStart != '' and cEnd != '':\n",
    "#     print(f'Context block start and end given: ({cStart}, {cEnd})')\n",
    "#     blockRange = np.arange(cStart, cEnd)\n",
    "#     assert 0 <= cStart <= len(Cs_t), f'0<= cStart <= len(Cs_t) does not hold: {cStart} vs. {len(Cs_t)}'\n",
    "#     assert 0 <= cEnd <= len(Cs_t), f'0<= cEnd <= len(Cs_t) does not hold: {cEnd} vs. {len(Cs_t)}'\n",
    "# else:\n",
    "#     print(f'Calculating all indices from 0 to len(Cs_t) = {len(Cs_t)}')\n",
    "#     blockRange = np.arange(len(Cs_t))\n",
    "\n",
    "\n",
    "# for c_idx in tqdm(blockRange):\n",
    "#     context_slice = p_wstar_wstar_pxtn_by_c(c_idx, m=50, asType='ndarray', parallel=True)\n",
    "\n",
    "#     with tiledb.SparseArray(array_name, mode='w') as A:\n",
    "#         slice_writer(c_idx, context_slice, A)\n",
    "        \n",
    "#     if c_idx % 100 == 0:\n",
    "#         tiledb.consolidate(config, uri=array_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T23:20:16.245264Z",
     "start_time": "2019-08-10T23:20:16.239252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word block start and end given: (0, 9171)\n"
     ]
    }
   ],
   "source": [
    "if wStart != '' and wEnd != '':\n",
    "    print(f'Word block start and end given: ({wStart}, {wEnd})')\n",
    "    blockRange = np.arange(wStart, wEnd)\n",
    "    assert 0 <= wStart < len(Ws_t), f'0<= wStart < len(Ws_t) does not hold: {wStart} vs. {len(Ws_t)}'\n",
    "    assert 0 <= wEnd < len(Ws_t), f'0<= wEnd < len(Ws_t) does not hold: {wEnd} vs. {len(Ws_t)}'\n",
    "else:\n",
    "    print(f'Calculating all indices from 0 to len(Ws_t)-1 = {len(Ws_t)}-1 = {len(Ws_t)-1}')\n",
    "    blockRange = np.arange(len(Ws_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:11:36.935011Z",
     "start_time": "2019-08-11T02:11:36.923294Z"
    }
   },
   "outputs": [],
   "source": [
    "def uncalculated_words_by_context(context_id, wordRange=None):\n",
    "    if wordRange is None:\n",
    "        wordRange = blockRange\n",
    "        \n",
    "    with tiledb.DenseArray(array_name, mode='r') as A:\n",
    "        nanMask = np.isnan(A[:,context_id][dbName])\n",
    "#         print(nanMask)\n",
    "#         print(nanMask.shape)\n",
    "        uncalculated_indices = np.arange(len(Ws_t))[ nanMask ]\n",
    "#         uncalculated_indices_s = set(uncalculated_indices)\n",
    "#         uncalculated_indices_in_range = np.array(sorted(list( uncalculated_indices_s & set(wordRange) )))\n",
    "        uncalculated_indices_in_range = np.intersect1d(uncalculated_indices, wordRange)\n",
    "        return uncalculated_indices_in_range\n",
    "\n",
    "def uncalculated_contexts_by_word(word_id, contextRange=None):\n",
    "    if contextRange is None:\n",
    "        contextRange = np.arange(len(Cs_t)) #case 3-specific assumption\n",
    "        \n",
    "    with tiledb.DenseArray(array_name, mode='r') as A:\n",
    "        nanMask = np.isnan(A[word_id,:][dbName])\n",
    "#         print(nanMask)\n",
    "#         print(nanMask.shape)\n",
    "        uncalculated_indices = np.arange(len(Cs_t))[ nanMask ]\n",
    "#         uncalculated_indices_s = set(uncalculated_indices)\n",
    "#         uncalculated_indices_in_range = np.array(sorted(list( uncalculated_indices_s & set(contextRange) )))\n",
    "        uncalculated_indices_in_range = np.intersect1d(uncalculated_indices, contextRange)\n",
    "        return uncalculated_indices_in_range\n",
    "    \n",
    "def is_completely_calculated(word_id=None, context_id=None):\n",
    "    if word_id is not None:\n",
    "        return np.array_equal( uncalculated_contexts_by_word(word_id), \n",
    "                               np.array([], dtype=np.float32))\n",
    "    if context_id is not None:\n",
    "        return np.array_equal( uncalculated_contexts_by_context(context_id),\n",
    "                               np.array([], dtype=np.float32))\n",
    "    raise Exception('At least one argument must be non-null.')\n",
    "    \n",
    "def is_completely_calculated_w(w):\n",
    "    return is_completely_calculated(w)\n",
    "\n",
    "def is_completely_calculated_c(c): \n",
    "    return is_completely_calculated(context_id=c)\n",
    "    \n",
    "def get_completed_indices(dim='words', rangeOfInterest=None):\n",
    "    if dim == 'words':\n",
    "        if rangeOfInterest is None:\n",
    "            rangeOfInterest = np.arange(len(Ws_t))\n",
    "        return np.array([w_idx\n",
    "                         for w_idx in tqdm(rangeOfInterest, total=len(rangeOfInterest))\n",
    "                         if is_completely_calculated(word_id=w_idx)])\n",
    "#         selection_mask = par(delayed(is_completely_calculated)(w_idx)\n",
    "#                              for w_idx in rangeOfInterest)\n",
    "#         return rangeOfInterest[ np.array(selection_mask) ] \n",
    "    if dim == 'contexts':\n",
    "        if rangeOfInterest is None:\n",
    "            rangeOfInterest = np.arange(len(Cs_t))\n",
    "        return np.array([c_idx\n",
    "                         for c_idx in tqdm(rangeOfInterest, total=len(rangeOfInterest))\n",
    "                         if is_completely_calculated(context_id=c_idx)])\n",
    "#         selection_mask = par(delayed(is_completely_calculated_c)(c_idx)\n",
    "#                             for c_idx in rangeOfInterest)\n",
    "#         return rangeOfInterest[ np.array(selection_mask) ]\n",
    "    raise Exception(f\"dim must be one of {'words', 'contexts'}, got {dim} instead\")\n",
    "                    \n",
    "def get_incomplete_indices(dim='words', rangeOfInterest=None):\n",
    "    if dim == 'words':\n",
    "        if rangeOfInterest is None:\n",
    "            rangeOfInterest = np.arange(len(Ws_t))\n",
    "    if dim == 'contexts':\n",
    "        if rangeOfInterest is None:\n",
    "            rangeOfInterest = np.arange(len(Cs_t))\n",
    "    \n",
    "    completed_indices = get_completed_indices(dim=dim, rangeOfInterest=rangeOfInterest)\n",
    "    \n",
    "    return np.array([i for i in rangeOfInterest if i not in completed_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T01:37:02.582404Z",
     "start_time": "2019-08-11T01:37:02.573233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T01:33:22.479753Z",
     "start_time": "2019-08-11T01:33:22.383698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9172"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 273,  274,  275, ..., 9168, 9169, 9170])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 106292, 106293, 106294])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ws_t)\n",
    "uncalculated_words_by_context(context_id=6703)\n",
    "# uncalculated_indices(context_id=np.array([6703, 6704]))\n",
    "uncalculated_contexts_by_word(word_id=6703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:10:05.181352Z",
     "start_time": "2019-08-11T02:09:39.482084Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-461-219dbe8ac73a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_incomplete_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrangeOfInterest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblockRange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-460-e096c4797420>\u001b[0m in \u001b[0;36mget_incomplete_indices\u001b[0;34m(dim, rangeOfInterest)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mrangeOfInterest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcompleted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completed_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrangeOfInterest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrangeOfInterest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrangeOfInterest\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleted_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-460-e096c4797420>\u001b[0m in \u001b[0;36mget_completed_indices\u001b[0;34m(dim, rangeOfInterest)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#                          if is_completely_calculated(word_id=w_idx)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         selection_mask = par(delayed(is_completely_calculated)(w_idx)\n\u001b[0;32m---> 52\u001b[0;31m                              for w_idx in rangeOfInterest)\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrangeOfInterest\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'contexts'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-501a20251bb0>\u001b[0m in \u001b[0;36mpar\u001b[0;34m(gen_expr)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBACKEND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREFER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/jax/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jax/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jax/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jax/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jax/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jax/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_incomplete_indices(rangeOfInterest=blockRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:13:40.606862Z",
     "start_time": "2019-08-11T02:13:40.601312Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:18:36.910982Z",
     "start_time": "2019-08-11T02:16:47.006561Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9171 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 51/9171 [00:00<00:18, 504.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying incompletely calculated indices in block range...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 104/9171 [00:00<00:17, 508.98it/s]\u001b[A\n",
      "  2%|▏         | 157/9171 [00:00<00:17, 514.08it/s]\u001b[A\n",
      "  2%|▏         | 210/9171 [00:00<00:17, 518.73it/s]\u001b[A\n",
      "  3%|▎         | 263/9171 [00:00<00:17, 521.38it/s]\u001b[A\n",
      "  3%|▎         | 307/9171 [00:00<00:38, 231.33it/s]\u001b[A\n",
      "  4%|▎         | 341/9171 [00:01<00:58, 149.71it/s]\u001b[A\n",
      "  4%|▍         | 367/9171 [00:01<01:13, 120.40it/s]\u001b[A\n",
      "  4%|▍         | 388/9171 [00:01<01:22, 106.12it/s]\u001b[A\n",
      "  4%|▍         | 405/9171 [00:02<01:29, 97.89it/s] \u001b[A\n",
      "  5%|▍         | 420/9171 [00:02<01:34, 92.35it/s]\u001b[A\n",
      "  5%|▍         | 433/9171 [00:02<01:37, 89.52it/s]\u001b[A\n",
      "  5%|▍         | 445/9171 [00:02<01:40, 87.15it/s]\u001b[A\n",
      "  5%|▍         | 456/9171 [00:02<01:41, 85.61it/s]\u001b[A\n",
      "  5%|▌         | 466/9171 [00:02<01:43, 84.28it/s]\u001b[A\n",
      "  5%|▌         | 476/9171 [00:02<01:44, 83.19it/s]\u001b[A\n",
      "  5%|▌         | 485/9171 [00:03<01:45, 82.66it/s]\u001b[A\n",
      "  5%|▌         | 494/9171 [00:03<01:45, 81.96it/s]\u001b[A\n",
      "  5%|▌         | 503/9171 [00:03<01:45, 81.95it/s]\u001b[A\n",
      "  6%|▌         | 512/9171 [00:03<01:45, 82.38it/s]\u001b[A\n",
      "  6%|▌         | 521/9171 [00:03<01:45, 82.19it/s]\u001b[A\n",
      "  6%|▌         | 530/9171 [00:03<01:44, 82.32it/s]\u001b[A\n",
      "  6%|▌         | 539/9171 [00:03<01:45, 81.48it/s]\u001b[A\n",
      "  6%|▌         | 548/9171 [00:03<01:46, 81.27it/s]\u001b[A\n",
      "  6%|▌         | 557/9171 [00:03<01:45, 81.41it/s]\u001b[A\n",
      "  6%|▌         | 566/9171 [00:04<01:45, 81.58it/s]\u001b[A\n",
      "  6%|▋         | 575/9171 [00:04<01:45, 81.32it/s]\u001b[A\n",
      "  6%|▋         | 584/9171 [00:04<01:45, 81.21it/s]\u001b[A\n",
      "  6%|▋         | 593/9171 [00:04<01:44, 81.72it/s]\u001b[A\n",
      "  7%|▋         | 602/9171 [00:04<01:45, 81.60it/s]\u001b[A\n",
      "  7%|▋         | 611/9171 [00:04<01:45, 81.19it/s]\u001b[A\n",
      "  7%|▋         | 620/9171 [00:04<01:45, 80.94it/s]\u001b[A\n",
      "  7%|▋         | 629/9171 [00:04<01:45, 81.09it/s]\u001b[A\n",
      "  7%|▋         | 638/9171 [00:04<01:45, 81.15it/s]\u001b[A\n",
      "  7%|▋         | 647/9171 [00:05<01:45, 81.11it/s]\u001b[A\n",
      "  7%|▋         | 656/9171 [00:05<01:45, 80.99it/s]\u001b[A\n",
      "  7%|▋         | 665/9171 [00:05<01:45, 80.84it/s]\u001b[A\n",
      "  7%|▋         | 674/9171 [00:05<01:45, 80.63it/s]\u001b[A\n",
      "  7%|▋         | 683/9171 [00:05<01:45, 80.41it/s]\u001b[A\n",
      "  8%|▊         | 692/9171 [00:05<01:45, 80.35it/s]\u001b[A\n",
      "  8%|▊         | 701/9171 [00:05<01:45, 80.26it/s]\u001b[A\n",
      "  8%|▊         | 710/9171 [00:05<01:44, 80.63it/s]\u001b[A\n",
      "  8%|▊         | 719/9171 [00:05<01:44, 80.85it/s]\u001b[A\n",
      "  8%|▊         | 728/9171 [00:06<01:44, 81.09it/s]\u001b[A\n",
      "  8%|▊         | 737/9171 [00:06<01:43, 81.38it/s]\u001b[A\n",
      "  8%|▊         | 746/9171 [00:06<01:43, 81.57it/s]\u001b[A\n",
      "  8%|▊         | 755/9171 [00:06<01:43, 81.58it/s]\u001b[A\n",
      "  8%|▊         | 764/9171 [00:06<01:42, 81.68it/s]\u001b[A\n",
      "  8%|▊         | 773/9171 [00:06<01:42, 81.69it/s]\u001b[A\n",
      "  9%|▊         | 782/9171 [00:06<01:43, 80.95it/s]\u001b[A\n",
      "  9%|▊         | 791/9171 [00:06<01:43, 80.64it/s]\u001b[A\n",
      "  9%|▊         | 800/9171 [00:06<01:43, 80.54it/s]\u001b[A\n",
      "  9%|▉         | 809/9171 [00:07<01:43, 80.62it/s]\u001b[A\n",
      "  9%|▉         | 818/9171 [00:07<01:43, 81.02it/s]\u001b[A\n",
      "  9%|▉         | 827/9171 [00:07<01:42, 81.24it/s]\u001b[A\n",
      "  9%|▉         | 836/9171 [00:07<01:42, 81.57it/s]\u001b[A\n",
      "  9%|▉         | 845/9171 [00:07<01:42, 81.55it/s]\u001b[A\n",
      "  9%|▉         | 854/9171 [00:07<01:41, 81.57it/s]\u001b[A\n",
      "  9%|▉         | 863/9171 [00:07<01:41, 81.75it/s]\u001b[A\n",
      " 10%|▉         | 872/9171 [00:07<01:42, 81.24it/s]\u001b[A\n",
      " 10%|▉         | 881/9171 [00:07<01:41, 81.43it/s]\u001b[A\n",
      " 10%|▉         | 890/9171 [00:08<01:41, 81.24it/s]\u001b[A\n",
      " 10%|▉         | 899/9171 [00:08<01:41, 81.23it/s]\u001b[A\n",
      " 10%|▉         | 908/9171 [00:08<01:42, 80.83it/s]\u001b[A\n",
      " 10%|▉         | 917/9171 [00:08<01:42, 80.78it/s]\u001b[A\n",
      " 10%|█         | 926/9171 [00:08<01:41, 80.97it/s]\u001b[A\n",
      " 10%|█         | 935/9171 [00:08<01:41, 81.22it/s]\u001b[A\n",
      " 10%|█         | 944/9171 [00:08<01:41, 81.43it/s]\u001b[A\n",
      " 10%|█         | 953/9171 [00:08<01:40, 81.38it/s]\u001b[A\n",
      " 10%|█         | 962/9171 [00:08<01:40, 81.35it/s]\u001b[A\n",
      " 11%|█         | 971/9171 [00:09<01:40, 81.26it/s]\u001b[A\n",
      " 11%|█         | 980/9171 [00:09<01:40, 81.41it/s]\u001b[A\n",
      " 11%|█         | 989/9171 [00:09<01:40, 81.77it/s]\u001b[A\n",
      " 11%|█         | 998/9171 [00:09<01:40, 81.42it/s]\u001b[A\n",
      " 11%|█         | 1007/9171 [00:09<01:40, 81.19it/s]\u001b[A\n",
      " 11%|█         | 1016/9171 [00:09<01:40, 81.32it/s]\u001b[A\n",
      " 11%|█         | 1025/9171 [00:09<01:39, 81.53it/s]\u001b[A\n",
      " 11%|█▏        | 1034/9171 [00:09<01:40, 80.94it/s]\u001b[A\n",
      " 11%|█▏        | 1043/9171 [00:09<01:41, 80.26it/s]\u001b[A\n",
      " 11%|█▏        | 1052/9171 [00:10<01:41, 80.39it/s]\u001b[A\n",
      " 12%|█▏        | 1061/9171 [00:10<01:40, 80.61it/s]\u001b[A\n",
      " 12%|█▏        | 1070/9171 [00:10<01:39, 81.29it/s]\u001b[A\n",
      " 12%|█▏        | 1079/9171 [00:10<01:39, 81.13it/s]\u001b[A\n",
      " 12%|█▏        | 1088/9171 [00:10<01:39, 80.94it/s]\u001b[A\n",
      " 12%|█▏        | 1097/9171 [00:10<01:40, 80.72it/s]\u001b[A\n",
      " 12%|█▏        | 1106/9171 [00:10<01:39, 80.89it/s]\u001b[A\n",
      " 12%|█▏        | 1115/9171 [00:10<01:39, 81.13it/s]\u001b[A\n",
      " 12%|█▏        | 1124/9171 [00:10<01:39, 80.82it/s]\u001b[A\n",
      " 12%|█▏        | 1133/9171 [00:11<01:39, 80.79it/s]\u001b[A\n",
      " 12%|█▏        | 1142/9171 [00:11<01:39, 80.50it/s]\u001b[A\n",
      " 13%|█▎        | 1151/9171 [00:11<01:40, 80.18it/s]\u001b[A\n",
      " 13%|█▎        | 1160/9171 [00:11<01:40, 79.94it/s]\u001b[A\n",
      " 13%|█▎        | 1168/9171 [00:11<01:40, 79.73it/s]\u001b[A\n",
      " 13%|█▎        | 1177/9171 [00:11<01:40, 79.87it/s]\u001b[A\n",
      " 13%|█▎        | 1186/9171 [00:11<01:39, 80.60it/s]\u001b[A\n",
      " 13%|█▎        | 1195/9171 [00:11<01:38, 81.37it/s]\u001b[A\n",
      " 13%|█▎        | 1204/9171 [00:11<01:38, 81.03it/s]\u001b[A\n",
      " 13%|█▎        | 1213/9171 [00:12<01:38, 80.73it/s]\u001b[A\n",
      " 13%|█▎        | 1222/9171 [00:12<01:38, 80.41it/s]\u001b[A\n",
      " 13%|█▎        | 1231/9171 [00:12<01:38, 80.63it/s]\u001b[A\n",
      " 14%|█▎        | 1240/9171 [00:12<01:37, 80.95it/s]\u001b[A\n",
      " 14%|█▎        | 1249/9171 [00:12<01:38, 80.82it/s]\u001b[A\n",
      " 14%|█▎        | 1258/9171 [00:12<01:38, 80.59it/s]\u001b[A\n",
      " 14%|█▍        | 1267/9171 [00:12<01:38, 80.62it/s]\u001b[A\n",
      " 14%|█▍        | 1276/9171 [00:12<01:38, 80.20it/s]\u001b[A\n",
      " 14%|█▍        | 1285/9171 [00:12<01:38, 80.09it/s]\u001b[A\n",
      " 14%|█▍        | 1294/9171 [00:13<01:38, 80.32it/s]\u001b[A\n",
      " 14%|█▍        | 1303/9171 [00:13<01:37, 80.72it/s]\u001b[A\n",
      " 14%|█▍        | 1312/9171 [00:13<01:37, 80.97it/s]\u001b[A\n",
      " 14%|█▍        | 1321/9171 [00:13<01:36, 81.09it/s]\u001b[A\n",
      " 15%|█▍        | 1330/9171 [00:13<01:36, 80.93it/s]\u001b[A\n",
      " 15%|█▍        | 1339/9171 [00:13<01:37, 80.61it/s]\u001b[A\n",
      " 15%|█▍        | 1348/9171 [00:13<01:36, 80.87it/s]\u001b[A\n",
      " 15%|█▍        | 1357/9171 [00:13<01:36, 80.98it/s]\u001b[A\n",
      " 15%|█▍        | 1366/9171 [00:13<01:36, 80.99it/s]\u001b[A\n",
      " 15%|█▍        | 1375/9171 [00:14<01:37, 80.18it/s]\u001b[A\n",
      " 15%|█▌        | 1384/9171 [00:14<01:36, 80.44it/s]\u001b[A\n",
      " 15%|█▌        | 1393/9171 [00:14<01:36, 80.21it/s]\u001b[A\n",
      " 15%|█▌        | 1402/9171 [00:14<01:37, 79.62it/s]\u001b[A\n",
      " 15%|█▌        | 1410/9171 [00:14<01:37, 79.51it/s]\u001b[A\n",
      " 15%|█▌        | 1418/9171 [00:14<01:37, 79.54it/s]\u001b[A\n",
      " 16%|█▌        | 1427/9171 [00:14<01:36, 80.05it/s]\u001b[A\n",
      " 16%|█▌        | 1436/9171 [00:14<01:36, 80.49it/s]\u001b[A\n",
      " 16%|█▌        | 1445/9171 [00:14<01:35, 80.67it/s]\u001b[A\n",
      " 16%|█▌        | 1454/9171 [00:15<01:35, 80.41it/s]\u001b[A\n",
      " 16%|█▌        | 1463/9171 [00:15<01:35, 80.52it/s]\u001b[A\n",
      " 16%|█▌        | 1472/9171 [00:15<01:35, 80.86it/s]\u001b[A\n",
      " 16%|█▌        | 1481/9171 [00:15<01:34, 80.98it/s]\u001b[A\n",
      " 16%|█▌        | 1490/9171 [00:15<01:34, 81.01it/s]\u001b[A\n",
      " 16%|█▋        | 1499/9171 [00:15<01:34, 80.79it/s]\u001b[A\n",
      " 16%|█▋        | 1508/9171 [00:15<01:34, 81.00it/s]\u001b[A\n",
      " 17%|█▋        | 1517/9171 [00:15<01:35, 80.54it/s]\u001b[A\n",
      " 17%|█▋        | 1526/9171 [00:15<01:35, 80.21it/s]\u001b[A\n",
      " 17%|█▋        | 1535/9171 [00:16<01:35, 80.20it/s]\u001b[A\n",
      " 17%|█▋        | 1544/9171 [00:16<01:35, 80.09it/s]\u001b[A\n",
      " 17%|█▋        | 1553/9171 [00:16<01:34, 80.23it/s]\u001b[A\n",
      " 17%|█▋        | 1562/9171 [00:16<01:34, 80.78it/s]\u001b[A\n",
      " 17%|█▋        | 1571/9171 [00:16<01:33, 80.86it/s]\u001b[A\n",
      " 17%|█▋        | 1580/9171 [00:16<01:33, 80.76it/s]\u001b[A\n",
      " 17%|█▋        | 1589/9171 [00:16<01:33, 81.20it/s]\u001b[A\n",
      " 17%|█▋        | 1598/9171 [00:16<01:32, 81.62it/s]\u001b[A\n",
      " 18%|█▊        | 1607/9171 [00:16<01:32, 81.88it/s]\u001b[A\n",
      " 18%|█▊        | 1616/9171 [00:17<01:32, 81.81it/s]\u001b[A\n",
      " 18%|█▊        | 1625/9171 [00:17<01:32, 81.19it/s]\u001b[A\n",
      " 18%|█▊        | 1634/9171 [00:17<01:33, 80.96it/s]\u001b[A\n",
      " 18%|█▊        | 1643/9171 [00:17<01:32, 81.16it/s]\u001b[A\n",
      " 18%|█▊        | 1652/9171 [00:17<01:32, 81.15it/s]\u001b[A\n",
      " 18%|█▊        | 1661/9171 [00:17<01:32, 80.86it/s]\u001b[A\n",
      " 18%|█▊        | 1670/9171 [00:17<01:32, 80.92it/s]\u001b[A\n",
      " 18%|█▊        | 1679/9171 [00:17<01:32, 80.97it/s]\u001b[A\n",
      " 18%|█▊        | 1688/9171 [00:17<01:32, 80.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1697/9171 [00:18<01:32, 80.74it/s]\u001b[A\n",
      " 19%|█▊        | 1706/9171 [00:18<01:32, 80.33it/s]\u001b[A\n",
      " 19%|█▊        | 1715/9171 [00:18<01:32, 80.89it/s]\u001b[A\n",
      " 19%|█▉        | 1724/9171 [00:18<01:31, 80.99it/s]\u001b[A\n",
      " 19%|█▉        | 1733/9171 [00:18<01:31, 80.94it/s]\u001b[A\n",
      " 19%|█▉        | 1742/9171 [00:18<01:32, 80.62it/s]\u001b[A\n",
      " 19%|█▉        | 1751/9171 [00:18<01:32, 80.54it/s]\u001b[A\n",
      " 19%|█▉        | 1760/9171 [00:18<01:32, 80.23it/s]\u001b[A\n",
      " 19%|█▉        | 1769/9171 [00:18<01:32, 80.12it/s]\u001b[A\n",
      " 19%|█▉        | 1778/9171 [00:19<01:32, 80.19it/s]\u001b[A\n",
      " 19%|█▉        | 1787/9171 [00:19<01:32, 80.15it/s]\u001b[A\n",
      " 20%|█▉        | 1796/9171 [00:19<01:31, 80.43it/s]\u001b[A\n",
      " 20%|█▉        | 1805/9171 [00:19<01:31, 80.81it/s]\u001b[A\n",
      " 20%|█▉        | 1814/9171 [00:19<01:30, 80.86it/s]\u001b[A\n",
      " 20%|█▉        | 1823/9171 [00:19<01:31, 80.74it/s]\u001b[A\n",
      " 20%|█▉        | 1832/9171 [00:19<01:30, 80.93it/s]\u001b[A\n",
      " 20%|██        | 1841/9171 [00:19<01:30, 81.14it/s]\u001b[A\n",
      " 20%|██        | 1850/9171 [00:19<01:30, 81.16it/s]\u001b[A\n",
      " 20%|██        | 1859/9171 [00:20<01:30, 81.09it/s]\u001b[A\n",
      " 20%|██        | 1868/9171 [00:20<01:30, 81.00it/s]\u001b[A\n",
      " 20%|██        | 1877/9171 [00:20<01:30, 80.53it/s]\u001b[A\n",
      " 21%|██        | 1886/9171 [00:20<01:30, 80.70it/s]\u001b[A\n",
      " 21%|██        | 1895/9171 [00:20<01:30, 80.83it/s]\u001b[A\n",
      " 21%|██        | 1904/9171 [00:20<01:30, 80.57it/s]\u001b[A\n",
      " 21%|██        | 1913/9171 [00:20<01:30, 80.42it/s]\u001b[A\n",
      " 21%|██        | 1922/9171 [00:20<01:29, 80.83it/s]\u001b[A\n",
      " 21%|██        | 1931/9171 [00:20<01:29, 81.15it/s]\u001b[A\n",
      " 21%|██        | 1940/9171 [00:21<01:29, 81.25it/s]\u001b[A\n",
      " 21%|██▏       | 1949/9171 [00:21<01:28, 81.54it/s]\u001b[A\n",
      " 21%|██▏       | 1958/9171 [00:21<01:28, 81.47it/s]\u001b[A\n",
      " 21%|██▏       | 1967/9171 [00:21<01:28, 81.60it/s]\u001b[A\n",
      " 22%|██▏       | 1976/9171 [00:21<01:28, 81.55it/s]\u001b[A\n",
      " 22%|██▏       | 1985/9171 [00:21<01:28, 81.15it/s]\u001b[A\n",
      " 22%|██▏       | 1994/9171 [00:21<01:28, 81.09it/s]\u001b[A\n",
      " 22%|██▏       | 2003/9171 [00:21<01:28, 80.82it/s]\u001b[A\n",
      " 22%|██▏       | 2012/9171 [00:21<01:28, 80.81it/s]\u001b[A\n",
      " 22%|██▏       | 2021/9171 [00:22<01:28, 80.77it/s]\u001b[A\n",
      " 22%|██▏       | 2030/9171 [00:22<01:28, 80.71it/s]\u001b[A\n",
      " 22%|██▏       | 2039/9171 [00:22<01:28, 80.71it/s]\u001b[A\n",
      " 22%|██▏       | 2048/9171 [00:22<01:27, 81.20it/s]\u001b[A\n",
      " 22%|██▏       | 2057/9171 [00:22<01:27, 81.22it/s]\u001b[A\n",
      " 23%|██▎       | 2066/9171 [00:22<01:27, 80.94it/s]\u001b[A\n",
      " 23%|██▎       | 2075/9171 [00:22<01:27, 80.99it/s]\u001b[A\n",
      " 23%|██▎       | 2084/9171 [00:22<01:27, 80.63it/s]\u001b[A\n",
      " 23%|██▎       | 2093/9171 [00:22<01:27, 80.52it/s]\u001b[A\n",
      " 23%|██▎       | 2102/9171 [00:23<01:27, 80.54it/s]\u001b[A\n",
      " 23%|██▎       | 2111/9171 [00:23<01:27, 80.43it/s]\u001b[A\n",
      " 23%|██▎       | 2120/9171 [00:23<01:27, 80.59it/s]\u001b[A\n",
      " 23%|██▎       | 2129/9171 [00:23<01:27, 80.89it/s]\u001b[A\n",
      " 23%|██▎       | 2138/9171 [00:23<01:26, 81.06it/s]\u001b[A\n",
      " 23%|██▎       | 2147/9171 [00:23<01:26, 81.18it/s]\u001b[A\n",
      " 24%|██▎       | 2156/9171 [00:23<01:26, 81.54it/s]\u001b[A\n",
      " 24%|██▎       | 2165/9171 [00:23<01:25, 81.71it/s]\u001b[A\n",
      " 24%|██▎       | 2174/9171 [00:23<01:25, 82.13it/s]\u001b[A\n",
      " 24%|██▍       | 2183/9171 [00:24<01:25, 81.74it/s]\u001b[A\n",
      " 24%|██▍       | 2192/9171 [00:24<01:25, 81.70it/s]\u001b[A\n",
      " 24%|██▍       | 2201/9171 [00:24<01:25, 81.97it/s]\u001b[A\n",
      " 24%|██▍       | 2210/9171 [00:24<01:25, 81.76it/s]\u001b[A\n",
      " 24%|██▍       | 2219/9171 [00:24<01:25, 81.67it/s]\u001b[A\n",
      " 24%|██▍       | 2228/9171 [00:24<01:24, 81.78it/s]\u001b[A\n",
      " 24%|██▍       | 2237/9171 [00:24<01:24, 81.66it/s]\u001b[A\n",
      " 24%|██▍       | 2246/9171 [00:24<01:25, 81.18it/s]\u001b[A\n",
      " 25%|██▍       | 2255/9171 [00:24<01:25, 81.26it/s]\u001b[A\n",
      " 25%|██▍       | 2264/9171 [00:25<01:25, 81.09it/s]\u001b[A\n",
      " 25%|██▍       | 2273/9171 [00:25<01:24, 81.55it/s]\u001b[A\n",
      " 25%|██▍       | 2282/9171 [00:25<01:24, 81.63it/s]\u001b[A\n",
      " 25%|██▍       | 2291/9171 [00:25<01:24, 81.36it/s]\u001b[A\n",
      " 25%|██▌       | 2300/9171 [00:25<01:24, 81.40it/s]\u001b[A\n",
      " 25%|██▌       | 2309/9171 [00:25<01:24, 81.63it/s]\u001b[A\n",
      " 25%|██▌       | 2318/9171 [00:25<01:23, 82.09it/s]\u001b[A\n",
      " 25%|██▌       | 2327/9171 [00:25<01:23, 81.94it/s]\u001b[A\n",
      " 25%|██▌       | 2336/9171 [00:25<01:23, 81.81it/s]\u001b[A\n",
      " 26%|██▌       | 2345/9171 [00:26<01:23, 81.45it/s]\u001b[A\n",
      " 26%|██▌       | 2354/9171 [00:26<01:23, 81.19it/s]\u001b[A\n",
      " 26%|██▌       | 2363/9171 [00:26<01:23, 81.48it/s]\u001b[A\n",
      " 26%|██▌       | 2372/9171 [00:26<01:23, 81.14it/s]\u001b[A\n",
      " 26%|██▌       | 2381/9171 [00:26<01:23, 80.84it/s]\u001b[A\n",
      " 26%|██▌       | 2390/9171 [00:26<01:24, 80.68it/s]\u001b[A\n",
      " 26%|██▌       | 2399/9171 [00:26<01:23, 81.32it/s]\u001b[A\n",
      " 26%|██▋       | 2408/9171 [00:26<01:23, 81.33it/s]\u001b[A\n",
      " 26%|██▋       | 2417/9171 [00:26<01:23, 81.14it/s]\u001b[A\n",
      " 26%|██▋       | 2426/9171 [00:27<01:23, 80.54it/s]\u001b[A\n",
      " 27%|██▋       | 2435/9171 [00:27<01:23, 80.63it/s]\u001b[A\n",
      " 27%|██▋       | 2444/9171 [00:27<01:23, 80.85it/s]\u001b[A\n",
      " 27%|██▋       | 2453/9171 [00:27<01:22, 81.12it/s]\u001b[A\n",
      " 27%|██▋       | 2462/9171 [00:27<01:22, 80.87it/s]\u001b[A\n",
      " 27%|██▋       | 2471/9171 [00:27<01:22, 81.10it/s]\u001b[A\n",
      " 27%|██▋       | 2480/9171 [00:27<01:22, 81.45it/s]\u001b[A\n",
      " 27%|██▋       | 2489/9171 [00:27<01:21, 81.79it/s]\u001b[A\n",
      " 27%|██▋       | 2498/9171 [00:27<01:21, 81.52it/s]\u001b[A\n",
      " 27%|██▋       | 2507/9171 [00:28<01:22, 81.00it/s]\u001b[A\n",
      " 27%|██▋       | 2516/9171 [00:28<01:22, 80.79it/s]\u001b[A\n",
      " 28%|██▊       | 2525/9171 [00:28<01:21, 81.24it/s]\u001b[A\n",
      " 28%|██▊       | 2534/9171 [00:28<01:21, 81.45it/s]\u001b[A\n",
      " 28%|██▊       | 2543/9171 [00:28<01:21, 81.15it/s]\u001b[A\n",
      " 28%|██▊       | 2552/9171 [00:28<01:21, 80.90it/s]\u001b[A\n",
      " 28%|██▊       | 2561/9171 [00:28<01:21, 81.15it/s]\u001b[A\n",
      " 28%|██▊       | 2570/9171 [00:28<01:21, 81.24it/s]\u001b[A\n",
      " 28%|██▊       | 2579/9171 [00:28<01:20, 81.50it/s]\u001b[A\n",
      " 28%|██▊       | 2588/9171 [00:29<01:21, 81.04it/s]\u001b[A\n",
      " 28%|██▊       | 2597/9171 [00:29<01:21, 80.87it/s]\u001b[A\n",
      " 28%|██▊       | 2606/9171 [00:29<01:20, 81.21it/s]\u001b[A\n",
      " 29%|██▊       | 2615/9171 [00:29<01:21, 80.65it/s]\u001b[A\n",
      " 29%|██▊       | 2624/9171 [00:29<01:21, 79.97it/s]\u001b[A\n",
      " 29%|██▊       | 2633/9171 [00:29<01:21, 80.17it/s]\u001b[A\n",
      " 29%|██▉       | 2642/9171 [00:29<01:20, 80.94it/s]\u001b[A\n",
      " 29%|██▉       | 2651/9171 [00:29<01:20, 81.07it/s]\u001b[A\n",
      " 29%|██▉       | 2660/9171 [00:29<01:20, 81.17it/s]\u001b[A\n",
      " 29%|██▉       | 2669/9171 [00:30<01:20, 80.76it/s]\u001b[A\n",
      " 29%|██▉       | 2678/9171 [00:30<01:20, 80.89it/s]\u001b[A\n",
      " 29%|██▉       | 2687/9171 [00:30<01:19, 81.25it/s]\u001b[A\n",
      " 29%|██▉       | 2696/9171 [00:30<01:19, 81.49it/s]\u001b[A\n",
      " 29%|██▉       | 2705/9171 [00:30<01:19, 81.27it/s]\u001b[A\n",
      " 30%|██▉       | 2714/9171 [00:30<01:19, 80.94it/s]\u001b[A\n",
      " 30%|██▉       | 2723/9171 [00:30<01:19, 81.49it/s]\u001b[A\n",
      " 30%|██▉       | 2732/9171 [00:30<01:19, 80.97it/s]\u001b[A\n",
      " 30%|██▉       | 2741/9171 [00:30<01:19, 80.55it/s]\u001b[A\n",
      " 30%|██▉       | 2750/9171 [00:31<01:19, 80.40it/s]\u001b[A\n",
      " 30%|███       | 2759/9171 [00:31<01:19, 80.88it/s]\u001b[A\n",
      " 30%|███       | 2768/9171 [00:31<01:19, 80.99it/s]\u001b[A\n",
      " 30%|███       | 2777/9171 [00:31<01:18, 81.31it/s]\u001b[A\n",
      " 30%|███       | 2786/9171 [00:31<01:18, 81.14it/s]\u001b[A\n",
      " 30%|███       | 2795/9171 [00:31<01:18, 81.02it/s]\u001b[A\n",
      " 31%|███       | 2804/9171 [00:31<01:18, 81.22it/s]\u001b[A\n",
      " 31%|███       | 2813/9171 [00:31<01:17, 81.70it/s]\u001b[A\n",
      " 31%|███       | 2822/9171 [00:31<01:17, 81.79it/s]\u001b[A\n",
      " 31%|███       | 2831/9171 [00:32<01:17, 81.66it/s]\u001b[A\n",
      " 31%|███       | 2840/9171 [00:32<01:18, 81.06it/s]\u001b[A\n",
      " 31%|███       | 2849/9171 [00:32<01:17, 81.26it/s]\u001b[A\n",
      " 31%|███       | 2858/9171 [00:32<01:17, 81.47it/s]\u001b[A\n",
      " 31%|███▏      | 2867/9171 [00:32<01:17, 81.63it/s]\u001b[A\n",
      " 31%|███▏      | 2876/9171 [00:32<01:17, 81.48it/s]\u001b[A\n",
      " 31%|███▏      | 2885/9171 [00:32<01:17, 81.57it/s]\u001b[A\n",
      " 32%|███▏      | 2894/9171 [00:32<01:18, 80.17it/s]\u001b[A\n",
      " 32%|███▏      | 2903/9171 [00:32<01:18, 79.79it/s]\u001b[A\n",
      " 32%|███▏      | 2912/9171 [00:33<01:18, 79.95it/s]\u001b[A\n",
      " 32%|███▏      | 2921/9171 [00:33<01:18, 80.02it/s]\u001b[A\n",
      " 32%|███▏      | 2930/9171 [00:33<01:17, 80.64it/s]\u001b[A\n",
      " 32%|███▏      | 2939/9171 [00:33<01:16, 81.40it/s]\u001b[A\n",
      " 32%|███▏      | 2948/9171 [00:33<01:16, 81.51it/s]\u001b[A\n",
      " 32%|███▏      | 2957/9171 [00:33<01:15, 81.78it/s]\u001b[A\n",
      " 32%|███▏      | 2966/9171 [00:33<01:16, 81.56it/s]\u001b[A\n",
      " 32%|███▏      | 2975/9171 [00:33<01:15, 82.02it/s]\u001b[A\n",
      " 33%|███▎      | 2984/9171 [00:33<01:16, 81.13it/s]\u001b[A\n",
      " 33%|███▎      | 2993/9171 [00:34<01:16, 80.83it/s]\u001b[A\n",
      " 33%|███▎      | 3002/9171 [00:34<01:16, 80.34it/s]\u001b[A\n",
      " 33%|███▎      | 3011/9171 [00:34<01:16, 80.61it/s]\u001b[A\n",
      " 33%|███▎      | 3020/9171 [00:34<01:15, 81.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3029/9171 [00:34<01:15, 80.99it/s]\u001b[A\n",
      " 33%|███▎      | 3038/9171 [00:34<01:15, 81.33it/s]\u001b[A\n",
      " 33%|███▎      | 3047/9171 [00:34<01:15, 81.65it/s]\u001b[A\n",
      " 33%|███▎      | 3056/9171 [00:34<01:14, 81.82it/s]\u001b[A\n",
      " 33%|███▎      | 3065/9171 [00:34<01:14, 82.13it/s]\u001b[A\n",
      " 34%|███▎      | 3074/9171 [00:35<01:14, 81.78it/s]\u001b[A\n",
      " 34%|███▎      | 3083/9171 [00:35<01:14, 81.52it/s]\u001b[A\n",
      " 34%|███▎      | 3092/9171 [00:35<01:15, 80.61it/s]\u001b[A\n",
      " 34%|███▍      | 3101/9171 [00:35<01:20, 75.58it/s]\u001b[A\n",
      " 34%|███▍      | 3109/9171 [00:35<01:20, 75.24it/s]\u001b[A\n",
      " 34%|███▍      | 3118/9171 [00:35<01:18, 77.21it/s]\u001b[A\n",
      " 34%|███▍      | 3127/9171 [00:35<01:17, 78.49it/s]\u001b[A\n",
      " 34%|███▍      | 3136/9171 [00:35<01:15, 79.57it/s]\u001b[A\n",
      " 34%|███▍      | 3145/9171 [00:35<01:14, 80.41it/s]\u001b[A\n",
      " 34%|███▍      | 3154/9171 [00:36<01:14, 80.46it/s]\u001b[A\n",
      " 34%|███▍      | 3163/9171 [00:36<01:14, 80.96it/s]\u001b[A\n",
      " 35%|███▍      | 3172/9171 [00:36<01:13, 81.07it/s]\u001b[A\n",
      " 35%|███▍      | 3181/9171 [00:36<01:13, 81.63it/s]\u001b[A\n",
      " 35%|███▍      | 3190/9171 [00:36<01:13, 81.78it/s]\u001b[A\n",
      " 35%|███▍      | 3199/9171 [00:36<01:13, 81.62it/s]\u001b[A\n",
      " 35%|███▍      | 3208/9171 [00:36<01:12, 81.79it/s]\u001b[A\n",
      " 35%|███▌      | 3217/9171 [00:36<01:12, 81.75it/s]\u001b[A\n",
      " 35%|███▌      | 3226/9171 [00:36<01:12, 81.66it/s]\u001b[A\n",
      " 35%|███▌      | 3235/9171 [00:37<01:12, 81.50it/s]\u001b[A\n",
      " 35%|███▌      | 3244/9171 [00:37<01:12, 81.53it/s]\u001b[A\n",
      " 35%|███▌      | 3253/9171 [00:37<01:12, 81.54it/s]\u001b[A\n",
      " 36%|███▌      | 3262/9171 [00:37<01:12, 81.86it/s]\u001b[A\n",
      " 36%|███▌      | 3271/9171 [00:37<01:12, 81.82it/s]\u001b[A\n",
      " 36%|███▌      | 3280/9171 [00:37<01:11, 82.04it/s]\u001b[A\n",
      " 36%|███▌      | 3289/9171 [00:37<01:11, 82.29it/s]\u001b[A\n",
      " 36%|███▌      | 3298/9171 [00:37<01:11, 82.22it/s]\u001b[A\n",
      " 36%|███▌      | 3307/9171 [00:37<01:11, 81.94it/s]\u001b[A\n",
      " 36%|███▌      | 3316/9171 [00:38<01:11, 82.10it/s]\u001b[A\n",
      " 36%|███▋      | 3325/9171 [00:38<01:11, 81.56it/s]\u001b[A\n",
      " 36%|███▋      | 3334/9171 [00:38<01:11, 81.30it/s]\u001b[A\n",
      " 36%|███▋      | 3343/9171 [00:38<01:11, 81.46it/s]\u001b[A\n",
      " 37%|███▋      | 3352/9171 [00:38<01:11, 81.29it/s]\u001b[A\n",
      " 37%|███▋      | 3361/9171 [00:38<01:11, 81.25it/s]\u001b[A\n",
      " 37%|███▋      | 3370/9171 [00:38<01:11, 81.51it/s]\u001b[A\n",
      " 37%|███▋      | 3379/9171 [00:38<01:11, 81.40it/s]\u001b[A\n",
      " 37%|███▋      | 3388/9171 [00:38<01:11, 81.31it/s]\u001b[A\n",
      " 37%|███▋      | 3397/9171 [00:39<01:11, 81.20it/s]\u001b[A\n",
      " 37%|███▋      | 3406/9171 [00:39<01:11, 80.77it/s]\u001b[A\n",
      " 37%|███▋      | 3415/9171 [00:39<01:11, 80.92it/s]\u001b[A\n",
      " 37%|███▋      | 3424/9171 [00:39<01:11, 80.86it/s]\u001b[A\n",
      " 37%|███▋      | 3433/9171 [00:39<01:10, 80.84it/s]\u001b[A\n",
      " 38%|███▊      | 3442/9171 [00:39<01:10, 81.33it/s]\u001b[A\n",
      " 38%|███▊      | 3451/9171 [00:39<01:10, 81.52it/s]\u001b[A\n",
      " 38%|███▊      | 3460/9171 [00:39<01:09, 81.72it/s]\u001b[A\n",
      " 38%|███▊      | 3469/9171 [00:39<01:10, 81.37it/s]\u001b[A\n",
      " 38%|███▊      | 3478/9171 [00:40<01:10, 81.20it/s]\u001b[A\n",
      " 38%|███▊      | 3487/9171 [00:40<01:10, 80.67it/s]\u001b[A\n",
      " 38%|███▊      | 3496/9171 [00:40<01:10, 80.70it/s]\u001b[A\n",
      " 38%|███▊      | 3505/9171 [00:40<01:10, 80.61it/s]\u001b[A\n",
      " 38%|███▊      | 3514/9171 [00:40<01:10, 80.68it/s]\u001b[A\n",
      " 38%|███▊      | 3523/9171 [00:40<01:09, 80.85it/s]\u001b[A\n",
      " 39%|███▊      | 3532/9171 [00:40<01:09, 80.99it/s]\u001b[A\n",
      " 39%|███▊      | 3541/9171 [00:40<01:09, 81.08it/s]\u001b[A\n",
      " 39%|███▊      | 3550/9171 [00:40<01:09, 80.45it/s]\u001b[A\n",
      " 39%|███▉      | 3559/9171 [00:41<01:09, 80.24it/s]\u001b[A\n",
      " 39%|███▉      | 3568/9171 [00:41<01:09, 80.08it/s]\u001b[A\n",
      " 39%|███▉      | 3577/9171 [00:41<01:09, 80.46it/s]\u001b[A\n",
      " 39%|███▉      | 3586/9171 [00:41<01:09, 80.55it/s]\u001b[A\n",
      " 39%|███▉      | 3595/9171 [00:41<01:09, 80.18it/s]\u001b[A\n",
      " 39%|███▉      | 3604/9171 [00:41<01:09, 80.63it/s]\u001b[A\n",
      " 39%|███▉      | 3613/9171 [00:41<01:08, 80.82it/s]\u001b[A\n",
      " 39%|███▉      | 3622/9171 [00:41<01:08, 81.03it/s]\u001b[A\n",
      " 40%|███▉      | 3631/9171 [00:41<01:08, 80.81it/s]\u001b[A\n",
      " 40%|███▉      | 3640/9171 [00:42<01:08, 80.73it/s]\u001b[A\n",
      " 40%|███▉      | 3649/9171 [00:42<01:08, 80.55it/s]\u001b[A\n",
      " 40%|███▉      | 3658/9171 [00:42<01:08, 80.67it/s]\u001b[A\n",
      " 40%|███▉      | 3667/9171 [00:42<01:08, 80.72it/s]\u001b[A\n",
      " 40%|████      | 3676/9171 [00:42<01:08, 79.74it/s]\u001b[A\n",
      " 40%|████      | 3685/9171 [00:42<01:08, 79.90it/s]\u001b[A\n",
      " 40%|████      | 3694/9171 [00:42<01:07, 80.62it/s]\u001b[A\n",
      " 40%|████      | 3703/9171 [00:42<01:07, 80.79it/s]\u001b[A\n",
      " 40%|████      | 3712/9171 [00:42<01:07, 80.34it/s]\u001b[A\n",
      " 41%|████      | 3721/9171 [00:43<01:08, 79.81it/s]\u001b[A\n",
      " 41%|████      | 3730/9171 [00:43<01:07, 80.14it/s]\u001b[A\n",
      " 41%|████      | 3739/9171 [00:43<01:07, 80.06it/s]\u001b[A\n",
      " 41%|████      | 3748/9171 [00:43<01:07, 80.19it/s]\u001b[A\n",
      " 41%|████      | 3757/9171 [00:43<01:07, 79.77it/s]\u001b[A\n",
      " 41%|████      | 3766/9171 [00:43<01:07, 80.00it/s]\u001b[A\n",
      " 41%|████      | 3775/9171 [00:43<01:07, 80.49it/s]\u001b[A\n",
      " 41%|████▏     | 3784/9171 [00:43<01:06, 80.92it/s]\u001b[A\n",
      " 41%|████▏     | 3793/9171 [00:43<01:06, 80.89it/s]\u001b[A\n",
      " 41%|████▏     | 3802/9171 [00:44<01:06, 80.65it/s]\u001b[A\n",
      " 42%|████▏     | 3811/9171 [00:44<01:06, 80.62it/s]\u001b[A\n",
      " 42%|████▏     | 3820/9171 [00:44<01:06, 80.85it/s]\u001b[A\n",
      " 42%|████▏     | 3829/9171 [00:44<01:05, 81.05it/s]\u001b[A\n",
      " 42%|████▏     | 3838/9171 [00:44<01:06, 80.41it/s]\u001b[A\n",
      " 42%|████▏     | 3847/9171 [00:44<01:06, 80.35it/s]\u001b[A\n",
      " 42%|████▏     | 3856/9171 [00:44<01:06, 80.22it/s]\u001b[A\n",
      " 42%|████▏     | 3865/9171 [00:44<01:05, 80.72it/s]\u001b[A\n",
      " 42%|████▏     | 3874/9171 [00:44<01:05, 80.99it/s]\u001b[A\n",
      " 42%|████▏     | 3883/9171 [00:45<01:05, 80.45it/s]\u001b[A\n",
      " 42%|████▏     | 3892/9171 [00:45<01:05, 80.47it/s]\u001b[A\n",
      " 43%|████▎     | 3901/9171 [00:45<01:05, 80.68it/s]\u001b[A\n",
      " 43%|████▎     | 3910/9171 [00:45<01:05, 80.85it/s]\u001b[A\n",
      " 43%|████▎     | 3919/9171 [00:45<01:05, 80.57it/s]\u001b[A\n",
      " 43%|████▎     | 3928/9171 [00:45<01:05, 80.54it/s]\u001b[A\n",
      " 43%|████▎     | 3937/9171 [00:45<01:04, 81.03it/s]\u001b[A\n",
      " 43%|████▎     | 3946/9171 [00:45<01:04, 81.20it/s]\u001b[A\n",
      " 43%|████▎     | 3955/9171 [00:45<01:04, 80.59it/s]\u001b[A\n",
      " 43%|████▎     | 3964/9171 [00:46<01:05, 79.69it/s]\u001b[A\n",
      " 43%|████▎     | 3973/9171 [00:46<01:05, 79.81it/s]\u001b[A\n",
      " 43%|████▎     | 3982/9171 [00:46<01:04, 80.39it/s]\u001b[A\n",
      " 44%|████▎     | 3991/9171 [00:46<01:04, 80.77it/s]\u001b[A\n",
      " 44%|████▎     | 4000/9171 [00:46<01:04, 80.53it/s]\u001b[A\n",
      " 44%|████▎     | 4009/9171 [00:46<01:04, 80.24it/s]\u001b[A\n",
      " 44%|████▍     | 4018/9171 [00:46<01:03, 80.86it/s]\u001b[A\n",
      " 44%|████▍     | 4027/9171 [00:46<01:03, 81.03it/s]\u001b[A\n",
      " 44%|████▍     | 4036/9171 [00:46<01:03, 80.94it/s]\u001b[A\n",
      " 44%|████▍     | 4045/9171 [00:47<01:03, 80.43it/s]\u001b[A\n",
      " 44%|████▍     | 4054/9171 [00:47<01:03, 80.13it/s]\u001b[A\n",
      " 44%|████▍     | 4063/9171 [00:47<01:03, 80.25it/s]\u001b[A\n",
      " 44%|████▍     | 4072/9171 [00:47<01:03, 80.52it/s]\u001b[A\n",
      " 44%|████▍     | 4081/9171 [00:47<01:03, 79.94it/s]\u001b[A\n",
      " 45%|████▍     | 4089/9171 [00:47<01:03, 79.50it/s]\u001b[A\n",
      " 45%|████▍     | 4097/9171 [00:47<01:03, 79.63it/s]\u001b[A\n",
      " 45%|████▍     | 4106/9171 [00:47<01:03, 80.24it/s]\u001b[A\n",
      " 45%|████▍     | 4115/9171 [00:47<01:02, 80.67it/s]\u001b[A\n",
      " 45%|████▍     | 4124/9171 [00:48<01:02, 80.62it/s]\u001b[A\n",
      " 45%|████▌     | 4133/9171 [00:48<01:02, 80.39it/s]\u001b[A\n",
      " 45%|████▌     | 4142/9171 [00:48<01:02, 80.66it/s]\u001b[A\n",
      " 45%|████▌     | 4151/9171 [00:48<01:01, 81.41it/s]\u001b[A\n",
      " 45%|████▌     | 4160/9171 [00:48<01:01, 81.77it/s]\u001b[A\n",
      " 45%|████▌     | 4169/9171 [00:48<01:01, 81.76it/s]\u001b[A\n",
      " 46%|████▌     | 4178/9171 [00:48<01:01, 81.64it/s]\u001b[A\n",
      " 46%|████▌     | 4187/9171 [00:48<01:01, 81.60it/s]\u001b[A\n",
      " 46%|████▌     | 4196/9171 [00:48<01:00, 81.56it/s]\u001b[A\n",
      " 46%|████▌     | 4205/9171 [00:49<01:01, 80.55it/s]\u001b[A\n",
      " 46%|████▌     | 4214/9171 [00:49<01:01, 80.34it/s]\u001b[A\n",
      " 46%|████▌     | 4223/9171 [00:49<01:01, 80.95it/s]\u001b[A\n",
      " 46%|████▌     | 4232/9171 [00:49<01:00, 81.60it/s]\u001b[A\n",
      " 46%|████▌     | 4241/9171 [00:49<01:00, 81.77it/s]\u001b[A\n",
      " 46%|████▋     | 4250/9171 [00:49<01:00, 81.87it/s]\u001b[A\n",
      " 46%|████▋     | 4259/9171 [00:49<01:00, 81.68it/s]\u001b[A\n",
      " 47%|████▋     | 4268/9171 [00:49<00:59, 82.13it/s]\u001b[A\n",
      " 47%|████▋     | 4277/9171 [00:49<00:59, 82.52it/s]\u001b[A\n",
      " 47%|████▋     | 4286/9171 [00:50<00:59, 82.72it/s]\u001b[A\n",
      " 47%|████▋     | 4295/9171 [00:50<00:59, 81.81it/s]\u001b[A\n",
      " 47%|████▋     | 4304/9171 [00:50<00:59, 81.54it/s]\u001b[A\n",
      " 47%|████▋     | 4313/9171 [00:50<00:59, 81.88it/s]\u001b[A\n",
      " 47%|████▋     | 4322/9171 [00:50<00:59, 81.61it/s]\u001b[A\n",
      " 47%|████▋     | 4331/9171 [00:50<00:59, 81.35it/s]\u001b[A\n",
      " 47%|████▋     | 4340/9171 [00:50<00:59, 81.06it/s]\u001b[A\n",
      " 47%|████▋     | 4349/9171 [00:50<00:59, 81.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4358/9171 [00:50<00:59, 81.52it/s]\u001b[A\n",
      " 48%|████▊     | 4367/9171 [00:51<00:58, 82.10it/s]\u001b[A\n",
      " 48%|████▊     | 4376/9171 [00:51<00:58, 81.71it/s]\u001b[A\n",
      " 48%|████▊     | 4385/9171 [00:51<00:58, 81.55it/s]\u001b[A\n",
      " 48%|████▊     | 4394/9171 [00:51<00:58, 81.89it/s]\u001b[A\n",
      " 48%|████▊     | 4403/9171 [00:51<00:58, 81.92it/s]\u001b[A\n",
      " 48%|████▊     | 4412/9171 [00:51<00:58, 82.02it/s]\u001b[A\n",
      " 48%|████▊     | 4421/9171 [00:51<00:58, 81.84it/s]\u001b[A\n",
      " 48%|████▊     | 4430/9171 [00:51<00:57, 82.08it/s]\u001b[A\n",
      " 48%|████▊     | 4439/9171 [00:51<00:57, 82.47it/s]\u001b[A\n",
      " 49%|████▊     | 4448/9171 [00:52<00:57, 82.26it/s]\u001b[A\n",
      " 49%|████▊     | 4457/9171 [00:52<00:57, 81.71it/s]\u001b[A\n",
      " 49%|████▊     | 4466/9171 [00:52<00:57, 81.24it/s]\u001b[A\n",
      " 49%|████▉     | 4475/9171 [00:52<00:57, 81.67it/s]\u001b[A\n",
      " 49%|████▉     | 4484/9171 [00:52<00:57, 81.87it/s]\u001b[A\n",
      " 49%|████▉     | 4493/9171 [00:52<00:57, 81.97it/s]\u001b[A\n",
      " 49%|████▉     | 4502/9171 [00:52<00:56, 82.28it/s]\u001b[A\n",
      " 49%|████▉     | 4511/9171 [00:52<00:56, 82.32it/s]\u001b[A\n",
      " 49%|████▉     | 4520/9171 [00:52<00:56, 82.47it/s]\u001b[A\n",
      " 49%|████▉     | 4529/9171 [00:53<00:56, 82.51it/s]\u001b[A\n",
      " 49%|████▉     | 4538/9171 [00:53<00:56, 82.16it/s]\u001b[A\n",
      " 50%|████▉     | 4547/9171 [00:53<00:56, 81.59it/s]\u001b[A\n",
      " 50%|████▉     | 4556/9171 [00:53<00:56, 81.99it/s]\u001b[A\n",
      " 50%|████▉     | 4565/9171 [00:53<00:56, 82.13it/s]\u001b[A\n",
      " 50%|████▉     | 4574/9171 [00:53<00:56, 81.79it/s]\u001b[A\n",
      " 50%|████▉     | 4583/9171 [00:53<00:56, 81.86it/s]\u001b[A\n",
      " 50%|█████     | 4592/9171 [00:53<00:55, 81.94it/s]\u001b[A\n",
      " 50%|█████     | 4601/9171 [00:53<00:55, 82.03it/s]\u001b[A\n",
      " 50%|█████     | 4610/9171 [00:54<00:55, 82.27it/s]\u001b[A\n",
      " 50%|█████     | 4619/9171 [00:54<00:55, 82.12it/s]\u001b[A\n",
      " 50%|█████     | 4628/9171 [00:54<00:55, 81.57it/s]\u001b[A\n",
      " 51%|█████     | 4637/9171 [00:54<00:55, 81.77it/s]\u001b[A\n",
      " 51%|█████     | 4646/9171 [00:54<00:55, 81.98it/s]\u001b[A\n",
      " 51%|█████     | 4655/9171 [00:54<00:55, 81.99it/s]\u001b[A\n",
      " 51%|█████     | 4664/9171 [00:54<00:54, 82.09it/s]\u001b[A\n",
      " 51%|█████     | 4673/9171 [00:54<00:54, 82.46it/s]\u001b[A\n",
      " 51%|█████     | 4682/9171 [00:54<00:54, 82.28it/s]\u001b[A\n",
      " 51%|█████     | 4691/9171 [00:55<00:54, 82.22it/s]\u001b[A\n",
      " 51%|█████     | 4700/9171 [00:55<00:54, 81.53it/s]\u001b[A\n",
      " 51%|█████▏    | 4709/9171 [00:55<00:54, 81.18it/s]\u001b[A\n",
      " 51%|█████▏    | 4718/9171 [00:55<00:54, 81.54it/s]\u001b[A\n",
      " 52%|█████▏    | 4727/9171 [00:55<00:54, 82.00it/s]\u001b[A\n",
      " 52%|█████▏    | 4736/9171 [00:55<00:54, 81.96it/s]\u001b[A\n",
      " 52%|█████▏    | 4745/9171 [00:55<00:53, 82.11it/s]\u001b[A\n",
      " 52%|█████▏    | 4754/9171 [00:55<00:53, 82.49it/s]\u001b[A\n",
      " 52%|█████▏    | 4763/9171 [00:55<00:53, 82.28it/s]\u001b[A\n",
      " 52%|█████▏    | 4772/9171 [00:55<00:53, 82.44it/s]\u001b[A\n",
      " 52%|█████▏    | 4781/9171 [00:56<00:53, 82.30it/s]\u001b[A\n",
      " 52%|█████▏    | 4790/9171 [00:56<00:53, 81.71it/s]\u001b[A\n",
      " 52%|█████▏    | 4799/9171 [00:56<00:53, 82.01it/s]\u001b[A\n",
      " 52%|█████▏    | 4808/9171 [00:56<00:53, 82.04it/s]\u001b[A\n",
      " 53%|█████▎    | 4817/9171 [00:56<00:53, 81.89it/s]\u001b[A\n",
      " 53%|█████▎    | 4826/9171 [00:56<00:52, 82.01it/s]\u001b[A\n",
      " 53%|█████▎    | 4835/9171 [00:56<00:52, 82.42it/s]\u001b[A\n",
      " 53%|█████▎    | 4844/9171 [00:56<00:52, 82.27it/s]\u001b[A\n",
      " 53%|█████▎    | 4853/9171 [00:56<00:52, 82.20it/s]\u001b[A\n",
      " 53%|█████▎    | 4862/9171 [00:57<00:52, 81.97it/s]\u001b[A\n",
      " 53%|█████▎    | 4871/9171 [00:57<00:52, 81.71it/s]\u001b[A\n",
      " 53%|█████▎    | 4880/9171 [00:57<00:52, 81.86it/s]\u001b[A\n",
      " 53%|█████▎    | 4889/9171 [00:57<00:52, 81.90it/s]\u001b[A\n",
      " 53%|█████▎    | 4898/9171 [00:57<00:52, 81.60it/s]\u001b[A\n",
      " 54%|█████▎    | 4907/9171 [00:57<00:52, 81.68it/s]\u001b[A\n",
      " 54%|█████▎    | 4916/9171 [00:57<00:51, 82.22it/s]\u001b[A\n",
      " 54%|█████▎    | 4925/9171 [00:57<00:51, 82.46it/s]\u001b[A\n",
      " 54%|█████▍    | 4934/9171 [00:57<00:51, 82.27it/s]\u001b[A\n",
      " 54%|█████▍    | 4943/9171 [00:58<00:51, 81.86it/s]\u001b[A\n",
      " 54%|█████▍    | 4952/9171 [00:58<00:51, 81.69it/s]\u001b[A\n",
      " 54%|█████▍    | 4961/9171 [00:58<00:51, 81.82it/s]\u001b[A\n",
      " 54%|█████▍    | 4970/9171 [00:58<00:51, 82.15it/s]\u001b[A\n",
      " 54%|█████▍    | 4979/9171 [00:58<00:51, 81.78it/s]\u001b[A\n",
      " 54%|█████▍    | 4988/9171 [00:58<00:51, 81.90it/s]\u001b[A\n",
      " 54%|█████▍    | 4997/9171 [00:58<00:50, 82.33it/s]\u001b[A\n",
      " 55%|█████▍    | 5006/9171 [00:58<00:50, 82.59it/s]\u001b[A\n",
      " 55%|█████▍    | 5015/9171 [00:58<00:50, 82.32it/s]\u001b[A\n",
      " 55%|█████▍    | 5024/9171 [00:59<00:50, 82.19it/s]\u001b[A\n",
      " 55%|█████▍    | 5033/9171 [00:59<00:50, 81.81it/s]\u001b[A\n",
      " 55%|█████▍    | 5042/9171 [00:59<00:50, 81.64it/s]\u001b[A\n",
      " 55%|█████▌    | 5051/9171 [00:59<00:50, 82.04it/s]\u001b[A\n",
      " 55%|█████▌    | 5060/9171 [00:59<00:50, 81.50it/s]\u001b[A\n",
      " 55%|█████▌    | 5069/9171 [00:59<00:50, 81.08it/s]\u001b[A\n",
      " 55%|█████▌    | 5078/9171 [00:59<00:50, 81.43it/s]\u001b[A\n",
      " 55%|█████▌    | 5087/9171 [00:59<00:49, 81.90it/s]\u001b[A\n",
      " 56%|█████▌    | 5096/9171 [00:59<00:49, 82.16it/s]\u001b[A\n",
      " 56%|█████▌    | 5105/9171 [01:00<00:49, 82.14it/s]\u001b[A\n",
      " 56%|█████▌    | 5114/9171 [01:00<00:49, 81.38it/s]\u001b[A\n",
      " 56%|█████▌    | 5123/9171 [01:00<00:49, 81.40it/s]\u001b[A\n",
      " 56%|█████▌    | 5132/9171 [01:00<00:49, 82.04it/s]\u001b[A\n",
      " 56%|█████▌    | 5141/9171 [01:00<00:49, 81.84it/s]\u001b[A\n",
      " 56%|█████▌    | 5150/9171 [01:00<00:49, 81.54it/s]\u001b[A\n",
      " 56%|█████▋    | 5159/9171 [01:00<00:48, 81.91it/s]\u001b[A\n",
      " 56%|█████▋    | 5168/9171 [01:00<00:48, 82.24it/s]\u001b[A\n",
      " 56%|█████▋    | 5177/9171 [01:00<00:48, 82.52it/s]\u001b[A\n",
      " 57%|█████▋    | 5186/9171 [01:01<00:48, 82.16it/s]\u001b[A\n",
      " 57%|█████▋    | 5195/9171 [01:01<00:48, 81.64it/s]\u001b[A\n",
      " 57%|█████▋    | 5204/9171 [01:01<00:48, 81.55it/s]\u001b[A\n",
      " 57%|█████▋    | 5213/9171 [01:01<00:48, 82.06it/s]\u001b[A\n",
      " 57%|█████▋    | 5222/9171 [01:01<00:48, 82.03it/s]\u001b[A\n",
      " 57%|█████▋    | 5231/9171 [01:01<00:48, 81.62it/s]\u001b[A\n",
      " 57%|█████▋    | 5240/9171 [01:01<00:47, 82.06it/s]\u001b[A\n",
      " 57%|█████▋    | 5249/9171 [01:01<00:47, 82.36it/s]\u001b[A\n",
      " 57%|█████▋    | 5258/9171 [01:01<00:47, 82.63it/s]\u001b[A\n",
      " 57%|█████▋    | 5267/9171 [01:02<00:47, 82.43it/s]\u001b[A\n",
      " 58%|█████▊    | 5276/9171 [01:02<00:47, 81.88it/s]\u001b[A\n",
      " 58%|█████▊    | 5285/9171 [01:02<00:47, 81.86it/s]\u001b[A\n",
      " 58%|█████▊    | 5294/9171 [01:02<00:47, 82.29it/s]\u001b[A\n",
      " 58%|█████▊    | 5303/9171 [01:02<00:46, 82.48it/s]\u001b[A\n",
      " 58%|█████▊    | 5312/9171 [01:02<00:47, 81.79it/s]\u001b[A\n",
      " 58%|█████▊    | 5321/9171 [01:02<00:47, 81.83it/s]\u001b[A\n",
      " 58%|█████▊    | 5330/9171 [01:02<00:46, 82.11it/s]\u001b[A\n",
      " 58%|█████▊    | 5339/9171 [01:02<00:46, 82.47it/s]\u001b[A\n",
      " 58%|█████▊    | 5348/9171 [01:03<00:46, 82.73it/s]\u001b[A\n",
      " 58%|█████▊    | 5357/9171 [01:03<00:46, 82.19it/s]\u001b[A\n",
      " 59%|█████▊    | 5366/9171 [01:03<00:46, 81.52it/s]\u001b[A\n",
      " 59%|█████▊    | 5375/9171 [01:03<00:46, 81.80it/s]\u001b[A\n",
      " 59%|█████▊    | 5384/9171 [01:03<00:46, 82.14it/s]\u001b[A\n",
      " 59%|█████▉    | 5393/9171 [01:03<00:46, 81.79it/s]\u001b[A\n",
      " 59%|█████▉    | 5402/9171 [01:03<00:46, 81.73it/s]\u001b[A\n",
      " 59%|█████▉    | 5411/9171 [01:03<00:45, 81.89it/s]\u001b[A\n",
      " 59%|█████▉    | 5420/9171 [01:03<00:45, 82.33it/s]\u001b[A\n",
      " 59%|█████▉    | 5429/9171 [01:04<00:45, 82.54it/s]\u001b[A\n",
      " 59%|█████▉    | 5438/9171 [01:04<00:45, 82.32it/s]\u001b[A\n",
      " 59%|█████▉    | 5447/9171 [01:04<00:45, 81.64it/s]\u001b[A\n",
      " 59%|█████▉    | 5456/9171 [01:04<00:45, 81.80it/s]\u001b[A\n",
      " 60%|█████▉    | 5465/9171 [01:04<00:45, 82.20it/s]\u001b[A\n",
      " 60%|█████▉    | 5474/9171 [01:04<00:44, 82.17it/s]\u001b[A\n",
      " 60%|█████▉    | 5483/9171 [01:04<00:45, 81.80it/s]\u001b[A\n",
      " 60%|█████▉    | 5492/9171 [01:04<00:44, 82.09it/s]\u001b[A\n",
      " 60%|█████▉    | 5501/9171 [01:04<00:44, 82.46it/s]\u001b[A\n",
      " 60%|██████    | 5510/9171 [01:04<00:44, 82.81it/s]\u001b[A\n",
      " 60%|██████    | 5519/9171 [01:05<00:44, 82.55it/s]\u001b[A\n",
      " 60%|██████    | 5528/9171 [01:05<00:44, 81.78it/s]\u001b[A\n",
      " 60%|██████    | 5537/9171 [01:05<00:44, 81.73it/s]\u001b[A\n",
      " 60%|██████    | 5546/9171 [01:05<00:44, 82.11it/s]\u001b[A\n",
      " 61%|██████    | 5555/9171 [01:05<00:44, 82.01it/s]\u001b[A\n",
      " 61%|██████    | 5564/9171 [01:05<00:44, 81.53it/s]\u001b[A\n",
      " 61%|██████    | 5573/9171 [01:05<00:44, 81.61it/s]\u001b[A\n",
      " 61%|██████    | 5582/9171 [01:05<00:43, 82.21it/s]\u001b[A\n",
      " 61%|██████    | 5591/9171 [01:05<00:43, 82.55it/s]\u001b[A\n",
      " 61%|██████    | 5600/9171 [01:06<00:43, 82.36it/s]\u001b[A\n",
      " 61%|██████    | 5609/9171 [01:06<00:43, 81.96it/s]\u001b[A\n",
      " 61%|██████▏   | 5618/9171 [01:06<00:43, 82.02it/s]\u001b[A\n",
      " 61%|██████▏   | 5627/9171 [01:06<00:43, 82.28it/s]\u001b[A\n",
      " 61%|██████▏   | 5636/9171 [01:06<00:42, 82.27it/s]\u001b[A\n",
      " 62%|██████▏   | 5645/9171 [01:06<00:42, 82.16it/s]\u001b[A\n",
      " 62%|██████▏   | 5654/9171 [01:06<00:42, 82.10it/s]\u001b[A\n",
      " 62%|██████▏   | 5663/9171 [01:06<00:42, 82.16it/s]\u001b[A\n",
      " 62%|██████▏   | 5672/9171 [01:06<00:42, 82.39it/s]\u001b[A\n",
      " 62%|██████▏   | 5681/9171 [01:07<00:42, 82.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5690/9171 [01:07<00:42, 81.45it/s]\u001b[A\n",
      " 62%|██████▏   | 5699/9171 [01:07<00:42, 81.31it/s]\u001b[A\n",
      " 62%|██████▏   | 5708/9171 [01:07<00:42, 81.78it/s]\u001b[A\n",
      " 62%|██████▏   | 5717/9171 [01:07<00:42, 81.96it/s]\u001b[A\n",
      " 62%|██████▏   | 5726/9171 [01:07<00:41, 82.08it/s]\u001b[A\n",
      " 63%|██████▎   | 5735/9171 [01:07<00:41, 81.98it/s]\u001b[A\n",
      " 63%|██████▎   | 5744/9171 [01:07<00:41, 82.17it/s]\u001b[A\n",
      " 63%|██████▎   | 5753/9171 [01:07<00:41, 82.53it/s]\u001b[A\n",
      " 63%|██████▎   | 5762/9171 [01:08<00:41, 82.70it/s]\u001b[A\n",
      " 63%|██████▎   | 5771/9171 [01:08<00:41, 82.27it/s]\u001b[A\n",
      " 63%|██████▎   | 5780/9171 [01:08<00:41, 81.93it/s]\u001b[A\n",
      " 63%|██████▎   | 5789/9171 [01:08<00:41, 82.12it/s]\u001b[A\n",
      " 63%|██████▎   | 5798/9171 [01:08<00:41, 82.02it/s]\u001b[A\n",
      " 63%|██████▎   | 5807/9171 [01:08<00:41, 81.99it/s]\u001b[A\n",
      " 63%|██████▎   | 5816/9171 [01:08<00:41, 81.80it/s]\u001b[A\n",
      " 64%|██████▎   | 5825/9171 [01:08<00:40, 82.08it/s]\u001b[A\n",
      " 64%|██████▎   | 5834/9171 [01:08<00:40, 82.45it/s]\u001b[A\n",
      " 64%|██████▎   | 5843/9171 [01:09<00:40, 82.54it/s]\u001b[A\n",
      " 64%|██████▍   | 5852/9171 [01:09<00:40, 82.30it/s]\u001b[A\n",
      " 64%|██████▍   | 5861/9171 [01:09<00:40, 81.84it/s]\u001b[A\n",
      " 64%|██████▍   | 5870/9171 [01:09<00:40, 81.99it/s]\u001b[A\n",
      " 64%|██████▍   | 5879/9171 [01:09<00:40, 82.02it/s]\u001b[A\n",
      " 64%|██████▍   | 5888/9171 [01:09<00:40, 82.04it/s]\u001b[A\n",
      " 64%|██████▍   | 5897/9171 [01:09<00:39, 82.24it/s]\u001b[A\n",
      " 64%|██████▍   | 5906/9171 [01:09<00:39, 82.18it/s]\u001b[A\n",
      " 64%|██████▍   | 5915/9171 [01:09<00:39, 82.20it/s]\u001b[A\n",
      " 65%|██████▍   | 5924/9171 [01:10<00:39, 82.36it/s]\u001b[A\n",
      " 65%|██████▍   | 5933/9171 [01:10<00:39, 81.98it/s]\u001b[A\n",
      " 65%|██████▍   | 5942/9171 [01:10<00:39, 81.86it/s]\u001b[A\n",
      " 65%|██████▍   | 5951/9171 [01:10<00:39, 81.96it/s]\u001b[A\n",
      " 65%|██████▍   | 5960/9171 [01:10<00:39, 82.10it/s]\u001b[A\n",
      " 65%|██████▌   | 5969/9171 [01:10<00:38, 82.24it/s]\u001b[A\n",
      " 65%|██████▌   | 5978/9171 [01:10<00:38, 82.30it/s]\u001b[A\n",
      " 65%|██████▌   | 5987/9171 [01:10<00:38, 82.27it/s]\u001b[A\n",
      " 65%|██████▌   | 5996/9171 [01:10<00:38, 82.08it/s]\u001b[A\n",
      " 65%|██████▌   | 6005/9171 [01:11<00:38, 82.25it/s]\u001b[A\n",
      " 66%|██████▌   | 6014/9171 [01:11<00:38, 82.15it/s]\u001b[A\n",
      " 66%|██████▌   | 6023/9171 [01:11<00:38, 81.90it/s]\u001b[A\n",
      " 66%|██████▌   | 6032/9171 [01:11<00:38, 81.77it/s]\u001b[A\n",
      " 66%|██████▌   | 6041/9171 [01:11<00:38, 81.88it/s]\u001b[A\n",
      " 66%|██████▌   | 6050/9171 [01:11<00:38, 81.82it/s]\u001b[A\n",
      " 66%|██████▌   | 6059/9171 [01:11<00:38, 81.62it/s]\u001b[A\n",
      " 66%|██████▌   | 6068/9171 [01:11<00:37, 82.05it/s]\u001b[A\n",
      " 66%|██████▋   | 6077/9171 [01:11<00:37, 81.85it/s]\u001b[A\n",
      " 66%|██████▋   | 6086/9171 [01:12<00:37, 82.09it/s]\u001b[A\n",
      " 66%|██████▋   | 6095/9171 [01:12<00:37, 82.10it/s]\u001b[A\n",
      " 67%|██████▋   | 6104/9171 [01:12<00:37, 81.80it/s]\u001b[A\n",
      " 67%|██████▋   | 6113/9171 [01:12<00:37, 81.63it/s]\u001b[A\n",
      " 67%|██████▋   | 6122/9171 [01:12<00:37, 82.01it/s]\u001b[A\n",
      " 67%|██████▋   | 6131/9171 [01:12<00:37, 81.96it/s]\u001b[A\n",
      " 67%|██████▋   | 6140/9171 [01:12<00:36, 82.03it/s]\u001b[A\n",
      " 67%|██████▋   | 6149/9171 [01:12<00:36, 82.50it/s]\u001b[A\n",
      " 67%|██████▋   | 6158/9171 [01:12<00:36, 82.51it/s]\u001b[A\n",
      " 67%|██████▋   | 6167/9171 [01:13<00:36, 82.35it/s]\u001b[A\n",
      " 67%|██████▋   | 6176/9171 [01:13<00:36, 82.09it/s]\u001b[A\n",
      " 67%|██████▋   | 6185/9171 [01:13<00:36, 81.42it/s]\u001b[A\n",
      " 68%|██████▊   | 6194/9171 [01:13<00:36, 81.48it/s]\u001b[A\n",
      " 68%|██████▊   | 6203/9171 [01:13<00:36, 81.61it/s]\u001b[A\n",
      " 68%|██████▊   | 6212/9171 [01:13<00:36, 81.59it/s]\u001b[A\n",
      " 68%|██████▊   | 6221/9171 [01:13<00:36, 81.49it/s]\u001b[A\n",
      " 68%|██████▊   | 6230/9171 [01:13<00:35, 82.02it/s]\u001b[A\n",
      " 68%|██████▊   | 6239/9171 [01:13<00:35, 82.16it/s]\u001b[A\n",
      " 68%|██████▊   | 6248/9171 [01:13<00:35, 82.07it/s]\u001b[A\n",
      " 68%|██████▊   | 6257/9171 [01:14<00:35, 81.88it/s]\u001b[A\n",
      " 68%|██████▊   | 6266/9171 [01:14<00:35, 81.82it/s]\u001b[A\n",
      " 68%|██████▊   | 6275/9171 [01:14<00:35, 81.94it/s]\u001b[A\n",
      " 69%|██████▊   | 6284/9171 [01:14<00:35, 81.91it/s]\u001b[A\n",
      " 69%|██████▊   | 6293/9171 [01:14<00:35, 81.65it/s]\u001b[A\n",
      " 69%|██████▊   | 6302/9171 [01:14<00:35, 81.64it/s]\u001b[A\n",
      " 69%|██████▉   | 6311/9171 [01:14<00:35, 81.47it/s]\u001b[A\n",
      " 69%|██████▉   | 6320/9171 [01:14<00:34, 81.90it/s]\u001b[A\n",
      " 69%|██████▉   | 6329/9171 [01:14<00:34, 81.83it/s]\u001b[A\n",
      " 69%|██████▉   | 6338/9171 [01:15<00:34, 81.73it/s]\u001b[A\n",
      " 69%|██████▉   | 6347/9171 [01:15<00:34, 81.75it/s]\u001b[A\n",
      " 69%|██████▉   | 6356/9171 [01:15<00:34, 82.18it/s]\u001b[A\n",
      " 69%|██████▉   | 6365/9171 [01:15<00:34, 82.36it/s]\u001b[A\n",
      " 70%|██████▉   | 6374/9171 [01:15<00:34, 81.82it/s]\u001b[A\n",
      " 70%|██████▉   | 6383/9171 [01:15<00:34, 81.85it/s]\u001b[A\n",
      " 70%|██████▉   | 6392/9171 [01:15<00:33, 82.11it/s]\u001b[A\n",
      " 70%|██████▉   | 6401/9171 [01:15<00:33, 82.43it/s]\u001b[A\n",
      " 70%|██████▉   | 6410/9171 [01:15<00:33, 82.44it/s]\u001b[A\n",
      " 70%|██████▉   | 6419/9171 [01:16<00:33, 82.05it/s]\u001b[A\n",
      " 70%|███████   | 6428/9171 [01:16<00:33, 81.88it/s]\u001b[A\n",
      " 70%|███████   | 6437/9171 [01:16<00:33, 81.69it/s]\u001b[A\n",
      " 70%|███████   | 6446/9171 [01:16<00:33, 82.04it/s]\u001b[A\n",
      " 70%|███████   | 6455/9171 [01:16<00:33, 81.76it/s]\u001b[A\n",
      " 70%|███████   | 6464/9171 [01:16<00:33, 81.46it/s]\u001b[A\n",
      " 71%|███████   | 6473/9171 [01:16<00:32, 81.92it/s]\u001b[A\n",
      " 71%|███████   | 6482/9171 [01:16<00:32, 82.46it/s]\u001b[A\n",
      " 71%|███████   | 6491/9171 [01:16<00:32, 82.69it/s]\u001b[A\n",
      " 71%|███████   | 6500/9171 [01:17<00:32, 82.32it/s]\u001b[A\n",
      " 71%|███████   | 6509/9171 [01:17<00:32, 81.96it/s]\u001b[A\n",
      " 71%|███████   | 6518/9171 [01:17<00:32, 81.67it/s]\u001b[A\n",
      " 71%|███████   | 6527/9171 [01:17<00:32, 81.87it/s]\u001b[A\n",
      " 71%|███████▏  | 6536/9171 [01:17<00:32, 81.80it/s]\u001b[A\n",
      " 71%|███████▏  | 6545/9171 [01:17<00:32, 81.54it/s]\u001b[A\n",
      " 71%|███████▏  | 6554/9171 [01:17<00:32, 81.64it/s]\u001b[A\n",
      " 72%|███████▏  | 6563/9171 [01:17<00:31, 81.88it/s]\u001b[A\n",
      " 72%|███████▏  | 6572/9171 [01:17<00:31, 82.25it/s]\u001b[A\n",
      " 72%|███████▏  | 6581/9171 [01:18<00:31, 82.06it/s]\u001b[A\n",
      " 72%|███████▏  | 6590/9171 [01:18<00:31, 81.71it/s]\u001b[A\n",
      " 72%|███████▏  | 6599/9171 [01:18<00:31, 81.52it/s]\u001b[A\n",
      " 72%|███████▏  | 6608/9171 [01:18<00:31, 81.81it/s]\u001b[A\n",
      " 72%|███████▏  | 6617/9171 [01:18<00:31, 81.80it/s]\u001b[A\n",
      " 72%|███████▏  | 6626/9171 [01:18<00:31, 81.48it/s]\u001b[A\n",
      " 72%|███████▏  | 6635/9171 [01:18<00:31, 81.78it/s]\u001b[A\n",
      " 72%|███████▏  | 6644/9171 [01:18<00:30, 82.27it/s]\u001b[A\n",
      " 73%|███████▎  | 6653/9171 [01:18<00:30, 82.62it/s]\u001b[A\n",
      " 73%|███████▎  | 6662/9171 [01:19<00:30, 82.72it/s]\u001b[A\n",
      " 73%|███████▎  | 6671/9171 [01:19<00:30, 82.41it/s]\u001b[A\n",
      " 73%|███████▎  | 6680/9171 [01:19<00:30, 81.72it/s]\u001b[A\n",
      " 73%|███████▎  | 6689/9171 [01:19<00:30, 82.14it/s]\u001b[A\n",
      " 73%|███████▎  | 6698/9171 [01:19<00:30, 82.19it/s]\u001b[A\n",
      " 73%|███████▎  | 6707/9171 [01:19<00:30, 81.97it/s]\u001b[A\n",
      " 73%|███████▎  | 6716/9171 [01:19<00:29, 81.97it/s]\u001b[A\n",
      " 73%|███████▎  | 6725/9171 [01:19<00:29, 82.11it/s]\u001b[A\n",
      " 73%|███████▎  | 6734/9171 [01:19<00:29, 82.42it/s]\u001b[A\n",
      " 74%|███████▎  | 6743/9171 [01:20<00:29, 82.61it/s]\u001b[A\n",
      " 74%|███████▎  | 6752/9171 [01:20<00:29, 82.20it/s]\u001b[A\n",
      " 74%|███████▎  | 6761/9171 [01:20<00:29, 81.67it/s]\u001b[A\n",
      " 74%|███████▍  | 6770/9171 [01:20<00:29, 82.16it/s]\u001b[A\n",
      " 74%|███████▍  | 6779/9171 [01:20<00:29, 82.32it/s]\u001b[A\n",
      " 74%|███████▍  | 6788/9171 [01:20<00:29, 82.16it/s]\u001b[A\n",
      " 74%|███████▍  | 6797/9171 [01:20<00:29, 81.68it/s]\u001b[A\n",
      " 74%|███████▍  | 6806/9171 [01:20<00:28, 81.65it/s]\u001b[A\n",
      " 74%|███████▍  | 6815/9171 [01:20<00:28, 81.67it/s]\u001b[A\n",
      " 74%|███████▍  | 6824/9171 [01:21<00:28, 81.69it/s]\u001b[A\n",
      " 75%|███████▍  | 6833/9171 [01:21<00:28, 81.31it/s]\u001b[A\n",
      " 75%|███████▍  | 6842/9171 [01:21<00:28, 80.86it/s]\u001b[A\n",
      " 75%|███████▍  | 6851/9171 [01:21<00:28, 81.62it/s]\u001b[A\n",
      " 75%|███████▍  | 6860/9171 [01:21<00:28, 82.20it/s]\u001b[A\n",
      " 75%|███████▍  | 6869/9171 [01:21<00:28, 82.09it/s]\u001b[A\n",
      " 75%|███████▍  | 6878/9171 [01:21<00:27, 81.94it/s]\u001b[A\n",
      " 75%|███████▌  | 6887/9171 [01:21<00:27, 81.97it/s]\u001b[A\n",
      " 75%|███████▌  | 6896/9171 [01:21<00:27, 82.42it/s]\u001b[A\n",
      " 75%|███████▌  | 6905/9171 [01:22<00:27, 82.52it/s]\u001b[A\n",
      " 75%|███████▌  | 6914/9171 [01:22<00:27, 82.43it/s]\u001b[A\n",
      " 75%|███████▌  | 6923/9171 [01:22<00:27, 81.72it/s]\u001b[A\n",
      " 76%|███████▌  | 6932/9171 [01:22<00:27, 81.70it/s]\u001b[A\n",
      " 76%|███████▌  | 6941/9171 [01:22<00:27, 82.16it/s]\u001b[A\n",
      " 76%|███████▌  | 6950/9171 [01:22<00:27, 82.11it/s]\u001b[A\n",
      " 76%|███████▌  | 6959/9171 [01:22<00:27, 81.86it/s]\u001b[A\n",
      " 76%|███████▌  | 6968/9171 [01:22<00:26, 81.99it/s]\u001b[A\n",
      " 76%|███████▌  | 6977/9171 [01:22<00:26, 82.07it/s]\u001b[A\n",
      " 76%|███████▌  | 6986/9171 [01:22<00:26, 82.24it/s]\u001b[A\n",
      " 76%|███████▋  | 6995/9171 [01:23<00:26, 82.29it/s]\u001b[A\n",
      " 76%|███████▋  | 7004/9171 [01:23<00:26, 82.16it/s]\u001b[A\n",
      " 76%|███████▋  | 7013/9171 [01:23<00:26, 81.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7022/9171 [01:23<00:26, 81.85it/s]\u001b[A\n",
      " 77%|███████▋  | 7031/9171 [01:23<00:26, 81.96it/s]\u001b[A\n",
      " 77%|███████▋  | 7040/9171 [01:23<00:25, 82.05it/s]\u001b[A\n",
      " 77%|███████▋  | 7049/9171 [01:23<00:26, 81.54it/s]\u001b[A\n",
      " 77%|███████▋  | 7058/9171 [01:23<00:25, 81.46it/s]\u001b[A\n",
      " 77%|███████▋  | 7067/9171 [01:23<00:25, 82.06it/s]\u001b[A\n",
      " 77%|███████▋  | 7076/9171 [01:24<00:25, 82.00it/s]\u001b[A\n",
      " 77%|███████▋  | 7085/9171 [01:24<00:25, 82.14it/s]\u001b[A\n",
      " 77%|███████▋  | 7094/9171 [01:24<00:25, 81.68it/s]\u001b[A\n",
      " 77%|███████▋  | 7103/9171 [01:24<00:25, 82.06it/s]\u001b[A\n",
      " 78%|███████▊  | 7112/9171 [01:24<00:25, 82.25it/s]\u001b[A\n",
      " 78%|███████▊  | 7121/9171 [01:24<00:24, 82.43it/s]\u001b[A\n",
      " 78%|███████▊  | 7130/9171 [01:24<00:24, 82.40it/s]\u001b[A\n",
      " 78%|███████▊  | 7139/9171 [01:24<00:24, 82.45it/s]\u001b[A\n",
      " 78%|███████▊  | 7148/9171 [01:24<00:24, 82.65it/s]\u001b[A\n",
      " 78%|███████▊  | 7157/9171 [01:25<00:24, 82.50it/s]\u001b[A\n",
      " 78%|███████▊  | 7166/9171 [01:25<00:24, 82.48it/s]\u001b[A\n",
      " 78%|███████▊  | 7175/9171 [01:25<00:24, 81.78it/s]\u001b[A\n",
      " 78%|███████▊  | 7184/9171 [01:25<00:24, 82.11it/s]\u001b[A\n",
      " 78%|███████▊  | 7193/9171 [01:25<00:24, 82.15it/s]\u001b[A\n",
      " 79%|███████▊  | 7202/9171 [01:25<00:23, 82.11it/s]\u001b[A\n",
      " 79%|███████▊  | 7211/9171 [01:25<00:23, 82.40it/s]\u001b[A\n",
      " 79%|███████▊  | 7220/9171 [01:25<00:23, 82.25it/s]\u001b[A\n",
      " 79%|███████▉  | 7229/9171 [01:25<00:23, 82.48it/s]\u001b[A\n",
      " 79%|███████▉  | 7238/9171 [01:26<00:23, 82.80it/s]\u001b[A\n",
      " 79%|███████▉  | 7247/9171 [01:26<00:23, 82.57it/s]\u001b[A\n",
      " 79%|███████▉  | 7256/9171 [01:26<00:23, 82.04it/s]\u001b[A\n",
      " 79%|███████▉  | 7265/9171 [01:26<00:23, 82.08it/s]\u001b[A\n",
      " 79%|███████▉  | 7274/9171 [01:26<00:23, 81.91it/s]\u001b[A\n",
      " 79%|███████▉  | 7283/9171 [01:26<00:22, 82.25it/s]\u001b[A\n",
      " 80%|███████▉  | 7292/9171 [01:26<00:22, 82.39it/s]\u001b[A\n",
      " 80%|███████▉  | 7301/9171 [01:26<00:22, 82.36it/s]\u001b[A\n",
      " 80%|███████▉  | 7310/9171 [01:26<00:22, 82.36it/s]\u001b[A\n",
      " 80%|███████▉  | 7319/9171 [01:27<00:22, 82.51it/s]\u001b[A\n",
      " 80%|███████▉  | 7328/9171 [01:27<00:22, 82.31it/s]\u001b[A\n",
      " 80%|████████  | 7337/9171 [01:27<00:22, 82.19it/s]\u001b[A\n",
      " 80%|████████  | 7346/9171 [01:27<00:22, 81.95it/s]\u001b[A\n",
      " 80%|████████  | 7355/9171 [01:27<00:22, 81.87it/s]\u001b[A\n",
      " 80%|████████  | 7364/9171 [01:27<00:22, 81.99it/s]\u001b[A\n",
      " 80%|████████  | 7373/9171 [01:27<00:21, 82.18it/s]\u001b[A\n",
      " 80%|████████  | 7382/9171 [01:27<00:21, 82.49it/s]\u001b[A\n",
      " 81%|████████  | 7391/9171 [01:27<00:21, 82.14it/s]\u001b[A\n",
      " 81%|████████  | 7400/9171 [01:28<00:21, 82.40it/s]\u001b[A\n",
      " 81%|████████  | 7409/9171 [01:28<00:21, 82.26it/s]\u001b[A\n",
      " 81%|████████  | 7418/9171 [01:28<00:21, 81.93it/s]\u001b[A\n",
      " 81%|████████  | 7427/9171 [01:28<00:21, 81.53it/s]\u001b[A\n",
      " 81%|████████  | 7436/9171 [01:28<00:21, 81.56it/s]\u001b[A\n",
      " 81%|████████  | 7445/9171 [01:28<00:21, 81.91it/s]\u001b[A\n",
      " 81%|████████▏ | 7454/9171 [01:28<00:20, 82.15it/s]\u001b[A\n",
      " 81%|████████▏ | 7463/9171 [01:28<00:20, 82.48it/s]\u001b[A\n",
      " 81%|████████▏ | 7472/9171 [01:28<00:20, 82.36it/s]\u001b[A\n",
      " 82%|████████▏ | 7481/9171 [01:29<00:20, 82.33it/s]\u001b[A\n",
      " 82%|████████▏ | 7490/9171 [01:29<00:20, 82.21it/s]\u001b[A\n",
      " 82%|████████▏ | 7499/9171 [01:29<00:20, 82.19it/s]\u001b[A\n",
      " 82%|████████▏ | 7508/9171 [01:29<00:20, 82.11it/s]\u001b[A\n",
      " 82%|████████▏ | 7517/9171 [01:29<00:20, 81.86it/s]\u001b[A\n",
      " 82%|████████▏ | 7526/9171 [01:29<00:20, 81.67it/s]\u001b[A\n",
      " 82%|████████▏ | 7535/9171 [01:29<00:19, 81.91it/s]\u001b[A\n",
      " 82%|████████▏ | 7544/9171 [01:29<00:19, 82.16it/s]\u001b[A\n",
      " 82%|████████▏ | 7553/9171 [01:29<00:19, 82.14it/s]\u001b[A\n",
      " 82%|████████▏ | 7562/9171 [01:30<00:19, 82.13it/s]\u001b[A\n",
      " 83%|████████▎ | 7571/9171 [01:30<00:19, 82.01it/s]\u001b[A\n",
      " 83%|████████▎ | 7580/9171 [01:30<00:19, 82.37it/s]\u001b[A\n",
      " 83%|████████▎ | 7589/9171 [01:30<00:19, 82.44it/s]\u001b[A\n",
      " 83%|████████▎ | 7598/9171 [01:30<00:19, 82.10it/s]\u001b[A\n",
      " 83%|████████▎ | 7607/9171 [01:30<00:19, 81.99it/s]\u001b[A\n",
      " 83%|████████▎ | 7616/9171 [01:30<00:18, 82.13it/s]\u001b[A\n",
      " 83%|████████▎ | 7625/9171 [01:30<00:18, 82.37it/s]\u001b[A\n",
      " 83%|████████▎ | 7634/9171 [01:30<00:18, 82.69it/s]\u001b[A\n",
      " 83%|████████▎ | 7643/9171 [01:30<00:18, 82.18it/s]\u001b[A\n",
      " 83%|████████▎ | 7652/9171 [01:31<00:18, 82.01it/s]\u001b[A\n",
      " 84%|████████▎ | 7661/9171 [01:31<00:18, 82.04it/s]\u001b[A\n",
      " 84%|████████▎ | 7670/9171 [01:31<00:18, 81.89it/s]\u001b[A\n",
      " 84%|████████▎ | 7679/9171 [01:31<00:18, 81.79it/s]\u001b[A\n",
      " 84%|████████▍ | 7688/9171 [01:31<00:18, 81.61it/s]\u001b[A\n",
      " 84%|████████▍ | 7697/9171 [01:31<00:18, 81.77it/s]\u001b[A\n",
      " 84%|████████▍ | 7706/9171 [01:31<00:17, 82.20it/s]\u001b[A\n",
      " 84%|████████▍ | 7715/9171 [01:31<00:17, 82.51it/s]\u001b[A\n",
      " 84%|████████▍ | 7724/9171 [01:31<00:17, 82.33it/s]\u001b[A\n",
      " 84%|████████▍ | 7733/9171 [01:32<00:17, 82.23it/s]\u001b[A\n",
      " 84%|████████▍ | 7742/9171 [01:32<00:17, 82.17it/s]\u001b[A\n",
      " 85%|████████▍ | 7751/9171 [01:32<00:17, 82.10it/s]\u001b[A\n",
      " 85%|████████▍ | 7760/9171 [01:32<00:17, 82.42it/s]\u001b[A\n",
      " 85%|████████▍ | 7769/9171 [01:32<00:17, 82.07it/s]\u001b[A\n",
      " 85%|████████▍ | 7778/9171 [01:32<00:17, 81.60it/s]\u001b[A\n",
      " 85%|████████▍ | 7787/9171 [01:32<00:16, 82.17it/s]\u001b[A\n",
      " 85%|████████▌ | 7796/9171 [01:32<00:16, 81.85it/s]\u001b[A\n",
      " 85%|████████▌ | 7805/9171 [01:32<00:16, 81.86it/s]\u001b[A\n",
      " 85%|████████▌ | 7814/9171 [01:33<00:16, 81.56it/s]\u001b[A\n",
      " 85%|████████▌ | 7823/9171 [01:33<00:16, 81.77it/s]\u001b[A\n",
      " 85%|████████▌ | 7832/9171 [01:33<00:16, 81.77it/s]\u001b[A\n",
      " 85%|████████▌ | 7841/9171 [01:33<00:16, 82.11it/s]\u001b[A\n",
      " 86%|████████▌ | 7850/9171 [01:33<00:16, 82.00it/s]\u001b[A\n",
      " 86%|████████▌ | 7859/9171 [01:33<00:16, 81.56it/s]\u001b[A\n",
      " 86%|████████▌ | 7868/9171 [01:33<00:15, 82.02it/s]\u001b[A\n",
      " 86%|████████▌ | 7877/9171 [01:33<00:15, 82.40it/s]\u001b[A\n",
      " 86%|████████▌ | 7886/9171 [01:33<00:15, 82.68it/s]\u001b[A\n",
      " 86%|████████▌ | 7895/9171 [01:34<00:15, 82.37it/s]\u001b[A\n",
      " 86%|████████▌ | 7904/9171 [01:34<00:15, 81.72it/s]\u001b[A\n",
      " 86%|████████▋ | 7913/9171 [01:34<00:15, 81.41it/s]\u001b[A\n",
      " 86%|████████▋ | 7922/9171 [01:34<00:15, 81.67it/s]\u001b[A\n",
      " 86%|████████▋ | 7931/9171 [01:34<00:15, 81.62it/s]\u001b[A\n",
      " 87%|████████▋ | 7940/9171 [01:34<00:15, 81.04it/s]\u001b[A\n",
      " 87%|████████▋ | 7949/9171 [01:34<00:14, 81.70it/s]\u001b[A\n",
      " 87%|████████▋ | 7958/9171 [01:34<00:14, 82.14it/s]\u001b[A\n",
      " 87%|████████▋ | 7967/9171 [01:34<00:14, 82.49it/s]\u001b[A\n",
      " 87%|████████▋ | 7976/9171 [01:35<00:14, 82.52it/s]\u001b[A\n",
      " 87%|████████▋ | 7985/9171 [01:35<00:14, 82.03it/s]\u001b[A\n",
      " 87%|████████▋ | 7994/9171 [01:35<00:14, 81.70it/s]\u001b[A\n",
      " 87%|████████▋ | 8003/9171 [01:35<00:14, 81.88it/s]\u001b[A\n",
      " 87%|████████▋ | 8012/9171 [01:35<00:14, 81.82it/s]\u001b[A\n",
      " 87%|████████▋ | 8021/9171 [01:35<00:14, 81.72it/s]\u001b[A\n",
      " 88%|████████▊ | 8030/9171 [01:35<00:13, 81.83it/s]\u001b[A\n",
      " 88%|████████▊ | 8039/9171 [01:35<00:13, 81.79it/s]\u001b[A\n",
      " 88%|████████▊ | 8048/9171 [01:35<00:13, 82.21it/s]\u001b[A\n",
      " 88%|████████▊ | 8057/9171 [01:36<00:13, 82.47it/s]\u001b[A\n",
      " 88%|████████▊ | 8066/9171 [01:36<00:13, 81.87it/s]\u001b[A\n",
      " 88%|████████▊ | 8075/9171 [01:36<00:13, 81.62it/s]\u001b[A\n",
      " 88%|████████▊ | 8084/9171 [01:36<00:13, 81.79it/s]\u001b[A\n",
      " 88%|████████▊ | 8093/9171 [01:36<00:13, 81.92it/s]\u001b[A\n",
      " 88%|████████▊ | 8102/9171 [01:36<00:13, 81.95it/s]\u001b[A\n",
      " 88%|████████▊ | 8111/9171 [01:36<00:12, 81.59it/s]\u001b[A\n",
      " 89%|████████▊ | 8120/9171 [01:36<00:12, 81.96it/s]\u001b[A\n",
      " 89%|████████▊ | 8129/9171 [01:36<00:12, 82.34it/s]\u001b[A\n",
      " 89%|████████▊ | 8138/9171 [01:37<00:12, 82.65it/s]\u001b[A\n",
      " 89%|████████▉ | 8147/9171 [01:37<00:12, 82.25it/s]\u001b[A\n",
      " 89%|████████▉ | 8156/9171 [01:37<00:12, 81.90it/s]\u001b[A\n",
      " 89%|████████▉ | 8165/9171 [01:37<00:12, 81.65it/s]\u001b[A\n",
      " 89%|████████▉ | 8174/9171 [01:37<00:12, 81.42it/s]\u001b[A\n",
      " 89%|████████▉ | 8183/9171 [01:37<00:12, 81.84it/s]\u001b[A\n",
      " 89%|████████▉ | 8192/9171 [01:37<00:12, 81.50it/s]\u001b[A\n",
      " 89%|████████▉ | 8201/9171 [01:37<00:11, 81.84it/s]\u001b[A\n",
      " 90%|████████▉ | 8210/9171 [01:37<00:11, 82.22it/s]\u001b[A\n",
      " 90%|████████▉ | 8219/9171 [01:38<00:11, 82.47it/s]\u001b[A\n",
      " 90%|████████▉ | 8228/9171 [01:38<00:11, 82.28it/s]\u001b[A\n",
      " 90%|████████▉ | 8237/9171 [01:38<00:11, 81.88it/s]\u001b[A\n",
      " 90%|████████▉ | 8246/9171 [01:38<00:11, 82.09it/s]\u001b[A\n",
      " 90%|█████████ | 8255/9171 [01:38<00:11, 82.15it/s]\u001b[A\n",
      " 90%|█████████ | 8264/9171 [01:38<00:11, 82.04it/s]\u001b[A\n",
      " 90%|█████████ | 8273/9171 [01:38<00:10, 81.76it/s]\u001b[A\n",
      " 90%|█████████ | 8282/9171 [01:38<00:10, 81.92it/s]\u001b[A\n",
      " 90%|█████████ | 8291/9171 [01:38<00:10, 81.74it/s]\u001b[A\n",
      " 91%|█████████ | 8300/9171 [01:39<00:10, 81.72it/s]\u001b[A\n",
      " 91%|█████████ | 8309/9171 [01:39<00:10, 81.54it/s]\u001b[A\n",
      " 91%|█████████ | 8318/9171 [01:39<00:10, 81.49it/s]\u001b[A\n",
      " 91%|█████████ | 8327/9171 [01:39<00:10, 81.32it/s]\u001b[A\n",
      " 91%|█████████ | 8336/9171 [01:39<00:10, 81.79it/s]\u001b[A\n",
      " 91%|█████████ | 8345/9171 [01:39<00:10, 81.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 8354/9171 [01:39<00:09, 81.89it/s]\u001b[A\n",
      " 91%|█████████ | 8363/9171 [01:39<00:09, 81.81it/s]\u001b[A\n",
      " 91%|█████████▏| 8372/9171 [01:39<00:09, 82.01it/s]\u001b[A\n",
      " 91%|█████████▏| 8381/9171 [01:40<00:09, 82.27it/s]\u001b[A\n",
      " 91%|█████████▏| 8390/9171 [01:40<00:09, 82.29it/s]\u001b[A\n",
      " 92%|█████████▏| 8399/9171 [01:40<00:09, 82.10it/s]\u001b[A\n",
      " 92%|█████████▏| 8408/9171 [01:40<00:09, 81.58it/s]\u001b[A\n",
      " 92%|█████████▏| 8417/9171 [01:40<00:09, 81.17it/s]\u001b[A\n",
      " 92%|█████████▏| 8426/9171 [01:40<00:09, 81.23it/s]\u001b[A\n",
      " 92%|█████████▏| 8435/9171 [01:40<00:09, 81.51it/s]\u001b[A\n",
      " 92%|█████████▏| 8444/9171 [01:40<00:08, 81.60it/s]\u001b[A\n",
      " 92%|█████████▏| 8453/9171 [01:40<00:08, 82.18it/s]\u001b[A\n",
      " 92%|█████████▏| 8462/9171 [01:40<00:08, 82.48it/s]\u001b[A\n",
      " 92%|█████████▏| 8471/9171 [01:41<00:08, 82.35it/s]\u001b[A\n",
      " 92%|█████████▏| 8480/9171 [01:41<00:08, 82.48it/s]\u001b[A\n",
      " 93%|█████████▎| 8489/9171 [01:41<00:08, 82.07it/s]\u001b[A\n",
      " 93%|█████████▎| 8498/9171 [01:41<00:08, 82.22it/s]\u001b[A\n",
      " 93%|█████████▎| 8507/9171 [01:41<00:08, 82.04it/s]\u001b[A\n",
      " 93%|█████████▎| 8516/9171 [01:41<00:07, 82.07it/s]\u001b[A\n",
      " 93%|█████████▎| 8525/9171 [01:41<00:07, 82.24it/s]\u001b[A\n",
      " 93%|█████████▎| 8534/9171 [01:41<00:07, 81.09it/s]\u001b[A\n",
      " 93%|█████████▎| 8543/9171 [01:42<00:08, 77.13it/s]\u001b[A\n",
      " 93%|█████████▎| 8551/9171 [01:42<00:07, 77.56it/s]\u001b[A\n",
      " 93%|█████████▎| 8559/9171 [01:42<00:07, 77.94it/s]\u001b[A\n",
      " 93%|█████████▎| 8567/9171 [01:42<00:07, 77.84it/s]\u001b[A\n",
      " 94%|█████████▎| 8575/9171 [01:42<00:07, 78.37it/s]\u001b[A\n",
      " 94%|█████████▎| 8583/9171 [01:42<00:07, 78.37it/s]\u001b[A\n",
      " 94%|█████████▎| 8591/9171 [01:42<00:07, 77.76it/s]\u001b[A\n",
      " 94%|█████████▍| 8599/9171 [01:42<00:07, 77.66it/s]\u001b[A\n",
      " 94%|█████████▍| 8607/9171 [01:42<00:07, 77.64it/s]\u001b[A\n",
      " 94%|█████████▍| 8615/9171 [01:42<00:07, 77.84it/s]\u001b[A\n",
      " 94%|█████████▍| 8623/9171 [01:43<00:06, 78.41it/s]\u001b[A\n",
      " 94%|█████████▍| 8631/9171 [01:43<00:06, 78.57it/s]\u001b[A\n",
      " 94%|█████████▍| 8639/9171 [01:43<00:06, 78.53it/s]\u001b[A\n",
      " 94%|█████████▍| 8648/9171 [01:43<00:06, 79.14it/s]\u001b[A\n",
      " 94%|█████████▍| 8657/9171 [01:43<00:06, 79.69it/s]\u001b[A\n",
      " 94%|█████████▍| 8666/9171 [01:43<00:06, 80.35it/s]\u001b[A\n",
      " 95%|█████████▍| 8675/9171 [01:43<00:06, 80.93it/s]\u001b[A\n",
      " 95%|█████████▍| 8684/9171 [01:43<00:05, 81.58it/s]\u001b[A\n",
      " 95%|█████████▍| 8693/9171 [01:43<00:05, 81.69it/s]\u001b[A\n",
      " 95%|█████████▍| 8702/9171 [01:43<00:05, 81.99it/s]\u001b[A\n",
      " 95%|█████████▍| 8711/9171 [01:44<00:05, 82.03it/s]\u001b[A\n",
      " 95%|█████████▌| 8720/9171 [01:44<00:05, 82.12it/s]\u001b[A\n",
      " 95%|█████████▌| 8729/9171 [01:44<00:05, 82.09it/s]\u001b[A\n",
      " 95%|█████████▌| 8738/9171 [01:44<00:05, 81.91it/s]\u001b[A\n",
      " 95%|█████████▌| 8747/9171 [01:44<00:05, 81.96it/s]\u001b[A\n",
      " 95%|█████████▌| 8756/9171 [01:44<00:05, 82.10it/s]\u001b[A\n",
      " 96%|█████████▌| 8765/9171 [01:44<00:04, 82.39it/s]\u001b[A\n",
      " 96%|█████████▌| 8774/9171 [01:44<00:04, 82.10it/s]\u001b[A\n",
      " 96%|█████████▌| 8783/9171 [01:44<00:04, 82.34it/s]\u001b[A\n",
      " 96%|█████████▌| 8792/9171 [01:45<00:04, 82.08it/s]\u001b[A\n",
      " 96%|█████████▌| 8801/9171 [01:45<00:04, 82.27it/s]\u001b[A\n",
      " 96%|█████████▌| 8810/9171 [01:45<00:04, 82.29it/s]\u001b[A\n",
      " 96%|█████████▌| 8819/9171 [01:45<00:04, 82.07it/s]\u001b[A\n",
      " 96%|█████████▋| 8828/9171 [01:45<00:04, 81.86it/s]\u001b[A\n",
      " 96%|█████████▋| 8837/9171 [01:45<00:04, 81.89it/s]\u001b[A\n",
      " 96%|█████████▋| 8846/9171 [01:45<00:03, 82.33it/s]\u001b[A\n",
      " 97%|█████████▋| 8855/9171 [01:45<00:04, 77.83it/s]\u001b[A\n",
      " 97%|█████████▋| 8863/9171 [01:46<00:04, 73.73it/s]\u001b[A\n",
      " 97%|█████████▋| 8871/9171 [01:46<00:04, 71.10it/s]\u001b[A\n",
      " 97%|█████████▋| 8879/9171 [01:46<00:04, 69.49it/s]\u001b[A\n",
      " 97%|█████████▋| 8887/9171 [01:46<00:04, 70.18it/s]\u001b[A\n",
      " 97%|█████████▋| 8896/9171 [01:46<00:03, 73.31it/s]\u001b[A\n",
      " 97%|█████████▋| 8905/9171 [01:46<00:03, 75.44it/s]\u001b[A\n",
      " 97%|█████████▋| 8914/9171 [01:46<00:03, 77.27it/s]\u001b[A\n",
      " 97%|█████████▋| 8923/9171 [01:46<00:03, 78.88it/s]\u001b[A\n",
      " 97%|█████████▋| 8932/9171 [01:46<00:02, 80.21it/s]\u001b[A\n",
      " 97%|█████████▋| 8941/9171 [01:47<00:02, 80.75it/s]\u001b[A\n",
      " 98%|█████████▊| 8950/9171 [01:47<00:02, 81.05it/s]\u001b[A\n",
      " 98%|█████████▊| 8959/9171 [01:47<00:02, 81.36it/s]\u001b[A\n",
      " 98%|█████████▊| 8968/9171 [01:47<00:02, 81.69it/s]\u001b[A\n",
      " 98%|█████████▊| 8977/9171 [01:47<00:02, 81.80it/s]\u001b[A\n",
      " 98%|█████████▊| 8986/9171 [01:47<00:02, 81.30it/s]\u001b[A\n",
      " 98%|█████████▊| 8995/9171 [01:47<00:02, 81.16it/s]\u001b[A\n",
      " 98%|█████████▊| 9004/9171 [01:47<00:02, 81.64it/s]\u001b[A\n",
      " 98%|█████████▊| 9013/9171 [01:47<00:01, 81.68it/s]\u001b[A\n",
      " 98%|█████████▊| 9022/9171 [01:48<00:01, 81.49it/s]\u001b[A\n",
      " 98%|█████████▊| 9031/9171 [01:48<00:01, 81.19it/s]\u001b[A\n",
      " 99%|█████████▊| 9040/9171 [01:48<00:01, 81.43it/s]\u001b[A\n",
      " 99%|█████████▊| 9049/9171 [01:48<00:01, 81.68it/s]\u001b[A\n",
      " 99%|█████████▉| 9058/9171 [01:48<00:01, 81.70it/s]\u001b[A\n",
      " 99%|█████████▉| 9067/9171 [01:48<00:01, 81.30it/s]\u001b[A\n",
      " 99%|█████████▉| 9076/9171 [01:48<00:01, 81.22it/s]\u001b[A\n",
      " 99%|█████████▉| 9085/9171 [01:48<00:01, 81.74it/s]\u001b[A\n",
      " 99%|█████████▉| 9094/9171 [01:48<00:00, 82.15it/s]\u001b[A\n",
      " 99%|█████████▉| 9103/9171 [01:48<00:00, 82.20it/s]\u001b[A\n",
      " 99%|█████████▉| 9112/9171 [01:49<00:00, 81.76it/s]\u001b[A\n",
      " 99%|█████████▉| 9121/9171 [01:49<00:00, 81.86it/s]\u001b[A\n",
      "100%|█████████▉| 9130/9171 [01:49<00:00, 81.76it/s]\u001b[A\n",
      "100%|█████████▉| 9139/9171 [01:49<00:00, 81.52it/s]\u001b[A\n",
      "100%|█████████▉| 9148/9171 [01:49<00:00, 80.94it/s]\u001b[A\n",
      "100%|█████████▉| 9157/9171 [01:49<00:00, 81.01it/s]\u001b[A\n",
      "100%|█████████▉| 9166/9171 [01:49<00:00, 81.56it/s]\u001b[A\n",
      "100%|██████████| 9171/9171 [01:49<00:00, 83.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original block range size = 9171\n",
      "New block range size = 8898\n",
      "|completed indices| = 273\n",
      "completed indices = {completed_indices}\n"
     ]
    }
   ],
   "source": [
    "if d:\n",
    "    #   identify indices that have not been completely calculated\n",
    "    print(\"Identifying incompletely calculated indices in block range...\")\n",
    "    print(\"\\t(Partially calculated indices will still be overwritten.)\")\n",
    "    old_block_range = deepcopy(blockRange)\n",
    "    old_block_range_l = len(old_block_range)\n",
    "    blockRange = get_incomplete_indices(rangeOfInterest=blockRange)\n",
    "    new_block_range_l = len(blockRange)\n",
    "    print(f\"Original block range size = {old_block_range_l}\\nNew block range size = {new_block_range_l}\")\n",
    "    completed_indices = np.array([i for i in old_block_range if not i in blockRange])\n",
    "    if completed_indices.shape[0] > 0:\n",
    "        print(f\"|completed indices| = {completed_indices.shape[0]}\")\n",
    "        print(\"completed indices = {completed_indices}\")\n",
    "else:\n",
    "    print(\"All indices in blockRange will be overwritten.\")\n",
    "# else:\n",
    "#     #erase and start over\n",
    "#     tiledb.remove(array_name) # <<<< this would destroy EVERYTHING\n",
    "#     tiledb.DenseArray.create(array_name, schema)\n",
    "#     print(f'Array with name\\n\\t{array_name}\\ncreated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:18:37.107526Z",
     "start_time": "2019-08-11T02:18:36.912317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            31G        8.0G         19G        9.5M        3.4G         22G\r\n",
      "Swap:          2.0G        1.1G        948M\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T01:38:55.980074Z",
     "start_time": "2019-08-08T00:59:53.204524Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin calculation. @ 17:59:53\n",
      "l = 7\n",
      "Sampling... @ 17:59:53\n",
      "\tVM used vs. available: 6.69GB vs. 26.52GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.8s remaining:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.3s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.7s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 17:59:59\n",
      "\tVM used vs. available: 8.19GB vs. 25.02GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:00:01\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:00:01\n",
      "\tVM used vs. available: 11.22GB vs. 21.99GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 102/426 [00:10<00:31, 10.18it/s]\u001b[A\n",
      " 48%|████▊     | 204/426 [00:20<00:21, 10.18it/s]\u001b[A\n",
      " 72%|███████▏  | 306/426 [00:30<00:11, 10.18it/s]\u001b[A\n",
      " 96%|█████████▌| 408/426 [00:40<00:01, 10.17it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:41<00:00, 10.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:00:43\n",
      "\tVM used vs. available: 11.30GB vs. 21.91GB\n",
      "Calculating numerator... @ 18:00:43\n",
      "\tVM used vs. available: 11.30GB vs. 21.91GB\n",
      "Calculating V_prime_w_C... @ 18:00:43\n",
      "Calculating O_w_C... @ 18:00:47\n",
      "Calculating U_w_C... @ 18:00:47\n",
      "Calculating E_w_C... @ 18:00:47\n",
      "\tVM used vs. available: 11.50GB vs. 21.71GB\n",
      "> End calculation. @ 18:00:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/9171 [00:54<138:51:09, 54.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "w_idx = 1 @ 18:00:47\n",
      "\tVM used vs. available: 9.88GB vs. 23.33GB\n",
      "Calculating word slice... @ 18:00:47\n",
      "> Begin calculation. @ 18:00:47\n",
      "l = 6\n",
      "Sampling... @ 18:00:47\n",
      "\tVM used vs. available: 9.88GB vs. 23.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.5s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:00:54\n",
      "\tVM used vs. available: 9.72GB vs. 23.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:00:54\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:00:54\n",
      "\tVM used vs. available: 10.96GB vs. 22.25GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 112/426 [00:10<00:28, 11.18it/s]\u001b[A\n",
      " 53%|█████▎    | 224/426 [00:20<00:18, 11.18it/s]\u001b[A\n",
      " 79%|███████▉  | 336/426 [00:30<00:08, 11.17it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:38<00:00, 11.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:01:32\n",
      "\tVM used vs. available: 10.96GB vs. 22.25GB\n",
      "Calculating numerator... @ 18:01:32\n",
      "\tVM used vs. available: 10.96GB vs. 22.25GB\n",
      "Calculating V_prime_w_C... @ 18:01:32\n",
      "Calculating O_w_C... @ 18:01:36\n",
      "Calculating U_w_C... @ 18:01:36\n",
      "Calculating E_w_C... @ 18:01:36\n",
      "\tVM used vs. available: 11.11GB vs. 22.10GB\n",
      "> End calculation. @ 18:01:36\n",
      "\tWriting to disk... @ 18:01:36\n",
      "\tVM used vs. available: 8.49GB vs. 24.72GB\n",
      "\tWrote to disk. @ 18:01:36\n",
      "\tVM used vs. available: 8.48GB vs. 24.73GB\n",
      "\tConsolidating... @ 18:01:36\n",
      "\tVM used vs. available: 8.48GB vs. 24.73GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/9171 [01:44<135:28:00, 53.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:01:37\n",
      "\tVM used vs. available: 8.54GB vs. 24.67GB\n",
      "\n",
      "w_idx = 2 @ 18:01:37\n",
      "\tVM used vs. available: 8.54GB vs. 24.67GB\n",
      "Calculating word slice... @ 18:01:37\n",
      "> Begin calculation. @ 18:01:37\n",
      "l = 11\n",
      "Sampling... @ 18:01:37\n",
      "\tVM used vs. available: 8.54GB vs. 24.67GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.4s remaining:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.8s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:01:46\n",
      "\tVM used vs. available: 10.88GB vs. 22.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:01:47\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:01:47\n",
      "\tVM used vs. available: 13.16GB vs. 20.05GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 42/426 [00:10<01:33,  4.10it/s]\u001b[A\n",
      " 19%|█▉        | 83/426 [00:20<01:23,  4.09it/s]\u001b[A\n",
      " 29%|██▉       | 124/426 [00:30<01:13,  4.09it/s]\u001b[A\n",
      " 39%|███▊      | 165/426 [00:40<01:04,  4.08it/s]\u001b[A\n",
      " 48%|████▊     | 206/426 [00:50<00:54,  4.06it/s]\u001b[A\n",
      " 58%|█████▊    | 247/426 [01:00<00:44,  4.05it/s]\u001b[A\n",
      " 68%|██████▊   | 288/426 [01:11<00:34,  4.04it/s]\u001b[A\n",
      " 77%|███████▋  | 329/426 [01:21<00:24,  4.03it/s]\u001b[A\n",
      " 87%|████████▋ | 370/426 [01:31<00:13,  4.02it/s]\u001b[A\n",
      " 97%|█████████▋| 412/426 [01:41<00:03,  4.06it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:45<00:00,  4.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:03:32\n",
      "\tVM used vs. available: 13.16GB vs. 20.05GB\n",
      "Calculating numerator... @ 18:03:32\n",
      "\tVM used vs. available: 13.16GB vs. 20.05GB\n",
      "Calculating V_prime_w_C... @ 18:03:32\n",
      "Calculating O_w_C... @ 18:03:37\n",
      "Calculating U_w_C... @ 18:03:37\n",
      "Calculating E_w_C... @ 18:03:38\n",
      "\tVM used vs. available: 13.39GB vs. 19.82GB\n",
      "> End calculation. @ 18:03:38\n",
      "\tWriting to disk... @ 18:03:38\n",
      "\tVM used vs. available: 8.60GB vs. 24.61GB\n",
      "\tWrote to disk. @ 18:03:38\n",
      "\tVM used vs. available: 8.59GB vs. 24.62GB\n",
      "\tConsolidating... @ 18:03:38\n",
      "\tVM used vs. available: 8.59GB vs. 24.62GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/9171 [03:46<187:40:52, 73.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:03:39\n",
      "\tVM used vs. available: 8.59GB vs. 24.62GB\n",
      "\n",
      "w_idx = 3 @ 18:03:39\n",
      "\tVM used vs. available: 8.59GB vs. 24.62GB\n",
      "Calculating word slice... @ 18:03:39\n",
      "> Begin calculation. @ 18:03:39\n",
      "l = 8\n",
      "Sampling... @ 18:03:39\n",
      "\tVM used vs. available: 8.59GB vs. 24.62GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.7s remaining:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.7s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:03:46\n",
      "\tVM used vs. available: 10.22GB vs. 22.98GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:03:47\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:03:47\n",
      "\tVM used vs. available: 11.95GB vs. 21.26GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 61/426 [00:10<01:00,  6.02it/s]\u001b[A\n",
      " 29%|██▊       | 122/426 [00:20<00:50,  6.00it/s]\u001b[A\n",
      " 43%|████▎     | 182/426 [00:30<00:40,  5.97it/s]\u001b[A\n",
      " 57%|█████▋    | 242/426 [00:40<00:30,  5.96it/s]\u001b[A\n",
      " 71%|███████   | 302/426 [00:50<00:20,  5.96it/s]\u001b[A\n",
      " 85%|████████▍ | 362/426 [01:00<00:10,  5.96it/s]\u001b[A\n",
      " 99%|█████████▉| 422/426 [01:10<00:00,  5.96it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:11<00:00,  5.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:04:58\n",
      "\tVM used vs. available: 11.92GB vs. 21.29GB\n",
      "Calculating numerator... @ 18:04:58\n",
      "\tVM used vs. available: 11.92GB vs. 21.29GB\n",
      "Calculating V_prime_w_C... @ 18:04:58\n",
      "Calculating O_w_C... @ 18:05:02\n",
      "Calculating U_w_C... @ 18:05:02\n",
      "Calculating E_w_C... @ 18:05:02\n",
      "\tVM used vs. available: 12.15GB vs. 21.06GB\n",
      "> End calculation. @ 18:05:02\n",
      "\tWriting to disk... @ 18:05:02\n",
      "\tVM used vs. available: 10.31GB vs. 22.90GB\n",
      "\tWrote to disk. @ 18:05:02\n",
      "\tVM used vs. available: 10.31GB vs. 22.90GB\n",
      "\tConsolidating... @ 18:05:02\n",
      "\tVM used vs. available: 10.30GB vs. 22.91GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/9171 [05:10<195:57:03, 76.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:05:03\n",
      "\tVM used vs. available: 8.64GB vs. 24.57GB\n",
      "\n",
      "w_idx = 4 @ 18:05:03\n",
      "\tVM used vs. available: 8.64GB vs. 24.57GB\n",
      "Calculating word slice... @ 18:05:03\n",
      "> Begin calculation. @ 18:05:03\n",
      "l = 5\n",
      "Sampling... @ 18:05:03\n",
      "\tVM used vs. available: 8.64GB vs. 24.57GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.9s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:05:09\n",
      "\tVM used vs. available: 9.71GB vs. 23.50GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:05:09\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:05:09\n",
      "\tVM used vs. available: 10.74GB vs. 22.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 125/426 [00:10<00:24, 12.40it/s]\u001b[A\n",
      " 59%|█████▊    | 250/426 [00:20<00:14, 12.40it/s]\u001b[A\n",
      " 88%|████████▊ | 374/426 [00:30<00:04, 12.40it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:05:44\n",
      "\tVM used vs. available: 10.74GB vs. 22.47GB\n",
      "Calculating numerator... @ 18:05:44\n",
      "\tVM used vs. available: 10.74GB vs. 22.47GB\n",
      "Calculating V_prime_w_C... @ 18:05:44\n",
      "Calculating O_w_C... @ 18:05:46\n",
      "Calculating U_w_C... @ 18:05:46\n",
      "Calculating E_w_C... @ 18:05:46\n",
      "\tVM used vs. available: 10.86GB vs. 22.35GB\n",
      "> End calculation. @ 18:05:46\n",
      "\tWriting to disk... @ 18:05:46\n",
      "\tVM used vs. available: 9.71GB vs. 23.50GB\n",
      "\tWrote to disk. @ 18:05:47\n",
      "\tVM used vs. available: 9.70GB vs. 23.51GB\n",
      "\tConsolidating... @ 18:05:47\n",
      "\tVM used vs. available: 9.70GB vs. 23.51GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/9171 [05:54<170:54:14, 67.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:05:48\n",
      "\tVM used vs. available: 9.70GB vs. 23.51GB\n",
      "\n",
      "w_idx = 5 @ 18:05:48\n",
      "\tVM used vs. available: 9.70GB vs. 23.51GB\n",
      "Calculating word slice... @ 18:05:48\n",
      "> Begin calculation. @ 18:05:48\n",
      "l = 9\n",
      "Sampling... @ 18:05:48\n",
      "\tVM used vs. available: 9.70GB vs. 23.51GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.1s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.7s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:05:55\n",
      "\tVM used vs. available: 10.58GB vs. 22.63GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:05:56\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:05:56\n",
      "\tVM used vs. available: 12.44GB vs. 20.77GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 52/426 [00:10<01:12,  5.17it/s]\u001b[A\n",
      " 24%|██▍       | 104/426 [00:20<01:02,  5.16it/s]\u001b[A\n",
      " 37%|███▋      | 156/426 [00:30<00:52,  5.16it/s]\u001b[A\n",
      " 49%|████▉     | 208/426 [00:40<00:42,  5.15it/s]\u001b[A\n",
      " 61%|██████    | 260/426 [00:50<00:32,  5.15it/s]\u001b[A\n",
      " 73%|███████▎  | 312/426 [01:00<00:22,  5.15it/s]\u001b[A\n",
      " 85%|████████▌ | 364/426 [01:10<00:12,  5.15it/s]\u001b[A\n",
      " 98%|█████████▊| 416/426 [01:20<00:01,  5.14it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:22<00:00,  5.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:07:19\n",
      "\tVM used vs. available: 12.44GB vs. 20.77GB\n",
      "Calculating numerator... @ 18:07:19\n",
      "\tVM used vs. available: 12.44GB vs. 20.77GB\n",
      "Calculating V_prime_w_C... @ 18:07:19\n",
      "Calculating O_w_C... @ 18:07:24\n",
      "Calculating U_w_C... @ 18:07:24\n",
      "Calculating E_w_C... @ 18:07:24\n",
      "\tVM used vs. available: 12.65GB vs. 20.56GB\n",
      "> End calculation. @ 18:07:24\n",
      "\tWriting to disk... @ 18:07:24\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\tWrote to disk. @ 18:07:24\n",
      "\tVM used vs. available: 8.70GB vs. 24.51GB\n",
      "\tConsolidating... @ 18:07:24\n",
      "\tVM used vs. available: 8.70GB vs. 24.51GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/9171 [07:32<193:51:32, 76.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:07:25\n",
      "\tVM used vs. available: 8.70GB vs. 24.51GB\n",
      "\n",
      "w_idx = 6 @ 18:07:25\n",
      "\tVM used vs. available: 8.70GB vs. 24.51GB\n",
      "Calculating word slice... @ 18:07:25\n",
      "> Begin calculation. @ 18:07:25\n",
      "l = 11\n",
      "Sampling... @ 18:07:25\n",
      "\tVM used vs. available: 8.70GB vs. 24.51GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.4s remaining:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.8s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:07:33\n",
      "\tVM used vs. available: 11.00GB vs. 22.21GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:07:34\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:07:34\n",
      "\tVM used vs. available: 13.28GB vs. 19.93GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 41/426 [00:10<01:34,  4.08it/s]\u001b[A\n",
      " 19%|█▉        | 82/426 [00:20<01:24,  4.07it/s]\u001b[A\n",
      " 29%|██▉       | 123/426 [00:30<01:14,  4.07it/s]\u001b[A\n",
      " 38%|███▊      | 164/426 [00:40<01:04,  4.05it/s]\u001b[A\n",
      " 48%|████▊     | 205/426 [00:50<00:54,  4.05it/s]\u001b[A\n",
      " 58%|█████▊    | 246/426 [01:00<00:44,  4.04it/s]\u001b[A\n",
      " 67%|██████▋   | 287/426 [01:11<00:34,  4.03it/s]\u001b[A\n",
      " 77%|███████▋  | 328/426 [01:21<00:24,  4.04it/s]\u001b[A\n",
      " 87%|████████▋ | 369/426 [01:31<00:14,  4.04it/s]\u001b[A\n",
      " 96%|█████████▌| 410/426 [01:41<00:03,  4.02it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:45<00:00,  4.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:09:20\n",
      "\tVM used vs. available: 13.28GB vs. 19.93GB\n",
      "Calculating numerator... @ 18:09:20\n",
      "\tVM used vs. available: 13.28GB vs. 19.93GB\n",
      "Calculating V_prime_w_C... @ 18:09:20\n",
      "Calculating O_w_C... @ 18:09:25\n",
      "Calculating U_w_C... @ 18:09:25\n",
      "Calculating E_w_C... @ 18:09:25\n",
      "\tVM used vs. available: 13.53GB vs. 19.68GB\n",
      "> End calculation. @ 18:09:25\n",
      "\tWriting to disk... @ 18:09:26\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\tWrote to disk. @ 18:09:26\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\tConsolidating... @ 18:09:26\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/9171 [09:34<228:52:18, 89.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:09:27\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\n",
      "w_idx = 7 @ 18:09:27\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "Calculating word slice... @ 18:09:27\n",
      "> Begin calculation. @ 18:09:27\n",
      "l = 5\n",
      "Sampling... @ 18:09:27\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.0s remaining:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:09:32\n",
      "\tVM used vs. available: 9.76GB vs. 23.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:09:33\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:09:33\n",
      "\tVM used vs. available: 10.79GB vs. 22.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 124/426 [00:10<00:24, 12.39it/s]\u001b[A\n",
      " 58%|█████▊    | 248/426 [00:20<00:14, 12.39it/s]\u001b[A\n",
      " 87%|████████▋ | 372/426 [00:30<00:04, 12.39it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:10:07\n",
      "\tVM used vs. available: 10.79GB vs. 22.42GB\n",
      "Calculating numerator... @ 18:10:07\n",
      "\tVM used vs. available: 10.79GB vs. 22.42GB\n",
      "Calculating V_prime_w_C... @ 18:10:07\n",
      "Calculating O_w_C... @ 18:10:10\n",
      "Calculating U_w_C... @ 18:10:10\n",
      "Calculating E_w_C... @ 18:10:10\n",
      "\tVM used vs. available: 10.91GB vs. 22.30GB\n",
      "> End calculation. @ 18:10:10\n",
      "\tWriting to disk... @ 18:10:10\n",
      "\tVM used vs. available: 9.76GB vs. 23.45GB\n",
      "\tWrote to disk. @ 18:10:10\n",
      "\tVM used vs. available: 9.75GB vs. 23.46GB\n",
      "\tConsolidating... @ 18:10:10\n",
      "\tVM used vs. available: 9.75GB vs. 23.46GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/9171 [10:18<194:00:58, 76.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:10:11\n",
      "\tVM used vs. available: 9.75GB vs. 23.46GB\n",
      "\n",
      "w_idx = 8 @ 18:10:11\n",
      "\tVM used vs. available: 9.75GB vs. 23.46GB\n",
      "Calculating word slice... @ 18:10:11\n",
      "> Begin calculation. @ 18:10:11\n",
      "l = 5\n",
      "Sampling... @ 18:10:11\n",
      "\tVM used vs. available: 9.75GB vs. 23.46GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.9s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:10:17\n",
      "\tVM used vs. available: 9.76GB vs. 23.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:10:17\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:10:17\n",
      "\tVM used vs. available: 10.79GB vs. 22.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 125/426 [00:10<00:24, 12.42it/s]\u001b[A\n",
      " 59%|█████▊    | 250/426 [00:20<00:14, 12.41it/s]\u001b[A\n",
      " 88%|████████▊ | 374/426 [00:30<00:04, 12.41it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:10:52\n",
      "\tVM used vs. available: 10.79GB vs. 22.42GB\n",
      "Calculating numerator... @ 18:10:52\n",
      "\tVM used vs. available: 10.79GB vs. 22.42GB\n",
      "Calculating V_prime_w_C... @ 18:10:52\n",
      "Calculating O_w_C... @ 18:10:54\n",
      "Calculating U_w_C... @ 18:10:54\n",
      "Calculating E_w_C... @ 18:10:54\n",
      "\tVM used vs. available: 10.91GB vs. 22.30GB\n",
      "> End calculation. @ 18:10:54\n",
      "\tWriting to disk... @ 18:10:54\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\tWrote to disk. @ 18:10:54\n",
      "\tVM used vs. available: 8.71GB vs. 24.49GB\n",
      "\tConsolidating... @ 18:10:54\n",
      "\tVM used vs. available: 8.71GB vs. 24.49GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/9171 [11:02<169:31:16, 66.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:10:55\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\n",
      "w_idx = 9 @ 18:10:55\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "Calculating word slice... @ 18:10:55\n",
      "> Begin calculation. @ 18:10:55\n",
      "l = 7\n",
      "Sampling... @ 18:10:55\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.5s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.9s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.4s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:11:02\n",
      "\tVM used vs. available: 10.18GB vs. 23.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:11:02\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:11:02\n",
      "\tVM used vs. available: 11.63GB vs. 21.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 101/426 [00:10<00:32, 10.03it/s]\u001b[A\n",
      " 47%|████▋     | 202/426 [00:20<00:22, 10.02it/s]\u001b[A\n",
      " 71%|███████   | 303/426 [00:30<00:12, 10.02it/s]\u001b[A\n",
      " 95%|█████████▍| 404/426 [00:40<00:02, 10.02it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:42<00:00, 10.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:11:45\n",
      "\tVM used vs. available: 11.63GB vs. 21.58GB\n",
      "Calculating numerator... @ 18:11:45\n",
      "\tVM used vs. available: 11.63GB vs. 21.58GB\n",
      "Calculating V_prime_w_C... @ 18:11:45\n",
      "Calculating O_w_C... @ 18:11:49\n",
      "Calculating U_w_C... @ 18:11:49\n",
      "Calculating E_w_C... @ 18:11:49\n",
      "\tVM used vs. available: 11.79GB vs. 21.42GB\n",
      "> End calculation. @ 18:11:49\n",
      "\tWriting to disk... @ 18:11:49\n",
      "\tVM used vs. available: 10.18GB vs. 23.03GB\n",
      "\tWrote to disk. @ 18:11:49\n",
      "\tVM used vs. available: 10.18GB vs. 23.03GB\n",
      "\tConsolidating... @ 18:11:49\n",
      "\tVM used vs. available: 10.18GB vs. 23.03GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/9171 [11:57<160:22:03, 63.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:11:50\n",
      "\tVM used vs. available: 10.17GB vs. 23.03GB\n",
      "\n",
      "w_idx = 10 @ 18:11:50\n",
      "\tVM used vs. available: 10.17GB vs. 23.03GB\n",
      "Calculating word slice... @ 18:11:50\n",
      "> Begin calculation. @ 18:11:50\n",
      "l = 5\n",
      "Sampling... @ 18:11:50\n",
      "\tVM used vs. available: 10.17GB vs. 23.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.1s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.8s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:11:56\n",
      "\tVM used vs. available: 9.77GB vs. 23.44GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:11:56\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:11:56\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 125/426 [00:10<00:24, 12.41it/s]\u001b[A\n",
      " 59%|█████▊    | 250/426 [00:20<00:14, 12.40it/s]\u001b[A\n",
      " 88%|████████▊ | 374/426 [00:30<00:04, 12.39it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:12:30\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n",
      "Calculating numerator... @ 18:12:30\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n",
      "Calculating V_prime_w_C... @ 18:12:30\n",
      "Calculating O_w_C... @ 18:12:33\n",
      "Calculating U_w_C... @ 18:12:33\n",
      "Calculating E_w_C... @ 18:12:33\n",
      "\tVM used vs. available: 10.92GB vs. 22.29GB\n",
      "> End calculation. @ 18:12:33\n",
      "\tWriting to disk... @ 18:12:33\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n",
      "\tWrote to disk. @ 18:12:33\n",
      "\tVM used vs. available: 8.72GB vs. 24.48GB\n",
      "\tConsolidating... @ 18:12:33\n",
      "\tVM used vs. available: 8.72GB vs. 24.48GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 11/9171 [12:41<146:10:50, 57.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:12:34\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\n",
      "w_idx = 11 @ 18:12:34\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "Calculating word slice... @ 18:12:34\n",
      "> Begin calculation. @ 18:12:34\n",
      "l = 9\n",
      "Sampling... @ 18:12:34\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.9s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.0s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:12:42\n",
      "\tVM used vs. available: 10.60GB vs. 22.61GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:12:43\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:12:43\n",
      "\tVM used vs. available: 12.46GB vs. 20.74GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 52/426 [00:10<01:12,  5.18it/s]\u001b[A\n",
      " 24%|██▍       | 104/426 [00:20<01:02,  5.17it/s]\u001b[A\n",
      " 37%|███▋      | 156/426 [00:30<00:52,  5.16it/s]\u001b[A\n",
      " 49%|████▉     | 208/426 [00:40<00:42,  5.15it/s]\u001b[A\n",
      " 61%|██████    | 260/426 [00:50<00:32,  5.16it/s]\u001b[A\n",
      " 73%|███████▎  | 312/426 [01:00<00:22,  5.15it/s]\u001b[A\n",
      " 73%|███████▎  | 312/426 [01:10<00:22,  5.15it/s]\u001b[A\n",
      " 85%|████████▌ | 364/426 [01:10<00:12,  5.13it/s]\u001b[A\n",
      " 98%|█████████▊| 416/426 [01:20<00:01,  5.13it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:22<00:00,  5.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:14:05\n",
      "\tVM used vs. available: 12.46GB vs. 20.75GB\n",
      "Calculating numerator... @ 18:14:05\n",
      "\tVM used vs. available: 12.46GB vs. 20.75GB\n",
      "Calculating V_prime_w_C... @ 18:14:05\n",
      "Calculating O_w_C... @ 18:14:10\n",
      "Calculating U_w_C... @ 18:14:10\n",
      "Calculating E_w_C... @ 18:14:10\n",
      "\tVM used vs. available: 12.63GB vs. 20.58GB\n",
      "> End calculation. @ 18:14:10\n",
      "\tWriting to disk... @ 18:14:10\n",
      "\tVM used vs. available: 10.56GB vs. 22.65GB\n",
      "\tWrote to disk. @ 18:14:10\n",
      "\tVM used vs. available: 10.56GB vs. 22.65GB\n",
      "\tConsolidating... @ 18:14:10\n",
      "\tVM used vs. available: 10.56GB vs. 22.65GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 12/9171 [14:18<176:09:50, 69.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:14:11\n",
      "\tVM used vs. available: 10.55GB vs. 22.66GB\n",
      "\n",
      "w_idx = 12 @ 18:14:11\n",
      "\tVM used vs. available: 10.55GB vs. 22.66GB\n",
      "Calculating word slice... @ 18:14:11\n",
      "> Begin calculation. @ 18:14:11\n",
      "l = 14\n",
      "Sampling... @ 18:14:11\n",
      "\tVM used vs. available: 10.55GB vs. 22.66GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.0s remaining:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.9s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    6.8s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:14:21\n",
      "\tVM used vs. available: 11.63GB vs. 21.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:14:22\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:14:22\n",
      "\tVM used vs. available: 14.53GB vs. 18.68GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 35/426 [00:10<01:54,  3.43it/s]\u001b[A\n",
      " 16%|█▋        | 70/426 [00:20<01:44,  3.39it/s]\u001b[A\n",
      " 16%|█▋        | 70/426 [00:20<01:44,  3.39it/s]\u001b[A\n",
      " 16%|█▋        | 70/426 [00:30<01:44,  3.39it/s]\u001b[A\n",
      " 24%|██▍       | 104/426 [00:30<01:35,  3.38it/s]\u001b[A\n",
      " 32%|███▏      | 138/426 [00:41<01:25,  3.37it/s]\u001b[A\n",
      " 40%|████      | 172/426 [00:51<01:15,  3.36it/s]\u001b[A\n",
      " 48%|████▊     | 206/426 [01:01<01:05,  3.35it/s]\u001b[A\n",
      " 56%|█████▋    | 240/426 [01:11<00:55,  3.34it/s]\u001b[A\n",
      " 64%|██████▍   | 274/426 [01:21<00:45,  3.33it/s]\u001b[A\n",
      " 72%|███████▏  | 308/426 [01:32<00:35,  3.33it/s]\u001b[A\n",
      " 80%|████████  | 342/426 [01:42<00:25,  3.35it/s]\u001b[A\n",
      " 88%|████████▊ | 376/426 [01:52<00:14,  3.34it/s]\u001b[A\n",
      " 96%|█████████▌| 410/426 [02:02<00:04,  3.36it/s]\u001b[A\n",
      "100%|██████████| 426/426 [02:07<00:00,  3.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:16:29\n",
      "\tVM used vs. available: 14.53GB vs. 18.68GB\n",
      "Calculating numerator... @ 18:16:29\n",
      "\tVM used vs. available: 14.53GB vs. 18.68GB\n",
      "Calculating V_prime_w_C... @ 18:16:29\n",
      "Calculating O_w_C... @ 18:16:37\n",
      "Calculating U_w_C... @ 18:16:37\n",
      "Calculating E_w_C... @ 18:16:37\n",
      "\tVM used vs. available: 14.83GB vs. 18.38GB\n",
      "> End calculation. @ 18:16:37\n",
      "\tWriting to disk... @ 18:16:37\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n",
      "\tWrote to disk. @ 18:16:37\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\tConsolidating... @ 18:16:37\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/9171 [16:45<235:32:52, 92.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:16:38\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\n",
      "w_idx = 13 @ 18:16:38\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "Calculating word slice... @ 18:16:38\n",
      "> Begin calculation. @ 18:16:38\n",
      "l = 7\n",
      "Sampling... @ 18:16:38\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.7s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.1s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.6s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:16:45\n",
      "\tVM used vs. available: 10.18GB vs. 23.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:16:45\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:16:45\n",
      "\tVM used vs. available: 11.63GB vs. 21.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 101/426 [00:10<00:32, 10.04it/s]\u001b[A\n",
      " 47%|████▋     | 202/426 [00:20<00:22, 10.03it/s]\u001b[A\n",
      " 71%|███████   | 303/426 [00:30<00:12, 10.03it/s]\u001b[A\n",
      " 95%|█████████▍| 404/426 [00:40<00:02, 10.02it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:42<00:00, 10.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:17:28\n",
      "\tVM used vs. available: 11.62GB vs. 21.59GB\n",
      "Calculating numerator... @ 18:17:28\n",
      "\tVM used vs. available: 11.62GB vs. 21.59GB\n",
      "Calculating V_prime_w_C... @ 18:17:28\n",
      "Calculating O_w_C... @ 18:17:32\n",
      "Calculating U_w_C... @ 18:17:32\n",
      "Calculating E_w_C... @ 18:17:32\n",
      "\tVM used vs. available: 11.79GB vs. 21.42GB\n",
      "> End calculation. @ 18:17:32\n",
      "\tWriting to disk... @ 18:17:32\n",
      "\tVM used vs. available: 10.17GB vs. 23.04GB\n",
      "\tWrote to disk. @ 18:17:32\n",
      "\tVM used vs. available: 10.17GB vs. 23.04GB\n",
      "\tConsolidating... @ 18:17:32\n",
      "\tVM used vs. available: 10.17GB vs. 23.04GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 14/9171 [17:40<206:43:35, 81.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:17:33\n",
      "\tVM used vs. available: 10.17GB vs. 23.04GB\n",
      "\n",
      "w_idx = 14 @ 18:17:33\n",
      "\tVM used vs. available: 10.17GB vs. 23.04GB\n",
      "Calculating word slice... @ 18:17:33\n",
      "> Begin calculation. @ 18:17:33\n",
      "l = 11\n",
      "Sampling... @ 18:17:33\n",
      "\tVM used vs. available: 10.17GB vs. 23.04GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.3s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.0s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.7s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:17:42\n",
      "\tVM used vs. available: 11.02GB vs. 22.19GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:17:43\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:17:43\n",
      "\tVM used vs. available: 13.30GB vs. 19.91GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 41/426 [00:10<01:33,  4.10it/s]\u001b[A\n",
      " 19%|█▉        | 82/426 [00:20<01:24,  4.07it/s]\u001b[A\n",
      " 29%|██▉       | 123/426 [00:30<01:14,  4.05it/s]\u001b[A\n",
      " 38%|███▊      | 164/426 [00:40<01:04,  4.03it/s]\u001b[A\n",
      " 38%|███▊      | 164/426 [00:50<01:04,  4.03it/s]\u001b[A\n",
      " 48%|████▊     | 205/426 [00:50<00:54,  4.04it/s]\u001b[A\n",
      " 58%|█████▊    | 246/426 [01:01<00:44,  4.03it/s]\u001b[A\n",
      " 67%|██████▋   | 287/426 [01:11<00:34,  4.03it/s]\u001b[A\n",
      " 77%|███████▋  | 328/426 [01:21<00:24,  4.02it/s]\u001b[A\n",
      " 87%|████████▋ | 369/426 [01:31<00:14,  4.01it/s]\u001b[A\n",
      " 96%|█████████▌| 410/426 [01:41<00:03,  4.02it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:45<00:00,  4.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:19:28\n",
      "\tVM used vs. available: 13.29GB vs. 19.92GB\n",
      "Calculating numerator... @ 18:19:28\n",
      "\tVM used vs. available: 13.29GB vs. 19.92GB\n",
      "Calculating V_prime_w_C... @ 18:19:28\n",
      "Calculating O_w_C... @ 18:19:34\n",
      "Calculating U_w_C... @ 18:19:34\n",
      "Calculating E_w_C... @ 18:19:34\n",
      "\tVM used vs. available: 13.53GB vs. 19.68GB\n",
      "> End calculation. @ 18:19:34\n",
      "\tWriting to disk... @ 18:19:34\n",
      "\tVM used vs. available: 8.74GB vs. 24.47GB\n",
      "\tWrote to disk. @ 18:19:34\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n",
      "\tConsolidating... @ 18:19:34\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 15/9171 [19:42<237:58:28, 93.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:19:35\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\n",
      "w_idx = 15 @ 18:19:35\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "Calculating word slice... @ 18:19:35\n",
      "> Begin calculation. @ 18:19:35\n",
      "l = 5\n",
      "Sampling... @ 18:19:35\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.1s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:19:41\n",
      "\tVM used vs. available: 9.77GB vs. 23.44GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:19:41\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:19:41\n",
      "\tVM used vs. available: 10.81GB vs. 22.40GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 125/426 [00:10<00:24, 12.42it/s]\u001b[A\n",
      " 59%|█████▊    | 250/426 [00:20<00:14, 12.41it/s]\u001b[A\n",
      " 88%|████████▊ | 374/426 [00:30<00:04, 12.40it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:20:16\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n",
      "Calculating numerator... @ 18:20:16\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n",
      "Calculating V_prime_w_C... @ 18:20:16\n",
      "Calculating O_w_C... @ 18:20:18\n",
      "Calculating U_w_C... @ 18:20:18\n",
      "Calculating E_w_C... @ 18:20:18\n",
      "\tVM used vs. available: 10.92GB vs. 22.29GB\n",
      "> End calculation. @ 18:20:18\n",
      "\tWriting to disk... @ 18:20:18\n",
      "\tVM used vs. available: 9.77GB vs. 23.44GB\n",
      "\tWrote to disk. @ 18:20:19\n",
      "\tVM used vs. available: 9.77GB vs. 23.44GB\n",
      "\tConsolidating... @ 18:20:19\n",
      "\tVM used vs. available: 9.77GB vs. 23.44GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 16/9171 [20:26<200:16:44, 78.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:20:20\n",
      "\tVM used vs. available: 9.76GB vs. 23.45GB\n",
      "\n",
      "w_idx = 16 @ 18:20:20\n",
      "\tVM used vs. available: 9.76GB vs. 23.45GB\n",
      "Calculating word slice... @ 18:20:20\n",
      "> Begin calculation. @ 18:20:20\n",
      "l = 6\n",
      "Sampling... @ 18:20:20\n",
      "\tVM used vs. available: 9.76GB vs. 23.45GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.3s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.7s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:20:26\n",
      "\tVM used vs. available: 9.98GB vs. 23.23GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:20:26\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:20:26\n",
      "\tVM used vs. available: 11.22GB vs. 21.99GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 112/426 [00:10<00:28, 11.19it/s]\u001b[A\n",
      " 53%|█████▎    | 224/426 [00:20<00:18, 11.18it/s]\u001b[A\n",
      " 79%|███████▉  | 336/426 [00:30<00:08, 11.17it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:38<00:00, 11.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:21:04\n",
      "\tVM used vs. available: 11.22GB vs. 21.99GB\n",
      "Calculating numerator... @ 18:21:04\n",
      "\tVM used vs. available: 11.22GB vs. 21.99GB\n",
      "Calculating V_prime_w_C... @ 18:21:04\n",
      "Calculating O_w_C... @ 18:21:08\n",
      "Calculating U_w_C... @ 18:21:08\n",
      "Calculating E_w_C... @ 18:21:08\n",
      "\tVM used vs. available: 11.36GB vs. 21.85GB\n",
      "> End calculation. @ 18:21:08\n",
      "\tWriting to disk... @ 18:21:08\n",
      "\tVM used vs. available: 9.98GB vs. 23.23GB\n",
      "\tWrote to disk. @ 18:21:08\n",
      "\tVM used vs. available: 9.97GB vs. 23.24GB\n",
      "\tConsolidating... @ 18:21:08\n",
      "\tVM used vs. available: 9.97GB vs. 23.24GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 17/9171 [21:16<177:45:42, 69.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:21:09\n",
      "\tVM used vs. available: 9.97GB vs. 23.24GB\n",
      "\n",
      "w_idx = 17 @ 18:21:09\n",
      "\tVM used vs. available: 9.97GB vs. 23.24GB\n",
      "Calculating word slice... @ 18:21:09\n",
      "> Begin calculation. @ 18:21:09\n",
      "l = 3\n",
      "Sampling... @ 18:21:09\n",
      "\tVM used vs. available: 9.97GB vs. 23.24GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.7s remaining:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.2s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:21:14\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:21:14\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:21:14\n",
      "\tVM used vs. available: 9.97GB vs. 23.24GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 167/426 [00:10<00:15, 16.64it/s]\u001b[A\n",
      " 78%|███████▊  | 334/426 [00:20<00:05, 16.64it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:25<00:00, 16.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:21:39\n",
      "\tVM used vs. available: 9.98GB vs. 23.23GB\n",
      "Calculating numerator... @ 18:21:39\n",
      "\tVM used vs. available: 9.98GB vs. 23.23GB\n",
      "Calculating V_prime_w_C... @ 18:21:39\n",
      "Calculating O_w_C... @ 18:21:41\n",
      "Calculating U_w_C... @ 18:21:41\n",
      "Calculating E_w_C... @ 18:21:41\n",
      "\tVM used vs. available: 10.04GB vs. 23.17GB\n",
      "> End calculation. @ 18:21:41\n",
      "\tWriting to disk... @ 18:21:41\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n",
      "\tWrote to disk. @ 18:21:41\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n",
      "\tConsolidating... @ 18:21:41\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 18/9171 [21:49<149:59:47, 59.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:21:42\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n",
      "\n",
      "w_idx = 18 @ 18:21:42\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n",
      "Calculating word slice... @ 18:21:42\n",
      "> Begin calculation. @ 18:21:42\n",
      "l = 5\n",
      "Sampling... @ 18:21:42\n",
      "\tVM used vs. available: 9.35GB vs. 23.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.1s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.8s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:21:48\n",
      "\tVM used vs. available: 9.77GB vs. 23.44GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:21:48\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:21:48\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 125/426 [00:10<00:24, 12.41it/s]\u001b[A\n",
      " 59%|█████▊    | 250/426 [00:20<00:14, 12.41it/s]\u001b[A\n",
      " 88%|████████▊ | 374/426 [00:30<00:04, 12.40it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:22:23\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n",
      "Calculating numerator... @ 18:22:23\n",
      "\tVM used vs. available: 10.80GB vs. 22.41GB\n",
      "Calculating V_prime_w_C... @ 18:22:23\n",
      "Calculating O_w_C... @ 18:22:26\n",
      "Calculating U_w_C... @ 18:22:26\n",
      "Calculating E_w_C... @ 18:22:26\n",
      "\tVM used vs. available: 10.92GB vs. 22.29GB\n",
      "> End calculation. @ 18:22:26\n",
      "\tWriting to disk... @ 18:22:26\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n",
      "\tWrote to disk. @ 18:22:26\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n",
      "\tConsolidating... @ 18:22:26\n",
      "\tVM used vs. available: 8.73GB vs. 24.48GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 19/9171 [22:34<139:00:05, 54.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:22:27\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\n",
      "w_idx = 19 @ 18:22:27\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "Calculating word slice... @ 18:22:27\n",
      "> Begin calculation. @ 18:22:27\n",
      "l = 4\n",
      "Sampling... @ 18:22:27\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.8s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:22:32\n",
      "\tVM used vs. available: 9.56GB vs. 23.65GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:22:32\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:22:32\n",
      "\tVM used vs. available: 10.39GB vs. 22.82GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 147/426 [00:10<00:18, 14.70it/s]\u001b[A\n",
      " 69%|██████▉   | 295/426 [00:20<00:08, 14.70it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:28<00:00, 14.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:23:01\n",
      "\tVM used vs. available: 10.39GB vs. 22.82GB\n",
      "Calculating numerator... @ 18:23:01\n",
      "\tVM used vs. available: 10.39GB vs. 22.82GB\n",
      "Calculating V_prime_w_C... @ 18:23:01\n",
      "Calculating O_w_C... @ 18:23:04\n",
      "Calculating U_w_C... @ 18:23:04\n",
      "Calculating E_w_C... @ 18:23:04\n",
      "\tVM used vs. available: 10.50GB vs. 22.71GB\n",
      "> End calculation. @ 18:23:04\n",
      "\tWriting to disk... @ 18:23:04\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\tWrote to disk. @ 18:23:04\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\tConsolidating... @ 18:23:04\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 20/9171 [23:12<126:15:05, 49.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:23:05\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\n",
      "w_idx = 20 @ 18:23:05\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "Calculating word slice... @ 18:23:05\n",
      "> Begin calculation. @ 18:23:05\n",
      "l = 7\n",
      "Sampling... @ 18:23:05\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.6s remaining:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.5s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:23:11\n",
      "\tVM used vs. available: 10.21GB vs. 23.00GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:23:12\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:23:12\n",
      "\tVM used vs. available: 11.66GB vs. 21.55GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 101/426 [00:10<00:32, 10.04it/s]\u001b[A\n",
      " 47%|████▋     | 202/426 [00:20<00:22, 10.03it/s]\u001b[A\n",
      " 71%|███████   | 303/426 [00:30<00:12, 10.02it/s]\u001b[A\n",
      " 95%|█████████▍| 404/426 [00:40<00:02, 10.02it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:42<00:00, 10.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:23:55\n",
      "\tVM used vs. available: 11.65GB vs. 21.56GB\n",
      "Calculating numerator... @ 18:23:55\n",
      "\tVM used vs. available: 11.65GB vs. 21.56GB\n",
      "Calculating V_prime_w_C... @ 18:23:55\n",
      "Calculating O_w_C... @ 18:23:58\n",
      "Calculating U_w_C... @ 18:23:58\n",
      "Calculating E_w_C... @ 18:23:58\n",
      "\tVM used vs. available: 11.82GB vs. 21.39GB\n",
      "> End calculation. @ 18:23:58\n",
      "\tWriting to disk... @ 18:23:58\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n",
      "\tWrote to disk. @ 18:23:59\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n",
      "\tConsolidating... @ 18:23:59\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 21/9171 [24:06<130:00:50, 51.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:24:00\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n",
      "\n",
      "w_idx = 21 @ 18:24:00\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n",
      "Calculating word slice... @ 18:24:00\n",
      "> Begin calculation. @ 18:24:00\n",
      "l = 12\n",
      "Sampling... @ 18:24:00\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.3s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.9s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:24:09\n",
      "\tVM used vs. available: 11.25GB vs. 21.96GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:24:09\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:24:09\n",
      "\tVM used vs. available: 13.74GB vs. 19.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 39/426 [00:10<01:39,  3.88it/s]\u001b[A\n",
      " 18%|█▊        | 78/426 [00:20<01:30,  3.87it/s]\u001b[A\n",
      " 27%|██▋       | 117/426 [00:30<01:20,  3.85it/s]\u001b[A\n",
      " 37%|███▋      | 156/426 [00:40<01:10,  3.85it/s]\u001b[A\n",
      " 46%|████▌     | 195/426 [00:50<01:00,  3.83it/s]\u001b[A\n",
      " 55%|█████▍    | 234/426 [01:01<00:50,  3.83it/s]\u001b[A\n",
      " 64%|██████▍   | 273/426 [01:11<00:39,  3.83it/s]\u001b[A\n",
      " 73%|███████▎  | 312/426 [01:21<00:29,  3.83it/s]\u001b[A\n",
      " 82%|████████▏ | 351/426 [01:31<00:19,  3.83it/s]\u001b[A\n",
      " 92%|█████████▏| 390/426 [01:41<00:09,  3.83it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:51<00:00,  3.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:26:01\n",
      "\tVM used vs. available: 13.74GB vs. 19.47GB\n",
      "Calculating numerator... @ 18:26:01\n",
      "\tVM used vs. available: 13.74GB vs. 19.47GB\n",
      "Calculating V_prime_w_C... @ 18:26:01\n",
      "Calculating O_w_C... @ 18:26:07\n",
      "Calculating U_w_C... @ 18:26:07\n",
      "Calculating E_w_C... @ 18:26:07\n",
      "\tVM used vs. available: 13.99GB vs. 19.22GB\n",
      "> End calculation. @ 18:26:07\n",
      "\tWriting to disk... @ 18:26:07\n",
      "\tVM used vs. available: 8.76GB vs. 24.45GB\n",
      "\tWrote to disk. @ 18:26:07\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\tConsolidating... @ 18:26:07\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 22/9171 [26:15<189:04:13, 74.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:26:08\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\n",
      "w_idx = 22 @ 18:26:08\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "Calculating word slice... @ 18:26:08\n",
      "> Begin calculation. @ 18:26:08\n",
      "l = 9\n",
      "Sampling... @ 18:26:08\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.0s remaining:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.5s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.1s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:26:16\n",
      "\tVM used vs. available: 10.63GB vs. 22.58GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:26:16\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:26:16\n",
      "\tVM used vs. available: 12.49GB vs. 20.72GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 52/426 [00:10<01:11,  5.20it/s]\u001b[A\n",
      " 24%|██▍       | 104/426 [00:20<01:02,  5.19it/s]\u001b[A\n",
      " 37%|███▋      | 156/426 [00:30<00:52,  5.16it/s]\u001b[A\n",
      " 49%|████▉     | 208/426 [00:40<00:42,  5.15it/s]\u001b[A\n",
      " 61%|██████    | 260/426 [00:50<00:32,  5.15it/s]\u001b[A\n",
      " 73%|███████▎  | 312/426 [01:00<00:22,  5.15it/s]\u001b[A\n",
      " 85%|████████▌ | 364/426 [01:10<00:12,  5.14it/s]\u001b[A\n",
      " 98%|█████████▊| 416/426 [01:20<00:01,  5.14it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:22<00:00,  5.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:27:39\n",
      "\tVM used vs. available: 12.49GB vs. 20.72GB\n",
      "Calculating numerator... @ 18:27:39\n",
      "\tVM used vs. available: 12.49GB vs. 20.72GB\n",
      "Calculating V_prime_w_C... @ 18:27:39\n",
      "Calculating O_w_C... @ 18:27:44\n",
      "Calculating U_w_C... @ 18:27:44\n",
      "Calculating E_w_C... @ 18:27:44\n",
      "\tVM used vs. available: 12.70GB vs. 20.51GB\n",
      "> End calculation. @ 18:27:44\n",
      "\tWriting to disk... @ 18:27:44\n",
      "\tVM used vs. available: 8.76GB vs. 24.45GB\n",
      "\tWrote to disk. @ 18:27:44\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\tConsolidating... @ 18:27:44\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 23/9171 [27:52<206:16:45, 81.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:27:45\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\n",
      "w_idx = 23 @ 18:27:45\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "Calculating word slice... @ 18:27:45\n",
      "> Begin calculation. @ 18:27:45\n",
      "l = 3\n",
      "Sampling... @ 18:27:45\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.8s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.2s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:27:50\n",
      "\tVM used vs. available: 9.38GB vs. 23.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:27:50\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:27:50\n",
      "\tVM used vs. available: 10.00GB vs. 23.21GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 167/426 [00:10<00:15, 16.65it/s]\u001b[A\n",
      " 78%|███████▊  | 334/426 [00:20<00:05, 16.64it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:25<00:00, 16.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:28:16\n",
      "\tVM used vs. available: 10.00GB vs. 23.21GB\n",
      "Calculating numerator... @ 18:28:16\n",
      "\tVM used vs. available: 10.00GB vs. 23.21GB\n",
      "Calculating V_prime_w_C... @ 18:28:16\n",
      "Calculating O_w_C... @ 18:28:17\n",
      "Calculating U_w_C... @ 18:28:17\n",
      "Calculating E_w_C... @ 18:28:17\n",
      "\tVM used vs. available: 10.03GB vs. 23.18GB\n",
      "> End calculation. @ 18:28:17\n",
      "\tWriting to disk... @ 18:28:17\n",
      "\tVM used vs. available: 9.32GB vs. 23.89GB\n",
      "\tWrote to disk. @ 18:28:18\n",
      "\tVM used vs. available: 9.31GB vs. 23.90GB\n",
      "\tConsolidating... @ 18:28:18\n",
      "\tVM used vs. available: 9.31GB vs. 23.90GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 24/9171 [28:25<169:48:34, 66.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:28:19\n",
      "\tVM used vs. available: 9.31GB vs. 23.90GB\n",
      "\n",
      "w_idx = 24 @ 18:28:19\n",
      "\tVM used vs. available: 9.31GB vs. 23.90GB\n",
      "Calculating word slice... @ 18:28:19\n",
      "> Begin calculation. @ 18:28:19\n",
      "l = 4\n",
      "Sampling... @ 18:28:19\n",
      "\tVM used vs. available: 9.31GB vs. 23.90GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.0s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:28:24\n",
      "\tVM used vs. available: 9.52GB vs. 23.69GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:28:24\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:28:24\n",
      "\tVM used vs. available: 10.35GB vs. 22.86GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 148/426 [00:10<00:18, 14.71it/s]\u001b[A\n",
      " 69%|██████▉   | 296/426 [00:20<00:08, 14.70it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:28<00:00, 14.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:28:53\n",
      "\tVM used vs. available: 10.35GB vs. 22.86GB\n",
      "Calculating numerator... @ 18:28:53\n",
      "\tVM used vs. available: 10.35GB vs. 22.86GB\n",
      "Calculating V_prime_w_C... @ 18:28:53\n",
      "Calculating O_w_C... @ 18:28:55\n",
      "Calculating U_w_C... @ 18:28:55\n",
      "Calculating E_w_C... @ 18:28:55\n",
      "\tVM used vs. available: 10.46GB vs. 22.75GB\n",
      "> End calculation. @ 18:28:55\n",
      "\tWriting to disk... @ 18:28:55\n",
      "\tVM used vs. available: 8.72GB vs. 24.49GB\n",
      "\tWrote to disk. @ 18:28:56\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\tConsolidating... @ 18:28:56\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 25/9171 [29:03<147:50:41, 58.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:28:57\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "> Begin calculation. @ 18:28:57\n",
      "l = 10\n",
      "Sampling... @ 18:28:57\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.1s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.7s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    5.4s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:29:05\n",
      "\tVM used vs. available: 10.81GB vs. 22.40GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:29:05\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:29:05\n",
      "\tVM used vs. available: 12.88GB vs. 20.33GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 44/426 [00:10<01:27,  4.37it/s]\u001b[A\n",
      " 21%|██        | 88/426 [00:20<01:17,  4.36it/s]\u001b[A\n",
      " 31%|███       | 132/426 [00:30<01:07,  4.35it/s]\u001b[A\n",
      " 41%|████▏     | 176/426 [00:40<00:57,  4.33it/s]\u001b[A\n",
      " 52%|█████▏    | 220/426 [00:50<00:47,  4.32it/s]\u001b[A\n",
      " 62%|██████▏   | 264/426 [01:00<00:37,  4.33it/s]\u001b[A\n",
      " 72%|███████▏  | 308/426 [01:11<00:27,  4.33it/s]\u001b[A\n",
      " 83%|████████▎ | 352/426 [01:21<00:17,  4.32it/s]\u001b[A\n",
      " 93%|█████████▎| 396/426 [01:31<00:06,  4.34it/s]\u001b[A\n",
      "100%|██████████| 426/426 [01:38<00:00,  4.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:30:43\n",
      "\tVM used vs. available: 12.88GB vs. 20.33GB\n",
      "Calculating numerator... @ 18:30:43\n",
      "\tVM used vs. available: 12.88GB vs. 20.33GB\n",
      "Calculating V_prime_w_C... @ 18:30:43\n",
      "Calculating O_w_C... @ 18:30:49\n",
      "Calculating U_w_C... @ 18:30:49\n",
      "Calculating E_w_C... @ 18:30:49\n",
      "\tVM used vs. available: 13.13GB vs. 20.08GB\n",
      "> End calculation. @ 18:30:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 26/9171 [30:56<189:12:54, 74.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "w_idx = 26 @ 18:30:49\n",
      "\tVM used vs. available: 8.74GB vs. 24.47GB\n",
      "Calculating word slice... @ 18:30:49\n",
      "> Begin calculation. @ 18:30:49\n",
      "l = 4\n",
      "Sampling... @ 18:30:49\n",
      "\tVM used vs. available: 8.74GB vs. 24.47GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.1s remaining:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.6s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:30:54\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:30:55\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:30:55\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 148/426 [00:10<00:18, 14.74it/s]\u001b[A\n",
      " 69%|██████▉   | 296/426 [00:20<00:08, 14.71it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:28<00:00, 14.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:31:24\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n",
      "Calculating numerator... @ 18:31:24\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n",
      "Calculating V_prime_w_C... @ 18:31:24\n",
      "Calculating O_w_C... @ 18:31:26\n",
      "Calculating U_w_C... @ 18:31:26\n",
      "Calculating E_w_C... @ 18:31:26\n",
      "\tVM used vs. available: 10.50GB vs. 22.71GB\n",
      "> End calculation. @ 18:31:26\n",
      "\tWriting to disk... @ 18:31:26\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n",
      "\tWrote to disk. @ 18:31:26\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n",
      "\tConsolidating... @ 18:31:26\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 27/9171 [31:34<161:25:13, 63.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:31:27\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n",
      "\n",
      "w_idx = 27 @ 18:31:27\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n",
      "Calculating word slice... @ 18:31:27\n",
      "> Begin calculation. @ 18:31:27\n",
      "l = 5\n",
      "Sampling... @ 18:31:27\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.2s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.6s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:31:33\n",
      "\tVM used vs. available: 10.62GB vs. 22.59GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:31:33\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:31:33\n",
      "\tVM used vs. available: 11.65GB vs. 21.56GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 124/426 [00:10<00:24, 12.39it/s]\u001b[A\n",
      " 58%|█████▊    | 248/426 [00:20<00:14, 12.39it/s]\u001b[A\n",
      " 87%|████████▋ | 372/426 [00:30<00:04, 12.39it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:32:08\n",
      "\tVM used vs. available: 10.82GB vs. 22.39GB\n",
      "Calculating numerator... @ 18:32:08\n",
      "\tVM used vs. available: 10.82GB vs. 22.39GB\n",
      "Calculating V_prime_w_C... @ 18:32:08\n",
      "Calculating O_w_C... @ 18:32:10\n",
      "Calculating U_w_C... @ 18:32:10\n",
      "Calculating E_w_C... @ 18:32:10\n",
      "\tVM used vs. available: 10.94GB vs. 22.27GB\n",
      "> End calculation. @ 18:32:10\n",
      "\tWriting to disk... @ 18:32:10\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "\tWrote to disk. @ 18:32:11\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "\tConsolidating... @ 18:32:11\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 28/9171 [32:18<146:52:33, 57.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:32:12\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "\n",
      "w_idx = 28 @ 18:32:12\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "Calculating word slice... @ 18:32:12\n",
      "> Begin calculation. @ 18:32:12\n",
      "l = 6\n",
      "Sampling... @ 18:32:12\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.3s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.7s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:32:18\n",
      "\tVM used vs. available: 10.00GB vs. 23.21GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:32:18\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:32:18\n",
      "\tVM used vs. available: 11.24GB vs. 21.97GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 112/426 [00:10<00:28, 11.16it/s]\u001b[A\n",
      " 53%|█████▎    | 224/426 [00:20<00:18, 11.16it/s]\u001b[A\n",
      " 79%|███████▉  | 336/426 [00:30<00:08, 11.15it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:38<00:00, 11.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:32:56\n",
      "\tVM used vs. available: 11.24GB vs. 21.97GB\n",
      "Calculating numerator... @ 18:32:56\n",
      "\tVM used vs. available: 11.24GB vs. 21.97GB\n",
      "Calculating V_prime_w_C... @ 18:32:56\n",
      "Calculating O_w_C... @ 18:33:00\n",
      "Calculating U_w_C... @ 18:33:00\n",
      "Calculating E_w_C... @ 18:33:00\n",
      "\tVM used vs. available: 11.38GB vs. 21.83GB\n",
      "> End calculation. @ 18:33:00\n",
      "\tWriting to disk... @ 18:33:00\n",
      "\tVM used vs. available: 10.00GB vs. 23.21GB\n",
      "\tWrote to disk. @ 18:33:00\n",
      "\tVM used vs. available: 9.99GB vs. 23.22GB\n",
      "\tConsolidating... @ 18:33:00\n",
      "\tVM used vs. available: 9.99GB vs. 23.22GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 29/9171 [33:08<140:21:29, 55.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:33:01\n",
      "\tVM used vs. available: 9.99GB vs. 23.22GB\n",
      "\n",
      "w_idx = 29 @ 18:33:01\n",
      "\tVM used vs. available: 9.99GB vs. 23.22GB\n",
      "Calculating word slice... @ 18:33:01\n",
      "> Begin calculation. @ 18:33:01\n",
      "l = 4\n",
      "Sampling... @ 18:33:01\n",
      "\tVM used vs. available: 9.99GB vs. 23.22GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.8s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.1s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.4s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:33:06\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:33:06\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:33:06\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 147/426 [00:10<00:19, 14.66it/s]\u001b[A\n",
      " 69%|██████▉   | 294/426 [00:20<00:08, 14.67it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:28<00:00, 14.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:33:35\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n",
      "Calculating numerator... @ 18:33:35\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n",
      "Calculating V_prime_w_C... @ 18:33:35\n",
      "Calculating O_w_C... @ 18:33:38\n",
      "Calculating U_w_C... @ 18:33:38\n",
      "Calculating E_w_C... @ 18:33:38\n",
      "\tVM used vs. available: 10.50GB vs. 22.71GB\n",
      "> End calculation. @ 18:33:38\n",
      "\tWriting to disk... @ 18:33:38\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n",
      "\tWrote to disk. @ 18:33:38\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n",
      "\tConsolidating... @ 18:33:38\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 30/9171 [33:46<127:11:22, 50.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:33:39\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n",
      "\n",
      "w_idx = 30 @ 18:33:39\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n",
      "Calculating word slice... @ 18:33:39\n",
      "> Begin calculation. @ 18:33:39\n",
      "l = 5\n",
      "Sampling... @ 18:33:39\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.1s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.8s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:33:45\n",
      "\tVM used vs. available: 9.79GB vs. 23.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:33:45\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:33:45\n",
      "\tVM used vs. available: 10.82GB vs. 22.39GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 125/426 [00:10<00:24, 12.40it/s]\u001b[A\n",
      " 59%|█████▊    | 250/426 [00:20<00:14, 12.40it/s]\u001b[A\n",
      " 88%|████████▊ | 374/426 [00:30<00:04, 12.39it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:34:19\n",
      "\tVM used vs. available: 10.82GB vs. 22.39GB\n",
      "Calculating numerator... @ 18:34:19\n",
      "\tVM used vs. available: 10.82GB vs. 22.39GB\n",
      "Calculating V_prime_w_C... @ 18:34:19\n",
      "Calculating O_w_C... @ 18:34:22\n",
      "Calculating U_w_C... @ 18:34:22\n",
      "Calculating E_w_C... @ 18:34:22\n",
      "\tVM used vs. available: 10.94GB vs. 22.27GB\n",
      "> End calculation. @ 18:34:22\n",
      "\tWriting to disk... @ 18:34:22\n",
      "\tVM used vs. available: 9.79GB vs. 23.42GB\n",
      "\tWrote to disk. @ 18:34:22\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "\tConsolidating... @ 18:34:22\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 31/9171 [34:30<122:49:29, 48.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:34:23\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "\n",
      "w_idx = 31 @ 18:34:23\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n",
      "Calculating word slice... @ 18:34:23\n",
      "> Begin calculation. @ 18:34:23\n",
      "l = 4\n",
      "Sampling... @ 18:34:23\n",
      "\tVM used vs. available: 9.78GB vs. 23.43GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.0s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:34:28\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:34:29\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:34:29\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 148/426 [00:10<00:18, 14.76it/s]\u001b[A\n",
      " 69%|██████▉   | 296/426 [00:20<00:08, 14.75it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:28<00:00, 14.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:34:58\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n",
      "Calculating numerator... @ 18:34:58\n",
      "\tVM used vs. available: 10.41GB vs. 22.80GB\n",
      "Calculating V_prime_w_C... @ 18:34:58\n",
      "Calculating O_w_C... @ 18:35:00\n",
      "Calculating U_w_C... @ 18:35:00\n",
      "Calculating E_w_C... @ 18:35:00\n",
      "\tVM used vs. available: 10.50GB vs. 22.71GB\n",
      "> End calculation. @ 18:35:00\n",
      "\tWriting to disk... @ 18:35:00\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n",
      "\tWrote to disk. @ 18:35:00\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n",
      "\tConsolidating... @ 18:35:00\n",
      "\tVM used vs. available: 9.58GB vs. 23.63GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 32/9171 [35:08<114:46:24, 45.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:35:01\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n",
      "\n",
      "w_idx = 32 @ 18:35:01\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n",
      "Calculating word slice... @ 18:35:01\n",
      "> Begin calculation. @ 18:35:01\n",
      "l = 7\n",
      "Sampling... @ 18:35:01\n",
      "\tVM used vs. available: 9.57GB vs. 23.64GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.6s remaining:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.1s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.5s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:35:08\n",
      "\tVM used vs. available: 10.20GB vs. 23.01GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:35:09\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:35:09\n",
      "\tVM used vs. available: 11.65GB vs. 21.56GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 101/426 [00:10<00:32, 10.04it/s]\u001b[A\n",
      " 47%|████▋     | 202/426 [00:20<00:22, 10.03it/s]\u001b[A\n",
      " 71%|███████   | 303/426 [00:30<00:12, 10.03it/s]\u001b[A\n",
      " 95%|█████████▍| 404/426 [00:40<00:02, 10.02it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:42<00:00, 10.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:35:51\n",
      "\tVM used vs. available: 11.65GB vs. 21.56GB\n",
      "Calculating numerator... @ 18:35:51\n",
      "\tVM used vs. available: 11.65GB vs. 21.56GB\n",
      "Calculating V_prime_w_C... @ 18:35:51\n",
      "Calculating O_w_C... @ 18:35:55\n",
      "Calculating U_w_C... @ 18:35:55\n",
      "Calculating E_w_C... @ 18:35:55\n",
      "\tVM used vs. available: 11.84GB vs. 21.37GB\n",
      "> End calculation. @ 18:35:55\n",
      "\tWriting to disk... @ 18:35:55\n",
      "\tVM used vs. available: 8.78GB vs. 24.43GB\n",
      "\tWrote to disk. @ 18:35:55\n",
      "\tVM used vs. available: 8.78GB vs. 24.43GB\n",
      "\tConsolidating... @ 18:35:55\n",
      "\tVM used vs. available: 8.78GB vs. 24.43GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 33/9171 [36:03<122:17:34, 48.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:35:56\n",
      "\tVM used vs. available: 8.83GB vs. 24.38GB\n",
      "\n",
      "w_idx = 33 @ 18:35:56\n",
      "\tVM used vs. available: 8.83GB vs. 24.38GB\n",
      "Calculating word slice... @ 18:35:56\n",
      "> Begin calculation. @ 18:35:56\n",
      "l = 6\n",
      "Sampling... @ 18:35:56\n",
      "\tVM used vs. available: 8.83GB vs. 24.38GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.1s remaining:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.4s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    4.9s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:36:03\n",
      "\tVM used vs. available: 10.00GB vs. 23.20GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:36:04\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:36:04\n",
      "\tVM used vs. available: 11.25GB vs. 21.96GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▋       | 112/426 [00:10<00:28, 11.15it/s]\u001b[A\n",
      " 26%|██▋       | 112/426 [00:20<00:28, 11.15it/s]\u001b[A\n",
      " 53%|█████▎    | 224/426 [00:20<00:18, 11.15it/s]\u001b[A\n",
      " 79%|███████▉  | 336/426 [00:30<00:08, 11.15it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:38<00:00, 11.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:36:42\n",
      "\tVM used vs. available: 11.25GB vs. 21.96GB\n",
      "Calculating numerator... @ 18:36:42\n",
      "\tVM used vs. available: 11.25GB vs. 21.96GB\n",
      "Calculating V_prime_w_C... @ 18:36:42\n",
      "Calculating O_w_C... @ 18:36:45\n",
      "Calculating U_w_C... @ 18:36:45\n",
      "Calculating E_w_C... @ 18:36:45\n",
      "\tVM used vs. available: 11.39GB vs. 21.82GB\n",
      "> End calculation. @ 18:36:45\n",
      "\tWriting to disk... @ 18:36:45\n",
      "\tVM used vs. available: 8.76GB vs. 24.45GB\n",
      "\tWrote to disk. @ 18:36:45\n",
      "\tVM used vs. available: 8.75GB vs. 24.45GB\n",
      "\tConsolidating... @ 18:36:45\n",
      "\tVM used vs. available: 8.75GB vs. 24.45GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 34/9171 [36:53<123:42:52, 48.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:36:46\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "\n",
      "w_idx = 34 @ 18:36:46\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n",
      "Calculating word slice... @ 18:36:46\n",
      "> Begin calculation. @ 18:36:46\n",
      "l = 5\n",
      "Sampling... @ 18:36:46\n",
      "\tVM used vs. available: 8.75GB vs. 24.46GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.0s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.7s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:36:52\n",
      "\tVM used vs. available: 9.80GB vs. 23.41GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:36:52\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:36:52\n",
      "\tVM used vs. available: 10.83GB vs. 22.37GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 124/426 [00:10<00:24, 12.39it/s]\u001b[A\n",
      " 58%|█████▊    | 248/426 [00:20<00:14, 12.39it/s]\u001b[A\n",
      " 87%|████████▋ | 372/426 [00:30<00:04, 12.39it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:34<00:00, 12.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:37:27\n",
      "\tVM used vs. available: 10.83GB vs. 22.38GB\n",
      "Calculating numerator... @ 18:37:27\n",
      "\tVM used vs. available: 10.83GB vs. 22.38GB\n",
      "Calculating V_prime_w_C... @ 18:37:27\n",
      "Calculating O_w_C... @ 18:37:29\n",
      "Calculating U_w_C... @ 18:37:29\n",
      "Calculating E_w_C... @ 18:37:29\n",
      "\tVM used vs. available: 10.95GB vs. 22.26GB\n",
      "> End calculation. @ 18:37:29\n",
      "\tWriting to disk... @ 18:37:29\n",
      "\tVM used vs. available: 9.80GB vs. 23.41GB\n",
      "\tWrote to disk. @ 18:37:29\n",
      "\tVM used vs. available: 9.80GB vs. 23.41GB\n",
      "\tConsolidating... @ 18:37:29\n",
      "\tVM used vs. available: 9.80GB vs. 23.41GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 35/9171 [37:37<120:16:17, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:37:30\n",
      "\tVM used vs. available: 9.79GB vs. 23.42GB\n",
      "\n",
      "w_idx = 35 @ 18:37:30\n",
      "\tVM used vs. available: 9.79GB vs. 23.42GB\n",
      "Calculating word slice... @ 18:37:30\n",
      "> Begin calculation. @ 18:37:30\n",
      "l = 2\n",
      "Sampling... @ 18:37:30\n",
      "\tVM used vs. available: 9.79GB vs. 23.42GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.7s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:37:35\n",
      "\tVM used vs. available: 9.17GB vs. 24.03GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:37:35\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:37:35\n",
      "\tVM used vs. available: 9.59GB vs. 23.62GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 181/426 [00:10<00:13, 18.09it/s]\u001b[A\n",
      " 85%|████████▍ | 362/426 [00:20<00:03, 18.09it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:23<00:00, 18.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:37:59\n",
      "\tVM used vs. available: 9.59GB vs. 23.62GB\n",
      "Calculating numerator... @ 18:37:59\n",
      "\tVM used vs. available: 9.59GB vs. 23.62GB\n",
      "Calculating V_prime_w_C... @ 18:37:59\n",
      "Calculating O_w_C... @ 18:38:00\n",
      "Calculating U_w_C... @ 18:38:00\n",
      "Calculating E_w_C... @ 18:38:00\n",
      "\tVM used vs. available: 9.61GB vs. 23.60GB\n",
      "> End calculation. @ 18:38:00\n",
      "\tWriting to disk... @ 18:38:00\n",
      "\tVM used vs. available: 9.19GB vs. 24.02GB\n",
      "\tWrote to disk. @ 18:38:00\n",
      "\tVM used vs. available: 9.19GB vs. 24.02GB\n",
      "\tConsolidating... @ 18:38:00\n",
      "\tVM used vs. available: 9.19GB vs. 24.02GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 36/9171 [38:08<107:20:57, 42.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:38:01\n",
      "\tVM used vs. available: 9.19GB vs. 24.02GB\n",
      "\n",
      "w_idx = 36 @ 18:38:01\n",
      "\tVM used vs. available: 9.19GB vs. 24.02GB\n",
      "Calculating word slice... @ 18:38:01\n",
      "> Begin calculation. @ 18:38:01\n",
      "l = 3\n",
      "Sampling... @ 18:38:01\n",
      "\tVM used vs. available: 9.19GB vs. 24.02GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.8s remaining:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.1s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:38:05\n",
      "\tVM used vs. available: 9.40GB vs. 23.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:38:06\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:38:06\n",
      "\tVM used vs. available: 10.02GB vs. 23.18GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 167/426 [00:10<00:15, 16.66it/s]\u001b[A\n",
      " 78%|███████▊  | 334/426 [00:20<00:05, 16.66it/s]\u001b[A\n",
      "100%|██████████| 426/426 [00:25<00:00, 16.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batches processed. @ 18:38:31\n",
      "\tVM used vs. available: 10.02GB vs. 23.19GB\n",
      "Calculating numerator... @ 18:38:31\n",
      "\tVM used vs. available: 10.02GB vs. 23.19GB\n",
      "Calculating V_prime_w_C... @ 18:38:31\n",
      "Calculating O_w_C... @ 18:38:33\n",
      "Calculating U_w_C... @ 18:38:33\n",
      "Calculating E_w_C... @ 18:38:33\n",
      "\tVM used vs. available: 10.05GB vs. 23.16GB\n",
      "> End calculation. @ 18:38:33\n",
      "\tWriting to disk... @ 18:38:33\n",
      "\tVM used vs. available: 9.34GB vs. 23.87GB\n",
      "\tWrote to disk. @ 18:38:33\n",
      "\tVM used vs. available: 9.34GB vs. 23.87GB\n",
      "\tConsolidating... @ 18:38:33\n",
      "\tVM used vs. available: 9.34GB vs. 23.87GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LD_Fisher_vocab_in_swbd2003_contexts/LTR_newdic_destressed_aligned_CM_filtered_LM_filtered_in_swbd2003_contexts.pW_WC_e'"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 37/9171 [38:41<100:34:56, 39.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tConsolidated. @ 18:38:34\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "\n",
      "w_idx = 37 @ 18:38:34\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n",
      "Calculating word slice... @ 18:38:34\n",
      "> Begin calculation. @ 18:38:34\n",
      "l = 4\n",
      "Sampling... @ 18:38:34\n",
      "\tVM used vs. available: 8.71GB vs. 24.50GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    3.0s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    3.6s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting samples by context... @ 18:38:40\n",
      "\tVM used vs. available: 9.55GB vs. 23.66GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/426 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting contexts into batches ... @ 18:38:40\n",
      "Num batches = 426\n",
      "Processing batches... @ 18:38:40\n",
      "\tVM used vs. available: 10.38GB vs. 22.83GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▍      | 147/426 [00:10<00:18, 14.70it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-371-aed4bdfbf4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         word_slice = pXhat0fX0i_ptc(w_idx, wordformTox0kCM(w_idx=w_idx), \n\u001b[1;32m     20\u001b[0m                                     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_contexts_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                     parallel=l, use_gpu=g).numpy()\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-255-3b6da08555d7>\u001b[0m in \u001b[0;36mpXhat0fX0i_ptc\u001b[0;34m(xhat0f_idx, x0k_CM, m, target_contexts_per_batch, parallel, use_gpu)\u001b[0m\n\u001b[1;32m    132\u001b[0m                                                                               Y_prime_C_split_batched_indices),\n\u001b[1;32m    133\u001b[0m                                                                           \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                                                                           mininterval=mininterval)]) \n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;31m#         Z_prime_C = torch.cat([denominator_batch_process_g(Y_prime_C_split_batched_batch.type(my_tt).cuda(), Q_l_g, indices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m#                                                             V_prime_contract_expr_by_batch_size[len(indices)],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-255-3b6da08555d7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         Z_prime_C = torch.cat([denominator_batch_process_g(Y_prime_C_split_batched_batch.type(my_tt).cuda(), Q_l_g, indices)\n\u001b[0;32m--> 131\u001b[0;31m                        for Y_prime_C_split_batched_batch, indices in tqdm(zip(Y_prime_C_split_batched,\n\u001b[0m\u001b[1;32m    132\u001b[0m                                                                               Y_prime_C_split_batched_indices),\n\u001b[1;32m    133\u001b[0m                                                                           \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-ed137a4d6981>\u001b[0m in \u001b[0;36mdenominator_batch_process_g\u001b[0;34m(Y_prime_ALL_split_batched_batch, Q_l, batch_context_indices)\u001b[0m\n\u001b[1;32m     21\u001b[0m     V_prime_ALL_batch = torch.einsum('cmli,kil->cmkl',\n\u001b[1;32m     22\u001b[0m                                      \u001b[0mY_prime_ALL_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                      Q_l)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mY_prime_ALL_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/anvil/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# the old interface of passing the operands as one list argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0moperands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def logCondition(w_idx):\n",
    "    if len(blockRange) < 50:\n",
    "        return True\n",
    "    elif len(blockRange) < 100:\n",
    "        return w_idx % 10 == 0\n",
    "#     elif len(blockRange) < 250:\n",
    "    else:\n",
    "        return w_idx % 25\n",
    "\n",
    "with tiledb.DenseArray(array_name, mode='w') as A:\n",
    "    for w_idx in tqdm(blockRange, total=len(blockRange)):\n",
    "#         word_slice = p_wstar_wstar_pxtn_by_c(c_idx, m=50, asType='ndarray', parallel=True)\n",
    "        \n",
    "        if logCondition(w_idx):\n",
    "            print('')\n",
    "            stampedMemNote(f'w_idx = {w_idx}')\n",
    "            stampedNote('Calculating word slice...')\n",
    "\n",
    "        word_slice = pXhat0fX0i_ptc(w_idx, wordformTox0kCM(w_idx=w_idx), \n",
    "                                    m = n, target_contexts_per_batch=b, \n",
    "                                    parallel=l, use_gpu=g).numpy()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if logCondition(w_idx):\n",
    "            stampedMemNote('\\tWriting to disk...')\n",
    "        slice_writer(w_idx, word_slice, A)\n",
    "        if logCondition(w_idx):\n",
    "            stampedMemNote('\\tWrote to disk.')\n",
    "        \n",
    "        if logCondition(w_idx) and consolidation_enabled:\n",
    "            stampedMemNote('\\tConsolidating...')\n",
    "            tiledb.consolidate(uri=array_name, config = config)\n",
    "            stampedMemNote('\\tConsolidated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:22:15.876663Z",
     "start_time": "2019-08-11T02:22:15.841686Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 10; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-466-865638289d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                      \u001b[0mstep_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Step 5b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                      \u001b[0mnb_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Calculate segmental posterior given segmental wordform + context'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                      other_md = {'blockRange'})\n\u001b[0m",
      "\u001b[0;32m~/wr/boilerplate.py\u001b[0m in \u001b[0;36mexportMatrixMetadata\u001b[0;34m(md_fp, matrix_fp, matrix, dim_md, step_name, nb_name, other_md)\u001b[0m\n\u001b[1;32m    404\u001b[0m           'Produced in notebook':nb_name}\n\u001b[1;32m    405\u001b[0m     \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0mexportDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Wrote metadata for \\n\\t{matrix_fp}\\n to \\n\\t{md_fp}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 10; 2 is required"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'x':x,\n",
    "    'd':d,\n",
    "    'n':n,\n",
    "    'k':k,\n",
    "    'b':b,\n",
    "    'l':l,\n",
    "    'g':g,\n",
    "    'r':r,\n",
    "    'e':e,\n",
    "    'wStart':wStart,\n",
    "    'wEnd':wEnd\n",
    "}\n",
    "\n",
    "dim_md = {'W':{'from fp':f\"from W dimension of {p}\",\n",
    "               'changes':'sorted full wordforms',\n",
    "               'size':len(Ws_t)},\n",
    "          'C':{'from fp':s,\n",
    "               'changes':'sorted contexts',\n",
    "               'size':len(Cs_t)}}\n",
    "exportMatrixMetadata(md_fp=array_name + '_metadata.json', \n",
    "                     matrix_fp=array_name, \n",
    "                     matrix=None, \n",
    "                     dim_md=dim_md, \n",
    "                     step_name='Step 5b', \n",
    "                     nb_name='Calculate segmental posterior given segmental wordform + context', \n",
    "                     other_md = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.964514Z",
     "start_time": "2019-08-08T05:35:29.568Z"
    }
   },
   "outputs": [],
   "source": [
    "myShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.965205Z",
     "start_time": "2019-08-08T05:35:29.581Z"
    }
   },
   "outputs": [],
   "source": [
    "first_word_slice = tensor_reader(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.965881Z",
     "start_time": "2019-08-08T05:35:29.593Z"
    }
   },
   "outputs": [],
   "source": [
    "blockRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.966574Z",
     "start_time": "2019-08-08T05:35:29.605Z"
    }
   },
   "outputs": [],
   "source": [
    "first_word_slice.shape\n",
    "non_inf_indices = np.where(first_word_slice < np.inf)[0]\n",
    "non_inf_indices\n",
    "len(non_inf_indices)\n",
    "non_inf_probs = first_word_slice[ non_inf_indices ]#.sum(); non_inf_counts\n",
    "non_inf_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.967308Z",
     "start_time": "2019-08-08T05:35:29.617Z"
    }
   },
   "outputs": [],
   "source": [
    "idealize_slice = pXhat0fX0i_ptc(0, CMsByLengthByWordformIndex_torch[len(ds2t(Ws_t[0]))][0],\n",
    "                                m=n, target_contexts_per_batch=b, parallel=l, use_gpu=g, exact_wf=True)\n",
    "idealize_slice.dtype\n",
    "type(idealize_slice)\n",
    "np.array_equal(first_word_slice, idealize_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.968054Z",
     "start_time": "2019-08-08T05:35:29.631Z"
    }
   },
   "outputs": [],
   "source": [
    "Cs_t[0]\n",
    "pXhat0fX0f_pxt(0, \n",
    "               CMsByLengthByWordformIndex_torch[len(ds2t(Ws_t[0]))][0], \n",
    "               0, m=n)\n",
    "idealize_slice.shape\n",
    "idealize_slice[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.968750Z",
     "start_time": "2019-08-08T05:35:29.644Z"
    }
   },
   "outputs": [],
   "source": [
    "idealize_CM = CMsByLengthByWordformIndex_torch[len(ds2t(Ws_t[0]))][0]\n",
    "idealize_slice_slow = par(delayed(pXhat0fX0f_pxt)(0,\n",
    "                                                  idealize_CM,\n",
    "                                                  c_idx,\n",
    "                                                  m = n)\n",
    "                          for c_idx in torch.arange(len(Cs_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.969439Z",
     "start_time": "2019-08-08T05:35:29.657Z"
    }
   },
   "outputs": [],
   "source": [
    "Ws_t[0]\n",
    "for c_idx in non_inf_indices:\n",
    "    Cs_t[c_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.970079Z",
     "start_time": "2019-08-08T05:35:29.669Z"
    }
   },
   "outputs": [],
   "source": [
    "idealize_slice2 = pXhat0fX0i_ptc(0, CMsByLengthByWordformIndex_torch[len(ds2t(Ws_t[0]))][0],\n",
    "                                m=n, target_contexts_per_batch=b, parallel=l, use_gpu=g)\n",
    "idealize_slice2.dtype\n",
    "type(idealize_slice2)\n",
    "np.array_equal(first_word_slice, idealize_slice2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T05:37:42.971494Z",
     "start_time": "2019-08-08T05:35:29.693Z"
    }
   },
   "outputs": [],
   "source": [
    "if g:\n",
    "    torch.cuda.max_memory_allocated(gpu) / 1e6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "313px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
